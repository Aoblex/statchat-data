[
    {
        "page_content": "概率论与数理统计研究的对象是随机对象.  \n在一定的条件下, 并不总是出现相同结果的现象称为随机现象, 如抛一枚硬币与郑一颗骰子.随机现象有两个特点:  \n1. 结果不止一个.\n2. 哪一个结果出现, 人们事先并不知道.  \n只有一个结果的现象称为确定性现象. 例如, 每天早晨太阳从东方升起; 水在标准大气压 (压力约为 $101 \\mathrm{kPa}$ ) 下加热到 $100^{\\circ} \\mathrm{C}$ 就沸腾; 一个口袋中有十只完全相同的白球, 从中任取一支必然为白球。  \n例 1.1.1: 随机现象的例子  \n1. 抛一枚硬币,有可能正面朝上,也有可能反面朝上;\n2. 掷一颗骰子, 出现的点数;\n3. 一天内进人某超市的顾客数;\n4. 某种型号电视机的寿命;\n5. 测量某物理量 (长度、直径等) 的误差.  \n随机现象到处可见.  \n在相同条件下可以重复的随机现象又称为随机试验. 也有很多随机现象是不能重复的, 例如某场足球赛的输赢是不能重复的, 某些经济现象 (如失业、经济增长速度等) 也不能重复. 概率论与数理统计主要研究能大量重复的随机现象, 但也十分注意研究不能重复的随机现象.",
        "metadata": {
            "Header 2": "1.1 随机事件及其运算",
            "Header 3": "1.1.1 随机现象"
        },
        "type": "Document"
    },
    {
        "page_content": "随机现象的一切可能基本结果组成的集合称为样本空间, 记为 $\\Omega=\\{\\omega\\}$, 其中 $\\omega$ 表示基本结果, 又称为样本点. 样本点是今后抽样的最基本单元. 认识随机现象首先要列出它的样本空间.  \n例 1.1.2: 下面给出例 1.1.1 中随机现象的样本空间.  \n1. 抛一枚硬币的样本空间为: $\\Omega_{1}=\\left\\{\\omega_{1}, \\omega_{2}\\right\\}$, 其中 $\\omega_{1}$ 表示正面朝上, $\\omega_{2}$ 表示反面朝上.\n2. 郑一颗骰子的样本空间为: $\\Omega_{2}=\\left\\{\\omega_{1}, \\omega_{2}, \\cdots, \\omega_{6}\\right\\}$, 其中 $\\omega_{i}$ 表示出现 $i$ 点, $i=1,2, \\cdots, 6$. 也更直接明了地记此样本空间为: $\\Omega_{2}=\\{1,2, \\cdots, 6\\}$.\n3. 一天内进人某商场地顾客数地样本空间为:  \n$$\n\\Omega_{3}=\\left\\{0,1,2, \\cdots, 500, \\cdots, 10^{4}, \\cdots\\right\\}\n$$  \n其中 “ 0 ”表示 “一天内无人光顾此商场”, 而 “ 10 ” 表示 “一天内有一万人光顾此商场”. 虽然此两种情况很少发生, 但我们无法说此两种情况不可能发生, 甚至于我们不能确切地说出一天内进人该商场地最多人数, 所以此样本空间用非负整数集表示, 既不脱离实际情况, 又是合理抽象, 便于数学上地处理.  \n4. 电视机寿命的样本空间为: $\\Omega_{4}=\\{t, t \\geqslant 0\\}$.\n5. 测量误差的样本空间为: $\\Omega_{5}=\\{x,-\\infty<x<+\\infty\\}$.  \n需要注意的是:  \n1. 样本空间中的元素可以是数也可以不是数.\n2. 样本空间至少有两个样本点,含两个样本点的样本空间是最简单的样本空间.",
        "metadata": {
            "Header 2": "1.1 随机事件及其运算",
            "Header 3": "1.1.2 样本空间"
        },
        "type": "Document"
    },
    {
        "page_content": "3. 一天内进人某商场地顾客数地样本空间为:  \n$$\n\\Omega_{3}=\\left\\{0,1,2, \\cdots, 500, \\cdots, 10^{4}, \\cdots\\right\\}\n$$  \n其中 “ 0 ”表示 “一天内无人光顾此商场”, 而 “ 10 ” 表示 “一天内有一万人光顾此商场”. 虽然此两种情况很少发生, 但我们无法说此两种情况不可能发生, 甚至于我们不能确切地说出一天内进人该商场地最多人数, 所以此样本空间用非负整数集表示, 既不脱离实际情况, 又是合理抽象, 便于数学上地处理.  \n4. 电视机寿命的样本空间为: $\\Omega_{4}=\\{t, t \\geqslant 0\\}$.\n5. 测量误差的样本空间为: $\\Omega_{5}=\\{x,-\\infty<x<+\\infty\\}$.  \n需要注意的是:  \n1. 样本空间中的元素可以是数也可以不是数.\n2. 样本空间至少有两个样本点,含两个样本点的样本空间是最简单的样本空间.\n3. 从样本空间含有样本点的个数来区分, 样本空间可分为有限与无限两类, 譬如以上样本空间 $\\Omega_{1}$ 和 $\\Omega_{2}$ 中样本点的个数为有限个, 而 $\\Omega_{3} 、 \\Omega_{4}$ 及 $\\Omega_{5}$ 中样本点的个数为无限个. 但 $\\Omega_{3}$ 中样本点的个数为可列个, 而 $\\Omega_{4}$ 和 $\\Omega_{5}$ 中的元素个数为不可列无限个. 在以后的数学处理上我们往往将样本点的个数为有限个或可列个的情况归为一类, 称为离散样本空间. 而将样本点的个数为不可列无限个的情况归为另一类, 称为连续样本空间. 由于这两类样本空间有着本质上的差异, 故分别称呼之.",
        "metadata": {
            "Header 2": "1.1 随机事件及其运算",
            "Header 3": "1.1.2 样本空间"
        },
        "type": "Document"
    },
    {
        "page_content": "随机现象的某些样本点组成的集合称为随机事件, 简称事件, 常用大写字母 $A, B, C, \\cdots$ 表示.如在掷一颗骰子中, $A=$ “出现奇数点”是一个事件, 即 $A=\\{1,3,5\\}$.  \n在以上事件的定义中, 要注意以下几点.  \n1. 任一事件 $A$ 是相应样本空间的一个子集. 在概率论中常用一个长方形表示样本空间 $\\Omega$, 用其中一个圆或其他几何图形表示事件 $A$, 见图 1.1.1, 这类图形称为维恩(Venn)图.\n2. 当子集 $A$ 中某个样本点出现了, 就说事件 $A$ 发生了, 或者说事件 $A$ 发生当且仅当 $A$ 中某个样本点出现了.\n3. 事件可以用集合表示, 也可用明白无误的语言描述.\n4. 由样本空间 $\\Omega$ 中的单个元素组成的子集称为基本事件, 而样本空间 $\\Omega$ 的最大子集（即 $\\Omega$ 本身) 称为必然事件, 样本空间 $\\Omega$ 的最小子集 (即空集 $\\varnothing$ ) 称为不可能事件.  \n!  \n图 1.1.1: 维恩图  \n例 1.1.3: 掷一颗股子的样本空间为: $\\Omega=\\{1,2, \\cdots, 6\\}$.  \n事件 $A=$ “出现 1 点”, 它由 $\\Omega$ 的单个样本点“ 1 ”组成.  \n事件 $B=$ “出现偶数点”, 它由 $\\Omega$ 的三个样本点 “ $2,4,6$ ”组成.  \n事件 $C=$ “出现的点数小于 7 ”, 它由的全部样本点 “ $1,2,3,4,5,6$ ”组成, 即必然事件 $\\Omega$.  \n事件 $D=$ “出现的点数大于 6 ”, $\\Omega$ 中任一样本点都不在 $D$ 中, 所以 $D$ 是空集, 即不可能事件  \n$\\varnothing$.",
        "metadata": {
            "Header 2": "1.1 随机事件及其运算",
            "Header 3": "1.1.3 随机事件"
        },
        "type": "Document"
    },
    {
        "page_content": "用来表示随机现象结果的变量称为随机变量, 常用大写字母 $X, Y, Z$ 表示. 很多事件都可用随机变量表示, 表示时应写明随机变量的含义.  \n例 1.1.4: 郑一颗骰子, 出现的点数是一个随机变量, 记为 $X$. 则事件 “出现 3 点”可用 “ $X=3$ ” 表示,事件“出现的点数不小于 3 ”可用 “ $X \\geqslant 3$ ”表示. 又如“ $X<3$ ” 表示事件“出现点数小于 3 ”.\n掷两颗骰子的样本空间为  \n$$\n\\Omega=\\left\\{\\begin{array}{cccc}\n(1,1) & (1,2) & \\ldots & (1,6) \\\\\n(2,1) & (2,2) & \\ldots & (2,6) \\\\\n\\ldots & \\ldots & \\ldots & \\ldots \\\\\n(6,1) & (6,2) & \\ldots & (6,6)\n\\end{array}\\right\\}\n$$  \n$\\Omega$ 共有 36 个样本点, 若记 $X$ 与 $Y$ 分别为第一与第二颗骰子出现的点数, 则 $X$ 与 $Y$ 均可取值: 1 , $2,3,4,5,6$. 而事件 “点数之和等于 5 ”可表示成  \n$$\n“ X+Y=5 \"=\\{(1,4),(2,3),(3,2),(4,1)\\} .\n$$  \n另外事件 “ $\\max (X, Y)=6$ ” 表示事件 “最大点数为 6 ”, 它含有  \n$$\n(1,6),(6,1),(2,6),(6,2),(3,6),(6,3),(4,6),(6,4),(5,6),(6,5),(6,6)\n$$  \n共 11 个样本点.  \n例 1.1.5: 检查 10 件产品, 其中不合格品数 $X$ 是一个随机变量, 它可以取值 $0,1, \\cdots, 10$. 则事件 “不合格品数不多于 1 件”可用 “ $X \\leqslant 1$ ”来表示. 而 “ $X>2$ ”表示事件“不合格品数超过 2 件”.  \n例 1.1.6: 电视机的寿命 $T$ 是一个随机变量, 则事件 “寿命超过 $40000 \\mathrm{~h}$ ”可用 “ $T>40000$ ”表示, 而 “ $T \\geqslant 10000 ”$ 表示事件”寿命不超过 $10000 \\mathrm{~h} ”$.",
        "metadata": {
            "Header 2": "1.1 随机事件及其运算",
            "Header 3": "1.1.4 随机变量"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n“ X+Y=5 \"=\\{(1,4),(2,3),(3,2),(4,1)\\} .\n$$  \n另外事件 “ $\\max (X, Y)=6$ ” 表示事件 “最大点数为 6 ”, 它含有  \n$$\n(1,6),(6,1),(2,6),(6,2),(3,6),(6,3),(4,6),(6,4),(5,6),(6,5),(6,6)\n$$  \n共 11 个样本点.  \n例 1.1.5: 检查 10 件产品, 其中不合格品数 $X$ 是一个随机变量, 它可以取值 $0,1, \\cdots, 10$. 则事件 “不合格品数不多于 1 件”可用 “ $X \\leqslant 1$ ”来表示. 而 “ $X>2$ ”表示事件“不合格品数超过 2 件”.  \n例 1.1.6: 电视机的寿命 $T$ 是一个随机变量, 则事件 “寿命超过 $40000 \\mathrm{~h}$ ”可用 “ $T>40000$ ”表示, 而 “ $T \\geqslant 10000 ”$ 表示事件”寿命不超过 $10000 \\mathrm{~h} ”$.  \n在不少场合, 用随机变量表示事件较为简洁明了. 这样一来, 事件有三种表示法:  \n1. 用集合表示.\n2. 用语言表示, 但语言要明白无误.\n3. 用随机变量表示.  \n在实际问题中, 哪一种表示法方便就用哪一种.",
        "metadata": {
            "Header 2": "1.1 随机事件及其运算",
            "Header 3": "1.1.4 随机变量"
        },
        "type": "Document"
    },
    {
        "page_content": "下而的讨论总是假设在同一个样本空间 $\\Omega$ (即同一个随机现象) 中进行. 事件间的关系与集合间关系一样主要有以下几种:",
        "metadata": {
            "Header 2": "1.1 随机事件及其运算",
            "Header 3": "1.1.5 事件间的关系"
        },
        "type": "Document"
    },
    {
        "page_content": "如果属于 $A$ 的样本点必属于 $B$, 则称 $A$ 被包含在 $B$ 中 (见图 1.1.2), 或称 $B$ 包含 $A$, 记为 $A \\subset B$, 或 $B \\supset A$. 用概率论的语言说: 事件 $A$ 发生必然导致事件 $B$ 发生.  \n!  \n图 1.1.2: $A \\subset B$  \n譬如郑一颗骰子, 事件 $A=$ “出现 4 点” 的发生必然导致事件 $B=$ “出现偶数点” 的发生, 故 $A \\subset B$.  \n又如电视机的寿命 $T$ 超过 $10000 \\mathrm{~h}$ （记为事件 $A=\\{T>10000\\}$ ）和 $T$ 超过 $20000 \\mathrm{~h}$ （记为事件 $B=\\{T>20000\\})$, 则 $A \\supset B$, 见图 1.1.3.  \n对任一事件 $A$, 必有 $\\varnothing \\subset A \\subset \\Omega$.  \n!  \n图 1.1.3: $\\{T>10000\\} \\supset\\{T>20000\\}$",
        "metadata": {
            "Header 2": "一、包含关系"
        },
        "type": "Document"
    },
    {
        "page_content": "如果事件 $A$ 与事件 $B$ 满足: 属于 $A$ 的样本点必属于 $B$, 而且属于 $B$ 的样本点必属于 $A$, 即 $A \\subset B$ 且 $B \\subset A$, 则称事件 $A$ 与 $B$ 相等, 记为 $A=B$.  \n从集合论观点看, 两个事件相等就意味着这两事件是同一个集合. 下例说明: 有时不同语言描述的事件也可能是同一件事.  \n例 1.1.7:  \n1. 郑两颗焆子, 以 $A$ 记事件 “两颗骰于的点数之和为奇数”, 以 $B$ 记事件 “两颗骰子的点数为一奇一偶”. 很容易证明: $A$ 发生必然导致 $B$ 发生, 而且 $B$ 发生也必然导致 $A$ 发生, 所以 $A=B$.\n2. 口袋中有 $a$ 只黑球, $b$ 只白球 ( $a$ 与 $b$ 都大于零), 从中不返回地一只一只摸球. 以 $A$ 记事件 “最后摸出的几个球全是黑球”, 以 $B$ 记事件 “最后摸出的一只球是黑球”. 对于此题粗看好像是 $A \\neq B$, 但只要设想将球全部摸完为止, 则明显有: $A$ 发生必然会导致 $B$ 发生, 即 $A \\subset B$; 反之注意到事件 $A$ 中所述的 “几个” 最少是 1 只, 也可以是 2 只, $\\cdots$, 最多为 $a$ 只, 则 $B$ 发生时 $A$ 也必然会发生 (对于这点请读者仔细体会), 即 $B \\subset A$, 由此得 $A=B$.",
        "metadata": {
            "Header 2": "二。相等关系"
        },
        "type": "Document"
    },
    {
        "page_content": "如果 $A$ 与 $B$ 没有相同的样本点 (见图 1.1.4), 则称 $A$ 与 $B$ 互不相容. 用概率论的语言说: $A$与 $B$ 互不相容就是事件 $A$ 与事件 $B$ 不可能同时发生.  \n!  \n图 1.1.4: $A$ 与 $B$ 互不相容  \n如在电视机寿命试验中, “寿命小于 1 万小时” “寿命大于 5 万小时” 是两个互不相容的事件,因为它们不可能同时发生.",
        "metadata": {
            "Header 2": "三、互不相容"
        },
        "type": "Document"
    },
    {
        "page_content": "事件的运算与集合的运算相当, 有并、交、差和余等四种运算.",
        "metadata": {
            "Header 2": "三、互不相容",
            "Header 3": "1.1.6 事件运算"
        },
        "type": "Document"
    },
    {
        "page_content": "记为 $A \\cup B$. 其含义为 “由事件 $A$ 与 $B$ 中所有的样本点 (相同的只计人一次) 组成的新事件” (见图 1.1.5). 或用概率论的语言说: “事件 $A$ 与 $B$ 中至少有一个发生”.  \n如在掷一颗骰子的试验中, 记事件 $A=$ “出现奇数点” $=\\{1,3,5\\}$, 记事件 $B=$ “出现的点数不超过 $3 \"=\\{1,2,3\\}$, 则 $A$ 与 $B$ 的并为 $A \\cup B=\\{1,2,3,5\\}$.  \n!  \n图 1.1.5: $A$ 与 $B$ 的并",
        "metadata": {
            "Header 2": "一、事件 $A$ 与 $B$ 的并"
        },
        "type": "Document"
    },
    {
        "page_content": "记为 $A \\cap B$, 或简记为 $A B$. 其含义为 “由事件 $A$ 与 $B$ 中公共的样本点组成的新事件” (见图 1.1.6)）. 或用概率论的语言说: “事件 $A$ 与 $B$ 同时发生”.  \n!  \n图 1.1.6: $A$ 与 $B$ 的交  \n如在郑一颗骰子的试验中, 记事件 $A=$ “出现奇数点” $=\\{1,3,5\\}$, 记事件 $B=$ “出现的点数不超过 $3 \"=\\{1,2,3\\}$, 则 $A$ 与 $B$ 的交为 $A B=\\{1,3\\}$.  \n若事件 $A$ 与 $B$ 为互不相容, 则其交必为不可能事件, 即 $A B=\\varnothing$, 反之亦然. 这表明: $A B=\\varnothing$就意味着 $A$ 与 $B$ 是互不相容事件.  \n事件的并与交运算可推广到有限个或可列个事件, 譬如有事件 $A_{1}, A_{2}, \\cdots$, 则 $\\bigcup_{i=1}^{n} A_{i}$ 称为有限并; $\\bigcup_{i=1}^{+\\infty} A_{i}$ 称为可列并; $\\bigcap_{i=1}^{n} A_{i}$ 称为有限交; $\\bigcup_{i=1}^{+\\infty} A_{i}$ 称为可列交.  \n三、事件 $A$ 对 $B$ 的差  \n记为 $A-B$, 其含义为 “由事件 $A$ 中而不在 $B$ 中的样本点组成的新事件” (见图 1.1.7). 或用概率论的语言说: “事件 $A$ 发生而 $B$ 不发生”.  \n!  \n(a) $A-B$  \n!  \n(b) $A-B(A \\supset B)$  \n图 1.1.7  \n如在郑一颗骰子的试验中, 记事件 $A=$ “出现奇数点” $=\\{1,3,5\\}$, 记事件 $B=$ “出现的点数不超过 $3 \"=\\{1,2,3\\}$, 则 $A$ 对 $B$ 的差为 $A-B=\\{15\\}$.  \n若设 $X$ 为随机变量, 则有  \n$$\n\\{X=a\\}=\\{X \\leqslant a\\}-\\{X<a\\}, \\quad\\{a<X \\leqslant b\\}=\\{X \\leqslant b\\}-\\{X \\leqslant a\\} .\n$$  \n四、对立事件",
        "metadata": {
            "Header 2": "二、事件 $A$ 与 $B$ 的交"
        },
        "type": "Document"
    },
    {
        "page_content": "三、事件 $A$ 对 $B$ 的差  \n记为 $A-B$, 其含义为 “由事件 $A$ 中而不在 $B$ 中的样本点组成的新事件” (见图 1.1.7). 或用概率论的语言说: “事件 $A$ 发生而 $B$ 不发生”.  \n!  \n(a) $A-B$  \n!  \n(b) $A-B(A \\supset B)$  \n图 1.1.7  \n如在郑一颗骰子的试验中, 记事件 $A=$ “出现奇数点” $=\\{1,3,5\\}$, 记事件 $B=$ “出现的点数不超过 $3 \"=\\{1,2,3\\}$, 则 $A$ 对 $B$ 的差为 $A-B=\\{15\\}$.  \n若设 $X$ 为随机变量, 则有  \n$$\n\\{X=a\\}=\\{X \\leqslant a\\}-\\{X<a\\}, \\quad\\{a<X \\leqslant b\\}=\\{X \\leqslant b\\}-\\{X \\leqslant a\\} .\n$$  \n四、对立事件  \n事件 $A$ 的对立事件, 记为 $\\bar{A}$, 即 “由在 $\\Omega$ 中而不在 $A$ 中的样本点组成的新事件” (见图 1.1.8) , 或用概率论的语言说: “ $A$ 不发生”, 即 $\\bar{A}=\\Omega-A$. 注意, 对立事件是相互的, 即 $A$ 的对立事件是 $\\bar{A}$, 而 $\\bar{A}$ 的对立事件是 $A$, 即 $\\overline{\\bar{A}}=A$. 必然事件 $\\Omega$ 与不可能事件 $\\varnothing$ 互为对立事件, 即 $\\bar{\\Omega}=\\varnothing$, $\\bar{\\varnothing}=\\Omega$.  \n!  \n图 1.1.8: $A$ 的对立事件 $\\bar{A}$  \n如在掷一颗骰子的试验中, 事件 $A=$ “出现奇数点” $=\\{1,3,5\\}$ 的对立事件是 $\\bar{A}=\\{2,4,6\\}$, 事件 $B=$ “出现的点数不超过 3 ” $=\\{1,2,3\\}$ 的对立事件是 $\\bar{B}=\\{4,5,6\\}$.  \n$A$ 与 $B$ 互为对立事件的充要条件是: $A \\cap B=\\varnothing$, 且 $A \\cup B=\\Omega$.",
        "metadata": {
            "Header 2": "二、事件 $A$ 与 $B$ 的交"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n图 1.1.8: $A$ 的对立事件 $\\bar{A}$  \n如在掷一颗骰子的试验中, 事件 $A=$ “出现奇数点” $=\\{1,3,5\\}$ 的对立事件是 $\\bar{A}=\\{2,4,6\\}$, 事件 $B=$ “出现的点数不超过 3 ” $=\\{1,2,3\\}$ 的对立事件是 $\\bar{B}=\\{4,5,6\\}$.  \n$A$ 与 $B$ 互为对立事件的充要条件是: $A \\cap B=\\varnothing$, 且 $A \\cup B=\\Omega$.  \n此性质也可作为对立事件的另一种定义, 即如果事件 $A$ 与 $B$ 满足: $A \\cap B=\\varnothing$, 且 $A \\cup B=\\Omega$,则称 $A$ 与 $B$ 互为对立事件, 记为 $\\bar{A}=B, \\bar{B}=A$.  \n例 1.1.8: 从数字 $1,2, \\cdots, 9$ 中可重复地任取 $n$ 次 $(n \\geqslant 2)$, 以 $A$ 表示事件 “所取的 $n$ 个数字的乘积能被 10 整除”. 因为乘积能被 10 整除必须既取到数字 5 , 又要取到偶数. 所以 $A$ 的对立事件 $\\bar{A}$为 “所取的 $n$ 个数字中或者没有 5 , 或者没有偶数”. 如果记 $B=$ “所取的 $n$ 个数字中没有 5 ”, $C=$ “所取的 $n$ 个数字中没有偶数”, 则 $\\bar{A}=B \\cup C$.  \n例 1.1.9: 设 $A 、 B 、 C$ 是某个随机现象的三个事件, 则  \n1. 事件 “ $A$ 与 $B$ 发生, $C$ 不发生”可表示为: $A B \\bar{C}$.\n2. 事件 “ $A 、 B 、 C$ 中至少有一个发生”可表示为: $A \\cup B \\cup C$.\n3. 事件 “ $A 、 B 、 C$ 中至少有两个发生”可表示为: $A B \\cup A C \\cup B C$.\n4. 事件 “ $A 、 B 、 C$ 中恰好有两个发生” 可表示为: $A B \\bar{C} \\cup A \\bar{B} C \\cup \\bar{A} B C$.\n5. 事件 “ $A 、 B 、 C$ 同时发生”可表示为: $A B C$.",
        "metadata": {
            "Header 2": "二、事件 $A$ 与 $B$ 的交"
        },
        "type": "Document"
    },
    {
        "page_content": "例 1.1.9: 设 $A 、 B 、 C$ 是某个随机现象的三个事件, 则  \n1. 事件 “ $A$ 与 $B$ 发生, $C$ 不发生”可表示为: $A B \\bar{C}$.\n2. 事件 “ $A 、 B 、 C$ 中至少有一个发生”可表示为: $A \\cup B \\cup C$.\n3. 事件 “ $A 、 B 、 C$ 中至少有两个发生”可表示为: $A B \\cup A C \\cup B C$.\n4. 事件 “ $A 、 B 、 C$ 中恰好有两个发生” 可表示为: $A B \\bar{C} \\cup A \\bar{B} C \\cup \\bar{A} B C$.\n5. 事件 “ $A 、 B 、 C$ 同时发生”可表示为: $A B C$.\n6. 事件 “ $A 、 B 、 C$ 都不发生”可表示为: $\\bar{A} \\bar{B} \\bar{C}$.\n7. 事件 “ $A 、 B 、 C$ 不全发生”可表示为: $\\bar{A} \\cup \\bar{B} \\cup \\bar{C}$.",
        "metadata": {
            "Header 2": "二、事件 $A$ 与 $B$ 的交"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nA \\cup B=B \\cup A, \\quad A B=B A \\tag{1.1.1}\n\\end{equation*}\n$$  \n2. 结合律  \n$$\n\\begin{align*}\n(A \\cup B) \\cup C & =A \\cup(B \\cup C)  \\tag{1.1.2}\\\\\n(A B) C & =A(B C) . \\tag{1.1.3}\n\\end{align*}\n$$  \n3. 分配律  \n$$\n\\begin{gather*}\n(A \\cup B) \\cup C=A \\cup(B \\cup C),  \\tag{1.1.4}\\\\\n(A \\cap B) \\cup C=(A \\cup C) \\cap(B \\cup C) . \\tag{1.1.5}\n\\end{gather*}\n$$  \n4. 对偶律 (德莫根公式)\n事件交的对立等于对立的并: $\\overline{A \\cap B}=\\bar{A} \\cup \\bar{B}$.  \n事件运算的对偶律是很有用的公式. 这些性质是不难证明的, 在此我们用集合论的语言证明其中的 (1.1.6) 式.  \n(1.1.6) 式的证明  \n设 $\\omega \\in \\overline{A \\cup B}$, 即 $\\omega \\notin A \\cup B$, 这表明 $\\omega$ 既不属于 $A$, 也不属于 $B$, 这意味着 $\\omega \\notin A$ 和 $\\omega \\notin B$同时成立, 所以 $\\omega \\in \\bar{A}$ 与 $\\omega \\in \\bar{B}$ 同时成立, 于是有 $\\omega \\in \\bar{A} \\cap \\bar{B}$, 这说明  \n$$\n\\overline{A \\cup B} \\subset \\bar{A} \\cap \\bar{B} .\n$$",
        "metadata": {
            "Header 2": "1. 交换律"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{gather*}\n$$  \n4. 对偶律 (德莫根公式)\n事件交的对立等于对立的并: $\\overline{A \\cap B}=\\bar{A} \\cup \\bar{B}$.  \n事件运算的对偶律是很有用的公式. 这些性质是不难证明的, 在此我们用集合论的语言证明其中的 (1.1.6) 式.  \n(1.1.6) 式的证明  \n设 $\\omega \\in \\overline{A \\cup B}$, 即 $\\omega \\notin A \\cup B$, 这表明 $\\omega$ 既不属于 $A$, 也不属于 $B$, 这意味着 $\\omega \\notin A$ 和 $\\omega \\notin B$同时成立, 所以 $\\omega \\in \\bar{A}$ 与 $\\omega \\in \\bar{B}$ 同时成立, 于是有 $\\omega \\in \\bar{A} \\cap \\bar{B}$, 这说明  \n$$\n\\overline{A \\cup B} \\subset \\bar{A} \\cap \\bar{B} .\n$$  \n反之, 设 $\\omega \\in \\bar{A} \\cap \\bar{B}$, 即同时有 $\\omega \\in \\bar{A}$ 和 $\\omega \\in \\bar{B}$, 从而同时有 $\\omega \\notin A$ 和 $\\omega \\notin B$, 这意味着 $\\omega$ 不属于 $A$ 与 $B$ 中的任一个, 即 $\\omega \\notin A \\cup B$, 也就是有 $\\omega \\in \\overline{A \\cup B}$, 这说明  \n$$\n\\overline{A \\cup B} \\supset \\bar{A} \\cap \\bar{B} .\n$$  \n综合上述两方面, 可得  \n$$\n\\overline{A \\cup B}=\\bar{A} \\cap \\bar{B} .\n$$  \n(1.1.6) 式得证.  \n德莫根公式可推广到多个事件及可列个事件场合:  \n$$\n\\begin{array}{ll}",
        "metadata": {
            "Header 2": "1. 交换律"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\overline{A \\cup B} \\subset \\bar{A} \\cap \\bar{B} .\n$$  \n反之, 设 $\\omega \\in \\bar{A} \\cap \\bar{B}$, 即同时有 $\\omega \\in \\bar{A}$ 和 $\\omega \\in \\bar{B}$, 从而同时有 $\\omega \\notin A$ 和 $\\omega \\notin B$, 这意味着 $\\omega$ 不属于 $A$ 与 $B$ 中的任一个, 即 $\\omega \\notin A \\cup B$, 也就是有 $\\omega \\in \\overline{A \\cup B}$, 这说明  \n$$\n\\overline{A \\cup B} \\supset \\bar{A} \\cap \\bar{B} .\n$$  \n综合上述两方面, 可得  \n$$\n\\overline{A \\cup B}=\\bar{A} \\cap \\bar{B} .\n$$  \n(1.1.6) 式得证.  \n德莫根公式可推广到多个事件及可列个事件场合:  \n$$\n\\begin{array}{ll}\n\\overline{\\bigcup_{i=1}^{n} A_{i}}=\\bigcap_{i=1}^{n} \\bar{A}_{i} ; & \\overline{\\bigcup_{i=1}^{+\\infty} A_{i}}=\\bigcap_{i=1}^{+\\infty} \\bar{A}_{i} ;  \\tag{1.1.8}\\\\\n\\overline{\\bigcap_{i=1}^{n} A_{i}}=\\bigcup_{i=1}^{n} \\bar{A}_{i} ; & \\overline{\\bigcap_{i=1}^{+\\infty} A_{i}}=\\bigcup_{i=1}^{+\\infty} \\bar{A}_{i} .\n\\end{array}\n$$",
        "metadata": {
            "Header 2": "1. 交换律"
        },
        "type": "Document"
    },
    {
        "page_content": "在此我们要给出的“事件域”概念, 目的是为下一节定义事件的概率作准备.  \n所谓的 “事件域” 从直观上讲就是一个样本空间中某些子集组成的集合类, 以后记事件域为 $\\mathscr{F}$.  \n当样本空间是实数轴上的一个区间时, 可以人为地构造出无法测量其长度的子集, 这样的子集常被称为不可测集. 如果将这些不可测集也看成是事件, 那么这些事件将无概率可言, 这是我们不希望出现的现象, 为了避免这种现象出现, 我们没有必要将连续样本空间的所有子集都看成是事件, 只需将我们感兴趣的子集 (又称可测集) 看成是事件即可.  \n现在的问题是: 我们应该对哪些子集感兴趣, 或换句话说, $\\mathscr{F}$ 中应该有哪些元素? 首先 $\\mathscr{F}$ 应该包括 $\\Omega$ 和 $\\varnothing$; 其次应该保证事件经过前面所定义的各种运算 (并、交、差、对立) 后仍然是事件,即 $\\mathscr{F}$ 要对集合的运算有封闭性. 经过研究人们发现  \n- 交的运算可通过并与对立来实现 (德莫根公式).\n- 差的运算可通过对立与交来实现 $(A-B=A \\bar{B})$.  \n这样一来, 可给出事件域的定义如下.  \n定义 1.1.1. 设 $\\Omega$ 为一样本空间, $\\mathscr{F}$ 为 $\\Omega$ 的某些子集所组成的集合类, 如果 $\\mathscr{F}$ 满足:  \n1. $\\Omega \\in \\mathscr{F}$\n2. 若 $A \\in \\mathscr{F}$, 则对立事件 $\\bar{A} \\in \\mathscr{F}$;\n3. 若 $A_{n} \\in \\mathscr{F}, 1,2, \\cdots$, 则可列并 $\\bigcup_{n=1}^{+\\infty} A_{n} \\in \\mathscr{F}$.  \n则称 $\\mathscr{F}$ 为一个事件域, 又称为 $\\sigma$ 代数.  \n在概率论中, 又称 $(\\Omega, \\mathscr{F})$ 为可测空间, 这里 “可测”是指 $\\mathscr{F}$ 中都是有概率可言的事件.\n例 1.1.10: 常见的事件域",
        "metadata": {
            "Header 2": "1. 交换律",
            "Header 3": "1.1.7 事件域"
        },
        "type": "Document"
    },
    {
        "page_content": "- 差的运算可通过对立与交来实现 $(A-B=A \\bar{B})$.  \n这样一来, 可给出事件域的定义如下.  \n定义 1.1.1. 设 $\\Omega$ 为一样本空间, $\\mathscr{F}$ 为 $\\Omega$ 的某些子集所组成的集合类, 如果 $\\mathscr{F}$ 满足:  \n1. $\\Omega \\in \\mathscr{F}$\n2. 若 $A \\in \\mathscr{F}$, 则对立事件 $\\bar{A} \\in \\mathscr{F}$;\n3. 若 $A_{n} \\in \\mathscr{F}, 1,2, \\cdots$, 则可列并 $\\bigcup_{n=1}^{+\\infty} A_{n} \\in \\mathscr{F}$.  \n则称 $\\mathscr{F}$ 为一个事件域, 又称为 $\\sigma$ 代数.  \n在概率论中, 又称 $(\\Omega, \\mathscr{F})$ 为可测空间, 这里 “可测”是指 $\\mathscr{F}$ 中都是有概率可言的事件.\n例 1.1.10: 常见的事件域  \n1. 若样本空间只含两个样本点: $\\Omega=\\left\\{\\omega_{1}, \\omega_{2}\\right\\}$, 记 $A=\\left\\{\\omega_{1}\\right\\}, \\bar{A}=\\left\\{\\omega_{2}\\right\\}$, 则其事件域为 $\\mathscr{F}=$ $\\{\\varnothing, A, \\bar{A}, \\Omega\\}$.",
        "metadata": {
            "Header 2": "1. 交换律",
            "Header 3": "1.1.7 事件域"
        },
        "type": "Document"
    },
    {
        "page_content": "3. 若 $A_{n} \\in \\mathscr{F}, 1,2, \\cdots$, 则可列并 $\\bigcup_{n=1}^{+\\infty} A_{n} \\in \\mathscr{F}$.  \n则称 $\\mathscr{F}$ 为一个事件域, 又称为 $\\sigma$ 代数.  \n在概率论中, 又称 $(\\Omega, \\mathscr{F})$ 为可测空间, 这里 “可测”是指 $\\mathscr{F}$ 中都是有概率可言的事件.\n例 1.1.10: 常见的事件域  \n1. 若样本空间只含两个样本点: $\\Omega=\\left\\{\\omega_{1}, \\omega_{2}\\right\\}$, 记 $A=\\left\\{\\omega_{1}\\right\\}, \\bar{A}=\\left\\{\\omega_{2}\\right\\}$, 则其事件域为 $\\mathscr{F}=$ $\\{\\varnothing, A, \\bar{A}, \\Omega\\}$.\n2. 若样本空间含有 $n$ 个样本点: $\\Omega=\\left\\{\\omega_{1}, \\omega_{2}, \\cdots, \\omega_{n}\\right\\}$, 则其事件域 $\\mathscr{F}$ 是由空集 $\\varnothing 、 n$ 个单元素集、 ( $\\left.\\begin{array}{l}n \\\\ 2\\end{array}\\right)$ 个双元素集、 $\\left(\\begin{array}{c}n \\\\ 3\\end{array}\\right)$ 个三元素集 $\\cdots . . .$. 和 $\\Omega$ 组成的集合类, 这时 $\\mathscr{F}$ 中共有 $\\left(\\begin{array}{l}n \\\\ 0\\end{array}\\right)+\\left(\\begin{array}{l}n \\\\ 1\\end{array}\\right)+$ $\\left(\\begin{array}{l}n \\\\ 2\\end{array}\\right)+\\cdots+\\left(\\begin{array}{l}n \\\\ n\\end{array}\\right)=2^{n}$ 个事件.",
        "metadata": {
            "Header 2": "1. 交换律",
            "Header 3": "1.1.7 事件域"
        },
        "type": "Document"
    },
    {
        "page_content": "3. 若样本空间含有可列个样本点: $\\Omega=\\left\\{\\omega_{1}, \\omega_{2}, \\cdots, \\omega_{n}, \\cdots\\right\\}$, 则其事件域 $\\mathscr{F}$ 是由空集 $\\varnothing$ 、可列个单元素集、可列个双元素集……可列个 $n$ 个元素集……和 $\\Omega$ 组成的集合类, 这时 $\\mathscr{F}$ 是由可列个的可列个 (仍为可列个) 元素 ( 事件) 组成.\n4. 若样本空间含有全体实数: $\\Omega=(-\\infty,+\\infty)=\\mathbb{R}$. 这时事件域 $\\mathscr{F}$ 中的元素无法一一列出, 而是由一个基本集合类逐步扩展形成, 具体操作如下:  \n。取基本集合类 $\\mathscr{F}=$ “全体半直线组成的类”, 即  \n$$\n\\mathscr{F}=\\{(-\\infty, x) ;-\\infty<x<+\\infty\\} .\n$$  \n- 利用事件域的要求, 首先把有限的左闭右开区间扩展进来:  \n$$\n[a, b)=(-\\infty, b)-(\\infty, a) \\text {, 其中 } a, b \\text { 为任意实数. }\n$$  \n- 再把闭区间、单点集、左开右闭区间、开区间扩展进来:  \n$$\n\\begin{gathered}\n{[a, b]=\\bigcap_{n=1}^{+\\infty}[a, b+1 / n),} \\\\\n\\{b\\}=[a, b]-[a, b), \\\\\n(a, b]=[a, b]-\\{a\\}, \\\\\n(a, b)=[a, b)-\\{a\\} .\n\\end{gathered}\n$$  \n- 最后用 (有限个或可列个) 并运算和交运算把实数集中一切有限集、可列集、开集、闭集都扩展进来.  \n经过上述几步扩展所得之集的全体就是人们希望得到的事件域 $\\mathscr{F}$, 因为它满足事件城的定义. 这样的事件域 $\\mathscr{F}$ 又称为波雷尔 (Borel) 事件城, 域中的每个元素 (集合) 又称为波雷尔集, 或称为可测集, 这种可测集都是有概率可言的事件.",
        "metadata": {
            "Header 2": "1. 交换律",
            "Header 3": "1.1.7 事件域"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 写出下列随机试验的样本空间:  \n(1) 抛三枚硬币;  \n(2) 抛三颗骰子;  \n(3) 连续抛一枚硬币, 直至出现正为之;  \n(4) 在某十字路口,一小时内通过的机动车辆数;  \n(5) 某城市一天内的用电量.  \n2. 在抛三枚硬币的试验中写出下列事件的集合表示:  \n- $A=$ “至少出现一个正面”;\n- $B=$ “最多出现一个正面”;\n- $C=$ “恰好出现一个正面”;\n- $D=$ “出现三面相同”.  \n3. 设 $A 、 B 、 C$ 为三事件, 试表示下列事件:  \n(1) $A 、 B 、 C$ 都发生或都不发生;  \n(2) $A 、 B 、 C$ 中不多于一个发生;  \n(3) $A 、 B 、 C$ 中不多于两个发生;  \n(4) $A 、 B 、 C$ 中至少有两个发生.  \n4. 请指明以下事件 $A$ 和 $B$ 间的关系:  \n(1) 检查两件产品, 记事件 $A=$ “至少有一件不合格产品”, $B=$ “两次检查结果不同”.  \n(2) 设 $T$ 表示轴承寿命, 记事件 $A=\\{T>5000 \\mathrm{~h}\\}, B=\\{T>8000 \\mathrm{~h}\\}$.  \n5. 设 $X$ 为随机变量, 其样本空间为 $\\Omega=\\{0 \\leqslant T \\leqslant 2\\}$, 记事件 $A=\\{0.5<X \\leqslant 1\\}, B=\\{0.25 \\leqslant$ $X<1.5\\}$. 写出下列事件:  \n(1) $\\bar{A} B$,  \n(2) $\\bar{A} \\cup B$,  \n(3) $\\overline{A B}$,  \n(4) $\\overline{A \\cup B}$.  \n6. 对飞机进行两次射击, 每次射一弹, 设 $A=\\{$ 恰有一弹击中飞机 $\\}, B=\\{$ 至少有弹击中飞机 $\\}$, $C=\\{$ 两弹都击中飞机 $\\}, D=\\{$ 两弹都没击中飞机 $\\}$. 又设随机变量 $X$ 为击中飞机的次数, 试用 $X$ 表示事件 $A, B, C, D$. 进一步问 $A, B, C, D$ 中哪些是互不相容的事件? 哪些是对立的事件?\n7. 试问下列命题是否成立?  \n(1) $A-(B-C)=(A-B) \\cup C$.",
        "metadata": {
            "Header 2": "习习题 1.1"
        },
        "type": "Document"
    },
    {
        "page_content": "5. 设 $X$ 为随机变量, 其样本空间为 $\\Omega=\\{0 \\leqslant T \\leqslant 2\\}$, 记事件 $A=\\{0.5<X \\leqslant 1\\}, B=\\{0.25 \\leqslant$ $X<1.5\\}$. 写出下列事件:  \n(1) $\\bar{A} B$,  \n(2) $\\bar{A} \\cup B$,  \n(3) $\\overline{A B}$,  \n(4) $\\overline{A \\cup B}$.  \n6. 对飞机进行两次射击, 每次射一弹, 设 $A=\\{$ 恰有一弹击中飞机 $\\}, B=\\{$ 至少有弹击中飞机 $\\}$, $C=\\{$ 两弹都击中飞机 $\\}, D=\\{$ 两弹都没击中飞机 $\\}$. 又设随机变量 $X$ 为击中飞机的次数, 试用 $X$ 表示事件 $A, B, C, D$. 进一步问 $A, B, C, D$ 中哪些是互不相容的事件? 哪些是对立的事件?\n7. 试问下列命题是否成立?  \n(1) $A-(B-C)=(A-B) \\cup C$.  \n(2) 若 $A B=\\varnothing$ 且 $C \\subset A$, 则 $B C=\\varnothing$.  \n(3) $(A \\cup B)-B=A$.  \n(4) $(A-B) \\cup B=A$.  \n8. 试用维恩图说明, 当事件 $A$ 与 $B$ 互不相容时, 能否得出结论 $\\bar{A}$ 与 $\\bar{B}$ 相容.\n9. 请叙述下列事件的对立事件:  \n(1) $A=$ “掷两枚硬币, 皆为正面”;  \n(2) $B=$ “射击三次, 皆命中目标”;  \n(3) $C=$ “加工四个零件, 至少有一个合格品”.  \n10. 如果 $A$ 与 $B$ 互为对立事件, 证明: $\\bar{A}$ 与 $\\bar{B}$ 也互为对立事件.\n11. 设 $\\mathscr{F}$ 为一事件域, 若 $A_{n} \\in \\mathscr{F}, n=1,2, \\cdots$, 试证:  \n(1) $\\varnothing \\in \\mathscr{F}$;  \n(2) 有限并 $\\bigcup_{i=1}^{n} A_{i} \\in \\mathscr{F}, n \\geqslant 1$;",
        "metadata": {
            "Header 2": "习习题 1.1"
        },
        "type": "Document"
    },
    {
        "page_content": "(3) $(A \\cup B)-B=A$.  \n(4) $(A-B) \\cup B=A$.  \n8. 试用维恩图说明, 当事件 $A$ 与 $B$ 互不相容时, 能否得出结论 $\\bar{A}$ 与 $\\bar{B}$ 相容.\n9. 请叙述下列事件的对立事件:  \n(1) $A=$ “掷两枚硬币, 皆为正面”;  \n(2) $B=$ “射击三次, 皆命中目标”;  \n(3) $C=$ “加工四个零件, 至少有一个合格品”.  \n10. 如果 $A$ 与 $B$ 互为对立事件, 证明: $\\bar{A}$ 与 $\\bar{B}$ 也互为对立事件.\n11. 设 $\\mathscr{F}$ 为一事件域, 若 $A_{n} \\in \\mathscr{F}, n=1,2, \\cdots$, 试证:  \n(1) $\\varnothing \\in \\mathscr{F}$;  \n(2) 有限并 $\\bigcup_{i=1}^{n} A_{i} \\in \\mathscr{F}, n \\geqslant 1$;  \n(3) 有限交 $\\cap_{i=1}^{n} A_{i} \\in \\mathscr{F}, n \\geqslant 1$;  \n(4) 可列交 $\\bigcap_{i=1}^{+\\infty} A_{i} \\in \\mathscr{F}$;  \n(5) 差运算 $A_{1}-A_{2} \\in \\mathscr{F}$.",
        "metadata": {
            "Header 2": "习习题 1.1"
        },
        "type": "Document"
    },
    {
        "page_content": "在这一节中, 我们要给出概率的定义及其确定方法, 这是概率论中最基本的个问题. 简单而直观的说法就是: 概率是随机事件发生的可能性大小, 对此我们先看下面一些经验事实:  \n1. 随机事件的发生是带有偶然性. 但随机事件发生的可能性是有大小之分的, 例如口袋中有 10 只相同大小的球, 其中 9 只黑球, 1 只红球, 从口袋中任取 1 球, 人们的共识是: 取出黑球的可能性比取出红球的可能性大;\n2. 随机事件发生的可能性是可以设法度量的, 就好比一根木棒有长度, 一块土地有面积一样.例如抛一枚硬币, 出现正面与出现反面的可能性是相同的, 各为 $1 / 2$. 足球裁判就用抛硬币的\n方法让双方队长选择场地, 以示机会均等;\n3. 在日常生活中, 人们对一些随机事件发生的可能性大小往往是用百分比 ( 0 到 1 之间的一个数) 进行度量的. 例如购买彩券后可能中奖, 可能不中奖, 但中奖的可能性大小可以用中奖率来度量; 抽取一个产品可能为合格品, 也可能为不合格品, 但产品质量的好坏可以用不合格品率来度量; 新生要儿可能为男孩, 也可能为女孩, 但生男孩的可能性可以用男婴出生率来度量  \n在概率论发展的历史上, 曾有过概率的古典定义、概率的几何定义、概率的频率定义和概率的主观定义. 这些定义各适合一类随机现象, 那么如何给出适合一切随机现象的概率的最一般的定义呢? 1900 年数学家希尔伯特 (1862-1943) 提出要建立概率的公理化定义以解决这个问题, 即以最少的几条本质特性出发去刻画概率的概念. 1933 年前苏联数学家柯尔莫哥洛夫 (1903-1987) 首次提出了概率的公理化定义, 这个定义既概括了历史上几种概率定义中的共同特性, 又避免了各自的局限性和含混之处, 不管什么随机现象, 只有满足定义中的三条公理, 才能说它是概率. 这一公理化体系迅速获得举世公认, 是概率论发展史上的一个里程碑. 有了这个公理化定义后, 概率论得到了很快的发展.",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 1.2.1. 设 $\\Omega$ 为一个样本空间, $\\mathscr{F}$ 为 $\\Omega$ 的某些子集组成的一个事件域. 如果对任一事件 $A \\in$ $\\mathscr{F}$, 定义在 $\\mathscr{F}$ 上的一个实值函数 $P(A)$ 满足:  \n1. 非负性公理: 若 $A \\in \\mathscr{F}$, 则 $P(A) \\geqslant 0$;\n2. 正则性公理: $P(\\Omega)=1$;\n3. 可列可加性公理: 若 $A_{1}, A_{2}, \\ldots, A_{n}, \\ldots$, 互不相容, 有  \n$$\n\\begin{equation*}\nP\\left(\\bigcup_{i=1}^{+\\infty} A_{i}\\right)=\\sum_{i=1}^{+\\infty} P\\left(A_{i}\\right) \\tag{1.2.1}\n\\end{equation*}\n$$  \n则称 $P(A)$ 为事件 $A$ 的概率, 称三元素 $(\\Omega, \\mathscr{F}, \\mathscr{P})$ 为概率空间.  \n概率的公理化定义刻画了概率的本质, 概率是集合 (事件) 的函数, 若在事件域 $\\mathscr{F}$ 上给出一个函数, 当这个函数能满足上述三条公理, 就被称为概率; 当这个函数不能满足上述三条公理中任一条, 就被认为不是概率.  \n公理化定义没有告诉人们如何去确定概率. 历史上在公理化定义出现之前概率的频率定义、古典定义、几何定义和主观定义都在一定的场合下, 有着各自确定概率的方法, 所以在有了概率的公理化定义之后, 把它们看作确定概率的方法是恰当的. 下面先介绍在确定概率的古典方法中大量使用的排列与组合公式, 然后分别讲述确定概率的方法.",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法",
            "Header 3": "1.2.1 概率的公理化定义"
        },
        "type": "Document"
    },
    {
        "page_content": "排列与组合都是计算 “从 $n$ 个元素中任取 $r$ 个元素” 的取法总数公式, 其主要区别在于: 如果不讲究取出元素间的次序, 则用组合公式, 否则用排列公式; 而所谓讲究元素间的次序, 可以从实际问题中得以辨别, 例如两个人相互握手是不讲次序的, 而两个人排队是讲次序的, 因为 “甲右乙左”与“乙右甲左”是两件事.  \n排列与组合公式的推导都基于如下两条计数原理:  \n1. 乘法原理: 如果某件事经 $k$ 个步骤才能完成, 做第一步有 $m_{1}$ 种方法, 做第二步有 $m_{2}$ 种方法, $\\ldots$, 做第 $k$ 步有 $m_{k}$ 种方法. 那么完成这件事共有 $m_{1} \\times m_{2} \\times \\cdots \\mathrm{m}_{k}$ 种方法.  \n譬如, 甲城到乙城有 3 条旅游线路, 由乙城到丙城有 2 条旅游线路, 那么从甲城经乙城去丙城共有 $3 \\times 2=6$ 条旅游线路  \n2. 加法原理: 如果某件事可由 $k$ 类不同途径之一去完成, 在第一类途径中有 $m_{1}$ 种完成方法, 在第二类途径中有 $m_{2}$ 种完成方法, ..., 在第 $k$ 类途径中有 $m_{k}$ 种完成方法, 那么完成这件事共有 $m_{1}+m_{2}+\\cdots+m_{k}$ 种方法.  \n譬如, 由甲城到乙城去旅游有三类交通工具: 汽车、火车和飞机. 而汽车有 5 个班次, 火车有 3 个班次, 飞机有 2 个班次, 那么从甲城到乙城共有 $5+3+2=10$ 个班次供旅游者选择.排列与组合的定义及其计算公式如下.  \n1. 排列: 从 $n$ 个不同元素中任取 $r(r \\leqslant n)$ 个元素排成一列 (考虑元素先后出现次序), 称此为一个排列, 此种排列的总数记为 $P_{n}^{r}$, 按乘法原理, 取出的第一个元素有 $n$ 种取法, 取出的第二个元素有 $n-1$ 种取法... 取出的第 $r$ 个元素有 $n-r+1$ 种取法, 所以有  \n$$\n\\begin{equation*}\nP_{n}^{r}=n \\times(n-1) \\times \\cdots \\times(n-r+1)=\\frac{n !}{(n-r !)} \\tag{1.2.2}",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法",
            "Header 3": "1.2.2 排列与组合公式"
        },
        "type": "Document"
    },
    {
        "page_content": "譬如, 由甲城到乙城去旅游有三类交通工具: 汽车、火车和飞机. 而汽车有 5 个班次, 火车有 3 个班次, 飞机有 2 个班次, 那么从甲城到乙城共有 $5+3+2=10$ 个班次供旅游者选择.排列与组合的定义及其计算公式如下.  \n1. 排列: 从 $n$ 个不同元素中任取 $r(r \\leqslant n)$ 个元素排成一列 (考虑元素先后出现次序), 称此为一个排列, 此种排列的总数记为 $P_{n}^{r}$, 按乘法原理, 取出的第一个元素有 $n$ 种取法, 取出的第二个元素有 $n-1$ 种取法... 取出的第 $r$ 个元素有 $n-r+1$ 种取法, 所以有  \n$$\n\\begin{equation*}\nP_{n}^{r}=n \\times(n-1) \\times \\cdots \\times(n-r+1)=\\frac{n !}{(n-r !)} \\tag{1.2.2}\n\\end{equation*}\n$$  \n若 $r=n$, 则称为全排列, 记为 $n$. 显然, 全排列 $P_{n}=n !$.  \n2. 重复排列: 从 $n$ 个不同元素中每次取出一个, 放回后再取下一个, 如此连续取 $r$ 次所得的排列称为重复排列, 此种重复排列数共有 $n^{r}$ 个. 注意这里的 $r$ 允许大于 $n$.\n3. 组合: 从 $n$ 个不同元素中任取 $r(r \\leqslant n)$ 个元素并成一组 (不考虑元素间的先后次序), 称此为一个组合, 此种组合的总数记为 $\\left(\\begin{array}{l}n \\\\ r\\end{array}\\right)$ 或 $C_{n}^{r}$. 按乘法原理此种组合的总数为  \n$$\n\\left(\\begin{array}{l}\nn  \\tag{1.2.3}\\\\\nr\n\\end{array}\\right)=\\frac{P_{n}^{r}}{r !}=\\frac{n(n-1) \\cdots(n-r+1)}{r !}=\\frac{n !}{r !(n-r) !}\n$$  \n在此规定 $0 !=1$ 与 $\\left(\\begin{array}{l}n \\\\ 0\\end{array}\\right)=1$.",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法",
            "Header 3": "1.2.2 排列与组合公式"
        },
        "type": "Document"
    },
    {
        "page_content": "2. 重复排列: 从 $n$ 个不同元素中每次取出一个, 放回后再取下一个, 如此连续取 $r$ 次所得的排列称为重复排列, 此种重复排列数共有 $n^{r}$ 个. 注意这里的 $r$ 允许大于 $n$.\n3. 组合: 从 $n$ 个不同元素中任取 $r(r \\leqslant n)$ 个元素并成一组 (不考虑元素间的先后次序), 称此为一个组合, 此种组合的总数记为 $\\left(\\begin{array}{l}n \\\\ r\\end{array}\\right)$ 或 $C_{n}^{r}$. 按乘法原理此种组合的总数为  \n$$\n\\left(\\begin{array}{l}\nn  \\tag{1.2.3}\\\\\nr\n\\end{array}\\right)=\\frac{P_{n}^{r}}{r !}=\\frac{n(n-1) \\cdots(n-r+1)}{r !}=\\frac{n !}{r !(n-r) !}\n$$  \n在此规定 $0 !=1$ 与 $\\left(\\begin{array}{l}n \\\\ 0\\end{array}\\right)=1$.  \n4. 重复组合: 从 $n$ 个不同元素中每次取出一个, 放回后再取下一个, 如此连续取 $r$ 次所得的组合称为重复组合, 此种重复组合总数为 $\\left(\\begin{array}{c}n+r-1 \\\\ r\\end{array}\\right)$. 注意这里的 $r$ 也允许大于 $n$.  \n上述四种排列组合及其总数计算公式, 在确定概率的古典方法中经常使用, 但在使用中要注意识别有序与无序、重复与不重复。",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法",
            "Header 3": "1.2.2 排列与组合公式"
        },
        "type": "Document"
    },
    {
        "page_content": "确定概率的频率方法是一种最常用的方法, 其基本思想是:  \n1. 与考察事件 $A$ 有关的随机现象可大量重复进行.\n2. 在 $n$ 次重复试验中, 记 $n(A)$ 为事件 $A$ 出现的次数, 又称 $n(A)$ 为事件 $A$ 的频数, 称  \n$$\n\\begin{equation*}\nf_{n}(A)=\\frac{n(A)}{n} \\tag{1.2.4}\n\\end{equation*}\n$$  \n为事件 $A$ 出现的频率.  \n3. 人们的长期实践表明: 随着试验重复次数 $n$ 的增加, 频率 $f_{n}(A)$ 会稳定在某一常数 $a$ 附近.我们称这个常数为频率的稳定值. 这个频率的稳定值就是我们所求的概率.\n4. 频率方法的缺点是: 在现实世界里, 人们无法把一个试验无限次地重复下去, 因此要精确获得频率的稳定值是困难的. 但频率方法提供了概率的一个可供想像的具体值, 并且在试验重复次数 $n$ 较大时, 可用频率给出概率的一个近似值, 这一点是频率方法最有价值的地方. 在统计学中就是如此做的, 且称频率为概率的估计值.  \n容易验证: 用频率方法确定的概率满足公理化定义, 它的非负性与正则性是显然的, 而可加性只需注意到: 当 $A$ 与 $B$ 互不相容时, 计算 $A \\cup B$ 的频数可以分别计算的 $A$ 的频数和 $B$ 的频数, 然后再相加, 这意味着 $n(A \\cup B)=n(A)+n(B)$. 从而有  \n$$\n\\begin{aligned}\nf_{n}(A \\cup B) & =\\frac{n(A \\cup B)}{n}=\\frac{n(A)+n(B)}{n} \\\\\n& =\\frac{n(A)}{n}+\\frac{n(B)}{n}=f_{n}(A)+f_{n}(B) .\n\\end{aligned}\n$$  \n例 1.2.1: 说明频率稳定性的例子.  \n1. 抛硬币试验  \n历史上有不少人做过抛硬币试验, 其结果见表 1.2.1. 从表中的数据可以看出: 出现正面的频率逐渐稳定在 0.5 , 用频率的方法可以说: 出现正面的概率为 0.5 .  \n表 1.2.1: 历史上抛硬币试验的若干结果  \n| 实验者 | 抛硬币次数 | 出现正面次数 | 频率 |\n| :--- | :--- | :--- | :--- |",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法",
            "Header 3": "1.2.3 确定概率的频率方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nf_{n}(A \\cup B) & =\\frac{n(A \\cup B)}{n}=\\frac{n(A)+n(B)}{n} \\\\\n& =\\frac{n(A)}{n}+\\frac{n(B)}{n}=f_{n}(A)+f_{n}(B) .\n\\end{aligned}\n$$  \n例 1.2.1: 说明频率稳定性的例子.  \n1. 抛硬币试验  \n历史上有不少人做过抛硬币试验, 其结果见表 1.2.1. 从表中的数据可以看出: 出现正面的频率逐渐稳定在 0.5 , 用频率的方法可以说: 出现正面的概率为 0.5 .  \n表 1.2.1: 历史上抛硬币试验的若干结果  \n| 实验者 | 抛硬币次数 | 出现正面次数 | 频率 |\n| :--- | :--- | :--- | :--- |\n| 德莫根 (De morgan) | 2048 | 1061 | 0.5181 |\n| 蒲丰 (Buffon) | 4040 | 2048 | 0.5069 |\n| 费勒 (Feller) | 10000 | 4979 | 0.4979 |\n| 皮尔逊 (Pearson) | 12000 | 6019 | 0.5016 |\n| 皮尔逊 | 24000 | 12012 | 0.5005 |  \n2. 英语字母的频率  \n人们在生活实践中已经认识到: 英语中某些字母出现的频率要高于另外一些字母. 但 26 个英文字母各自出现的频率到底是多少? 有人对各类典型的英语书刊中字母出现的频率进行统计, 发现各个字母的使用频率相当稳定 (见表 1.2.2). 这项研究对计算机键盘的设计 (在方便的地方安排使用频率最高的宇母键)、信息的编码 (用较短的码编排使用频率最高的字母键) 等等方面都是十分有用的.  \n| 表 1.2.2: 英文字母的使用率 |  |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 字母 | 使用频率 | 字母 | 使用频率 | 字母 | 使用频率 |\n| $\\mathrm{E}$ | 0.1268 | $\\mathrm{~L}$ | 0.0394 | $\\mathrm{P}$ | 0.0186 |",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法",
            "Header 3": "1.2.3 确定概率的频率方法"
        },
        "type": "Document"
    },
    {
        "page_content": "| 皮尔逊 (Pearson) | 12000 | 6019 | 0.5016 |\n| 皮尔逊 | 24000 | 12012 | 0.5005 |  \n2. 英语字母的频率  \n人们在生活实践中已经认识到: 英语中某些字母出现的频率要高于另外一些字母. 但 26 个英文字母各自出现的频率到底是多少? 有人对各类典型的英语书刊中字母出现的频率进行统计, 发现各个字母的使用频率相当稳定 (见表 1.2.2). 这项研究对计算机键盘的设计 (在方便的地方安排使用频率最高的宇母键)、信息的编码 (用较短的码编排使用频率最高的字母键) 等等方面都是十分有用的.  \n| 表 1.2.2: 英文字母的使用率 |  |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 字母 | 使用频率 | 字母 | 使用频率 | 字母 | 使用频率 |\n| $\\mathrm{E}$ | 0.1268 | $\\mathrm{~L}$ | 0.0394 | $\\mathrm{P}$ | 0.0186 |\n| $\\mathrm{~T}$ | 0.0978 | $\\mathrm{D}$ | 0.0389 | $\\mathrm{~B}$ | 0.0156 |\n| $\\mathrm{~A}$ | 0.0788 | $\\mathrm{U}$ | 0.0280 | $\\mathrm{~V}$ | 0.0102 |\n| $\\mathrm{O}$ | 0.0776 | $\\mathrm{C}$ | 0.0268 | $\\mathrm{~K}$ | 0.0060 |\n| $\\mathrm{I}$ | 0.0707 | $\\mathrm{~F}$ | 0.0256 | $\\mathrm{X}$ | 0.0016 |\n| $\\mathrm{~N}$ | 0.0706 | $\\mathrm{M}$ | 0.0244 | $\\mathrm{~J}$ | 0.0010 |\n| $\\mathrm{~S}$ | 0.0634 | $\\mathrm{~W}$ | 0.0214 | $\\mathrm{Q}$ | 0.0009 |",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法",
            "Header 3": "1.2.3 确定概率的频率方法"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\mathrm{~T}$ | 0.0978 | $\\mathrm{D}$ | 0.0389 | $\\mathrm{~B}$ | 0.0156 |\n| $\\mathrm{~A}$ | 0.0788 | $\\mathrm{U}$ | 0.0280 | $\\mathrm{~V}$ | 0.0102 |\n| $\\mathrm{O}$ | 0.0776 | $\\mathrm{C}$ | 0.0268 | $\\mathrm{~K}$ | 0.0060 |\n| $\\mathrm{I}$ | 0.0707 | $\\mathrm{~F}$ | 0.0256 | $\\mathrm{X}$ | 0.0016 |\n| $\\mathrm{~N}$ | 0.0706 | $\\mathrm{M}$ | 0.0244 | $\\mathrm{~J}$ | 0.0010 |\n| $\\mathrm{~S}$ | 0.0634 | $\\mathrm{~W}$ | 0.0214 | $\\mathrm{Q}$ | 0.0009 |\n| $\\mathrm{R}$ | 0.0594 | $\\mathrm{Y}$ | 0.0202 | $\\mathrm{Z}$ | 0.0006 |\n| $\\mathrm{H}$ | 0.0573 | $\\mathrm{G}$ | 0.0187 |  |  |",
        "metadata": {
            "Header 2": "1.2 概率的定义及其确定方法",
            "Header 3": "1.2.3 确定概率的频率方法"
        },
        "type": "Document"
    },
    {
        "page_content": "研究女婴出生频率, 对人口统计是很重要的. 历史上较早研究这个问题的有拉普拉斯 (17941827), 他对伦敦、彼得堡、柏林和全法国的大量人口资料进行研究, 发现女要出生频率总是在 21/43 左右波动.  \n统计学家克拉梅 (1893-1985) 用瑞典 1935 年的官方统计资料 (见表 1.2.3), 发现女要出生频率总是在 0.482 左右波动.  \n表 1.2.3: 瑞典 1935 年各月出生女的频率  \n| 月份 | 1 | 2 | 3 | 4 | 5 | 6 |  |\n| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 婴儿数 | 7280 | 6957 | 7883 | 7884 | 7892 | 7609 |  |\n| 女婴数 | 3537 | 3407 | 3866 | 3711 | 3775 | 3665 |  |\n| 频率 | 0.486 | 0.489 | 0.490 | 0.471 | 0.478 | 0.482 |  |\n| 月份 | 7 | 8 | 9 | 10 | 11 | 12 | 全年 |\n| 婴儿数 | 7585 | 7393 | 7203 | 6903 | 6552 | 7132 | 88273 |\n| 女婴数 | 3621 | 3596 | 3491 | 3391 | 3160 | 3371 | 42591 |\n| 频率 | 0.462 | 0.484 | 0.485 | 0.491 | 0.482 | 0.473 | 0.4825 |",
        "metadata": {
            "Header 2": "3. 女婴出生频率"
        },
        "type": "Document"
    },
    {
        "page_content": "确定概率的古典方法是概率论历史上最先开始研究的情形. 它简单、直观, 不需要做大量重复试验, 而是在经验事实的基础上, 对被考察事件的可能性进行逻辑分析后得出该事件的概率.  \n古典方法的基本思想如下:  \n1. 所涉及的随机现象只有有限个样本点, 譬如为 $n$ 个.\n2. 每个样本点发生的可能性相等 (称为等可能性). 例如, 抛一枚均匀硬币, “出现正面”与 “出现反面” 的可能性相等; 抛一枚均匀骰子, 出现各点 (1-6) 的可能性相等; 从一副扑克牌中任取一张, 每张牌被取到的可能性相等.\n3. 若事件 $A$ 含有 $k$ 个样本点, 则事件 $A$ 的概率为  \n$$\n\\begin{equation*}\nP(A)=\\frac{\\text { 事件 } A \\text { 所含样本点的个数 }}{\\Omega \\text { 中所有样本点的个数 }}=\\frac{k}{n} \\text {. } \\tag{1.2.5}\n\\end{equation*}\n$$  \n容易验证, 由上式确定的概率满足公理化定义, 它的非负性与正则性是显然的; 而满足可加性的理由与频率方法类似: 当 $A$ 与 $B$ 互不相容时, 计算 $A \\cup B$ 的样本点个数可以分别计算 $A$ 的样本点个数和 $B$ 的样本点个数, 然后再相加, 从而有可加性 $P(A \\cup B)=P(A)+P(B)$.  \n在古典方法中, 求事件 $A$ 的概率主要是计算 $A$ 中含有的样本点的个数和 $\\Omega$ 中含有的样本点的个数. 所以在计算中经常用到排列组合工具.  \n例 1.2.2: 掷两枚硬币, 求出现一个正面一个反面的概率.  \n解: 此例的样本空间为 $\\Omega=\\{$ (正, 正), (正, 反), (反, 正), (反, 反) $\\}$. 所以 $\\Omega$ 中含有样本点的个数为 4 , 事件 “出现一个正面一个反面”含有的样本点的个数为 2 个, 因此所求概率为 $1 / 2$.  \n注意, 如果将此样本空间记成 $\\Omega=\\{$ (二正), (二反), (一正一反) $\\}$, 则此三个样本点不是等可能的.",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n容易验证, 由上式确定的概率满足公理化定义, 它的非负性与正则性是显然的; 而满足可加性的理由与频率方法类似: 当 $A$ 与 $B$ 互不相容时, 计算 $A \\cup B$ 的样本点个数可以分别计算 $A$ 的样本点个数和 $B$ 的样本点个数, 然后再相加, 从而有可加性 $P(A \\cup B)=P(A)+P(B)$.  \n在古典方法中, 求事件 $A$ 的概率主要是计算 $A$ 中含有的样本点的个数和 $\\Omega$ 中含有的样本点的个数. 所以在计算中经常用到排列组合工具.  \n例 1.2.2: 掷两枚硬币, 求出现一个正面一个反面的概率.  \n解: 此例的样本空间为 $\\Omega=\\{$ (正, 正), (正, 反), (反, 正), (反, 反) $\\}$. 所以 $\\Omega$ 中含有样本点的个数为 4 , 事件 “出现一个正面一个反面”含有的样本点的个数为 2 个, 因此所求概率为 $1 / 2$.  \n注意, 如果将此样本空间记成 $\\Omega=\\{$ (二正), (二反), (一正一反) $\\}$, 则此三个样本点不是等可能的.  \n在计算古典概型时, 一般不用把样本空间详细写出, 但一定要保证样本点为等可能. 以下是一些较为有用的模型, 请读者熟练掌握和灵活运用.  \n例 1.2.3 抽样模型: 一批产品共有 $N$ 个, 其中 $M$ 个是不合格品, $N-M$ 个是合格品. 从中随机取出 $n$ 个, 试求事件 $A_{m}=$ “取出的 $n$ 个产品中有 $m$ 个不合格品”的概率.  \n解: 先计算样本空间 $\\Omega$ 中样本点的个数: 从 $N$ 个产品中任取 $n$ 个, 因为不讲次序, 所以样本点的总数为 $\\left(\\begin{array}{l}N \\\\ n\\end{array}\\right)$. 又因为是随机抽取的, 所以这 $\\left(\\begin{array}{l}N \\\\ n\\end{array}\\right)$ 个样本点是等可能的.  \n下面我们先计算事件 $A_{0}, A_{1}$ 的概率, 然后再计算 $A_{m}$ 的概率.",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "注意, 如果将此样本空间记成 $\\Omega=\\{$ (二正), (二反), (一正一反) $\\}$, 则此三个样本点不是等可能的.  \n在计算古典概型时, 一般不用把样本空间详细写出, 但一定要保证样本点为等可能. 以下是一些较为有用的模型, 请读者熟练掌握和灵活运用.  \n例 1.2.3 抽样模型: 一批产品共有 $N$ 个, 其中 $M$ 个是不合格品, $N-M$ 个是合格品. 从中随机取出 $n$ 个, 试求事件 $A_{m}=$ “取出的 $n$ 个产品中有 $m$ 个不合格品”的概率.  \n解: 先计算样本空间 $\\Omega$ 中样本点的个数: 从 $N$ 个产品中任取 $n$ 个, 因为不讲次序, 所以样本点的总数为 $\\left(\\begin{array}{l}N \\\\ n\\end{array}\\right)$. 又因为是随机抽取的, 所以这 $\\left(\\begin{array}{l}N \\\\ n\\end{array}\\right)$ 个样本点是等可能的.  \n下面我们先计算事件 $A_{0}, A_{1}$ 的概率, 然后再计算 $A_{m}$ 的概率.  \n因为事件 $A_{0}=$ “取出的 $n$ 个产品中有 0 个不合格品” $=$ “取出的 $n$ 个产品全是合格品”, 这意味着取出的 $n$ 个产品全是从 $N-M$ 个合格品中抽取, 所以有 $\\left(\\begin{array}{c}N-M \\\\ n\\end{array}\\right)$ 种取法, 故 $A_{0}$ 的概率为  \n$$\nP\\left(A_{0}\\right)=\\frac{\\left(\\begin{array}{c}\nN-M \\\\\nn\n\\end{array}\\right)}{\\left(\\begin{array}{c}\nN \\\\\nn\n\\end{array}\\right)}\n$$  \n事件 $A_{1}=$ “取出的 $n$ 个产品中有 1 个不合格品”, 要使取出的 $n$ 个产品中只有一个不合格品,其他 $n-1$ 个是合格品, 那么必须分两步进行:  \n第一步: 从 $M$ 个不合格品中随机取出 1 个, 共有 $\\left(\\begin{array}{c}M \\\\ 1\\end{array}\\right)$ 种取法.",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "因为事件 $A_{0}=$ “取出的 $n$ 个产品中有 0 个不合格品” $=$ “取出的 $n$ 个产品全是合格品”, 这意味着取出的 $n$ 个产品全是从 $N-M$ 个合格品中抽取, 所以有 $\\left(\\begin{array}{c}N-M \\\\ n\\end{array}\\right)$ 种取法, 故 $A_{0}$ 的概率为  \n$$\nP\\left(A_{0}\\right)=\\frac{\\left(\\begin{array}{c}\nN-M \\\\\nn\n\\end{array}\\right)}{\\left(\\begin{array}{c}\nN \\\\\nn\n\\end{array}\\right)}\n$$  \n事件 $A_{1}=$ “取出的 $n$ 个产品中有 1 个不合格品”, 要使取出的 $n$ 个产品中只有一个不合格品,其他 $n-1$ 个是合格品, 那么必须分两步进行:  \n第一步: 从 $M$ 个不合格品中随机取出 1 个, 共有 $\\left(\\begin{array}{c}M \\\\ 1\\end{array}\\right)$ 种取法.  \n第二步: 从 $N-M$ 个合格品中随机取出 $n-1$ 个, 共有 $\\left(\\begin{array}{c}N-M \\\\ n-1\\end{array}\\right)$ 种取法.  \n所以根据乘法原理, $A_{1}$ 中共有 $\\left(\\begin{array}{c}M \\\\ 1\\end{array}\\right)\\left(\\begin{array}{c}N-M \\\\ n-1\\end{array}\\right)$ 个样本点. 故 $A_{1}$ 的概率为  \n$$\nP\\left(A_{1}\\right)=\\frac{\\left(\\begin{array}{c}\nM \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-1\n\\end{array}\\right)}{\\left(\\begin{array}{c}\nN \\\\\nn\n\\end{array}\\right)}\n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "第二步: 从 $N-M$ 个合格品中随机取出 $n-1$ 个, 共有 $\\left(\\begin{array}{c}N-M \\\\ n-1\\end{array}\\right)$ 种取法.  \n所以根据乘法原理, $A_{1}$ 中共有 $\\left(\\begin{array}{c}M \\\\ 1\\end{array}\\right)\\left(\\begin{array}{c}N-M \\\\ n-1\\end{array}\\right)$ 个样本点. 故 $A_{1}$ 的概率为  \n$$\nP\\left(A_{1}\\right)=\\frac{\\left(\\begin{array}{c}\nM \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-1\n\\end{array}\\right)}{\\left(\\begin{array}{c}\nN \\\\\nn\n\\end{array}\\right)}\n$$  \n有了以上对 $A_{0}$ 和 $A_{1}$ 的分析, 我们就容易计算一般事件 $A_{m}$ 中含有的样本点个数: 要使 $A_{m}$发生, 必须从 $M$ 个不合格品中抽 $m$ 个, 再从 $N-M$ 个合格品中抽 $n-m$ 个, 根据乘法原理, $A_{m}$ 含\n有 $\\left(\\begin{array}{c}M \\\\ m\\end{array}\\right)\\left(\\begin{array}{c}N-M \\\\ n-m\\end{array}\\right)$ 个样本点, 由此得 $A_{m}$ 的概率为  \n$$\nP\\left(A_{m}\\right)=\\frac{\\left(\\begin{array}{c}\nM  \\tag{1.2.6}\\\\\nm\n\\end{array}\\right)\\left(\\begin{array}{l}\nN-M \\\\\nn-m\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}, \\quad m=0,1,2, \\cdots, r, \\quad r=\\min (n, M)\n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "有 $\\left(\\begin{array}{c}M \\\\ m\\end{array}\\right)\\left(\\begin{array}{c}N-M \\\\ n-m\\end{array}\\right)$ 个样本点, 由此得 $A_{m}$ 的概率为  \n$$\nP\\left(A_{m}\\right)=\\frac{\\left(\\begin{array}{c}\nM  \\tag{1.2.6}\\\\\nm\n\\end{array}\\right)\\left(\\begin{array}{l}\nN-M \\\\\nn-m\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}, \\quad m=0,1,2, \\cdots, r, \\quad r=\\min (n, M)\n$$  \n注意, 在此应有 $m \\leqslant n, m \\leqslant M$. 所以 $m \\leqslant \\min (n, M)$, 否则其概率为 0 .  \n如果取 $N=9, M=3, n=4$, 则有  \n$$\n\\begin{aligned}\n& P\\left(A_{0}\\right)=\\frac{\\left(\\begin{array}{l}\n6 \\\\\n4\n\\end{array}\\right)}{\\left(\\begin{array}{l}\n9 \\\\\n4\n\\end{array}\\right)}=\\frac{5}{42} . \\\\\n& P\\left(A_{1}\\right)=\\frac{\\left(\\begin{array}{l}\n6 \\\\\n3\n\\end{array}\\right)\\left(\\begin{array}{l}\n3 \\\\\n1\n\\end{array}\\right)}{\\left(\\begin{array}{l}\n9 \\\\\n4\n\\end{array}\\right)}=\\frac{20}{42} . \\\\\n& P\\left(A_{2}\\right)=\\frac{\\left(\\begin{array}{l}\n6 \\\\\n2\n\\end{array}\\right)\\left(\\begin{array}{l}\n3 \\\\\n2\n\\end{array}\\right)}{\\left(\\begin{array}{l}\n9 \\\\\n4",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "& P\\left(A_{0}\\right)=\\frac{\\left(\\begin{array}{l}\n6 \\\\\n4\n\\end{array}\\right)}{\\left(\\begin{array}{l}\n9 \\\\\n4\n\\end{array}\\right)}=\\frac{5}{42} . \\\\\n& P\\left(A_{1}\\right)=\\frac{\\left(\\begin{array}{l}\n6 \\\\\n3\n\\end{array}\\right)\\left(\\begin{array}{l}\n3 \\\\\n1\n\\end{array}\\right)}{\\left(\\begin{array}{l}\n9 \\\\\n4\n\\end{array}\\right)}=\\frac{20}{42} . \\\\\n& P\\left(A_{2}\\right)=\\frac{\\left(\\begin{array}{l}\n6 \\\\\n2\n\\end{array}\\right)\\left(\\begin{array}{l}\n3 \\\\\n2\n\\end{array}\\right)}{\\left(\\begin{array}{l}\n9 \\\\\n4\n\\end{array}\\right)}=\\frac{15}{42} . \\\\\n& P\\left(A_{2}\\right)=\\frac{\\left(\\begin{array}{l}\n6 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{l}\n3 \\\\\n3\n\\end{array}\\right)}{\\left(\\begin{array}{l}\n9 \\\\\n4\n\\end{array}\\right)}=\\frac{2}{42} .\n\\end{aligned}\n$$  \n将以上计算结果列成表 1.2.4. 由于表中概率之和为 1 , 所以可称其为一个概率分布. 若把 $m$ 看  \n表 1.2.4: 事件 $A_{m}$ 的概率  \n| $m$ | 0 | 1 | 2 | 3 |\n| :--- | :--- | :--- | :--- | :--- |\n| $P\\left(A_{m}\\right)$ | $\\frac{5}{42}$ | $\\frac{20}{42}$ | $\\frac{15}{42}$ | $\\frac{2}{42}$ |",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "9 \\\\\n4\n\\end{array}\\right)}=\\frac{15}{42} . \\\\\n& P\\left(A_{2}\\right)=\\frac{\\left(\\begin{array}{l}\n6 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{l}\n3 \\\\\n3\n\\end{array}\\right)}{\\left(\\begin{array}{l}\n9 \\\\\n4\n\\end{array}\\right)}=\\frac{2}{42} .\n\\end{aligned}\n$$  \n将以上计算结果列成表 1.2.4. 由于表中概率之和为 1 , 所以可称其为一个概率分布. 若把 $m$ 看  \n表 1.2.4: 事件 $A_{m}$ 的概率  \n| $m$ | 0 | 1 | 2 | 3 |\n| :--- | :--- | :--- | :--- | :--- |\n| $P\\left(A_{m}\\right)$ | $\\frac{5}{42}$ | $\\frac{20}{42}$ | $\\frac{15}{42}$ | $\\frac{2}{42}$ |  \n作随机变量, 则此分布为 $m$ 的分布.  \n例 1.2.4 放回抽样: 抽样有两种方式: 不放回抽样与放回抽样. 上例讨论的是不放回抽样, 放回抽样是抽取一个后放回, 然后再抽取下一个.......如此重复直至抽出 $n$ 个为止. 现对例 1.2 .3 在有放回抽样情况下, 讨论事件 $B_{n}=$ “取出的 $n$ 个产品中有 $m$ 个不合格品”的概率.  \n解: 同样我们先计算样本空间 $\\Omega$ 中样本点的个数: 第一次抽取时, 可从 $N$ 个中任取一个, 有 $N$ 种取法. 因为是放回抽取, 所以第二次抽取时, 仍有 $N$ 种取法……如此下去, 每一次都有 $N$ 种取法,一共抽取了 $n$ 次, 所以共有 $N^{n}$ 个等可能的样本点.  \n事件 $B_{0}=$ “取出的 $n$ 个产品全是合格品” 发生必须从 $N-M$ 个合格品中有放回地抽取 $n$ 次,所以 $B_{0}$ 中含有 $(N-M)^{n}$ ”个样本点, 故 $B_{0}$ 的概率为  \n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "作随机变量, 则此分布为 $m$ 的分布.  \n例 1.2.4 放回抽样: 抽样有两种方式: 不放回抽样与放回抽样. 上例讨论的是不放回抽样, 放回抽样是抽取一个后放回, 然后再抽取下一个.......如此重复直至抽出 $n$ 个为止. 现对例 1.2 .3 在有放回抽样情况下, 讨论事件 $B_{n}=$ “取出的 $n$ 个产品中有 $m$ 个不合格品”的概率.  \n解: 同样我们先计算样本空间 $\\Omega$ 中样本点的个数: 第一次抽取时, 可从 $N$ 个中任取一个, 有 $N$ 种取法. 因为是放回抽取, 所以第二次抽取时, 仍有 $N$ 种取法……如此下去, 每一次都有 $N$ 种取法,一共抽取了 $n$ 次, 所以共有 $N^{n}$ 个等可能的样本点.  \n事件 $B_{0}=$ “取出的 $n$ 个产品全是合格品” 发生必须从 $N-M$ 个合格品中有放回地抽取 $n$ 次,所以 $B_{0}$ 中含有 $(N-M)^{n}$ ”个样本点, 故 $B_{0}$ 的概率为  \n$$\nP\\left(B_{0}\\right)=\\frac{(N-M)^{n}}{N^{n}}=\\left(1-\\frac{M}{N}\\right)^{n}\n$$  \n事件 $B_{1}=$ “取出的 $n$ 个中恰有 1 个不合格品”发生必须从 $N-M$ 个合格品中有放回地抽取 $n-1$ 次, 从 $M$ 个不合格品中抽取 1 次, 这样就有 $M \\cdot(N-M)^{n-1}$ 种取法. 再考虑到这个不合格品可能在第一次抽取中得到, 也可能在第二次抽取中得到…‥也可能在第 $n$ 次抽取中得到, 总共有 $n$种可能. 所以 $B_{1}$ 中含有 $n \\cdot M \\cdot(N-M)^{n}$ 个样本点, 故 $B_{1}$ 的概率为  \n$$\nP\\left(B_{1}\\right)=\\frac{n M(N-M)^{n-1}}{N^{n}}=n \\frac{M}{N}\\left(1-\\frac{M}{N}\\right)^{n-1} .\n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP\\left(B_{0}\\right)=\\frac{(N-M)^{n}}{N^{n}}=\\left(1-\\frac{M}{N}\\right)^{n}\n$$  \n事件 $B_{1}=$ “取出的 $n$ 个中恰有 1 个不合格品”发生必须从 $N-M$ 个合格品中有放回地抽取 $n-1$ 次, 从 $M$ 个不合格品中抽取 1 次, 这样就有 $M \\cdot(N-M)^{n-1}$ 种取法. 再考虑到这个不合格品可能在第一次抽取中得到, 也可能在第二次抽取中得到…‥也可能在第 $n$ 次抽取中得到, 总共有 $n$种可能. 所以 $B_{1}$ 中含有 $n \\cdot M \\cdot(N-M)^{n}$ 个样本点, 故 $B_{1}$ 的概率为  \n$$\nP\\left(B_{1}\\right)=\\frac{n M(N-M)^{n-1}}{N^{n}}=n \\frac{M}{N}\\left(1-\\frac{M}{N}\\right)^{n-1} .\n$$  \n事件 $B_{m}=$ “取出的 $n$ 个中恰有 $m$ 个不合格品” 发生必须从 $N-M$ 个合格品中有放回地抽取 $n-m$ 次, 从 $M$ 个不合格品中有放回地抽取 $m$ 次, 这样就有 $M^{m} \\cdot(N-M)^{n-m}$ 种取法. 再考虑到这 $m$ 个不合格品可能在 $n$ 次中的任何 $m$ 次抽取中得到, 总共有 $\\left(\\begin{array}{l}n \\\\ m\\end{array}\\right)$ 种可能. 所以事件 $B_{m}$ 含有 $\\left(\\begin{array}{l}n \\\\ m\\end{array}\\right) M_{m}(N-M)^{n-m}$ 个样本点, 故 $B_{m}$ 的概率为  \n$$\nP\\left(B_{m}\\right)=\\left(\\begin{array}{c}\nn  \\tag{1.2.7}\\\\\nm\n\\end{array}\\right) \\frac{M^{m}(N-M)^{n-m}}{N^{n}}=\\left(\\begin{array}{c}\nn \\\\\nm",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n事件 $B_{m}=$ “取出的 $n$ 个中恰有 $m$ 个不合格品” 发生必须从 $N-M$ 个合格品中有放回地抽取 $n-m$ 次, 从 $M$ 个不合格品中有放回地抽取 $m$ 次, 这样就有 $M^{m} \\cdot(N-M)^{n-m}$ 种取法. 再考虑到这 $m$ 个不合格品可能在 $n$ 次中的任何 $m$ 次抽取中得到, 总共有 $\\left(\\begin{array}{l}n \\\\ m\\end{array}\\right)$ 种可能. 所以事件 $B_{m}$ 含有 $\\left(\\begin{array}{l}n \\\\ m\\end{array}\\right) M_{m}(N-M)^{n-m}$ 个样本点, 故 $B_{m}$ 的概率为  \n$$\nP\\left(B_{m}\\right)=\\left(\\begin{array}{c}\nn  \\tag{1.2.7}\\\\\nm\n\\end{array}\\right) \\frac{M^{m}(N-M)^{n-m}}{N^{n}}=\\left(\\begin{array}{c}\nn \\\\\nm\n\\end{array}\\right)\\left(\\frac{M}{N}\\right)^{m}\\left(1-\\frac{M}{N}\\right)^{n-m}, \\quad m=0,1,2, \\cdots, n .\n$$  \n由于是放回抽样, 不合格品在整批产品中所占比例是不变的, 记此比例为 $p$, 则上式可改写为  \n$$\nP\\left(B_{m}\\right)=\\left(\\begin{array}{c}\nn \\\\\nm\n\\end{array}\\right) p^{m}(1-p)^{n-m} \\quad m=0,1,2, \\cdots, n .\n$$  \n同样取 $N=9, M=3, n=4$, 则有  \n$$\n\\begin{aligned}\n& P\\left(B_{0}\\right)=\\left(1-\\frac{3}{9}\\right)^{4}=\\frac{16}{81} \\\\\n& P\\left(B_{1}\\right)=4 \\frac{1}{3}\\left(\\frac{2}{3}\\right)^{3}=\\frac{32}{81} \\\\",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "n \\\\\nm\n\\end{array}\\right)\\left(\\frac{M}{N}\\right)^{m}\\left(1-\\frac{M}{N}\\right)^{n-m}, \\quad m=0,1,2, \\cdots, n .\n$$  \n由于是放回抽样, 不合格品在整批产品中所占比例是不变的, 记此比例为 $p$, 则上式可改写为  \n$$\nP\\left(B_{m}\\right)=\\left(\\begin{array}{c}\nn \\\\\nm\n\\end{array}\\right) p^{m}(1-p)^{n-m} \\quad m=0,1,2, \\cdots, n .\n$$  \n同样取 $N=9, M=3, n=4$, 则有  \n$$\n\\begin{aligned}\n& P\\left(B_{0}\\right)=\\left(1-\\frac{3}{9}\\right)^{4}=\\frac{16}{81} \\\\\n& P\\left(B_{1}\\right)=4 \\frac{1}{3}\\left(\\frac{2}{3}\\right)^{3}=\\frac{32}{81} \\\\\n& P\\left(B_{2}\\right)=6\\left(\\frac{1}{3}\\right)^{2}\\left(\\frac{2}{3}\\right)^{2}=\\frac{24}{81}, \\\\\n& P\\left(B_{3}\\right)=4\\left(\\frac{1}{3}\\right)^{3}\\left(\\frac{2}{3}\\right)=\\frac{8}{81} \\\\\n& P\\left(B_{4}\\right)=\\left(\\frac{1}{3}\\right)^{4}=\\frac{1}{81} .\n\\end{aligned}\n$$  \n将以上计算结果列成表 1.2.5:  \n表 1.2.5: 事件 $B_{m}$ 的概率  \n| $m$ | 0 | 1 | 2 | 3 | 4 |\n| :---: | :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "& P\\left(B_{1}\\right)=4 \\frac{1}{3}\\left(\\frac{2}{3}\\right)^{3}=\\frac{32}{81} \\\\\n& P\\left(B_{2}\\right)=6\\left(\\frac{1}{3}\\right)^{2}\\left(\\frac{2}{3}\\right)^{2}=\\frac{24}{81}, \\\\\n& P\\left(B_{3}\\right)=4\\left(\\frac{1}{3}\\right)^{3}\\left(\\frac{2}{3}\\right)=\\frac{8}{81} \\\\\n& P\\left(B_{4}\\right)=\\left(\\frac{1}{3}\\right)^{4}=\\frac{1}{81} .\n\\end{aligned}\n$$  \n将以上计算结果列成表 1.2.5:  \n表 1.2.5: 事件 $B_{m}$ 的概率  \n| $m$ | 0 | 1 | 2 | 3 | 4 |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $P\\left(B_{m}\\right)$ | $\\frac{16}{81}$ | $\\frac{32}{81}$ | $\\frac{24}{81}$ | $\\frac{8}{81}$ | $\\frac{1}{81}$ |  \n表 1.2 .5 中的概率之和为 1 , 它可以称为一个分布. 从上表中我们可以看出  \n$$\nP(m \\leqslant 1)=P(m=0)+P(m=1)=\\frac{16}{27} .\n$$  \n例 1.2.5 彩票问题: 一种福利彩票称为幸福 35 选 7 , 即从 $01,02, \\ldots, 35$ 中不重复地开出 7 个基本号码和一个特殊号码. 中各等奖的规则如表 1.2.6, 试求各等奖的中奖概率.  \n表 1.2.6: 幸福 35 选 7 的中奖规则  \n| 中奖级别 | 中奖规则 |\n| :--- | :--- |\n| 二等奖 | 7 个基本号码全中 |\n| 二等奖 | 中 6 个基本号码及特殊号码 |\n| 三等奖 | 中 6 个基本号码 |\n| 四等奖 | 中 5 个基本号码及特殊号码 |\n| 五等奖 | 中 5 个基本号码 |",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "| $P\\left(B_{m}\\right)$ | $\\frac{16}{81}$ | $\\frac{32}{81}$ | $\\frac{24}{81}$ | $\\frac{8}{81}$ | $\\frac{1}{81}$ |  \n表 1.2 .5 中的概率之和为 1 , 它可以称为一个分布. 从上表中我们可以看出  \n$$\nP(m \\leqslant 1)=P(m=0)+P(m=1)=\\frac{16}{27} .\n$$  \n例 1.2.5 彩票问题: 一种福利彩票称为幸福 35 选 7 , 即从 $01,02, \\ldots, 35$ 中不重复地开出 7 个基本号码和一个特殊号码. 中各等奖的规则如表 1.2.6, 试求各等奖的中奖概率.  \n表 1.2.6: 幸福 35 选 7 的中奖规则  \n| 中奖级别 | 中奖规则 |\n| :--- | :--- |\n| 二等奖 | 7 个基本号码全中 |\n| 二等奖 | 中 6 个基本号码及特殊号码 |\n| 三等奖 | 中 6 个基本号码 |\n| 四等奖 | 中 5 个基本号码及特殊号码 |\n| 五等奖 | 中 5 个基本号码 |\n| 六等奖 | 中 4 个基本号码及特殊号码 |\n| 七等奖 | 中 4 个基本号码, 或中 3 个基本号码及特殊号码 |  \n解: 因为不重复地选号码是一种不放回抽样, 所以样本空间 $\\Omega$ 含有 $\\left(\\begin{array}{c}35 \\\\ 7\\end{array}\\right)$ 个样本点. 要中奖应把抽取看成是在三种类型中抽取:  \n第一类号码: 7 个基本号码;  \n第二类号码: 1 个特殊号码;  \n第三类号码: 27 个无用号码.  \n注意到例 1.2.3 中是在两类元素 (合格品和不合格品) 中抽取, 如今在三类号码中抽取, 若记 $p_{i}$为中第 $i$ 等奖的概率 $(i=1,2, \\cdots, 7)$, 仿照例 1.2 . 3 的方法, 可得各等奖的中奖概率如下  \n$$\n\\begin{aligned}\n& p_{1}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n7\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n0",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "| 五等奖 | 中 5 个基本号码 |\n| 六等奖 | 中 4 个基本号码及特殊号码 |\n| 七等奖 | 中 4 个基本号码, 或中 3 个基本号码及特殊号码 |  \n解: 因为不重复地选号码是一种不放回抽样, 所以样本空间 $\\Omega$ 含有 $\\left(\\begin{array}{c}35 \\\\ 7\\end{array}\\right)$ 个样本点. 要中奖应把抽取看成是在三种类型中抽取:  \n第一类号码: 7 个基本号码;  \n第二类号码: 1 个特殊号码;  \n第三类号码: 27 个无用号码.  \n注意到例 1.2.3 中是在两类元素 (合格品和不合格品) 中抽取, 如今在三类号码中抽取, 若记 $p_{i}$为中第 $i$ 等奖的概率 $(i=1,2, \\cdots, 7)$, 仿照例 1.2 . 3 的方法, 可得各等奖的中奖概率如下  \n$$\n\\begin{aligned}\n& p_{1}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n7\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n0\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n0\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=0.149 \\times 10^{-6}, \\\\\n& p_{2}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n6\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n0\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=1.04 \\times 10^{-6}, \\\\\n& p_{3}=\\frac{\\left(\\begin{array}{c}\n7 \\\\\n6\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n0",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "1 \\\\\n0\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n0\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=0.149 \\times 10^{-6}, \\\\\n& p_{2}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n6\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n0\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=1.04 \\times 10^{-6}, \\\\\n& p_{3}=\\frac{\\left(\\begin{array}{c}\n7 \\\\\n6\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n0\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n1\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=28.106 \\times 10^{-6}, \\\\\n& p_{4}=\\frac{\\left(\\begin{array}{c}\n7 \\\\\n5\n\\end{array}\\right)\\left(\\begin{array}{c}\n1 \\\\\n1 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n1\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=84.318 \\times 10^{-6},\n\\end{aligned}\n$$  \n$$\n\\begin{aligned}\n& p_{5}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n5\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n0",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "27 \\\\\n1\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=28.106 \\times 10^{-6}, \\\\\n& p_{4}=\\frac{\\left(\\begin{array}{c}\n7 \\\\\n5\n\\end{array}\\right)\\left(\\begin{array}{c}\n1 \\\\\n1 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n1\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=84.318 \\times 10^{-6},\n\\end{aligned}\n$$  \n$$\n\\begin{aligned}\n& p_{5}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n5\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n0\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n2\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=1.096 \\times 10^{-3}, \\\\\n& p_{6}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n4\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n2\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=1.827 \\times 10^{-3}, \\\\\n& p_{7}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n4\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n0\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n3",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "27 \\\\\n2\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=1.096 \\times 10^{-3}, \\\\\n& p_{6}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n4\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n2\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=1.827 \\times 10^{-3}, \\\\\n& p_{7}=\\frac{\\left(\\begin{array}{l}\n7 \\\\\n4\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n0\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n3\n\\end{array}\\right)+\\left(\\begin{array}{l}\n7 \\\\\n3\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n3\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=30.448 \\times 10^{-3} .\n\\end{aligned}\n$$  \n若记 $A$ 为事件 “中奖”, 则 $\\bar{A}$ 为事件 “不中奖”, 且由 $P(A)+P(A)=P(\\Omega)=1$ 可得  \n$$\n\\begin{aligned}\nP(\\text { 中奖 }) & =P(A)=p_{1}+p_{2}+\\cdots+p_{7}=0.033485, \\\\\nP(\\text { 不中奖 }) & =P(\\bar{A})=1-P(A)=0.966515 .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "27 \\\\\n3\n\\end{array}\\right)+\\left(\\begin{array}{l}\n7 \\\\\n3\n\\end{array}\\right)\\left(\\begin{array}{l}\n1 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n27 \\\\\n3\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n35 \\\\\n7\n\\end{array}\\right)}=30.448 \\times 10^{-3} .\n\\end{aligned}\n$$  \n若记 $A$ 为事件 “中奖”, 则 $\\bar{A}$ 为事件 “不中奖”, 且由 $P(A)+P(A)=P(\\Omega)=1$ 可得  \n$$\n\\begin{aligned}\nP(\\text { 中奖 }) & =P(A)=p_{1}+p_{2}+\\cdots+p_{7}=0.033485, \\\\\nP(\\text { 不中奖 }) & =P(\\bar{A})=1-P(A)=0.966515 .\n\\end{aligned}\n$$  \n这就说明: 一百个人中约有 3 人中奖; 而中头奖的概率只有 $0.149 \\times 10^{-6}$, 即二千万个人中约有 3 人中头奖. 因此购买彩票要有平常心, 期望值不宜过高.  \n例 1.2.6 盒子模型: 设有 $n$ 个球, 每个球都等可能地被放到 $N$ 个不同盒子中的任一个, 每个盒子所放球数不限. 试求  \n1. 指定的 $n(n \\leqslant N)$ 个盒子中各有一球的概率 $p_{1}$;\n2. 恰好有 $n(n \\leqslant N)$ 个盒子各有一球的概率 $p_{2}$.  \n解：因为每个球都可放到 $N$ 个盒子中的任一个, 所以 $n$ 个球放的方式共有 $N^{n}$ 种, 它们是等可能的.  \n1. 因为各有一球的 $n$ 个盒子已经指定, 余下的没有球的 $N-n$ 个盒子也同时被指定, 所以只要考虑 $n$ 个球在这指定的 $n$ 个盒子中各放 1 个的放法数. 设想第 1 个球有 $n$ 种放法, 第 2 个球只有 $n-1$ 种放法...第 $n$ 个球只有 1 种放法, 所以根据乘法原则, 其可能总数为 $n$ !, 因此其概率为  \n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "例 1.2.6 盒子模型: 设有 $n$ 个球, 每个球都等可能地被放到 $N$ 个不同盒子中的任一个, 每个盒子所放球数不限. 试求  \n1. 指定的 $n(n \\leqslant N)$ 个盒子中各有一球的概率 $p_{1}$;\n2. 恰好有 $n(n \\leqslant N)$ 个盒子各有一球的概率 $p_{2}$.  \n解：因为每个球都可放到 $N$ 个盒子中的任一个, 所以 $n$ 个球放的方式共有 $N^{n}$ 种, 它们是等可能的.  \n1. 因为各有一球的 $n$ 个盒子已经指定, 余下的没有球的 $N-n$ 个盒子也同时被指定, 所以只要考虑 $n$ 个球在这指定的 $n$ 个盒子中各放 1 个的放法数. 设想第 1 个球有 $n$ 种放法, 第 2 个球只有 $n-1$ 种放法...第 $n$ 个球只有 1 种放法, 所以根据乘法原则, 其可能总数为 $n$ !, 因此其概率为  \n$$\n\\begin{equation*}\np_{1}=\\frac{n !}{N^{n}} \\tag{1.2.8}\n\\end{equation*}\n$$  \n2. 与上面的差别在于: 此 $n$ 个盒子可以在 $N$ 个盒子中任意选取. 此时可分两步做: 第一步从 $N$个盒子中任取 $n$ 个盒子准备放球, 共有 $\\left(\\begin{array}{l}N \\\\ n\\end{array}\\right)$ 种取法; 第二步将 $n$ 个球放人选中的 $n$ 个盒子中,每个盒子各放 1 个球, 共有 $n$ ! 种放法. 所以根据乘法原则共有  \n$$\n\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right) \\cdot n !=P_{N}^{n}=N(N-1)(N-2) \\cdots(N-n+1)\n$$  \n种放法. 其实这个放法数可以更直接的考虑成: 第 1 个球可放在 $N$ 个盒子中的任一个, 第 2 个球只可放在余下的 $N-1$ 个盒子中的任一个...第 $n$ 个球只可放在余下的 $N-n+1$ 个盒子中的任一个, 由乘法原则即可得以上放法数. 因此所求概率为  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n2. 与上面的差别在于: 此 $n$ 个盒子可以在 $N$ 个盒子中任意选取. 此时可分两步做: 第一步从 $N$个盒子中任取 $n$ 个盒子准备放球, 共有 $\\left(\\begin{array}{l}N \\\\ n\\end{array}\\right)$ 种取法; 第二步将 $n$ 个球放人选中的 $n$ 个盒子中,每个盒子各放 1 个球, 共有 $n$ ! 种放法. 所以根据乘法原则共有  \n$$\n\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right) \\cdot n !=P_{N}^{n}=N(N-1)(N-2) \\cdots(N-n+1)\n$$  \n种放法. 其实这个放法数可以更直接的考虑成: 第 1 个球可放在 $N$ 个盒子中的任一个, 第 2 个球只可放在余下的 $N-1$ 个盒子中的任一个...第 $n$ 个球只可放在余下的 $N-n+1$ 个盒子中的任一个, 由乘法原则即可得以上放法数. 因此所求概率为  \n$$\n\\begin{equation*}\np_{2}=\\frac{P_{N}^{n}}{N^{n}}=\\frac{N !}{N^{n}(N-n) !} \\tag{1.2.9}\n\\end{equation*}\n$$  \n表面上看, 盒子模型讨论的是球和盒子问题, 似乎是一种游戏, 但实际上我们可以将这个模型应用到很多实际问题中. 譬如将球解释为 “粒子”, 把盒子解释为相空间中的小 “区域”, 则这个问题便是统计物理学中的马克斯威尔-波尔兹曼 (Maxwell-Boltzmann) 统计. 若 $n$ 个“粒子”是不可辨的,便是波色-爱因斯坦 (Bose-Einstein) 统计. 若 $n$ 个 “粒子” 是不可辨的, 且每个 “盒子”里最多只能放一个“粒子”, 这时就是费米-狄拉克 (Fermi-Drac) 统计. 这三种统计在物理学中有各自的适用范围,详细情况请参看文献 [?].  \n下面我们用盒子模型来讨论概率论历史上颇为有名的 “生日问题”.  \n例 1.2.7 生日问题: $n$ 个人的生日全不相同的概率 $p_{n}$ 是多少?",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\np_{2}=\\frac{P_{N}^{n}}{N^{n}}=\\frac{N !}{N^{n}(N-n) !} \\tag{1.2.9}\n\\end{equation*}\n$$  \n表面上看, 盒子模型讨论的是球和盒子问题, 似乎是一种游戏, 但实际上我们可以将这个模型应用到很多实际问题中. 譬如将球解释为 “粒子”, 把盒子解释为相空间中的小 “区域”, 则这个问题便是统计物理学中的马克斯威尔-波尔兹曼 (Maxwell-Boltzmann) 统计. 若 $n$ 个“粒子”是不可辨的,便是波色-爱因斯坦 (Bose-Einstein) 统计. 若 $n$ 个 “粒子” 是不可辨的, 且每个 “盒子”里最多只能放一个“粒子”, 这时就是费米-狄拉克 (Fermi-Drac) 统计. 这三种统计在物理学中有各自的适用范围,详细情况请参看文献 [?].  \n下面我们用盒子模型来讨论概率论历史上颇为有名的 “生日问题”.  \n例 1.2.7 生日问题: $n$ 个人的生日全不相同的概率 $p_{n}$ 是多少?  \n解: 把 $n$ 个人看成是 $n$ 个球, 将一年 365 天看成是 $N=365$ 个盒子, 则 “ $n$ 个人的生日全不相同”\n就相当于 “恰好有 $n(n \\leqslant N)$ 个盒子各有一球”, 所以 $n$ 个人的生日全不相同的概率为  \n$$\n\\begin{equation*}\nP_{n}=\\frac{365 !}{365^{n}(365-n) !}=\\left(1-\\frac{1}{365}\\right)\\left(1-\\frac{2}{365}\\right) \\cdots\\left(1-\\frac{n-1}{365}\\right) \\tag{1.2.10}\n\\end{equation*}\n$$  \n上式看似简单,但其具体计算是繁琐的,对此可用以下方法作近似计算:  \n1. 当 $n$ 较小时, (1.2.10) 右边中各因子的第二项之间的乘积 $\\frac{i}{365} \\times \\frac{j}{365}$ 都可以忽略, 于是有近似公式  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 把 $n$ 个人看成是 $n$ 个球, 将一年 365 天看成是 $N=365$ 个盒子, 则 “ $n$ 个人的生日全不相同”\n就相当于 “恰好有 $n(n \\leqslant N)$ 个盒子各有一球”, 所以 $n$ 个人的生日全不相同的概率为  \n$$\n\\begin{equation*}\nP_{n}=\\frac{365 !}{365^{n}(365-n) !}=\\left(1-\\frac{1}{365}\\right)\\left(1-\\frac{2}{365}\\right) \\cdots\\left(1-\\frac{n-1}{365}\\right) \\tag{1.2.10}\n\\end{equation*}\n$$  \n上式看似简单,但其具体计算是繁琐的,对此可用以下方法作近似计算:  \n1. 当 $n$ 较小时, (1.2.10) 右边中各因子的第二项之间的乘积 $\\frac{i}{365} \\times \\frac{j}{365}$ 都可以忽略, 于是有近似公式  \n$$\n\\begin{equation*}\np_{n} \\approx 1-\\frac{1+2+\\cdots+(n-1)}{365}=1-\\frac{n(n-1)}{730} \\tag{1.2.11}\n\\end{equation*}\n$$  \n2. 当 $n$ 较大时, 因为对小的正数 $x$, 有 $\\ln (1-x) \\approx-x$, 所以由 (1.2.10) 得  \n$$\n\\begin{equation*}\n\\ln p_{n} \\approx \\frac{1+2+\\cdots+(n-1)}{365}=-\\frac{n(n-1)}{730} . \\tag{1.2.12}\n\\end{equation*}\n$$  \n例如当 $n=10$ 时, 由 (1.2.12) 给出的近似值为 0.8840 , 而糟确值为 $p_{n}=0.8831 \\ldots ; n=30$时, 近似值为 0.3037 , 精确值为 $p_{n}=0.2937$.",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\np_{n} \\approx 1-\\frac{1+2+\\cdots+(n-1)}{365}=1-\\frac{n(n-1)}{730} \\tag{1.2.11}\n\\end{equation*}\n$$  \n2. 当 $n$ 较大时, 因为对小的正数 $x$, 有 $\\ln (1-x) \\approx-x$, 所以由 (1.2.10) 得  \n$$\n\\begin{equation*}\n\\ln p_{n} \\approx \\frac{1+2+\\cdots+(n-1)}{365}=-\\frac{n(n-1)}{730} . \\tag{1.2.12}\n\\end{equation*}\n$$  \n例如当 $n=10$ 时, 由 (1.2.12) 给出的近似值为 0.8840 , 而糟确值为 $p_{n}=0.8831 \\ldots ; n=30$时, 近似值为 0.3037 , 精确值为 $p_{n}=0.2937$.  \n这个数值结果是令人吃惊的, 因为许多人会认为: 一年 365 天, 30 个人的生日全不相同的可能性是较大的, 至少会大于 $1 / 2$. 甚至有人会认为: 100 个人的生日全不相同的可能性也是较大的. 对一些不同的 $n$ 值, 表 1.2.7 列出用 (1.2.12) 近似公式计算出的 $p$ 值.  \n表 1.2.7: $p_{n}$ 的近似值.  \n| $n$ | 10 | 20 | 30 | 40 | 50 | 60 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $p_{n}$ | 0.8840 | 0.5942 | 0.3037 | 0.1180 | 0.0349 | 0.0078 |\n| $1-p_{n}$ | 0.1160 | 0.4058 | 0.6963 | 0.8820 | 0.9651 | 0.9922 |  \n表中最后一行是对立事件 “ $n$ 个人中至少有两个人生日相同” 的概率 $1-p_{n}$. 当 $n=60$ 时, $1-p_{n}=0.9922$ 表明在 60 个人的群体中至少有两个人生日相同的概率超过 $99 \\%$, 这是出乎人们预料的.",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.4 确定概率的古典方法"
        },
        "type": "Document"
    },
    {
        "page_content": "确定概率的几何方法, 其基本思想是:  \n1. 如果一个随机现象的样本空间 $\\Omega$ 充满某个区域, 其度量 (长度、面积或体积等) 大小可用 $S_{\\Omega}$表示;\n2. 任意一点落在度量相同的子区域内是等可能的. 譬如在样本空间 $\\Omega$ 中有一单位正方形 $A$ 和直角边为 1 与 2 的直角三角形 $B$, 面点落在区域 $A$ 和区域 $B$ 是等可能的, 因为这两个区域面积相等 (见图 1.2.1);\n3. 若事件 $A$ 为 $\\Omega$ 中的某个子区域 (见图 1.2.2), 且其度量大小可用 $S_{A}$ 表示, 则事件 $A$ 的概率为  \n$$\n\\begin{equation*}\nP(A)=\\frac{S_{A}}{S_{\\Omega}} \\tag{1.2.13}\n\\end{equation*}\n$$  \n!  \n图 1.2.1: 落在度量相同的子区域内的等可能性.  \n!  \n图 1.2.2: 几何概率.\n这个概率称为几何概率, 它满足概率的公理化定义.  \n求几何概率的关键是对样本空间 $\\Omega$ 和所求事件 $A$ 用图形描述清楚 (一般用平面或空间图形).然后计算出相关图形的度量 (一般为面积或体积).  \n例 1.2.8 会商问题: 甲乙两人约定在下午 6 时到 7 时之间在某处会面, 并约定先到者应等候另一个人 $20 \\mathrm{~min}$, 过时即可离去. 求两人能会面的概率.  \n解: 以 $x$ 和 $y$ 分别表示甲、乙两人到达约会地点的时间 (以 $\\min$ 为单位), 在平面上建立 $x O y$ 直角坐标系 (见图 1.2.3).  \n!  \n图 1.2.3: 会面问题中的 $\\Omega$ 与 $A$.  \n因为甲、乙都是在 0 至 $60 \\mathrm{~min}$ 内等可能地到达, 所以由等可能性知这是一个几何概率问题. $(x, y)$ 的所有可能取值是边长为 60 的正方形, 其面积为 $S_{\\Omega}=60^{2}$. 而事件 $A=$ “两人能够会面”相当于:  \n$$\n|x-y| \\leqslant 20\n$$  \n即图中的阴影部分, 其面积为 $S_{A}=60^{2}-40^{2}$, 由 (1.2.13) 式知  \n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.5 确定概率的几何方法"
        },
        "type": "Document"
    },
    {
        "page_content": "例 1.2.8 会商问题: 甲乙两人约定在下午 6 时到 7 时之间在某处会面, 并约定先到者应等候另一个人 $20 \\mathrm{~min}$, 过时即可离去. 求两人能会面的概率.  \n解: 以 $x$ 和 $y$ 分别表示甲、乙两人到达约会地点的时间 (以 $\\min$ 为单位), 在平面上建立 $x O y$ 直角坐标系 (见图 1.2.3).  \n!  \n图 1.2.3: 会面问题中的 $\\Omega$ 与 $A$.  \n因为甲、乙都是在 0 至 $60 \\mathrm{~min}$ 内等可能地到达, 所以由等可能性知这是一个几何概率问题. $(x, y)$ 的所有可能取值是边长为 60 的正方形, 其面积为 $S_{\\Omega}=60^{2}$. 而事件 $A=$ “两人能够会面”相当于:  \n$$\n|x-y| \\leqslant 20\n$$  \n即图中的阴影部分, 其面积为 $S_{A}=60^{2}-40^{2}$, 由 (1.2.13) 式知  \n$$\nP(A)=\\frac{S_{A}}{S_{\\Omega}}=\\frac{60^{2}-40^{2}}{60^{2}}=0.5556\n$$  \n结果表明: 按此规则约会, 两人能会面的概率不超过 0.6. 若把约定时间改为在下午 6 时到 6 时 30 分, 其他不变, 则两人能会面的概率提高到 0.8889 .  \n例 1.2.9 蒲丰投针问题: 平面上画有间隔为 $d(d>0)$ 的等距平行线, 向平面任意投郑一枚长为 $l(l<d)$ 的针, 求针与任一平行线相交的概率.  \n解: 以 $x$ 表示针的中点与最近一条平行线的距离, 又以 $\\varphi$ 表示针与此直线间的交角, 见图 1.2.4. 易知样本空间 $\\Omega$ 满足  \n$$\n0 \\leqslant x \\leqslant d / 2, \\quad 0 \\leqslant \\varphi \\leqslant \\pi\n$$  \n由这两式可以确定 $x-\\varphi$ 平面上的一个矩形 $\\Omega$, 这就是样本空间, 其面积为 $S_{\\Omega}=d \\pi / 2$. 这时为了针与平行线相交 (记为事件 $A$ ), 其充要条件是  \n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.5 确定概率的几何方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n结果表明: 按此规则约会, 两人能会面的概率不超过 0.6. 若把约定时间改为在下午 6 时到 6 时 30 分, 其他不变, 则两人能会面的概率提高到 0.8889 .  \n例 1.2.9 蒲丰投针问题: 平面上画有间隔为 $d(d>0)$ 的等距平行线, 向平面任意投郑一枚长为 $l(l<d)$ 的针, 求针与任一平行线相交的概率.  \n解: 以 $x$ 表示针的中点与最近一条平行线的距离, 又以 $\\varphi$ 表示针与此直线间的交角, 见图 1.2.4. 易知样本空间 $\\Omega$ 满足  \n$$\n0 \\leqslant x \\leqslant d / 2, \\quad 0 \\leqslant \\varphi \\leqslant \\pi\n$$  \n由这两式可以确定 $x-\\varphi$ 平面上的一个矩形 $\\Omega$, 这就是样本空间, 其面积为 $S_{\\Omega}=d \\pi / 2$. 这时为了针与平行线相交 (记为事件 $A$ ), 其充要条件是  \n$$\nx \\leqslant \\frac{l}{2} \\sin \\varphi\n$$  \n由这个不等式表示的区域是图 1.2.5 中的阴影部分.  \n由于针是向平面任意投郑的, 所以由等可能性知这是一个几何概率问题. 由此得  \n$$\nP(A)=\\frac{S_{A}}{S_{\\Omega}}=\\frac{\\int_{0}^{\\pi} \\frac{l}{2} \\sin \\varphi \\mathrm{d} \\varphi}{\\frac{d}{2} \\pi}=\\frac{2 l}{d \\pi}\n$$  \n如果 $l, d$ 为已知, 则以 $\\pi$ 的值代人上式即可计算得 $P(A)$ 之值. 反之, 如果已知 $P(A)$ 的值, 则也可以利用上式去求 $\\pi$, 而关于 $P(A)$ 的值, 可用从试验中获得的频率去近似它: 即投针 $N$ 次, 其中针与平行线相交 $n$ 次, 则频率 $n / N$ 可作为 $P(A)$ 的估计值, 于是由  \n$$\n\\frac{n}{N} \\approx P(A)=\\frac{2 l}{d \\pi}\n$$  \n!  \n图 1.2.4: 蒲丰投针问题  \n!  \n图 1.2.5: 蒲丰投针问题中的 $\\Omega$ 和 $A$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.5 确定概率的几何方法"
        },
        "type": "Document"
    },
    {
        "page_content": "由于针是向平面任意投郑的, 所以由等可能性知这是一个几何概率问题. 由此得  \n$$\nP(A)=\\frac{S_{A}}{S_{\\Omega}}=\\frac{\\int_{0}^{\\pi} \\frac{l}{2} \\sin \\varphi \\mathrm{d} \\varphi}{\\frac{d}{2} \\pi}=\\frac{2 l}{d \\pi}\n$$  \n如果 $l, d$ 为已知, 则以 $\\pi$ 的值代人上式即可计算得 $P(A)$ 之值. 反之, 如果已知 $P(A)$ 的值, 则也可以利用上式去求 $\\pi$, 而关于 $P(A)$ 的值, 可用从试验中获得的频率去近似它: 即投针 $N$ 次, 其中针与平行线相交 $n$ 次, 则频率 $n / N$ 可作为 $P(A)$ 的估计值, 于是由  \n$$\n\\frac{n}{N} \\approx P(A)=\\frac{2 l}{d \\pi}\n$$  \n!  \n图 1.2.4: 蒲丰投针问题  \n!  \n图 1.2.5: 蒲丰投针问题中的 $\\Omega$ 和 $A$  \n可得  \n$$\n\\pi \\approx \\frac{2 l N}{d n}\n$$  \n历史上有一些学者曾亲自做过这个试验, 下表记录了他们的试验结果.  \n| 试验者 | 年份 | $l / d$ | 投郑次数 | 相交次数 | $\\pi$ 的近似值 |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| Wolf | 1850 | 0.8 | 5000 | 2532 | 3.1596 |\n| Fox | 1884 | 0.75 | 1030 | 489 | 3.1595 |\n| Lazzerini | 1901 | 0.83 | 3408 | 1808 | 3.1415 |\n| Reina | 1925 | 0.54 | 2520 | 859 | 3.1795 |",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.5 确定概率的几何方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\frac{n}{N} \\approx P(A)=\\frac{2 l}{d \\pi}\n$$  \n!  \n图 1.2.4: 蒲丰投针问题  \n!  \n图 1.2.5: 蒲丰投针问题中的 $\\Omega$ 和 $A$  \n可得  \n$$\n\\pi \\approx \\frac{2 l N}{d n}\n$$  \n历史上有一些学者曾亲自做过这个试验, 下表记录了他们的试验结果.  \n| 试验者 | 年份 | $l / d$ | 投郑次数 | 相交次数 | $\\pi$ 的近似值 |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| Wolf | 1850 | 0.8 | 5000 | 2532 | 3.1596 |\n| Fox | 1884 | 0.75 | 1030 | 489 | 3.1595 |\n| Lazzerini | 1901 | 0.83 | 3408 | 1808 | 3.1415 |\n| Reina | 1925 | 0.54 | 2520 | 859 | 3.1795 |  \n这是一个颇为奇妙的方法: 只要设计一个随机试验, 使一个事件的概率与某个未知数有关, 然后通过重复试验, 以频率估计概率, 即可求得未知数的近似解. 一般来说, 试验次数越多, 则求得的近似解就越精确。随着电子计算机的出现, 人们便可利用计算机来大量重复地模拟所设计的随机试验。这种方法得到了迅速的发展和广泛的应用。人们称这种方法为随机模拟法, 也称为蒙特卡罗 (Montecarlo) 法.  \n例 1.2.10: 在长度为 $a$ 的线段内任取两点将其分为三段, 求它们可以构成一个三角形的概率.  \n解：由于是将线段任意分成三段, 所以由等可能性知这是一个几何概率问题. 分别用 $x, y$ 和 $a-x-y$ 表示线段被分成的三段长度, 见图 1.2.6. 则显然应该有  \n$$\n0<x<a ; \\quad 0<y<a ; \\quad 0<a-(x+y)<a .\n$$  \n第三个式子等价于: $0<x+y<a$. 所以样本空间为 (见图 1.2.7)  \n$$\n\\Omega=\\{(x, y): 0<x<a, 0<y<a, 0<x+y<a\\} .\n$$  \n$\\Omega$ 的面积为  \n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.5 确定概率的几何方法"
        },
        "type": "Document"
    },
    {
        "page_content": "例 1.2.10: 在长度为 $a$ 的线段内任取两点将其分为三段, 求它们可以构成一个三角形的概率.  \n解：由于是将线段任意分成三段, 所以由等可能性知这是一个几何概率问题. 分别用 $x, y$ 和 $a-x-y$ 表示线段被分成的三段长度, 见图 1.2.6. 则显然应该有  \n$$\n0<x<a ; \\quad 0<y<a ; \\quad 0<a-(x+y)<a .\n$$  \n第三个式子等价于: $0<x+y<a$. 所以样本空间为 (见图 1.2.7)  \n$$\n\\Omega=\\{(x, y): 0<x<a, 0<y<a, 0<x+y<a\\} .\n$$  \n$\\Omega$ 的面积为  \n$$\nS_{\\Omega}=\\frac{a^{2}}{2}\n$$  \n又根据构成三角形的条件: 三角形中任意两边之和大于第三边, 得事件 $A$ 所含样本点 $(x, y)$必须满足:  \n$$\n\\begin{aligned}\n& 0<a-(x+y)<x+y, \\\\\n& 0<x<y+(a-x-y), \\\\\n& 0<y<x+(a-x-y) .\n\\end{aligned}\n$$  \n整理得  \n$$\n\\frac{a}{2}<x+y<a ; \\quad 0<x<\\frac{a}{2} ; \\quad 0<y<\\frac{a}{2} \\text {. }\n$$  \n所以事件 $A$ 可用图 1.2.8 中的阴影部分表示. 事件 $A$ 的面积为  \n$$\nS_{A}=\\frac{a^{2}}{8}\n$$  \n!  \n图 1.2.6: 长度为 $a$ 的线段分成三段.  \n!  \n图 1.2.7: 线段分成三段的样本空间 $\\Omega$.  \n!  \n图 1.2.8: 构成三角形的条件  \n由此得  \n$$\nP(A)=\\frac{1}{4}\n$$",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.5 确定概率的几何方法"
        },
        "type": "Document"
    },
    {
        "page_content": "在现实世界里有一些随机现象是不能重复的或不能大量重复的, 这时有关事件的概率如何确定呢?  \n统计界的贝叶斯学派认为: 一个事件的概率是人们根据经验对该事件发生的可能性所给出的个人信念. 这样给出的概率称为主观概率.  \n这种利用经验确定随机享件发生可能性大小的例子是很多的, 人们也常依据某些主观概率来行事.  \n例 1.2.11: 用主观方法确定概率的例子.  \n1. 在气象预报中, 往往会说: “明天下雨的概率为 $90 \\%$ ”, 这是气象专家根据气象专业知识和最近的气象情况给出的主观概率. 听到这一信息的人, 大多出门会带企.\n2. 一个企业家根据他多年的经验和当时的一些市场信息, 认为 “某项新产品在未来市场上畅销”的可能性为 $80 \\%$.\n3. 一个外科医生根据自己多年的临床经验和一位患者的病情, 认为 “此手术成功” 的可能性为 $90 \\%$.\n4. 一个教师根据自己多年的教学经验和甲、乙两学生的学习情况, 认为 “甲学生能考取大学” 的可能性为 $95 \\%$, “乙学生能考取大学”的可能性为 $40 \\%$.  \n从以上例子可以看出:  \n1. 主观概率和主观臆造有着本质上的不同, 前者要求当事人对所考察的事件有透彻的了解和丰富的经验, 甚至是这一行的专家, 并能对历史信息和当时信息进行仔细分析, 如此确定的主观概率是可信的. 从某种意义上说, 不利用这些丰富的经验也是一种浪费.\n2. 用主观方法得出的随机事件发生的可能性大小, 本质上是对随机事件概率的一种推断和估计. 虽然结论的精确性有待实践的检验和修正, 但结论的可信性在统计意义上是有其价值的.\n3. 在遇到的随机现象无法大量重复时, 用主观方法去做决策和判断是适合的. 从这点看, 主观方法至少是频率方法的一种补充.  \n另外要说明的是, 主观概率的确定除根据自己的经验外, 决策者还可以利用别人的经验。例如,对一项有风险的投资,决策者向某位专家咨询的结果为 “成功的可能性为 $60 \\%$ ”, 而决策者很熟悉这位专家, 认为专家的估计往往是偏保守的、过分蓫慎的. 为此决策者将结论修改为 “成功的可能性为 $70 \\%$.  \n主观给定的概率要符合公理化的定义.",
        "metadata": {
            "Header 2": "3. 女婴出生频率",
            "Header 3": "1.2.6 确定概率的主观方法"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 对于组合数 $\\left(\\begin{array}{l}n \\\\ r\\end{array}\\right)$, 证明  \n(1) $\\left(\\begin{array}{l}n \\\\ r\\end{array}\\right)=\\left(\\begin{array}{c}n \\\\ n-r\\end{array}\\right)$;  \n(2) $\\left(\\begin{array}{l}n \\\\ r\\end{array}\\right)=\\left(\\begin{array}{c}n-1 \\\\ r-1\\end{array}\\right)+\\left(\\begin{array}{c}n-1 \\\\ r\\end{array}\\right)$;  \n(3) $\\left(\\begin{array}{l}n \\\\ 0\\end{array}\\right)+\\left(\\begin{array}{l}n \\\\ 1\\end{array}\\right)+\\cdots+\\left(\\begin{array}{l}n \\\\ n\\end{array}\\right)=2^{n}$;  \n(4) $\\left(\\begin{array}{l}n \\\\ 1\\end{array}\\right)+2\\left(\\begin{array}{l}n \\\\ 2\\end{array}\\right)+\\cdots+n\\left(\\begin{array}{l}n \\\\ n\\end{array}\\right)=n 2^{n-1}$;",
        "metadata": {
            "Header 2": "习习题 1.2"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) $\\left(\\begin{array}{l}n \\\\ r\\end{array}\\right)=\\left(\\begin{array}{c}n-1 \\\\ r-1\\end{array}\\right)+\\left(\\begin{array}{c}n-1 \\\\ r\\end{array}\\right)$;  \n(3) $\\left(\\begin{array}{l}n \\\\ 0\\end{array}\\right)+\\left(\\begin{array}{l}n \\\\ 1\\end{array}\\right)+\\cdots+\\left(\\begin{array}{l}n \\\\ n\\end{array}\\right)=2^{n}$;  \n(4) $\\left(\\begin{array}{l}n \\\\ 1\\end{array}\\right)+2\\left(\\begin{array}{l}n \\\\ 2\\end{array}\\right)+\\cdots+n\\left(\\begin{array}{l}n \\\\ n\\end{array}\\right)=n 2^{n-1}$;  \n(5) $\\left(\\begin{array}{l}a \\\\ 0\\end{array}\\right)\\left(\\begin{array}{l}b \\\\ n\\end{array}\\right)+\\left(\\begin{array}{l}a \\\\ 1\\end{array}\\right)\\left(\\begin{array}{c}b \\\\ n-1\\end{array}\\right)+\\cdots+\\left(\\begin{array}{l}a \\\\ n\\end{array}\\right)\\left(\\begin{array}{c}b \\\\ 0\\end{array}\\right)=\\left(\\begin{array}{c}a+b \\\\ n\\end{array}\\right), n=\\min (a, b)$;",
        "metadata": {
            "Header 2": "习习题 1.2"
        },
        "type": "Document"
    },
    {
        "page_content": "(5) $\\left(\\begin{array}{l}a \\\\ 0\\end{array}\\right)\\left(\\begin{array}{l}b \\\\ n\\end{array}\\right)+\\left(\\begin{array}{l}a \\\\ 1\\end{array}\\right)\\left(\\begin{array}{c}b \\\\ n-1\\end{array}\\right)+\\cdots+\\left(\\begin{array}{l}a \\\\ n\\end{array}\\right)\\left(\\begin{array}{c}b \\\\ 0\\end{array}\\right)=\\left(\\begin{array}{c}a+b \\\\ n\\end{array}\\right), n=\\min (a, b)$;  \n(6) $\\left(\\begin{array}{l}n \\\\ 0\\end{array}\\right)^{2}+\\left(\\begin{array}{l}n \\\\ 1\\end{array}\\right)^{2}+\\cdots+\\left(\\begin{array}{l}n \\\\ n\\end{array}\\right)^{2}=\\left(\\begin{array}{c}2 n \\\\ n\\end{array}\\right)$.  \n2. 抛两枚硬币, 求至少出现一个正面的概率.\n3. 任取两个正整数, 求它们的和为偶数的概率.\n4. 掷两颗骰子, 求下列事件的概率:  \n(1) 点数之和为 7 ;  \n(2) 点数之和不超过 5 ;  \n(3) 两个点数中一个恰是另一个的两倍.  \n5. 考虑一元二次方程 $x^{2}+B x+C=0$, 其中 $B, C$ 分别是将一枚骰子接连掷两次先后出现的点数, 求该方程有实根的概率 $p$ 和有重根的概率 $q$.\n6. 从一副 52 张的扑克牌中任取 4 张, 求下列事件的概率:  \n(1) 全是黑桃;  \n(2) 同花;  \n(3) 没有两张同一花色;  \n(4) 同色.  \n7. 设 5 个产品中有 3 个合格品、 2 个不合格品. 从中不返回地任取 2 个, 求取出的 2 个中全是合格品、仅有一个合格品和没有合格品的概率各为多少?",
        "metadata": {
            "Header 2": "习习题 1.2"
        },
        "type": "Document"
    },
    {
        "page_content": "2. 抛两枚硬币, 求至少出现一个正面的概率.\n3. 任取两个正整数, 求它们的和为偶数的概率.\n4. 掷两颗骰子, 求下列事件的概率:  \n(1) 点数之和为 7 ;  \n(2) 点数之和不超过 5 ;  \n(3) 两个点数中一个恰是另一个的两倍.  \n5. 考虑一元二次方程 $x^{2}+B x+C=0$, 其中 $B, C$ 分别是将一枚骰子接连掷两次先后出现的点数, 求该方程有实根的概率 $p$ 和有重根的概率 $q$.\n6. 从一副 52 张的扑克牌中任取 4 张, 求下列事件的概率:  \n(1) 全是黑桃;  \n(2) 同花;  \n(3) 没有两张同一花色;  \n(4) 同色.  \n7. 设 5 个产品中有 3 个合格品、 2 个不合格品. 从中不返回地任取 2 个, 求取出的 2 个中全是合格品、仅有一个合格品和没有合格品的概率各为多少?\n8. 口袋中有 5 个白球、 3 个黑球, 从中任取两个, 求取到的两个球颜色相同的概率.\n9. 甲口袋有 5 个白球、 3 个黑球, 乙口袋有 4 个白球、 6 个黑球. 从两个口袋中各任取一球, 求取到射两个球颜色相同的概率.\n10. 从 $n$ 个数 $1,2, \\cdots, n$ 中任取 2 个, 问其中一个小于 $k(1<k<n)$, 另一个大于 $k$ 的概率是多少?\n11. 口袋中有 10 只球, 分别标有号码 1 到 10 , 从中不返回地任取 3 只, 记下取出球的号码, 试求:  \n(1) 最小号码为 5 的概率;  \n(2) 最大号码为 5 的概率.  \n12. 掷三颗骰子, 求以下事件的概率:  \n(1) 所得的最大点数小于等于 5 ;  \n(2) 所得的最大点数等于 5 .  \n13. 把 10 本书任意地放在书架上, 求其中指定的三本书放在一起的概率.\n14. $n$ 个人隨机地圍一圆桌而坐, 求甲、乙两人相邻而坐的概率.\n15. 5 个人在第一层进人十一层楼的电梯. 假如每个人以相同的概率走出任一层 (从第二层开), 求此 5 个人在不同楼层走出的概率.\n16. 一个人把六根草紧在手中, 仅露出它们的头和尾, 然后随机地把六个头两两相接, 六个尾也两两相接. 求放开手后六根草恰巧连成一个环的概率.",
        "metadata": {
            "Header 2": "习习题 1.2"
        },
        "type": "Document"
    },
    {
        "page_content": "10. 从 $n$ 个数 $1,2, \\cdots, n$ 中任取 2 个, 问其中一个小于 $k(1<k<n)$, 另一个大于 $k$ 的概率是多少?\n11. 口袋中有 10 只球, 分别标有号码 1 到 10 , 从中不返回地任取 3 只, 记下取出球的号码, 试求:  \n(1) 最小号码为 5 的概率;  \n(2) 最大号码为 5 的概率.  \n12. 掷三颗骰子, 求以下事件的概率:  \n(1) 所得的最大点数小于等于 5 ;  \n(2) 所得的最大点数等于 5 .  \n13. 把 10 本书任意地放在书架上, 求其中指定的三本书放在一起的概率.\n14. $n$ 个人隨机地圍一圆桌而坐, 求甲、乙两人相邻而坐的概率.\n15. 5 个人在第一层进人十一层楼的电梯. 假如每个人以相同的概率走出任一层 (从第二层开), 求此 5 个人在不同楼层走出的概率.\n16. 一个人把六根草紧在手中, 仅露出它们的头和尾, 然后随机地把六个头两两相接, 六个尾也两两相接. 求放开手后六根草恰巧连成一个环的概率.\n17. 把 $n$ 个“ 0 ”与 $n$ 个“ 1 ”随机地排列, 求没有两个“ 1 ”连在一起的概率.\n18. 口袋中有 $n$ 个白球, $n$ 个黑球, 从中一个一个不返回地摸球, 直至摸完为止. 求黑白球恰好相间取出的概率.\n19. $n$ 个男孩, $m$ 个女孩 $(m \\leqslant n+1)$ 随机地排成一排, 试求任意两个女孩都不相邻的概率.\n20. 将 3 个球随机地放人 4 个杯子中去, 求杯子中球的最大个数分别为 $1,2,3$ 的概率各为多少?\n21. 将 12 只球随意地放人 3 个盒子中, 试求第一个盒子中有 3 只球的概率.\n22. 将 $n$ 个完全相同的球 (这时也称球是不可辨的) 随机地放人 $N$ 个盒子中, 试求:  \n(1) 某个指定的盒子中恰好有 $k$ 个球的概率;  \n(2) 恰好有 $m$ 个空盒的概率;  \n(3) 某个指定的 $m$ 个盒子中恰好有 $j$ 个球的概率.  \n23. 在区间 $(0,1)$ 中随机地取两个数, 求事件 “两数之和小于 $6 / 5$ ” 的概率.",
        "metadata": {
            "Header 2": "习习题 1.2"
        },
        "type": "Document"
    },
    {
        "page_content": "17. 把 $n$ 个“ 0 ”与 $n$ 个“ 1 ”随机地排列, 求没有两个“ 1 ”连在一起的概率.\n18. 口袋中有 $n$ 个白球, $n$ 个黑球, 从中一个一个不返回地摸球, 直至摸完为止. 求黑白球恰好相间取出的概率.\n19. $n$ 个男孩, $m$ 个女孩 $(m \\leqslant n+1)$ 随机地排成一排, 试求任意两个女孩都不相邻的概率.\n20. 将 3 个球随机地放人 4 个杯子中去, 求杯子中球的最大个数分别为 $1,2,3$ 的概率各为多少?\n21. 将 12 只球随意地放人 3 个盒子中, 试求第一个盒子中有 3 只球的概率.\n22. 将 $n$ 个完全相同的球 (这时也称球是不可辨的) 随机地放人 $N$ 个盒子中, 试求:  \n(1) 某个指定的盒子中恰好有 $k$ 个球的概率;  \n(2) 恰好有 $m$ 个空盒的概率;  \n(3) 某个指定的 $m$ 个盒子中恰好有 $j$ 个球的概率.  \n23. 在区间 $(0,1)$ 中随机地取两个数, 求事件 “两数之和小于 $6 / 5$ ” 的概率.\n24. 甲乙两艘轮船驶向一个不能同时停泊两艘轮船的码头, 它们在一昼夜内到达的时间是等可能的. 如果甲船的停泊时间是一小时, 乙船的停泊时间是两小时, 求它们中任何一般都不需要等候码头空出的概率是多少?\n25. 在平面上画有间隔为 $d$ 的等距平行线, 向平面任意投郑一个边长为 $a, b, c$ (均小于 $d$ ) 的三角形,求三角形与平行线相交的概率.\n26. 在半径为 $R$ 的圆内画平行弦, 如果这些弦与垂直于弦的直径的交点在该直径上的位量是等可能的, 即交点在直径上一个区间内的可能性与这区间的长度成比例, 求任意弦的长度大于 $R$ 的概率.\n27. 设一个质点落在 $x O y$ 平面上由 $x$ 轴 $y$ 轴及直线 $x+y=1$ 所围成的三角形内, 而落在这三角形内各点处的可能性相等, 即落在这三角形内任何区域上的概率与这区域的面积成正比, 试求此质点落在直线 $x=1 / 3$ 的左边的概率是多少?\n28. 设 $a>0$, 有任意两数 $x, y$, 且 $0<x<a, 0<y<a$, 试求 $x y<a^{2} / 4$ 的概率.\n29. 用主观方法确定: 大学生中戴眼镜的概率是多少?",
        "metadata": {
            "Header 2": "习习题 1.2"
        },
        "type": "Document"
    },
    {
        "page_content": "25. 在平面上画有间隔为 $d$ 的等距平行线, 向平面任意投郑一个边长为 $a, b, c$ (均小于 $d$ ) 的三角形,求三角形与平行线相交的概率.\n26. 在半径为 $R$ 的圆内画平行弦, 如果这些弦与垂直于弦的直径的交点在该直径上的位量是等可能的, 即交点在直径上一个区间内的可能性与这区间的长度成比例, 求任意弦的长度大于 $R$ 的概率.\n27. 设一个质点落在 $x O y$ 平面上由 $x$ 轴 $y$ 轴及直线 $x+y=1$ 所围成的三角形内, 而落在这三角形内各点处的可能性相等, 即落在这三角形内任何区域上的概率与这区域的面积成正比, 试求此质点落在直线 $x=1 / 3$ 的左边的概率是多少?\n28. 设 $a>0$, 有任意两数 $x, y$, 且 $0<x<a, 0<y<a$, 试求 $x y<a^{2} / 4$ 的概率.\n29. 用主观方法确定: 大学生中戴眼镜的概率是多少?\n30. 用主观方法确定: 学生中考试作弊的概率是多少?",
        "metadata": {
            "Header 2": "习习题 1.2"
        },
        "type": "Document"
    },
    {
        "page_content": "利用概率的公理化定义 (非负性、正则性和可列可加性), 可以导出概率的一系列性质. 以下我们逐个给出概率的一些常用性质.  \n首先, 在概率的正则性中说明了必然事件 $\\Omega$ 的概率为 1 . 那么可想而知, 不可能事件 $\\varnothing$ 的概率应该为 0 , 下面性质正说明了这一点.  \n性质 1.3.1:  \n$$\nP(\\varnothing)=0 .\n$$  \n证明: 由于可列个不可能事件之并仍是不可能事件, 所以  \n$$\n\\Omega=\\Omega \\cup \\varnothing \\cup \\varnothing \\cdots \\cup \\varnothing \\cup \\cdots .\n$$  \n因为不可能事件与任何事件是互不相容的, 故由可列可邡性公理得  \n$$\nP(\\Omega)=P(\\Omega)+P(\\varnothing)+\\cdots+P(\\varnothing)+\\cdots .\n$$  \n从而由 $P(\\Omega)=1$ 得  \n$$\nP(\\Omega)+P(\\varnothing)+\\cdots=0 .\n$$  \n再由非负性公理, 必有  \n$$\nP(\\varnothing)=0 \\text {. }\n$$  \n结论得证",
        "metadata": {
            "Header 2": "1.3 概率的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "概率的可列可加性说明了对可列个互不相容的事件 $A_{1}, A_{2}, \\cdots$, 其可列并的概率可以分别求之再相加, 那么对有限个互不相容的事件 $A_{1}, A_{2}, \\cdots, A_{n}$, 其有限并的概率是否也可以分别求之再相加呢? 下面性质回答了这个问题.  \n性质 1.3.2: [有限可加性] 若有限个事件 $A_{1}, A_{2}, \\cdots, A_{n}$ 互不相容, 则有  \n$$\n\\begin{equation*}\nP\\left(\\bigcup_{i=1}^{n} A_{i}\\right)=\\sum_{i=1}^{n} P\\left(A_{i}\\right) \\tag{1.3.1}\n\\end{equation*}\n$$  \n证明: 对 $A_{1}, A_{2}, \\cdots, A_{n}, \\varnothing, \\varnothing, \\cdots$, 应用可列可加性, 得  \n$$\n\\begin{aligned}\nP\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n}\\right) & =\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n} \\cup \\varnothing \\cup \\varnothing \\cup \\cdots\\right) \\\\\n& =P\\left(A_{1}\\right)+\\cdots+P\\left(A_{n}\\right)+P(\\varnothing)+P(\\varnothing)+\\cdots \\\\\n& =P\\left(A_{1}\\right)+\\cdots+P\\left(A_{n}\\right) .\n\\end{aligned}\n$$  \n结论得证.  \n由有限可加性, 我们就可以得到以下求对立事件概率的公式.  \n性质 1.3 .3 : 对任一事件 $A$, 有  \n$$\n\\begin{equation*}\nP(\\bar{A})=1-P(A) \\text {. } \\tag{1.3.2}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.1 概率的可加性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nP\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n}\\right) & =\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n} \\cup \\varnothing \\cup \\varnothing \\cup \\cdots\\right) \\\\\n& =P\\left(A_{1}\\right)+\\cdots+P\\left(A_{n}\\right)+P(\\varnothing)+P(\\varnothing)+\\cdots \\\\\n& =P\\left(A_{1}\\right)+\\cdots+P\\left(A_{n}\\right) .\n\\end{aligned}\n$$  \n结论得证.  \n由有限可加性, 我们就可以得到以下求对立事件概率的公式.  \n性质 1.3 .3 : 对任一事件 $A$, 有  \n$$\n\\begin{equation*}\nP(\\bar{A})=1-P(A) \\text {. } \\tag{1.3.2}\n\\end{equation*}\n$$  \n证明: 因为 $A$ 与 $\\bar{A}$ 互不相容, 且 $\\Omega=A \\cup \\bar{A}$. 所以由概率的正则性和有限可加性得 $1=P(A)+P(\\bar{A})$. 由此得 $P(A)=1-P(\\bar{A})$.  \n有些事件直接考虑较为复杂, 而考虑其对立事件则相对比较简单. 对此类问题就可以利用性质 1.3 .1 , 见下面例子.  \n例 1.3.1: 36 只灯泡中 4 只是 $60 \\mathrm{~W}$, 其余都是 $40 \\mathrm{~W}$ 的. 现从中任取 3 只, 求至少取到一只 $60 \\mathrm{~W}$ 灯泡的概率.",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.1 概率的可加性"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n结论得证.  \n由有限可加性, 我们就可以得到以下求对立事件概率的公式.  \n性质 1.3 .3 : 对任一事件 $A$, 有  \n$$\n\\begin{equation*}\nP(\\bar{A})=1-P(A) \\text {. } \\tag{1.3.2}\n\\end{equation*}\n$$  \n证明: 因为 $A$ 与 $\\bar{A}$ 互不相容, 且 $\\Omega=A \\cup \\bar{A}$. 所以由概率的正则性和有限可加性得 $1=P(A)+P(\\bar{A})$. 由此得 $P(A)=1-P(\\bar{A})$.  \n有些事件直接考虑较为复杂, 而考虑其对立事件则相对比较简单. 对此类问题就可以利用性质 1.3 .1 , 见下面例子.  \n例 1.3.1: 36 只灯泡中 4 只是 $60 \\mathrm{~W}$, 其余都是 $40 \\mathrm{~W}$ 的. 现从中任取 3 只, 求至少取到一只 $60 \\mathrm{~W}$ 灯泡的概率.  \n解: 记事件 $A$ 为 “取出的 3 只中至少有一只 $60 \\mathrm{~W}$ ”, 则 $A$ 包括三种情况: 取到一只 $60 \\mathrm{~W}$ 两只 $40 \\mathrm{~W}$,或取到两只 $60 \\mathrm{~W}$ 一只 $40 \\mathrm{~W}$, 或取到三只 $60 \\mathrm{~W}$. 而 $A$ 的对立事件 $\\bar{A}$ 只包括一种情况, 即 “取出的 3 只全部是 $40 \\mathrm{~W}$ ”, 由例 1.2 .3 抽样模型可知  \n$$\nP(\\bar{A})=\\frac{\\left(\\begin{array}{c}\n32 \\\\\n3\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n36 \\\\\n3\n\\end{array}\\right)}=\\frac{248}{357}=0.695\n$$  \n所以  \n$$\nP(A)=1-P(\\bar{A})=\\frac{109}{357}=0.305 \\text {. }\n$$  \n例 1.3.2: 抛一枚硬币 5 次, 求既出现正面又出现反面的概率.",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.1 概率的可加性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(\\bar{A})=\\frac{\\left(\\begin{array}{c}\n32 \\\\\n3\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n36 \\\\\n3\n\\end{array}\\right)}=\\frac{248}{357}=0.695\n$$  \n所以  \n$$\nP(A)=1-P(\\bar{A})=\\frac{109}{357}=0.305 \\text {. }\n$$  \n例 1.3.2: 抛一枚硬币 5 次, 求既出现正面又出现反面的概率.  \n解：记事件 $A$ 为 “抛 5 次硬币中既出现正面又出现反面”, 则 $A$ 的情况较复杂, 因为出现正面的次数可以是 1 次至 4 次, 而 $A$ 的对立事件则相对简单: 5 次全部是正面 (记为 $B$ ), 或 5 次全部是反面  \n(记为 $C$ ), 即 $A=B \\cup C$, 其中 $B$ 与 $C$ 互不相容. 所以由对立事件公式和概率的有限可加性得  \n$$\n\\begin{aligned}\nP(A) & =1-P(\\bar{A})=1-P(B \\cup C)=1-P(B)-P(C) \\\\\n& =1-\\frac{1}{2^{5}}-\\frac{1}{2^{5}}=\\frac{15}{16} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.1 概率的可加性"
        },
        "type": "Document"
    },
    {
        "page_content": "可以想象: 当 $B$ 被 $A$ 包含时 (即 $B$ 发生必然导致 $A$ 发生), 说明事件 $A$ 比事件 $B$ 更容易发生,那么 $B$ 的概率不应该比 $A$ 的概率大, 这可由以下性质 的推论说明之.  \n性质 给出了两个有包含关系事件差的概率公式, 而性质 给出了任意两个事件差的概率公式.性质 1.3.4: 若 $A \\supset B$, 则  \n$$\n\\begin{equation*}\nP(A-B)=P(A)-P(B) \\text {. } \\tag{1.3.3}\n\\end{equation*}\n$$  \n证明: 因为 $A \\supset B$, 所以  \n$$\nP(A-B)=B \\cup(A-B),\n$$  \n且 $B$ 与 $A-B$ 互不相容, 由有限可加性得  \n$$\nP(A)=P(B)+P(A-B),\n$$  \n即得  \n$$\nP(A-B)=P(A)-P(B) .\n$$  \n结论得证.  \n推论 1.3.1. $A \\supset B$, 则 $P(A) \\geqslant P(B)$.  \n很容易举例说明: 以上推论的逆命题不成立, 即由 $P(A) \\geqslant P(B)$ 无法推出 $A \\supset B$.  \n性质 1.3 .5 : 对任意两个事件 $A, B$, 有  \n$$\n\\begin{equation*}\nP(A-B)=P(A)-P(A B) . \\tag{1.3.4}\n\\end{equation*}\n$$  \n证明: 因为 $A-B=A-A B$, 且 $A B \\subset A$, 所以由性质得  \n$$\np(A-B)=P(A-A B)=P(A)-P(A B) \\text {. }\n$$  \n结论得证.  \n利用性质, 我们可以求一些较为复杂的事件的概率.  \n例 1.3.3: 口袋中有编号为 $1,2, \\ldots, n$ 的 $n$ 个球, 从中有放回地任取 $m$ 次, 求取出的 $m$ 个球的最大号码为 $k$ 的概率.  \n解：记事件 $A_{k}$ 为 “取出的 $m$ 个球的最大号码为 $k$ ”. 如果直接考虑事件 $A_{k}$, 则比较复杂, 因为 “最大号码为 $k$ ”可以包括取到 1 次 $k$ 、取到 2 次 $k 、 \\ldots$ 、取到 $m$ 次 $k$.",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.2 概率的単调性"
        },
        "type": "Document"
    },
    {
        "page_content": "性质 1.3 .5 : 对任意两个事件 $A, B$, 有  \n$$\n\\begin{equation*}\nP(A-B)=P(A)-P(A B) . \\tag{1.3.4}\n\\end{equation*}\n$$  \n证明: 因为 $A-B=A-A B$, 且 $A B \\subset A$, 所以由性质得  \n$$\np(A-B)=P(A-A B)=P(A)-P(A B) \\text {. }\n$$  \n结论得证.  \n利用性质, 我们可以求一些较为复杂的事件的概率.  \n例 1.3.3: 口袋中有编号为 $1,2, \\ldots, n$ 的 $n$ 个球, 从中有放回地任取 $m$ 次, 求取出的 $m$ 个球的最大号码为 $k$ 的概率.  \n解：记事件 $A_{k}$ 为 “取出的 $m$ 个球的最大号码为 $k$ ”. 如果直接考虑事件 $A_{k}$, 则比较复杂, 因为 “最大号码为 $k$ ”可以包括取到 1 次 $k$ 、取到 2 次 $k 、 \\ldots$ 、取到 $m$ 次 $k$.  \n为此我们记事件 $B_{i}$ 为 “取出的 $m$ 个球的最大号码小于等于 $i$ ”, $i=1,2, \\cdots, n$. 则 $B$ 发生只需每次从 $1,2, \\cdots, i$ 号球中取球即可. 所以由古典概率知  \n$$\nP\\left(B_{i}\\right)=\\frac{i^{m}}{n^{m}}, \\quad i=1,2, \\cdots, n\n$$  \n又因为 $A_{k}=B_{k}-B_{k-1}$, 且 $B_{k-1} \\subset B_{k}$, 由性质得  \n$$\n\\begin{aligned}\nP\\left(A_{k}\\right) & =P\\left(B_{k}-B_{k-1}\\right)=P\\left(B_{k}\\right)-P\\left(B_{k-1}\\right) \\\\\n& =\\frac{k^{m}-(k-1)^{m}}{n^{m}}, \\quad k=1,2, \\cdots, n .\n\\end{aligned}\n$$  \n譬如, $n=6, m=3$, 可算得  \n其他的 $P\\left(A_{k}\\right)$ 也都可算出, 现列表如下:  \n$$",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.2 概率的単调性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP\\left(B_{i}\\right)=\\frac{i^{m}}{n^{m}}, \\quad i=1,2, \\cdots, n\n$$  \n又因为 $A_{k}=B_{k}-B_{k-1}$, 且 $B_{k-1} \\subset B_{k}$, 由性质得  \n$$\n\\begin{aligned}\nP\\left(A_{k}\\right) & =P\\left(B_{k}-B_{k-1}\\right)=P\\left(B_{k}\\right)-P\\left(B_{k-1}\\right) \\\\\n& =\\frac{k^{m}-(k-1)^{m}}{n^{m}}, \\quad k=1,2, \\cdots, n .\n\\end{aligned}\n$$  \n譬如, $n=6, m=3$, 可算得  \n其他的 $P\\left(A_{k}\\right)$ 也都可算出, 现列表如下:  \n$$\nP\\left(A_{4}\\right)=\\frac{4^{3}-3^{3}}{6^{3}}=\\frac{37}{216}=0.1713\n$$  \n| $k$ | 1 | 2 | 3 | 4 | 5 | 6 | 和 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P\\left(A_{k}\\right)$ | 0.0046 | 0.0324 | 0.0880 | 0.1713 | 0.2824 | 0.4213 | 1.000 |  \n这相当于郑三颗骰子, 最大点数为 6 的概率是 0.4213 , 而由  \n$$\nP(k \\leqslant 3)=0.0046+0.0324+0.0880=0.1250 .\n$$  \n说明: 掷三颗骰子, 最大点数不超过 3 的概率仅为 0.1250 .",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.2 概率的単调性"
        },
        "type": "Document"
    },
    {
        "page_content": "当事件之间互不相容时, 有限可加性或可列可加性给出了求事件并的概率的公式。那么对一般的事件 (不一定互不相容), 又如何求事件并的概率? 以下性质 给出求任意两个事件并的概率加法公式, (1.3.6) 给出求任意 $n$ 个事件并的概率加法公式. 这些性质在计算概率时是非常有用的.性质 1.3.6:[加法公式] 对任意两个事件 $A, B$, 有  \n$$\n\\begin{equation*}\nP(A \\cup B)=P(A)+P(B)-P(A B) . \\tag{1.3.5}\n\\end{equation*}\n$$  \n对任意 $n$ 个事件 $A_{1}, A_{2}, \\cdots, A_{n}$, 有  \n$$\n\\begin{array}{rl}\nP\\left(\\bigcup_{i=1}^{n} A_{i}\\right)=\\sum_{i=1}^{n} P\\left(A_{i}\\right)-\\sum_{1 \\leqslant i<j<\\leqslant n} P\\left(A_{i} A_{j}\\right)+\\sum_{1 \\leqslant i<j<k \\leqslant n} & P\\left(A_{i} A_{j} A_{k}\\right) \\\\\n+\\cdots+(-1)^{n-1} P\\left(A_{1} A_{2} \\cdots A_{n}\\right) . \\tag{1.3.6}\n\\end{array}\n$$  \n证明: 先证 (1.3.5). 因为  \n$$\nA \\cup B=A \\cup(B-A),\n$$  \n且 $A$ 与 $B-A$ 互不相容, 所以由有限可加性和性质得  \n$$\nP(A \\cup B)=P(A)+P(B-A)=P(A)+P(B)-P(A B) \\text {. }\n$$  \n下面用归纳法证明 (1.3.6). 当 $n=2$ 时, (1.3.6) 即为 (1.3.5). 设 (1.3.6) 对 $n-1$ 成立, 则对 $n$, 先对两个事件 $\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right)$ 与 $A_{n}$ 用 (1.3.5),  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.3 概率的加法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "+\\cdots+(-1)^{n-1} P\\left(A_{1} A_{2} \\cdots A_{n}\\right) . \\tag{1.3.6}\n\\end{array}\n$$  \n证明: 先证 (1.3.5). 因为  \n$$\nA \\cup B=A \\cup(B-A),\n$$  \n且 $A$ 与 $B-A$ 互不相容, 所以由有限可加性和性质得  \n$$\nP(A \\cup B)=P(A)+P(B-A)=P(A)+P(B)-P(A B) \\text {. }\n$$  \n下面用归纳法证明 (1.3.6). 当 $n=2$ 时, (1.3.6) 即为 (1.3.5). 设 (1.3.6) 对 $n-1$ 成立, 则对 $n$, 先对两个事件 $\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right)$ 与 $A_{n}$ 用 (1.3.5),  \n$$\n\\begin{aligned}\nP\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n}\\right) & =P\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right)+P\\left(A_{n}\\right)-P\\left(\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right) \\cap A_{n}\\right) \\\\\n& =P\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right)+P\\left(A_{n}\\right)-P\\left(\\left(A_{1} A_{n}\\right) \\cup\\left(A_{2} A_{n}\\right) \\cup \\cdots \\cup\\left(A_{n-1} A_{n}\\right)\\right) .\n\\end{aligned}\n$$  \n然后由归纳假设, 对  \n$$",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.3 概率的加法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nP\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n}\\right) & =P\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right)+P\\left(A_{n}\\right)-P\\left(\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right) \\cap A_{n}\\right) \\\\\n& =P\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right)+P\\left(A_{n}\\right)-P\\left(\\left(A_{1} A_{n}\\right) \\cup\\left(A_{2} A_{n}\\right) \\cup \\cdots \\cup\\left(A_{n-1} A_{n}\\right)\\right) .\n\\end{aligned}\n$$  \n然后由归纳假设, 对  \n$$\nP\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n-1}\\right) \\quad \\text { 及 } \\quad P\\left(\\left(A_{1} A_{n}\\right) \\cup\\left(A_{2} A_{n}\\right) \\cup \\cdots \\cup\\left(A_{n-1} A_{n}\\right)\\right)\n$$  \n进行展开, 经过整理合并即可知: (1.3.6) 对 $n$ 也成立, 结论得证.  \n推论 1.3 .2 (半可加性)。任意两个事件 $A, B$, 有  \n$$\n\\begin{equation*}\nP(A \\cup B) \\leqslant P(A)+P(B) . \\tag{1.3.7}\n\\end{equation*}\n$$  \n对任意 $n$ 个事件 $A_{1}, A_{2}, \\cdots, A_{n}$, 有  \n$$\n\\begin{equation*}\nP\\left(\\bigcup_{i=1}^{n} A_{i}\\right) \\leqslant \\sum_{i=1}^{n} P\\left(A_{i}\\right) \\tag{1.3.8}",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.3 概率的加法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n进行展开, 经过整理合并即可知: (1.3.6) 对 $n$ 也成立, 结论得证.  \n推论 1.3 .2 (半可加性)。任意两个事件 $A, B$, 有  \n$$\n\\begin{equation*}\nP(A \\cup B) \\leqslant P(A)+P(B) . \\tag{1.3.7}\n\\end{equation*}\n$$  \n对任意 $n$ 个事件 $A_{1}, A_{2}, \\cdots, A_{n}$, 有  \n$$\n\\begin{equation*}\nP\\left(\\bigcup_{i=1}^{n} A_{i}\\right) \\leqslant \\sum_{i=1}^{n} P\\left(A_{i}\\right) \\tag{1.3.8}\n\\end{equation*}\n$$  \n例 1.3.4: 已知事件 $A, B, A \\cup B$ 的概率分别为 $0.4,0.3,0.6$, 求 $P(A \\bar{B})$.  \n解: 由加法公式及题没条件知:  \n$$\n0.6=0.4+0.3-P(A B),\n$$  \n由此解得 $P(A B)=0.1$, 所以再由 (1.3.4) 得  \n$$\nP(A \\bar{B})=P(A-B)=P(A)-P(A B)=0.4-0.1=0.3 \\text {. }\n$$  \n例 1.3.5: 已知 $P(A)=P(B)=P(C)=1 / 4, P(A B)=0, P(A C)=P(B C)=1 / 16$. 则 $A, B, C$中至少发生一个的概率是多少? $A, B, C$ 都不发生的概率是多少?  \n解: 因为 $P(A B)=0$, 且 $A B C \\subset A B$, 所以由概率的单调性知 $P(A B C)=0$. 再由加法公式, 得 $A$, $B, C$ 中至少发生一个的概率为  \n$$\n\\begin{aligned}\nP(A \\cup B \\cup C) & =P(A)+P(B)+P(C)-P(A B)-P(A C)-P(B C)+P(A B C) \\\\\n& =\\frac{3}{4}-\\frac{2}{16}=\\frac{5}{8} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.3 概率的加法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n0.6=0.4+0.3-P(A B),\n$$  \n由此解得 $P(A B)=0.1$, 所以再由 (1.3.4) 得  \n$$\nP(A \\bar{B})=P(A-B)=P(A)-P(A B)=0.4-0.1=0.3 \\text {. }\n$$  \n例 1.3.5: 已知 $P(A)=P(B)=P(C)=1 / 4, P(A B)=0, P(A C)=P(B C)=1 / 16$. 则 $A, B, C$中至少发生一个的概率是多少? $A, B, C$ 都不发生的概率是多少?  \n解: 因为 $P(A B)=0$, 且 $A B C \\subset A B$, 所以由概率的单调性知 $P(A B C)=0$. 再由加法公式, 得 $A$, $B, C$ 中至少发生一个的概率为  \n$$\n\\begin{aligned}\nP(A \\cup B \\cup C) & =P(A)+P(B)+P(C)-P(A B)-P(A C)-P(B C)+P(A B C) \\\\\n& =\\frac{3}{4}-\\frac{2}{16}=\\frac{5}{8} .\n\\end{aligned}\n$$  \n又因为“ $A, B, C$ 都不发生”的对立事件为 “ $A, B, C$ 中至少发生一个”, 所以由对立事件公式得  \n$$\nP(A, B, C \\text { 都不发生 })=1-\\frac{5}{8}=\\frac{3}{8} .\n$$  \n一般而言, 求 “至少有一个......” 的概率时, 用对立事件公式去求较为方便. 但下面例 1.3.6 的配对问题却不能用对立事件去求解, 而一定要将事件 “至少有个......” 表示成事件的并, 然后用一般事件的加法公式去求解.  \n例 1.3.6 配对问题: 在一个有 $n$ 个人参加的晚会上, 每个人带了一件礼物, 且假定各人带的礼物都不相同. 晚会期间各人从放在一起的 $n$ 件礼物中随机抽取一件, 问至少有一个人自己抽到自己礼物的概率是多少?  \n解: 以 $A_{i}$ 记事件 “第 $i$ 个人自己抽到自己的礼物”, $i=1, \\cdots, n$. 所求概率为 $P\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n}\\right)$.因为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.3 概率的加法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "又因为“ $A, B, C$ 都不发生”的对立事件为 “ $A, B, C$ 中至少发生一个”, 所以由对立事件公式得  \n$$\nP(A, B, C \\text { 都不发生 })=1-\\frac{5}{8}=\\frac{3}{8} .\n$$  \n一般而言, 求 “至少有一个......” 的概率时, 用对立事件公式去求较为方便. 但下面例 1.3.6 的配对问题却不能用对立事件去求解, 而一定要将事件 “至少有个......” 表示成事件的并, 然后用一般事件的加法公式去求解.  \n例 1.3.6 配对问题: 在一个有 $n$ 个人参加的晚会上, 每个人带了一件礼物, 且假定各人带的礼物都不相同. 晚会期间各人从放在一起的 $n$ 件礼物中随机抽取一件, 问至少有一个人自己抽到自己礼物的概率是多少?  \n解: 以 $A_{i}$ 记事件 “第 $i$ 个人自己抽到自己的礼物”, $i=1, \\cdots, n$. 所求概率为 $P\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n}\\right)$.因为  \n$$\n\\begin{aligned}\n& P\\left(A_{1}\\right)=P\\left(A_{2}\\right)=\\cdots=P\\left(A_{n}\\right)=\\frac{1}{n}, \\\\\n& P\\left(A_{1} A_{2}\\right)=P\\left(A_{1} A_{3}\\right)=\\cdots=P\\left(A_{n-1} A_{n}\\right)=\\frac{1}{n(n-1)}, \\\\\n& P\\left(A_{1} A_{2} A_{3}\\right)=P\\left(A_{1} A_{2} A_{4}\\right)=\\cdots=P\\left(A_{n-2} A_{n-1} A_{n}\\right)=\\frac{1}{n(n-1)(n-2)}, \\\\\n& \\cdots \\\\\n& P\\left(A_{1} A_{2} \\cdots A_{n}\\right)=\\frac{1}{n !} .\n\\end{aligned}\n$$  \n所以由概率的加法公式 (1.3.6) 得  \n$$",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.3 概率的加法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n& P\\left(A_{1}\\right)=P\\left(A_{2}\\right)=\\cdots=P\\left(A_{n}\\right)=\\frac{1}{n}, \\\\\n& P\\left(A_{1} A_{2}\\right)=P\\left(A_{1} A_{3}\\right)=\\cdots=P\\left(A_{n-1} A_{n}\\right)=\\frac{1}{n(n-1)}, \\\\\n& P\\left(A_{1} A_{2} A_{3}\\right)=P\\left(A_{1} A_{2} A_{4}\\right)=\\cdots=P\\left(A_{n-2} A_{n-1} A_{n}\\right)=\\frac{1}{n(n-1)(n-2)}, \\\\\n& \\cdots \\\\\n& P\\left(A_{1} A_{2} \\cdots A_{n}\\right)=\\frac{1}{n !} .\n\\end{aligned}\n$$  \n所以由概率的加法公式 (1.3.6) 得  \n$$\nP\\left(A_{1} \\cup A_{2} \\cup \\cdots \\cup A_{n}\\right)=1-\\frac{1}{2 !}+\\frac{1}{3 !}-\\frac{1}{4 !}+\\cdots+(-1)^{n-1} \\frac{1}{n !}\n$$  \n譬如, 当 $n=5$ 时, 此概率为 0.6333 ; 当 $n \\geqslant 10$ 时, 此概率近似为 $1-e^{-1}=0.6321$. 这表明: 即使参加晚会的人很多 (譬如 100 人以上), 事件“至少有一个人自己抽到自己礼物”也不是必然事件.",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.3 概率的加法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "为了讨论概率的连续性, 我们先对事件序列的极限给出如下的定义.  \n定义 1.3.1. 1. 对 $\\mathscr{F}$ 中任一单调不减的事件序列 $F_{1} \\subset F_{2} \\subset \\cdots \\subset F_{n} \\subset \\cdots$, 称可列并 $\\bigcup_{n=1}^{+\\infty} F_{n}$为 $\\left\\{F_{n}\\right\\}$ 的极限事件, 记为  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} F_{n}=\\bigcup_{n=1}^{+\\infty} F_{n} \\tag{1.3.9}\n\\end{equation*}\n$$  \n2. 对 $\\mathscr{F}$ 中任一单调不增的事件序列 $E_{1} \\supset E_{2} \\supset \\cdots \\supset E_{n} \\supset \\cdots$, 称可列交 $\\cap_{n=1}^{+\\infty} E_{n}$ 为 $\\left\\{E_{n}\\right\\}$ 的极限事件, 记为  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} E_{n}=\\bigcap_{n=1}^{+\\infty} E_{n} \\tag{1.3.10}\n\\end{equation*}\n$$  \n有了以上极限事件的定义, 我们就可如下给出一个概率函数的连续性定义.  \n定义 1.3.2. 对 $\\mathscr{F}$ 上的一个概率 $P$,  \n1. 若它对 $\\mathscr{F}$ 中任一单调不减的事件序列 $\\left\\{F_{n}\\right\\}$ 均成立  \n则称概率 $P$ 是下连续的.  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(F_{n}\\right)=P\\left(\\lim _{n \\rightarrow+\\infty} F_{n}\\right),\n$$  \n2. 若它对 $\\mathscr{F}$ 中任一单调不增的事件序列 $\\left\\{E_{n}\\right\\}$ 均成立",
        "metadata": {
            "Header 2": "1.3 概率的性质",
            "Header 3": "1.3.4 概率的连续性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\lim _{n \\rightarrow+\\infty} P\\left(E_{n}\\right)=P\\left(\\lim _{n \\rightarrow+\\infty} E_{n}\\right),\n$$  \n有了以上的定义, 我们就可以证明概率的连续性了.  \n性质 1.3.7: [概率的连续性] 若 $P$ 为事件域上的概率, 则 $P$ 既是下连续的, 又是上连续的.  \n证明: 先证 $P$ 的下连续性. 设 $\\left\\{F_{n}\\right\\}$ 是 $\\mathscr{F}$ 中一个单调不减的事件序列, 即  \n$$\n\\bigcup_{i=1}^{+\\infty} F_{i}=\\lim _{n \\rightarrow+\\infty} F_{n}\n$$  \n若定义 $F_{0}=\\varnothing$, 则  \n$$\n\\bigcup_{i=1}^{+\\infty} F_{i}=\\bigcup_{i=1}^{+\\infty}\\left(F_{i}-F_{i-1}\\right)\n$$  \n由于 $F_{i-1} \\subset F_{i}$, 显然诸 $\\left(F_{i}, F_{i-1}\\right)$ 两两不相容, 再由可列可加性得  \n$$\nP\\left(\\bigcup_{i=1}^{+\\infty} F_{i}\\right)=\\sum_{i=1}^{+\\infty} P\\left(F_{i}-F_{i-1}\\right)=\\lim _{n \\rightarrow+\\infty} \\sum_{i=1}^{n} P\\left(F_{i}-F_{i-1}\\right) .\n$$  \n又由有限可加性得  \n$$\n\\sum_{i=1}^{n} P\\left(F_{i}-F_{i-1}\\right)=P\\left(\\bigcup_{i=1}^{n}\\left(F_{i}-F_{i-1}\\right)\\right)=P\\left(F_{n}\\right)\n$$  \n所以  \n$$\nP\\left(\\lim _{n \\rightarrow+\\infty} F_{n}\\right)=\\lim _{n \\rightarrow+\\infty} P\\left(F_{n}\\right) .\n$$  \n这就证得了 $P$ 的下连续性.",
        "metadata": {
            "Header 2": "则称概率 $P$ 是上连续的."
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP\\left(\\bigcup_{i=1}^{+\\infty} F_{i}\\right)=\\sum_{i=1}^{+\\infty} P\\left(F_{i}-F_{i-1}\\right)=\\lim _{n \\rightarrow+\\infty} \\sum_{i=1}^{n} P\\left(F_{i}-F_{i-1}\\right) .\n$$  \n又由有限可加性得  \n$$\n\\sum_{i=1}^{n} P\\left(F_{i}-F_{i-1}\\right)=P\\left(\\bigcup_{i=1}^{n}\\left(F_{i}-F_{i-1}\\right)\\right)=P\\left(F_{n}\\right)\n$$  \n所以  \n$$\nP\\left(\\lim _{n \\rightarrow+\\infty} F_{n}\\right)=\\lim _{n \\rightarrow+\\infty} P\\left(F_{n}\\right) .\n$$  \n这就证得了 $P$ 的下连续性.  \n再证 $P$ 的上连续性. 设 $\\left\\{E_{n}\\right\\}$ 是单调不增的事件序列, 则 $\\left\\{\\bar{E}_{n}\\right\\}$ 为单调不减的事件序列, 由概率的下连续性得  \n$$\n\\begin{aligned}\n1-\\lim _{n \\rightarrow+\\infty} P\\left(E_{n}\\right) & =\\lim _{n \\rightarrow+\\infty}\\left[1-P\\left(E_{n}\\right)\\right]=\\lim _{n \\rightarrow+\\infty} P\\left(\\bar{E}_{n}\\right) \\\\\n& =P\\left(\\bigcup_{n=1}^{+\\infty} \\bar{E}_{n}\\right)=P\\left(\\bigcap_{n=1}^{+\\infty} E_{n}\\right) \\\\\n& =1-P\\left(\\bigcap_{n=1}^{+\\infty} E_{n}\\right) .\n\\end{aligned}\n$$  \n注意最后第二个等式用了德莫根公式. 至此得  \n$$",
        "metadata": {
            "Header 2": "则称概率 $P$ 是上连续的."
        },
        "type": "Document"
    },
    {
        "page_content": "再证 $P$ 的上连续性. 设 $\\left\\{E_{n}\\right\\}$ 是单调不增的事件序列, 则 $\\left\\{\\bar{E}_{n}\\right\\}$ 为单调不减的事件序列, 由概率的下连续性得  \n$$\n\\begin{aligned}\n1-\\lim _{n \\rightarrow+\\infty} P\\left(E_{n}\\right) & =\\lim _{n \\rightarrow+\\infty}\\left[1-P\\left(E_{n}\\right)\\right]=\\lim _{n \\rightarrow+\\infty} P\\left(\\bar{E}_{n}\\right) \\\\\n& =P\\left(\\bigcup_{n=1}^{+\\infty} \\bar{E}_{n}\\right)=P\\left(\\bigcap_{n=1}^{+\\infty} E_{n}\\right) \\\\\n& =1-P\\left(\\bigcap_{n=1}^{+\\infty} E_{n}\\right) .\n\\end{aligned}\n$$  \n注意最后第二个等式用了德莫根公式. 至此得  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(E_{n}\\right)=P\\left(\\bigcap_{n=1}^{+\\infty} E_{n}\\right)\n$$  \n这就证得了 $P$ 的上连续性.  \n下面我们对可列可加性作进一步讨论. 从上面的讨论可知, 由可列可加性可推出有限可加性和下连续性, 但由有限可加性不能推出可列可加性. 这意味着要由有限可加性去推可列可加性, 还缺少条件. 下面性质说明: 所缺少的条件就是下连续性.  \n性质 1.3.8: 若 $P$ 是 $\\mathscr{F}$ 上满足 $P(\\Omega)=1$ 的非负集合函数, 则它具有可列可加性的充要条件是 (1)它是有限可加的; (2) 它是下连续的.\n证明: 必要性可从性质 1.3.1 和性质 1.3.4 获得. 下证充分性.  \n设 $A_{i} \\in \\mathscr{F}, i=1,2, \\cdots$ 是两两不相容的事件序列, 由有限可加性可知: 对任意有限的 $n$ 都有  \n$$",
        "metadata": {
            "Header 2": "则称概率 $P$ 是上连续的."
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n注意最后第二个等式用了德莫根公式. 至此得  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(E_{n}\\right)=P\\left(\\bigcap_{n=1}^{+\\infty} E_{n}\\right)\n$$  \n这就证得了 $P$ 的上连续性.  \n下面我们对可列可加性作进一步讨论. 从上面的讨论可知, 由可列可加性可推出有限可加性和下连续性, 但由有限可加性不能推出可列可加性. 这意味着要由有限可加性去推可列可加性, 还缺少条件. 下面性质说明: 所缺少的条件就是下连续性.  \n性质 1.3.8: 若 $P$ 是 $\\mathscr{F}$ 上满足 $P(\\Omega)=1$ 的非负集合函数, 则它具有可列可加性的充要条件是 (1)它是有限可加的; (2) 它是下连续的.\n证明: 必要性可从性质 1.3.1 和性质 1.3.4 获得. 下证充分性.  \n设 $A_{i} \\in \\mathscr{F}, i=1,2, \\cdots$ 是两两不相容的事件序列, 由有限可加性可知: 对任意有限的 $n$ 都有  \n$$\nP\\left(\\bigcup_{i=1}^{n} A_{i}\\right)=\\sum_{i=1}^{n} P\\left(A_{i}\\right)\n$$  \n这个等式的左边不超过 1 , 因此正项级数 $\\sum_{i=1}^{+\\infty} P\\left(A_{i}\\right)$ 收玫, 即  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\bigcup_{i=1}^{n} A_{i}\\right)=\\lim _{n \\rightarrow+\\infty} \\sum_{i=1}^{n} P\\left(A_{i}\\right)=\\sum_{i=1}^{+\\infty} P\\left(A_{i}\\right) \\tag{1.3.11}\n\\end{equation*}\n$$  \n记  \n$$\nF_{i}=\\bigcup_{i=1}^{n} A_{i}\n$$  \n则 $\\{F n\\}$ 为单调不减的事件序列, 所以由下连续性得  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "则称概率 $P$ 是上连续的."
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP\\left(\\bigcup_{i=1}^{n} A_{i}\\right)=\\sum_{i=1}^{n} P\\left(A_{i}\\right)\n$$  \n这个等式的左边不超过 1 , 因此正项级数 $\\sum_{i=1}^{+\\infty} P\\left(A_{i}\\right)$ 收玫, 即  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\bigcup_{i=1}^{n} A_{i}\\right)=\\lim _{n \\rightarrow+\\infty} \\sum_{i=1}^{n} P\\left(A_{i}\\right)=\\sum_{i=1}^{+\\infty} P\\left(A_{i}\\right) \\tag{1.3.11}\n\\end{equation*}\n$$  \n记  \n$$\nF_{i}=\\bigcup_{i=1}^{n} A_{i}\n$$  \n则 $\\{F n\\}$ 为单调不减的事件序列, 所以由下连续性得  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\bigcup_{i=1}^{n} A_{i}\\right)=\\lim _{n \\rightarrow+\\infty} P\\left(F_{n}\\right)=P\\left(\\bigcup_{n=1}^{+\\infty} F_{n}\\right)=P\\left(\\bigcup_{n=1}^{+\\infty} A_{n}\\right) \\tag{1.3.12}\n\\end{equation*}\n$$  \n综合 (1.3.11) 和 (1.3.12), 即得可列可加性.  \n从性质 1.3.4 可以看出: 在概率的公理化定义中, 可以将可列可加性换成是有限可加性和下连续性.",
        "metadata": {
            "Header 2": "则称概率 $P$ 是上连续的."
        },
        "type": "Document"
    },
    {
        "page_content": "1. 对下述五个事件发生可能性的文宇插述找出最合适的数值答案:  \n| 文字描述 | 数值答童 |\n| :--- | :--- |\n| (1) 事件 $A$ 发生与不发生的可能性一样 | (a) 0 |\n| (2) 事件 $B$ 很可能发生, 但不一定发生 | (b) 0.1 |\n| (3) 事件 $C$ 肯定不发生 | (c) 0.5 |\n| (5) 事件 $D$ 能够发生, 但可能性不大 | (d) 0.9 |  \n2. 设 $P(A B)=0$, 则下列说法哪些是正确的?  \n(1) $A$ 和 $B$ 不相容;  \n(2) $A$ 和 $B$ 相容;  \n(3) $A B$ 是不可能事件;  \n(4) $A B$ 不一定是不可能事件;  \n(5) $P(A)=0$, 或 $P(B)=0$;  \n(6) $P(A-B)=P(A)$.  \n3. 一批产品分一、二、三级, 其中一级品是二级品的两倍, 三级品是二级品的一半, 从这批产品中随机地抽取一个, 试求取到二级品的概率.\n4. 从 $0,1,2, \\ldots, 9$ 等十个数字中任意选出三个不同的数字, 试求下列事件的概率:  \n(1) $A_{1}=\\{$ 三个数字中不含 0 和 5$\\}$;  \n(2) $A_{2}=\\{$ 三个数字中不含 0 或 5$\\}$;  \n(3) $A_{3}=\\{$ 三个数字中含 0 但不含 5$\\}$.  \n5. 某城市中共发行 3 种报纸 A, B, C. 在这城市的居民中有 $45 \\%$ 订阅 A 报、 $35 \\%$ 订阅 B 报、 $30 \\%$订阅 $\\mathrm{C}$ 报, $10 \\%$ 同时订阅 $\\mathrm{A}$ 报 $\\mathrm{B}$ 报、 $8 \\%$ 同时订阅 $\\mathrm{A}$ 报 $\\mathrm{C}$ 报、 $5 \\%$ 同时订阅 $\\mathrm{B}$ 报 $\\mathrm{C}$ 报、 $3 \\%$ 同时订阅 $A, B, C$ 报. 求以下事件的百分率:  \n(1) 只订阅 $\\mathrm{A}$ 报的;  \n(2) 只订阅一种报纸的;  \n(3) 至少订阅一种报纸的;  \n(4) 不订阅任何一种报纸的.",
        "metadata": {
            "Header 2": "习题 1.3"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) $A_{1}=\\{$ 三个数字中不含 0 和 5$\\}$;  \n(2) $A_{2}=\\{$ 三个数字中不含 0 或 5$\\}$;  \n(3) $A_{3}=\\{$ 三个数字中含 0 但不含 5$\\}$.  \n5. 某城市中共发行 3 种报纸 A, B, C. 在这城市的居民中有 $45 \\%$ 订阅 A 报、 $35 \\%$ 订阅 B 报、 $30 \\%$订阅 $\\mathrm{C}$ 报, $10 \\%$ 同时订阅 $\\mathrm{A}$ 报 $\\mathrm{B}$ 报、 $8 \\%$ 同时订阅 $\\mathrm{A}$ 报 $\\mathrm{C}$ 报、 $5 \\%$ 同时订阅 $\\mathrm{B}$ 报 $\\mathrm{C}$ 报、 $3 \\%$ 同时订阅 $A, B, C$ 报. 求以下事件的百分率:  \n(1) 只订阅 $\\mathrm{A}$ 报的;  \n(2) 只订阅一种报纸的;  \n(3) 至少订阅一种报纸的;  \n(4) 不订阅任何一种报纸的.  \n6. 某工厂一个班组共有男工 7 人、女工 4 人, 现要选出 3 个代表, 问选的 3 个代表中至少有 1 个女工的概率是多少?\n7. 奢徒认为郑一颗骰子 4 次至少出现一次 6 点与郑两颗骰子 24 次至少出现一次双 6 点的机会是相等的, 你认为如何?\n8. 从数字 $1,2, \\ldots, 9$ 中可重复地任取 $n$ 次, 求 $n$ 次所取数字的乘积能被 10 整除的概率.\n9. 口袋中有 $n-1$ 个黑球和 1 个白球, 每次从口袋中随机地摸出一球, 并换人一只黑球. 问第 $k$ 次摸球时, 摸到黑球的概率是多少?\n10. 甲郑硬币 $n+1$ 次, 乙郑 $n$ 次. 求甲郑出的正面数比乙郑出的正面数多的概率.\n11. 郑 $2 n+1$ 次硬币, 求出现的正面数多于反面数的概率.\n12. 有三个人, 每个人都以同样的概率 $1 / 4$ 被分配到四个房间中的每一间中, 试求:  \n(1) 三个人都分配到同一个房间的概率;  \n(2) 三个人分配到不同房间的概率.  \n13. 一间宿舍内住有 6 位同学, 求他们之中至少有 2 个人的生日在同一个月份的概率.",
        "metadata": {
            "Header 2": "习题 1.3"
        },
        "type": "Document"
    },
    {
        "page_content": "6. 某工厂一个班组共有男工 7 人、女工 4 人, 现要选出 3 个代表, 问选的 3 个代表中至少有 1 个女工的概率是多少?\n7. 奢徒认为郑一颗骰子 4 次至少出现一次 6 点与郑两颗骰子 24 次至少出现一次双 6 点的机会是相等的, 你认为如何?\n8. 从数字 $1,2, \\ldots, 9$ 中可重复地任取 $n$ 次, 求 $n$ 次所取数字的乘积能被 10 整除的概率.\n9. 口袋中有 $n-1$ 个黑球和 1 个白球, 每次从口袋中随机地摸出一球, 并换人一只黑球. 问第 $k$ 次摸球时, 摸到黑球的概率是多少?\n10. 甲郑硬币 $n+1$ 次, 乙郑 $n$ 次. 求甲郑出的正面数比乙郑出的正面数多的概率.\n11. 郑 $2 n+1$ 次硬币, 求出现的正面数多于反面数的概率.\n12. 有三个人, 每个人都以同样的概率 $1 / 4$ 被分配到四个房间中的每一间中, 试求:  \n(1) 三个人都分配到同一个房间的概率;  \n(2) 三个人分配到不同房间的概率.  \n13. 一间宿舍内住有 6 位同学, 求他们之中至少有 2 个人的生日在同一个月份的概率.\n14. 某班 $n$ 个战士各有 1 支归个人保管使用的枪, 这些枪的外形完全一样, 在一次夜间紧急集合中,每人随机地取了 1 支枪, 求至少有 1 人拿到自己的枪的概率.\n15. 设 $A, B$ 是两事件, 且 $P(A)=0.6, P(B)=0.7$, 问:  \n(1) 在什么条件下 $P(A B)$ 取到最大值, 最大值是多少?  \n(2) 在什么条件下 $P(A B)$ 取到最小值, 最小值是多少?  \n16. 已知事件 $A, B$ 满足 $P(A B)=P(\\bar{A} \\cap \\bar{B})$, 记 $P(A)=p$, 试求 $P(B)$.\n17. 已知 $P(A)=0.7, P(A-B)=0.3$, 试求 $P(\\overline{A B})$.\n18. 设 $P(A)=P(B)=1 / 2$, 试证 $P(A B)=P(A \\cap B)$.\n19. 对任意的事件 $A, B, C$, 证明:  \n(1) $P(A B)+P(A C)-P(B C) \\leqslant P(A)$,",
        "metadata": {
            "Header 2": "习题 1.3"
        },
        "type": "Document"
    },
    {
        "page_content": "14. 某班 $n$ 个战士各有 1 支归个人保管使用的枪, 这些枪的外形完全一样, 在一次夜间紧急集合中,每人随机地取了 1 支枪, 求至少有 1 人拿到自己的枪的概率.\n15. 设 $A, B$ 是两事件, 且 $P(A)=0.6, P(B)=0.7$, 问:  \n(1) 在什么条件下 $P(A B)$ 取到最大值, 最大值是多少?  \n(2) 在什么条件下 $P(A B)$ 取到最小值, 最小值是多少?  \n16. 已知事件 $A, B$ 满足 $P(A B)=P(\\bar{A} \\cap \\bar{B})$, 记 $P(A)=p$, 试求 $P(B)$.\n17. 已知 $P(A)=0.7, P(A-B)=0.3$, 试求 $P(\\overline{A B})$.\n18. 设 $P(A)=P(B)=1 / 2$, 试证 $P(A B)=P(A \\cap B)$.\n19. 对任意的事件 $A, B, C$, 证明:  \n(1) $P(A B)+P(A C)-P(B C) \\leqslant P(A)$,  \n(2) $P(A B)+P(A C)+P(B C) \\geqslant P(A)+P(B)+P(C)-1$.  \n20. 设 $A, B, C$ 为三个事件, 且 $P(A)=a, P(B)=2 a, P(C)=3 a, P(A B)=P(A C)=P(B C)=$ $b$, 证明: $a \\leqslant 1 / 4, b \\leqslant 1 / 4$.\n21. 设事件 $A, B, C$ 的概率都是 $1 / 2$, 且 $P(A B C)=P(\\bar{A} \\cap \\bar{B} \\cap \\bar{C})$, 证明:  \n$$\n2 P(A B C)=P(A B)+P(A C)+P(B C) / 1 / 2 \\text {. }\n$$  \n22. 证明:  \n(1) $P(A B) \\geqslant P(A)+P(B)-1$,  \n(2) $P\\left(A_{1} A_{2} \\cdots A_{n}\\right) \\geqslant P\\left(A_{1}\\right)+P\\left(A_{2}\\right)+\\cdots+P\\left(A_{n}\\right)-(n-1)$.  \n23. 证明:  \n$$",
        "metadata": {
            "Header 2": "习题 1.3"
        },
        "type": "Document"
    },
    {
        "page_content": "20. 设 $A, B, C$ 为三个事件, 且 $P(A)=a, P(B)=2 a, P(C)=3 a, P(A B)=P(A C)=P(B C)=$ $b$, 证明: $a \\leqslant 1 / 4, b \\leqslant 1 / 4$.\n21. 设事件 $A, B, C$ 的概率都是 $1 / 2$, 且 $P(A B C)=P(\\bar{A} \\cap \\bar{B} \\cap \\bar{C})$, 证明:  \n$$\n2 P(A B C)=P(A B)+P(A C)+P(B C) / 1 / 2 \\text {. }\n$$  \n22. 证明:  \n(1) $P(A B) \\geqslant P(A)+P(B)-1$,  \n(2) $P\\left(A_{1} A_{2} \\cdots A_{n}\\right) \\geqslant P\\left(A_{1}\\right)+P\\left(A_{2}\\right)+\\cdots+P\\left(A_{n}\\right)-(n-1)$.  \n23. 证明:  \n$$\n|P(A B)-P(A) P(B)| \\leqslant \\frac{1}{4}\n$$",
        "metadata": {
            "Header 2": "习题 1.3"
        },
        "type": "Document"
    },
    {
        "page_content": "条件概率是概率论中的一个既重要又实用的概念。  \n!  \n图 1.4.1: 例 1.4.2 的维恩图.",
        "metadata": {
            "Header 2": "1.4 条件概率"
        },
        "type": "Document"
    },
    {
        "page_content": "所谓条件概率, 它是指在某事件 $B$ 发生的条件下, 求另一事件 $A$ 的概率, 记为 $P(A \\mid B)$, 它与 $P(A)$ 是不同的两类概率. 下面用一个例子说明之.  \n例 1.4.1: 考察有两个小孩的家庭, 其样本空间为 $\\Omega=\\{b b, b g, g b, g g\\}$, 其中 $b$ 代表男孩, $g$ 代表女孩, $b g$ 表示大的是男孩、小的是女孩,其他样本点可类似说明.  \n在 $\\Omega$ 中 4 个样本点等可能情况下, 我们来讨论如下一些事件的概率.  \n1. 事件 $A=$ “家中至少有一个女孩”发生的概率为  \n$$\nP(A)=\\frac{3}{4}\n$$  \n2. 若已知事件 $B=$ “家中至少有一个男孩”发生, 再求事件 $A$ 发生的概率为  \n$$\nP(A \\mid B)=\\frac{2}{3} \\text {. }\n$$  \n这是因为事件 $B$ 的发生, 排除了 $g g$ 发生的可能性, 这时样本空间 $\\Omega$ 也随之改为 $\\Omega_{B}=$ $\\{b b, b g, g b\\}$, 而在 $\\Omega_{B}$ 中事件 $A$ 只含 2 个样本点, 故 $P(A \\mid B)=2 / 3$. 这就是条件概率, 它与 (无条件) 概率 $P(A)$ 是不同的两个概念.  \n3. 若对上述条件概率的分子分母各除以 4 , 则可得  \n$$\nP(A \\mid B)=\\frac{2 / 4}{3 / 4}=\\frac{P(A B)}{P(B)},\n$$  \n其中交事件 $A B=$ “家有一男一女两个小孩”.  \n这个关系具有一般性, 即条件概率是两个无条件概率之商, 这就是条件概率的定义.  \n定义 1.4.1. 设 $A$ 与 $B$ 是样本空间 $\\Omega$ 中的两事件, 若 $P(B)>0$, 则称  \n$$\n\\begin{equation*}\nP(A \\mid B)=\\frac{P(A B)}{P(B)} . \\tag{1.4.1}\n\\end{equation*}\n$$  \n为“在 $B$ 发生下 $A$ 的条件概率”, 简称条件概率.",
        "metadata": {
            "Header 2": "1.4 条件概率",
            "Header 3": "1.4.1 条件概率的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "3. 若对上述条件概率的分子分母各除以 4 , 则可得  \n$$\nP(A \\mid B)=\\frac{2 / 4}{3 / 4}=\\frac{P(A B)}{P(B)},\n$$  \n其中交事件 $A B=$ “家有一男一女两个小孩”.  \n这个关系具有一般性, 即条件概率是两个无条件概率之商, 这就是条件概率的定义.  \n定义 1.4.1. 设 $A$ 与 $B$ 是样本空间 $\\Omega$ 中的两事件, 若 $P(B)>0$, 则称  \n$$\n\\begin{equation*}\nP(A \\mid B)=\\frac{P(A B)}{P(B)} . \\tag{1.4.1}\n\\end{equation*}\n$$  \n为“在 $B$ 发生下 $A$ 的条件概率”, 简称条件概率.  \n例 1.4.2: 设某样本空间 $\\Omega$ 含有 25 个等可能的样本点, 事件 $A$ 含有 15 个样本点, 事件 $B$ 含有 7 个样本点, 交事件 $A B$ 含有 5 个样本点, 具体见图 1.4.1.  \n这时有  \n则在事件 $B$ 发生的条件下, 事件 $A$ 的条件概率为  \n$$\n\\begin{aligned}\n& P(A)=\\frac{15}{25}, \\\\\n& P(B)=\\frac{7}{25}, \\\\\n& P(A B)=\\frac{5}{25} .\n\\end{aligned}\n$$  \n$$\nP(A \\mid B)=\\frac{P(A B)}{p(B)}=\\frac{5 / 25}{7 / 25}=\\frac{5}{7} .\n$$  \n此结果也可以如此考虑: 事件 $B$ 发生, 表明事件 $\\bar{B}$ 不可能发生, 因此 $\\bar{B}$ 中的 18 个样本点可以不予考虑. 此时在 $B$ 中 7 个样本点中属于 $A$ 的只有 5 个, 所以 $P(A \\mid B)=5 / 7$. 这意味着, 在计算\n条件概率 $P(A \\mid B)$ 时, 样本空间 $\\Omega$ 缩小为 $\\Omega_{B}=B$.  \n类似地  \n$$\nP(B \\mid A)=\\frac{P(A B)}{P(A)}=\\frac{5 / 25}{15 / 25}=\\frac{1}{3} .\n$$  \n它也可作如上解释.",
        "metadata": {
            "Header 2": "1.4 条件概率",
            "Header 3": "1.4.1 条件概率的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n& P(A)=\\frac{15}{25}, \\\\\n& P(B)=\\frac{7}{25}, \\\\\n& P(A B)=\\frac{5}{25} .\n\\end{aligned}\n$$  \n$$\nP(A \\mid B)=\\frac{P(A B)}{p(B)}=\\frac{5 / 25}{7 / 25}=\\frac{5}{7} .\n$$  \n此结果也可以如此考虑: 事件 $B$ 发生, 表明事件 $\\bar{B}$ 不可能发生, 因此 $\\bar{B}$ 中的 18 个样本点可以不予考虑. 此时在 $B$ 中 7 个样本点中属于 $A$ 的只有 5 个, 所以 $P(A \\mid B)=5 / 7$. 这意味着, 在计算\n条件概率 $P(A \\mid B)$ 时, 样本空间 $\\Omega$ 缩小为 $\\Omega_{B}=B$.  \n类似地  \n$$\nP(B \\mid A)=\\frac{P(A B)}{P(A)}=\\frac{5 / 25}{15 / 25}=\\frac{1}{3} .\n$$  \n它也可作如上解释.  \n我们要注意的是: 条件概率 $P(A \\mid B)$ 是在给定 $B$ 下讨论事件 $A$ 的概率, 那么概率的性质对 $P(\\cdot \\mid B)$ 而言是否都成立呢? 譬如  \n$$\n\\begin{gathered}\nP(\\bar{A} \\mid B)=1-P(A \\mid B), \\\\\nP\\left(A_{1} \\cup A_{2} \\mid B\\right)=P\\left(A_{1} \\mid B\\right)+P\\left(A_{2} \\mid B\\right)-P\\left(A_{1} A_{2} \\mid B\\right)\n\\end{gathered}\n$$  \n这些概率性质都成立吗? 为此我们只要能验证条件概率满足三条公理即可回答这个问题.  \n性质 1.4.1: 条件概率是概率, 即若设 $P(B)>0$, 则  \n1. $P(A \\mid B) \\geqslant 0, A \\in \\mathscr{F}$,\n2. $P(\\Omega \\mid B)=1$,",
        "metadata": {
            "Header 2": "1.4 条件概率",
            "Header 3": "1.4.1 条件概率的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n它也可作如上解释.  \n我们要注意的是: 条件概率 $P(A \\mid B)$ 是在给定 $B$ 下讨论事件 $A$ 的概率, 那么概率的性质对 $P(\\cdot \\mid B)$ 而言是否都成立呢? 譬如  \n$$\n\\begin{gathered}\nP(\\bar{A} \\mid B)=1-P(A \\mid B), \\\\\nP\\left(A_{1} \\cup A_{2} \\mid B\\right)=P\\left(A_{1} \\mid B\\right)+P\\left(A_{2} \\mid B\\right)-P\\left(A_{1} A_{2} \\mid B\\right)\n\\end{gathered}\n$$  \n这些概率性质都成立吗? 为此我们只要能验证条件概率满足三条公理即可回答这个问题.  \n性质 1.4.1: 条件概率是概率, 即若设 $P(B)>0$, 则  \n1. $P(A \\mid B) \\geqslant 0, A \\in \\mathscr{F}$,\n2. $P(\\Omega \\mid B)=1$,\n3. 若 $\\mathscr{F}$ 中的 $A_{1}, A_{2}, \\ldots, A_{n}, \\ldots$ 互不相容, 则  \n$$\nP\\left(\\bigcup_{n=1}^{+\\infty} A_{n} \\mid B\\right)=\\sum_{n=1}^{+\\infty} P\\left(A_{n} \\mid B\\right)\n$$  \n证明：用条件概率的定义很容易证明前两点. 下面来证明第三点. 因为 $A_{1}, A_{2}, \\ldots, A_{n}, \\ldots$ 互不相容, 所以 $A_{1} B, A_{2} B, \\ldots, A_{n} B, \\ldots$ 也互不相容, 故  \n$$\n\\begin{aligned}\nP\\left(\\bigcup_{n=1}^{+\\infty} A_{n} \\mid B\\right) & =\\frac{P\\left(\\left(\\bigcup_{n=1}^{+\\infty} A_{n}\\right) B\\right)}{P(B)}=\\frac{P\\left(\\bigcup_{n=1}^{+\\infty}\\left(A_{n} B\\right)\\right)}{P(B)} \\\\",
        "metadata": {
            "Header 2": "1.4 条件概率",
            "Header 3": "1.4.1 条件概率的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP\\left(\\bigcup_{n=1}^{+\\infty} A_{n} \\mid B\\right)=\\sum_{n=1}^{+\\infty} P\\left(A_{n} \\mid B\\right)\n$$  \n证明：用条件概率的定义很容易证明前两点. 下面来证明第三点. 因为 $A_{1}, A_{2}, \\ldots, A_{n}, \\ldots$ 互不相容, 所以 $A_{1} B, A_{2} B, \\ldots, A_{n} B, \\ldots$ 也互不相容, 故  \n$$\n\\begin{aligned}\nP\\left(\\bigcup_{n=1}^{+\\infty} A_{n} \\mid B\\right) & =\\frac{P\\left(\\left(\\bigcup_{n=1}^{+\\infty} A_{n}\\right) B\\right)}{P(B)}=\\frac{P\\left(\\bigcup_{n=1}^{+\\infty}\\left(A_{n} B\\right)\\right)}{P(B)} \\\\\n& =\\sum_{n=1}^{+\\infty} \\frac{P\\left(A_{n} B\\right)}{P(B)}=\\sum_{n=1}^{+\\infty} P\\left(A_{n} \\mid B\\right) .\n\\end{aligned}\n$$  \n以下给出条件概率特有的三个非常实用的公式: 乘法公式、全概率公式和贝叶斯公式. 这些公式可以帮助我们计算一些复杂事件的概率.",
        "metadata": {
            "Header 2": "1.4 条件概率",
            "Header 3": "1.4.1 条件概率的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "性质 1.4.2:[乘法公式]  \n1. 若 $P(B)>0$, 则  \n$$\n\\begin{equation*}\nP(A B)=P(B) P(A \\mid B) . \\tag{1.4.2}\n\\end{equation*}\n$$  \n2. 若 $P\\left(A_{1} A_{2} \\cdots A_{n-1}\\right)>0$, 则  \n$$\n\\begin{equation*}\nP\\left(A_{1} \\cdots A_{n}\\right)=P\\left(A_{1}\\right) P\\left(A_{2} \\mid A_{1}\\right) P\\left(A_{3} \\mid A_{2} A_{1}\\right) \\cdots P\\left(A_{n} \\mid A 1 \\cdots A_{n-1}\\right) \\tag{1.4.3}\n\\end{equation*}\n$$  \n证明: 由条件概率的定义, 移项即得 (1.4.2). 下证 (1.4.3), 因为  \n$$\nP\\left(A_{1}\\right) \\geqslant P\\left(A_{1} A_{2}\\right) \\geqslant \\cdots \\geqslant P\\left(A_{1} \\cdots A_{n-1}\\right)>0,\n$$  \n所以 (1.4.3) 中的条件概率均有意义, 且按条件概率的定义, (1.4.3) 的右边等于  \n$$\nP\\left(A_{1}\\right) \\cdot \\frac{P\\left(A_{1} A_{2}\\right)}{P\\left(A_{1}\\right)} \\cdot \\frac{P\\left(A_{1} A_{2} A_{3}\\right)}{P\\left(A_{1} A_{2}\\right)} \\cdots \\cdots \\frac{P\\left(A_{1} \\cdots A_{n}\\right)}{P\\left(A_{1} \\cdots A_{n-1}\\right)}=P\\left(A_{1} \\cdots A_{n}\\right)\n$$  \n从而 (1.4.3) 式成立.  \n例 1.4.3: 一批零件共有 100 个, 其中有 10 个不合格品. 从中一个一个取出, 求第三次才取得不合格品的概率是多少?",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n所以 (1.4.3) 中的条件概率均有意义, 且按条件概率的定义, (1.4.3) 的右边等于  \n$$\nP\\left(A_{1}\\right) \\cdot \\frac{P\\left(A_{1} A_{2}\\right)}{P\\left(A_{1}\\right)} \\cdot \\frac{P\\left(A_{1} A_{2} A_{3}\\right)}{P\\left(A_{1} A_{2}\\right)} \\cdots \\cdots \\frac{P\\left(A_{1} \\cdots A_{n}\\right)}{P\\left(A_{1} \\cdots A_{n-1}\\right)}=P\\left(A_{1} \\cdots A_{n}\\right)\n$$  \n从而 (1.4.3) 式成立.  \n例 1.4.3: 一批零件共有 100 个, 其中有 10 个不合格品. 从中一个一个取出, 求第三次才取得不合格品的概率是多少?\n解：以 $A_{i}$ 记事件 “第 $i$ 次取出的是不合格品”, $i=1,2,3$. 则所求概率为 $P\\left(\\overline{A_{1}} \\overline{A_{2}} A_{3}\\right)$, 由乘法公式得  \n$$\n\\begin{aligned}\nP\\left(\\overline{A_{1}} \\overline{A_{2}} A_{3}\\right) & =P\\left(\\overline{A_{1}}\\right) P\\left(\\overline{A_{2}} \\mid \\overline{A_{1}}\\right) P\\left(A_{3} \\mid \\overline{A_{1}} \\overline{A_{2}}\\right) \\\\\n& =\\frac{90}{100} \\frac{89}{99} \\frac{10}{98}=0.0826 .\n\\end{aligned}\n$$  \n其实, 例 1.4.3 是下面例 1.4.4 的特例.",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "解：以 $A_{i}$ 记事件 “第 $i$ 次取出的是不合格品”, $i=1,2,3$. 则所求概率为 $P\\left(\\overline{A_{1}} \\overline{A_{2}} A_{3}\\right)$, 由乘法公式得  \n$$\n\\begin{aligned}\nP\\left(\\overline{A_{1}} \\overline{A_{2}} A_{3}\\right) & =P\\left(\\overline{A_{1}}\\right) P\\left(\\overline{A_{2}} \\mid \\overline{A_{1}}\\right) P\\left(A_{3} \\mid \\overline{A_{1}} \\overline{A_{2}}\\right) \\\\\n& =\\frac{90}{100} \\frac{89}{99} \\frac{10}{98}=0.0826 .\n\\end{aligned}\n$$  \n其实, 例 1.4.3 是下面例 1.4.4 的特例.  \n例 1.4.4 罐子模型: 设罐中有 $b$ 个黑球、 $r$ 个红球, 每次随机取出一个球, 取出后将原球放回, 还加进 $c$ 个同色球和 $d$ 个异色球. 记 $B_{i}$ 为 “第 $i$ 次取出的是黑球”, $R_{j}$ 为 “第 $j$ 次取出的是红球”.  \n若连续从罐中取出三个球, 其中有两个红球、一个黑球. 则由乘法公式我们可得  \n$$\n\\begin{aligned}\nP\\left(B_{1} R_{2} R_{3}\\right) & =P\\left(B_{1}\\right) P\\left(R_{2} \\mid B_{1}\\right) P\\left(R_{3} \\mid B_{1} R_{2}\\right) \\\\\n& =\\frac{b}{b+r} \\frac{r+d}{b+r+c+d} \\frac{r+d+c}{b+r+2 c+2 d}, \\\\\nP\\left(R_{1} B_{2} R_{3}\\right) & =P\\left(R_{1}\\right) P\\left(B_{2} \\mid R_{1}\\right) P\\left(R_{3} \\mid R_{1} B_{2}\\right) \\\\",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "若连续从罐中取出三个球, 其中有两个红球、一个黑球. 则由乘法公式我们可得  \n$$\n\\begin{aligned}\nP\\left(B_{1} R_{2} R_{3}\\right) & =P\\left(B_{1}\\right) P\\left(R_{2} \\mid B_{1}\\right) P\\left(R_{3} \\mid B_{1} R_{2}\\right) \\\\\n& =\\frac{b}{b+r} \\frac{r+d}{b+r+c+d} \\frac{r+d+c}{b+r+2 c+2 d}, \\\\\nP\\left(R_{1} B_{2} R_{3}\\right) & =P\\left(R_{1}\\right) P\\left(B_{2} \\mid R_{1}\\right) P\\left(R_{3} \\mid R_{1} B_{2}\\right) \\\\\n& =\\frac{r}{b+r} \\frac{b+d}{b+r+c+d} \\frac{r+d+c}{b+r+2 c+2 d}, \\\\\nP\\left(R_{1} R_{2} B_{3}\\right) & =P\\left(R_{1}\\right) P\\left(R_{2} \\mid R_{1}\\right) P\\left(B_{3} \\mid R_{1} R_{2}\\right) \\\\\n& =\\frac{r}{b+r} \\frac{r+c}{b+r+c+d} \\frac{b+2 d}{b+r+2 c+2 d} .\n\\end{aligned}\n$$  \n以上概率与黑球在第几次被抽取有关.  \n罐子模型也称为波利亚 (Polya) 模型, 这个模型可以有各种变化, 具体见下:  \n1. 当 $c=-1, d=0$ 时, 即为不返回抽样. 此时前次抽取结果会影响后次抽取结果. 但只要抽取的黑球与红球个数确定, 则概率不依赖其抽出球的次序, 都是一样的. 此例中有  \n$$\n\\begin{aligned}\nP\\left(B_{1} R_{2} R_{3}\\right) & =P\\left(R_{1} B_{2} R_{3}\\right)=P\\left(R_{1} R_{2} B_{3}\\right) \\\\\n& =\\frac{b r(r-1)}{(b+r)(b+r-1)(b+r-2)} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{r}{b+r} \\frac{r+c}{b+r+c+d} \\frac{b+2 d}{b+r+2 c+2 d} .\n\\end{aligned}\n$$  \n以上概率与黑球在第几次被抽取有关.  \n罐子模型也称为波利亚 (Polya) 模型, 这个模型可以有各种变化, 具体见下:  \n1. 当 $c=-1, d=0$ 时, 即为不返回抽样. 此时前次抽取结果会影响后次抽取结果. 但只要抽取的黑球与红球个数确定, 则概率不依赖其抽出球的次序, 都是一样的. 此例中有  \n$$\n\\begin{aligned}\nP\\left(B_{1} R_{2} R_{3}\\right) & =P\\left(R_{1} B_{2} R_{3}\\right)=P\\left(R_{1} R_{2} B_{3}\\right) \\\\\n& =\\frac{b r(r-1)}{(b+r)(b+r-1)(b+r-2)} .\n\\end{aligned}\n$$  \n例 1.4.3 可以归结为此种情况.  \n2. 当 $c=0, d=0$ 时, 即为返回抽样. 此时前次抽取结果不会影响后次抽取结果. 故上述三个概率相等, 且都等于  \n$$\nP\\left(B_{1} R_{2} R_{3}\\right)=P\\left(R_{1} B_{2} R_{3}\\right)=P\\left(R_{1} R_{2} B_{3}\\right)=\\frac{b r^{2}}{(b+r)^{3}}\n$$  \n3. 当 $c>0, d=0$ 时, 称为传染病模型. 此时, 每次取出球后会增加下一次取到同色球的概率,或换句话说, 每次发现一个传染病患者, 以后都会增加再传染的概率. 与前面两个一样, 以上三个概率都相等, 且都等于  \n$$\n\\begin{aligned}\nP\\left(B_{1} R_{2} R_{3}\\right) & =P\\left(R_{1} B_{2} R_{3}\\right)=P\\left(R_{1} R_{2} B_{3}\\right) \\\\\n& =\\frac{b r(r+c)}{(b+r)(b+r+c)(b+r+2 c)} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "2. 当 $c=0, d=0$ 时, 即为返回抽样. 此时前次抽取结果不会影响后次抽取结果. 故上述三个概率相等, 且都等于  \n$$\nP\\left(B_{1} R_{2} R_{3}\\right)=P\\left(R_{1} B_{2} R_{3}\\right)=P\\left(R_{1} R_{2} B_{3}\\right)=\\frac{b r^{2}}{(b+r)^{3}}\n$$  \n3. 当 $c>0, d=0$ 时, 称为传染病模型. 此时, 每次取出球后会增加下一次取到同色球的概率,或换句话说, 每次发现一个传染病患者, 以后都会增加再传染的概率. 与前面两个一样, 以上三个概率都相等, 且都等于  \n$$\n\\begin{aligned}\nP\\left(B_{1} R_{2} R_{3}\\right) & =P\\left(R_{1} B_{2} R_{3}\\right)=P\\left(R_{1} R_{2} B_{3}\\right) \\\\\n& =\\frac{b r(r+c)}{(b+r)(b+r+c)(b+r+2 c)} .\n\\end{aligned}\n$$  \n从以上可以看出: 在罐子模型中只要 $d=0$, 则以上三个概率都相等. 即只要抽取的黑球与红球个数确定, 则概率不依赖其抽出球的次序, 都是一样的. 但当 $d>0$ 时, 就不同了.  \n4. 当 $c=0, d>0$ 时, 称为安全模型. 此模型可解释为: 每当事故发生了 (红球被取出), 安全工作就抓紧一些, 下次再发生事故的概率就会减少; 而当事故没有发生时 (黑球被取出), 安全工作就放松一些, 下次再发生事故的概率就会增大. 在这种场合, 上述三个概率分别为  \n$$\n\\begin{aligned}\nP\\left(B_{1} R_{2} R_{3}\\right) & =\\frac{b}{b+r} \\frac{r+d}{b+r+d} \\frac{r+d}{b+r+2 d} \\\\\nP\\left(R_{1} B_{2} R_{3}\\right) & =\\frac{r}{b+r} \\frac{b+d}{b+r+d} \\frac{r+d}{b+r+2 d} \\\\",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n从以上可以看出: 在罐子模型中只要 $d=0$, 则以上三个概率都相等. 即只要抽取的黑球与红球个数确定, 则概率不依赖其抽出球的次序, 都是一样的. 但当 $d>0$ 时, 就不同了.  \n4. 当 $c=0, d>0$ 时, 称为安全模型. 此模型可解释为: 每当事故发生了 (红球被取出), 安全工作就抓紧一些, 下次再发生事故的概率就会减少; 而当事故没有发生时 (黑球被取出), 安全工作就放松一些, 下次再发生事故的概率就会增大. 在这种场合, 上述三个概率分别为  \n$$\n\\begin{aligned}\nP\\left(B_{1} R_{2} R_{3}\\right) & =\\frac{b}{b+r} \\frac{r+d}{b+r+d} \\frac{r+d}{b+r+2 d} \\\\\nP\\left(R_{1} B_{2} R_{3}\\right) & =\\frac{r}{b+r} \\frac{b+d}{b+r+d} \\frac{r+d}{b+r+2 d} \\\\\nP\\left(R_{1} R_{2} B_{3}\\right) & =\\frac{r}{b+r} \\frac{r}{b+r+d} \\frac{b+2 d}{b+r+2 d}\n\\end{aligned}\n$$  \n!  \n图 1.4.2: 样本空间的一个分割 $(n=5)$  \n!  \n图 1.4.3: 用 $B$ 和 $\\bar{B}$ 来分割样本空间",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式"
        },
        "type": "Document"
    },
    {
        "page_content": "全概率公式是概率论中的一个重要公式, 它提供了计算复杂事件概率的一条有效途径, 使一个复杂事件的概率计算问题化繁就简.  \n性质 1.4.3: [全概率公式] 设 $B_{1}, B_{2}, \\cdots, B_{n}$ 为样本空间 $\\Omega$ 的一个分割 (见图 14.2), 即 $B_{1}, B_{2}, \\cdots, B_{n}$互不相容, 且 $\\bigcup_{i=1}^{n} B_{i}=\\Omega$, 如果 $P\\left(B_{i}\\right)>0, i=1,2, \\cdots, n$, 则对任一事件 $A$ 有  \n$$\n\\begin{equation*}\nP(A)=\\sum_{i=1}^{n} P\\left(B_{i}\\right) P\\left(A \\mid B_{i}\\right) \\tag{1.4.4}\n\\end{equation*}\n$$  \n证明: 因为  \n$$\nA=A \\Omega=A\\left(\\bigcup_{n=1}^{n} B_{i}\\right)=\\bigcup_{i=1}^{n}\\left(A B_{i}\\right)\n$$  \n且 $A B_{1}, A B_{2}, \\ldots, A B_{n}$ 互不相容, 所以由可加性得  \n$$\nP(A)=P\\left(\\bigcup_{i=1}^{n}\\left(A B_{i}\\right)\\right)=\\sum_{i=1}^{n} P\\left(A B_{i}\\right)\n$$  \n再将 $P\\left(A B_{i}\\right)=P\\left(B_{i}\\right) P\\left(A \\mid B_{i}\\right), i=1,2, \\cdots, n$, 代人上式即得(1.4.4).  \n对于全概率公式, 我们要注意以下两点:  \n1. 全概率公式的最简单形式: 假如 $0<P(B)<1$, 则  \n$$\n\\begin{equation*}\nP(A)=P(B) P(A \\mid B)+P(\\bar{B}) P(A \\mid \\bar{B}) \\tag{1.4.5}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.3 全概率公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n且 $A B_{1}, A B_{2}, \\ldots, A B_{n}$ 互不相容, 所以由可加性得  \n$$\nP(A)=P\\left(\\bigcup_{i=1}^{n}\\left(A B_{i}\\right)\\right)=\\sum_{i=1}^{n} P\\left(A B_{i}\\right)\n$$  \n再将 $P\\left(A B_{i}\\right)=P\\left(B_{i}\\right) P\\left(A \\mid B_{i}\\right), i=1,2, \\cdots, n$, 代人上式即得(1.4.4).  \n对于全概率公式, 我们要注意以下两点:  \n1. 全概率公式的最简单形式: 假如 $0<P(B)<1$, 则  \n$$\n\\begin{equation*}\nP(A)=P(B) P(A \\mid B)+P(\\bar{B}) P(A \\mid \\bar{B}) \\tag{1.4.5}\n\\end{equation*}\n$$  \n2. 条件 $B_{1}, B_{2}, \\cdots, B_{n}$ 为样本空间的一个分割, 可改成 $B_{1}, B_{2}, \\cdots, B_{n}$ 互不相容, 且 $A \\subset \\cup_{i=1}^{n} B_{i}$,性质 1.4 .3 仍然成立.  \n例 1.4.5 摸彩模型: 设在 $n$ 张彩票中有一张奖券. 求第二人摸到奖券的概率是多少?  \n解：设 $A_{i}$ 表示事件 “第 $i$ 人摸到奖券”, $i=1,2, \\cdots, n$, 现在目的是求 $P\\left(A_{2}\\right)$. 因为 $A_{1}$ 是否发生直接关系到 $A_{2}$ 发生的概率, 即  \n$$\nP\\left(A_{2} \\mid A_{1}\\right)=0, \\quad P\\left(A_{2} \\mid A_{1}\\right)=\\frac{1}{n-1},\n$$  \n而 $A_{1}$ 与 $\\bar{A}_{1}$ 是两个概率大于 0 的事件:  \n于是由全概率公式得  \n$$\nP\\left(A_{1}\\right)=\\frac{1}{n}, \\quad P\\left(\\bar{A}_{1}\\right)=\\frac{n-1}{n} .\n$$  \n$$",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.3 全概率公式"
        },
        "type": "Document"
    },
    {
        "page_content": "例 1.4.5 摸彩模型: 设在 $n$ 张彩票中有一张奖券. 求第二人摸到奖券的概率是多少?  \n解：设 $A_{i}$ 表示事件 “第 $i$ 人摸到奖券”, $i=1,2, \\cdots, n$, 现在目的是求 $P\\left(A_{2}\\right)$. 因为 $A_{1}$ 是否发生直接关系到 $A_{2}$ 发生的概率, 即  \n$$\nP\\left(A_{2} \\mid A_{1}\\right)=0, \\quad P\\left(A_{2} \\mid A_{1}\\right)=\\frac{1}{n-1},\n$$  \n而 $A_{1}$ 与 $\\bar{A}_{1}$ 是两个概率大于 0 的事件:  \n于是由全概率公式得  \n$$\nP\\left(A_{1}\\right)=\\frac{1}{n}, \\quad P\\left(\\bar{A}_{1}\\right)=\\frac{n-1}{n} .\n$$  \n$$\n\\begin{aligned}\nP\\left(A_{2}\\right) & =P\\left(A_{1}\\right) P\\left(A_{2} \\mid A_{1}\\right)+P\\left(A_{1}\\right) P\\left(A_{2} \\mid \\bar{A}_{1}\\right) \\\\\n& =\\frac{1}{n} .\n\\end{aligned}\n$$  \n用类似的方法可得  \n$$\nP\\left(A_{3}\\right)=P\\left(A_{4}\\right)=\\cdots=P\\left(A_{n}\\right)=\\frac{1}{n} .\n$$  \n!  \n图 1.4.4: 敏感性问题的答卷  \n如果设 $n$ 张彩票中有 $k(\\leqslant n)$ 张奖券, 则可得  \n$$\nP\\left(A_{1}\\right)=P\\left(A_{2}\\right)=\\cdots=P\\left(A_{n}\\right)=\\frac{k}{n} .\n$$  \n这说明, 购买彩票时, 不论先买后买, 中彩机会是均等的.",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.3 全概率公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n$$\n\\begin{aligned}\nP\\left(A_{2}\\right) & =P\\left(A_{1}\\right) P\\left(A_{2} \\mid A_{1}\\right)+P\\left(A_{1}\\right) P\\left(A_{2} \\mid \\bar{A}_{1}\\right) \\\\\n& =\\frac{1}{n} .\n\\end{aligned}\n$$  \n用类似的方法可得  \n$$\nP\\left(A_{3}\\right)=P\\left(A_{4}\\right)=\\cdots=P\\left(A_{n}\\right)=\\frac{1}{n} .\n$$  \n!  \n图 1.4.4: 敏感性问题的答卷  \n如果设 $n$ 张彩票中有 $k(\\leqslant n)$ 张奖券, 则可得  \n$$\nP\\left(A_{1}\\right)=P\\left(A_{2}\\right)=\\cdots=P\\left(A_{n}\\right)=\\frac{k}{n} .\n$$  \n这说明, 购买彩票时, 不论先买后买, 中彩机会是均等的.  \n例 1.4.6 敏感性问题调查: 学生阅读黄色书刊和观看黄色影像会严重影响学生身心健康发展. 但这些都是避着教师与家长进行的, 属个人隐私行为. 现在要设计一个调查方案, 从调查数据中估计出学生中阅读黄色书刊和观看黄色影像的比率 $p$.  \n像这类敏感性问题的调查是社会调查的一类, 如一群人中参加奢博的比率、吸毒人的比率、经营者中偷税漏税户的比率、学生中考试作弊的比率等等.  \n敏感性问趣的调查方案, 关键要使被调查者愿意作出真实回答又能保守个人秘密. 一且调查方案设计有误, 被调查者就会拒绝配合, 所得调查数据将失去真实性. 经过多年研究和实践, 一些心理学家和统计学家设计了一种调查方案, 在这个方案中被调查者只需回答以下两个问题中的一个问题,而且只需回答“是”或“否”。  \n问题 A: 你的生日是否在 7 月 1 日之前?  \n问题 B: 你是否看过黄色书刊或影像?  \n这个调查方来看似简单, 但为了消除被调查者的顾虑, 使被调查者确信他这次调查不会泄露个人秘密, 在操作上有以下关键点:  \n1. 被调查者在没有旁人的情况下, 独自一人回答问题",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.3 全概率公式"
        },
        "type": "Document"
    },
    {
        "page_content": "例 1.4.6 敏感性问题调查: 学生阅读黄色书刊和观看黄色影像会严重影响学生身心健康发展. 但这些都是避着教师与家长进行的, 属个人隐私行为. 现在要设计一个调查方案, 从调查数据中估计出学生中阅读黄色书刊和观看黄色影像的比率 $p$.  \n像这类敏感性问题的调查是社会调查的一类, 如一群人中参加奢博的比率、吸毒人的比率、经营者中偷税漏税户的比率、学生中考试作弊的比率等等.  \n敏感性问趣的调查方案, 关键要使被调查者愿意作出真实回答又能保守个人秘密. 一且调查方案设计有误, 被调查者就会拒绝配合, 所得调查数据将失去真实性. 经过多年研究和实践, 一些心理学家和统计学家设计了一种调查方案, 在这个方案中被调查者只需回答以下两个问题中的一个问题,而且只需回答“是”或“否”。  \n问题 A: 你的生日是否在 7 月 1 日之前?  \n问题 B: 你是否看过黄色书刊或影像?  \n这个调查方来看似简单, 但为了消除被调查者的顾虑, 使被调查者确信他这次调查不会泄露个人秘密, 在操作上有以下关键点:  \n1. 被调查者在没有旁人的情况下, 独自一人回答问题\n2. 被调查者从一个罐子中随机抽一只球, 看过颜色后即放回. 若抽到白球, 则回答问题 $\\mathrm{A}$; 若抽到红球, 则回答问题 B. 且罐中只有白球和红球.  \n被调查者无论回答问题 A 或问题 $\\mathrm{B}$, 只需在下面答卷上认可的方框内打钩, 然后把答卷放人一只密封的投票箱内.  \n如此的调查方法, 主要在于旁人无法知道被调查回答的是问题 $\\mathrm{A}$ 还是问题 $\\mathrm{B}$, 由此可以极大地消除被调查者的顾虑.  \n现在的问题是如何分析调查的结果. 很显然, 我们对问题 $\\mathrm{A}$ 是不感兴趣的.  \n首先我们设有 $n$ 张答卷 ( $n$ 较大, 譬如 1000 以上), 其中有 $k$ 张回答 “是”. 而我们又无法知道此 $n$ 张答卷中有多少张是回答问题 $B$ 的, 同样无法知道 $k$ 张回答 “是” 的答卷中有多少张是回答问题 $B$ 的. 但有两个信息我们是预先知道的, 即  \n1. 在参加人数较多的场合, 任选一人其生日在 7 月 1 日之前的概率为 0.5 .",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.3 全概率公式"
        },
        "type": "Document"
    },
    {
        "page_content": "2. 被调查者从一个罐子中随机抽一只球, 看过颜色后即放回. 若抽到白球, 则回答问题 $\\mathrm{A}$; 若抽到红球, 则回答问题 B. 且罐中只有白球和红球.  \n被调查者无论回答问题 A 或问题 $\\mathrm{B}$, 只需在下面答卷上认可的方框内打钩, 然后把答卷放人一只密封的投票箱内.  \n如此的调查方法, 主要在于旁人无法知道被调查回答的是问题 $\\mathrm{A}$ 还是问题 $\\mathrm{B}$, 由此可以极大地消除被调查者的顾虑.  \n现在的问题是如何分析调查的结果. 很显然, 我们对问题 $\\mathrm{A}$ 是不感兴趣的.  \n首先我们设有 $n$ 张答卷 ( $n$ 较大, 譬如 1000 以上), 其中有 $k$ 张回答 “是”. 而我们又无法知道此 $n$ 张答卷中有多少张是回答问题 $B$ 的, 同样无法知道 $k$ 张回答 “是” 的答卷中有多少张是回答问题 $B$ 的. 但有两个信息我们是预先知道的, 即  \n1. 在参加人数较多的场合, 任选一人其生日在 7 月 1 日之前的概率为 0.5 .\n2. 罐中红球的比率 $\\pi$ 是已知. 现在就要从这 4 个数据 $(n, k, 0.5, \\pi)$ 去求出 $p$. 因为由全概率公式得  \n$$\nP(\\text { 是 })=P(\\text { 白球 }) P(\\text { 是 } \\mid \\text { 白球 })+P(\\text { 红球 }) P(\\text { 是 } \\mid \\text { 红球 }) .\n$$  \n所以将 $P($ 红球 $)=\\pi, P($ 白球 $)=1-\\pi, P($ 是 $\\mid$ 白球 $)=0.5, P($ 是 $\\mid$ 红球 $)=p$ 代人上式右边, 而上式左边用频率 $k / n$ 代替, 得  \n$$\n\\frac{k}{n}=0.5(1-\\pi)+p \\cdot \\pi\n$$  \n由此得  \n$$\np=\\frac{k / n-0.5(1-\\pi)}{\\pi}\n$$  \n因为我们用频率 $k / n$ 代替了概率 $P$ (是), 所以从上式得到的是 $p$ 的估计.",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.3 全概率公式"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 在参加人数较多的场合, 任选一人其生日在 7 月 1 日之前的概率为 0.5 .\n2. 罐中红球的比率 $\\pi$ 是已知. 现在就要从这 4 个数据 $(n, k, 0.5, \\pi)$ 去求出 $p$. 因为由全概率公式得  \n$$\nP(\\text { 是 })=P(\\text { 白球 }) P(\\text { 是 } \\mid \\text { 白球 })+P(\\text { 红球 }) P(\\text { 是 } \\mid \\text { 红球 }) .\n$$  \n所以将 $P($ 红球 $)=\\pi, P($ 白球 $)=1-\\pi, P($ 是 $\\mid$ 白球 $)=0.5, P($ 是 $\\mid$ 红球 $)=p$ 代人上式右边, 而上式左边用频率 $k / n$ 代替, 得  \n$$\n\\frac{k}{n}=0.5(1-\\pi)+p \\cdot \\pi\n$$  \n由此得  \n$$\np=\\frac{k / n-0.5(1-\\pi)}{\\pi}\n$$  \n因为我们用频率 $k / n$ 代替了概率 $P$ (是), 所以从上式得到的是 $p$ 的估计.  \n例如, 在一次实际调查中, 罐中放有红球 30 个、白球 20 个, 则 $\\pi=0.6$, 调查结束后共收到 1583 张有效答卷, 其中有 389 张回答 “是”, 由此可计算得  \n$$\np=\\frac{389 / 1583-0.5 \\times 0.4}{0.6}=0.0762 .\n$$  \n这表明: 约有 $7.62 \\%$ 的学生看过黄色书刊或黄色影像.",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.3 全概率公式"
        },
        "type": "Document"
    },
    {
        "page_content": "在乘法公式和全概率公式的基础上立即可推得一个很著名的公式.  \n性质 1.4.4: [贝叶斯公式] 设 $B_{1}, B_{2}, \\cdots, B_{n}$ 是样本空间 $\\Omega$ 的一个分割, 即 $B_{1}, B_{2}, \\cdots, B_{n}$ 互不相容, 且 $\\bigcup_{i=1}^{n} B_{i}=\\Omega$, 如果 $P(A)>0, P\\left(B_{i}\\right)>0, i=1,2, \\cdots, n$, 则  \n$$\n\\begin{equation*}\nP\\left(B_{i} \\mid A\\right)=\\frac{P\\left(B_{i}\\right) P\\left(A \\mid B_{i}\\right)}{\\sum_{j=1}^{n} P\\left(B_{j}\\right) P\\left(A \\mid B_{j}\\right)}, i=1,2, \\cdots, n \\tag{1.4.6}\n\\end{equation*}\n$$  \n证明: 由条件概率的定义  \n$$\nP\\left(B_{i} \\mid A\\right)=\\frac{P\\left(A B_{i}\\right)}{P(A)}\n$$  \n对上式的分子用乘法公式、分母用全概率公式,  \n$$\n\\begin{aligned}\n& P\\left(A B_{i}\\right)=P\\left(B_{i}\\right) P\\left(A \\mid B_{i}\\right), \\\\\n& P(A)=\\sum_{j=1}^{n} P\\left(B_{j}\\right) P\\left(A \\mid B_{j}\\right),\n\\end{aligned}\n$$  \n即得  \n$$\nP\\left(B_{i} \\mid A\\right)=\\frac{P\\left(B_{i}\\right) P\\left(A \\mid B_{i}\\right)}{\\sum_{j=1}^{n} P\\left(B_{j}\\right) P\\left(A \\mid B_{j}\\right)} .\n$$  \n结论得证.",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.4 贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n证明: 由条件概率的定义  \n$$\nP\\left(B_{i} \\mid A\\right)=\\frac{P\\left(A B_{i}\\right)}{P(A)}\n$$  \n对上式的分子用乘法公式、分母用全概率公式,  \n$$\n\\begin{aligned}\n& P\\left(A B_{i}\\right)=P\\left(B_{i}\\right) P\\left(A \\mid B_{i}\\right), \\\\\n& P(A)=\\sum_{j=1}^{n} P\\left(B_{j}\\right) P\\left(A \\mid B_{j}\\right),\n\\end{aligned}\n$$  \n即得  \n$$\nP\\left(B_{i} \\mid A\\right)=\\frac{P\\left(B_{i}\\right) P\\left(A \\mid B_{i}\\right)}{\\sum_{j=1}^{n} P\\left(B_{j}\\right) P\\left(A \\mid B_{j}\\right)} .\n$$  \n结论得证.  \n例 1.4.7: 某地区居民的肝癌发病率为 0.0004, 现用甲胎蛋白法进行普查. 医学研究表明, 化验结果是存有错误的. 已知患有肝癌的人其化验结果 $99 \\%$ 呈阳性 (有病), 而没患肝癌的人其化验结果 $99.9 \\%$ 呈阴性 (无病). 现某人的检查结果呈阳性, 问他真的患肝癌的概率是多少?  \n解: 记 $B$ 为事件 “被检查者患有肝癌”, $A$ 为事件 “检查结果呈阳性”. 由题设知  \n$$\n\\begin{gathered}\nP(B)=0.0004, \\quad P(\\bar{B})=0.996 \\\\\nP(A \\mid B)=0.99, \\quad P(A \\mid \\bar{B})=0.001 .\n\\end{gathered}\n$$  \n我们现在的目的是求 $P(B \\mid A)$. 由贝叶斯公式得  \n$$\n\\begin{aligned}\nP(B \\mid A) & =\\frac{P(B) P(A \\mid B)}{P(B) P(A \\mid B)+P(\\bar{B}) P(A \\mid \\bar{B})} \\\\",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.4 贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n结论得证.  \n例 1.4.7: 某地区居民的肝癌发病率为 0.0004, 现用甲胎蛋白法进行普查. 医学研究表明, 化验结果是存有错误的. 已知患有肝癌的人其化验结果 $99 \\%$ 呈阳性 (有病), 而没患肝癌的人其化验结果 $99.9 \\%$ 呈阴性 (无病). 现某人的检查结果呈阳性, 问他真的患肝癌的概率是多少?  \n解: 记 $B$ 为事件 “被检查者患有肝癌”, $A$ 为事件 “检查结果呈阳性”. 由题设知  \n$$\n\\begin{gathered}\nP(B)=0.0004, \\quad P(\\bar{B})=0.996 \\\\\nP(A \\mid B)=0.99, \\quad P(A \\mid \\bar{B})=0.001 .\n\\end{gathered}\n$$  \n我们现在的目的是求 $P(B \\mid A)$. 由贝叶斯公式得  \n$$\n\\begin{aligned}\nP(B \\mid A) & =\\frac{P(B) P(A \\mid B)}{P(B) P(A \\mid B)+P(\\bar{B}) P(A \\mid \\bar{B})} \\\\\n& =\\frac{0.0004 \\times 0.99}{0.0004 \\times 0.99+0.9996 \\times 0.001} \\\\\n& =0.284 .\n\\end{aligned}\n$$  \n这表明, 在检查结果呈阳性的人中, 真患肝癌的人不到 $30 \\%$, 这个结果可能会使人吃惊, 但仔细分析一下就可以理解了. 因为肝癌发病率很低, 在 10000 个人中, 约有 4 人, 而约有 9996 个人不惠肝癌. 对 10000 个人用甲胎蛋白法进行检查, 按其错检的概率可知, 9996 个不患肝癌者中约有 $9996 \\times 0.001 \\cong 9.994$ 个呈阳性. 另外 4 个真患肝癌者的检查报告中约有 $4 \\times 0.99 \\cong 3.96$ 个呈阳性. 仅从 13.956 个呈阳性者中看, 真患肝癌的 3.96 人约占 $28.4 \\%$.  \n进一步降低错检的概率是提高检验精度的关键. 在实际中由于技术和操作等种种原因, 降低",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.4 贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{0.0004 \\times 0.99}{0.0004 \\times 0.99+0.9996 \\times 0.001} \\\\\n& =0.284 .\n\\end{aligned}\n$$  \n这表明, 在检查结果呈阳性的人中, 真患肝癌的人不到 $30 \\%$, 这个结果可能会使人吃惊, 但仔细分析一下就可以理解了. 因为肝癌发病率很低, 在 10000 个人中, 约有 4 人, 而约有 9996 个人不惠肝癌. 对 10000 个人用甲胎蛋白法进行检查, 按其错检的概率可知, 9996 个不患肝癌者中约有 $9996 \\times 0.001 \\cong 9.994$ 个呈阳性. 另外 4 个真患肝癌者的检查报告中约有 $4 \\times 0.99 \\cong 3.96$ 个呈阳性. 仅从 13.956 个呈阳性者中看, 真患肝癌的 3.96 人约占 $28.4 \\%$.  \n进一步降低错检的概率是提高检验精度的关键. 在实际中由于技术和操作等种种原因, 降低\n错检的概率又是很困难的. 所以在实际中, 常采用复查的方法来减少错误率. 或用另一些简单易行的辅助方法先进行初查, 排除了大量明显不是肝癌的人后, 再用甲胎蛋白法对被怀疑的对象进行检查. 此时被怀疑的对象群体中, 肝癌的发病率已大大提高了. 警如, 对首次检查得阳性的人群再进行复查, 此时 $P(B)=0.284$, 这时再用贝叶斯公式计算得  \n$$\nP(B \\mid A)=\\frac{0.284 \\times 0.99}{0.284 \\times 0.99+0.716 \\times 0.0001}=0.997\n$$  \n这就大大提高了甲胎蛋白法的准确率了.  \n在上面例中, 如果我们将事件 B (“被检查者患有肝癌”) 看作是“原因”, 将事件 $A$ (“检查结果呈阳性” ) 看作是最后 “结果”. 则我们用贝叶斯公式在已知 “结果” 的条件下, 求出了 “原因” 的概率 $P(B \\mid A)$. 而求 “结果” 的 (无条件) 概率 $P(A)$, 用全概率公式. 在上例中若取 $P(B)=0.284$, 则  \n$$\n\\begin{aligned}\nP(A) & =P(B) P(A \\mid B)+P(\\bar{B}) P(A \\mid \\bar{B}) \\\\",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.4 贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(B \\mid A)=\\frac{0.284 \\times 0.99}{0.284 \\times 0.99+0.716 \\times 0.0001}=0.997\n$$  \n这就大大提高了甲胎蛋白法的准确率了.  \n在上面例中, 如果我们将事件 B (“被检查者患有肝癌”) 看作是“原因”, 将事件 $A$ (“检查结果呈阳性” ) 看作是最后 “结果”. 则我们用贝叶斯公式在已知 “结果” 的条件下, 求出了 “原因” 的概率 $P(B \\mid A)$. 而求 “结果” 的 (无条件) 概率 $P(A)$, 用全概率公式. 在上例中若取 $P(B)=0.284$, 则  \n$$\n\\begin{aligned}\nP(A) & =P(B) P(A \\mid B)+P(\\bar{B}) P(A \\mid \\bar{B}) \\\\\n& =0.284 \\times 0.99+0.716 \\times 0.001 \\\\\n& =0.2819\n\\end{aligned}\n$$  \n条件概率的三公式中, 乘法公式是求事件交的概率. 全概率公式是求一个复杂事件的概率, 而贝叶斯公式是求一个条件概率.  \n在贝叶斯公式中, 如果称 $P\\left(B_{i}\\right)$ 为 $B_{i}$ 的先验概率, 称 $P\\left(B_{i} \\mid A\\right)$ 为 $B_{i}$ 的后验概率, 则贝叶斯公式是专门用于计算后验概率的, 也就是通过 $A$ 的发生这个新信息, 来对 $B_{i}$ 的概率作出的修正. 下面例子很好地说明了这一点.  \n例 1.4.8: 伊索寓言 “孩子与狼” 讲的是一个小孩每天到山上放羊, 山里有狼出没. 第一天, 他在山上喊: “狼来了! 狼来了!”, 山下的村民闻声便去打狼, 可到山上, 发现狼没有来; 第二天仍是如此; 第三天, 狼真的来了, 可无论小孩怎么喊叫, 也没有人来救他, 因为前二次他说了谎, 人们不再相信他了.  \n现在用贝叶斯公式来分析此寓言中村民对这个小孩的可信程度是如何下降的.  \n首先记事件 $A$ 为“小孩说谎”, 记事件 $B$ 为“小孩可信”. 不妨设村民过去对这个小孩的印象为  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.4 贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "在贝叶斯公式中, 如果称 $P\\left(B_{i}\\right)$ 为 $B_{i}$ 的先验概率, 称 $P\\left(B_{i} \\mid A\\right)$ 为 $B_{i}$ 的后验概率, 则贝叶斯公式是专门用于计算后验概率的, 也就是通过 $A$ 的发生这个新信息, 来对 $B_{i}$ 的概率作出的修正. 下面例子很好地说明了这一点.  \n例 1.4.8: 伊索寓言 “孩子与狼” 讲的是一个小孩每天到山上放羊, 山里有狼出没. 第一天, 他在山上喊: “狼来了! 狼来了!”, 山下的村民闻声便去打狼, 可到山上, 发现狼没有来; 第二天仍是如此; 第三天, 狼真的来了, 可无论小孩怎么喊叫, 也没有人来救他, 因为前二次他说了谎, 人们不再相信他了.  \n现在用贝叶斯公式来分析此寓言中村民对这个小孩的可信程度是如何下降的.  \n首先记事件 $A$ 为“小孩说谎”, 记事件 $B$ 为“小孩可信”. 不妨设村民过去对这个小孩的印象为  \n$$\n\\begin{equation*}\nP(B)=0.8, \\quad P(\\bar{B})=0.2 . \\tag{1.4.7}\n\\end{equation*}\n$$  \n我们现在用贝叶斯公式来求 $P(B \\mid A)$, 亦即这个小孩说了一次谎后, 村民对他可信程度的改变.在贝叶斯公式中我们要用到概率 $P(A \\mid B)$ 和 $P(A \\mid \\bar{B})$, 这两个概率的含义是: 前者为 “可信” $(B)$ 的孩子 “说谎” $(A)$ 的可能性, 后者为 “不可信” $(\\bar{B})$ 的孩子“说谎” $(A)$ 的可能性. 在此不妨设  \n$$\nP(A \\mid B)=0.1, \\quad P(A \\mid \\bar{B})=0.5 \\text {. }\n$$  \n第一次村民上山打狼, 发现狼没有来, 即小孩说了谎 $(A)$. 村民根据这个信息, 对这个小孩的可信程度改变为 (用贝叶斯公式)  \n$$\n\\begin{aligned}\nP(B \\mid A) & =\\frac{P(B) P(A \\mid B)}{P(B) P(A \\mid B)+P(\\bar{B}) P(A \\mid \\bar{B})} \\\\",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.4 贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n我们现在用贝叶斯公式来求 $P(B \\mid A)$, 亦即这个小孩说了一次谎后, 村民对他可信程度的改变.在贝叶斯公式中我们要用到概率 $P(A \\mid B)$ 和 $P(A \\mid \\bar{B})$, 这两个概率的含义是: 前者为 “可信” $(B)$ 的孩子 “说谎” $(A)$ 的可能性, 后者为 “不可信” $(\\bar{B})$ 的孩子“说谎” $(A)$ 的可能性. 在此不妨设  \n$$\nP(A \\mid B)=0.1, \\quad P(A \\mid \\bar{B})=0.5 \\text {. }\n$$  \n第一次村民上山打狼, 发现狼没有来, 即小孩说了谎 $(A)$. 村民根据这个信息, 对这个小孩的可信程度改变为 (用贝叶斯公式)  \n$$\n\\begin{aligned}\nP(B \\mid A) & =\\frac{P(B) P(A \\mid B)}{P(B) P(A \\mid B)+P(\\bar{B}) P(A \\mid \\bar{B})} \\\\\n& =\\frac{0.8 \\times 0.1}{0.8 \\times 0.1+0.2 \\times 0.5}=0.444 .\n\\end{aligned}\n$$  \n这表明村民上了一次当后, 对这个小孩的可信程度由原来的 0.8 调整为 0.444 , 也就是 (1.4.7)调整为  \n$$\n\\begin{equation*}\nP(B)=0.444, \\quad P(\\bar{B})=0.556 . \\tag{1.4.8}\n\\end{equation*}\n$$  \n在此基础上,我们再一次用贝叶斯公式来计算 $P(B \\mid A)$, 亦即这个小孩第二次说谎后, 村民对他的可信程度改变为  \n$$\nP(B \\mid A)=\\frac{0.444 \\times 0.1}{0.444 \\times 0.1+0.556 \\times 0.5}=0.138 .\n$$  \n这表明村民们经过两次上当, 对这个小孩的可信程度已经从 0.8 下降到了 0.138 ,如此低的可\n信度,村民听到第三次呼叫时怎么再会上山打狼呢?  \n这个例子启发人们:若某人向银行贷款,连续两次未还,银行还会第三次贷款给他吗?",
        "metadata": {
            "Header 2": "1.4 .2 乘法公式",
            "Header 3": "1.4.4 贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 某班级学生的考试成绩数学不及格的占 $15 \\%$, 语文不及格的占 $5 \\%$, 这两门都不及格的占 $3 \\%$.  \n(1) 已知一学生数学不及格,他语文也不及格的概率是多少?  \n(2) 已知一学生语文不及格, 他数学也不及格的概率是多少?  \n2. 设一批产品中一、二、三等品各占 $60 \\%, 30 \\%, 10 \\%$. 从中任意取出一件, 结果不是三等品, 求取到的是一等品的概率.\n3. 郑两颗骰子,以 $A$ 记事件 “两颗点数之和为 10 ”, 以 $B$ 记事件 “第一颗点数小于第二颗点数”, 试求条件概率 $P(A \\mid B)$ 和 $P(B \\mid A)$.\n4. 设某种动物由出生活到 10 岁的概率为 0.8 , 而活到 15 岁的概率为 0.4 . 问现年为 10 岁的这种动物能活到 15 岁的概率是多少?\n5. 设 10 件产品中有 4 件不合格品, 从中任取两件, 已知其中一件是不合格品, 求另一件也是不合格品的概率.\n6. 设 $n$ 件产品中有 $m$ 件不合格品, 从中任取两件, 已知两件中有一件是不合格品, 求另一件也是不合格品的概率.\n7. 掷一颗骰子两次,以 $x, y$ 分别表示先后郑出的点数,记  \n$$\nA=\\{x+y=10\\}, \\quad B=\\{x>y\\},\n$$  \n求 $P(B \\mid A), P(A \\mid B)$.  \n8. 已知 $P(A)=1 / 4, P(B \\mid A)=1 / 3, P(A \\mid B)=1 / 2$, 求 $P(A \\cup B)$.\n9. 已知 $P(\\bar{A})=0.3, P(B)=0.4, P(A \\bar{B})=0.5$, 求 $P(B \\mid A \\cup \\bar{B})$.\n10. 设 $A, B$ 为两事件, $P(A)=P(B)=1 / 3, P(A \\mid B)=1 / 6$, 求 $P(\\bar{A} \\mid \\bar{B})$.\n11. 口袋中有 1 只白球, 1 只黑球. 从中任取 1 只, 若取出白球, 则试验停止; 若取出黑球,则把取出的黑球放回的同时, 再加人 1 只黑球, 如此下去, 直到取出的是白球为止, 试求下列事件的概率.  \n(1) 取到第 $n$ 次,试验没有结束;",
        "metadata": {
            "Header 2": "如 题 1.4"
        },
        "type": "Document"
    },
    {
        "page_content": "7. 掷一颗骰子两次,以 $x, y$ 分别表示先后郑出的点数,记  \n$$\nA=\\{x+y=10\\}, \\quad B=\\{x>y\\},\n$$  \n求 $P(B \\mid A), P(A \\mid B)$.  \n8. 已知 $P(A)=1 / 4, P(B \\mid A)=1 / 3, P(A \\mid B)=1 / 2$, 求 $P(A \\cup B)$.\n9. 已知 $P(\\bar{A})=0.3, P(B)=0.4, P(A \\bar{B})=0.5$, 求 $P(B \\mid A \\cup \\bar{B})$.\n10. 设 $A, B$ 为两事件, $P(A)=P(B)=1 / 3, P(A \\mid B)=1 / 6$, 求 $P(\\bar{A} \\mid \\bar{B})$.\n11. 口袋中有 1 只白球, 1 只黑球. 从中任取 1 只, 若取出白球, 则试验停止; 若取出黑球,则把取出的黑球放回的同时, 再加人 1 只黑球, 如此下去, 直到取出的是白球为止, 试求下列事件的概率.  \n(1) 取到第 $n$ 次,试验没有结束;  \n(2) 取到第 $n$ 次, 试验恰好结束.  \n12. 一盒晶体管中有 6 只合格品、 4 只不合格品. 从中不返回地一只一只取出, 试求第二次取出合格品的概率.\n13. 甲口袋有 $a$ 只黑球、 $b$ 只白球,乙口袋有 $n$ 只黑球、 $m$ 只白球.  \n(1) 从甲口袋任取 1 只球放人乙口袋, 然后再从乙口袋任取 1 只球. 试求最后从乙口袋取出的是黑球的概率.  \n(2) 从甲口袋任取 2 只球放人乙口袋, 然后再从乙口袋任取 1 只球. 试求最后从乙口袋取出的是黑球的概率.  \n14. 两台车床加工同样的零件, 第一台出现不合格品的概率是 0.03 , 第二台出现不合格品的概率是 0.06 , 加工出来的零件放在一起, 并且已知第一台加工的零件比第二台加工的零件多一倍.  \n(1) 求任取一个零件是合格品的概率.  \n(2) 如果取出的零件是不合格品,求它是由第二台车床加工的概率.  \n15. 已知男人中有 $5 \\%$ 是色育患者, 女人中有 $0.25 \\%$ 是色盲患者, 今从男女人数相等的人群中随机地挑选一人,发现恰好是色育患者, 问此人是男性的概率是多少?",
        "metadata": {
            "Header 2": "如 题 1.4"
        },
        "type": "Document"
    },
    {
        "page_content": "12. 一盒晶体管中有 6 只合格品、 4 只不合格品. 从中不返回地一只一只取出, 试求第二次取出合格品的概率.\n13. 甲口袋有 $a$ 只黑球、 $b$ 只白球,乙口袋有 $n$ 只黑球、 $m$ 只白球.  \n(1) 从甲口袋任取 1 只球放人乙口袋, 然后再从乙口袋任取 1 只球. 试求最后从乙口袋取出的是黑球的概率.  \n(2) 从甲口袋任取 2 只球放人乙口袋, 然后再从乙口袋任取 1 只球. 试求最后从乙口袋取出的是黑球的概率.  \n14. 两台车床加工同样的零件, 第一台出现不合格品的概率是 0.03 , 第二台出现不合格品的概率是 0.06 , 加工出来的零件放在一起, 并且已知第一台加工的零件比第二台加工的零件多一倍.  \n(1) 求任取一个零件是合格品的概率.  \n(2) 如果取出的零件是不合格品,求它是由第二台车床加工的概率.  \n15. 已知男人中有 $5 \\%$ 是色育患者, 女人中有 $0.25 \\%$ 是色盲患者, 今从男女人数相等的人群中随机地挑选一人,发现恰好是色育患者, 问此人是男性的概率是多少?\n16. 钥匙掉了, 掉在宿舍里、掉在教室里、掉在路上的概率分别是 $40 \\% 、 30 \\%$ 和 $20 \\%$, 而掉在上述三处地方被找到的概率分别是 $0.8 、 0.3$ 和 0.1 . 试求找到钥匙的概率.\n17. 口袋中有 $a$ 个白球, $b$ 个黑球和 $n$ 个红球, 现从中一个一个不返回地取球. 试证白球比黑球出现\n得早的概率为 $a /(a+b)$, 与 $n$ 无关.\n18. 有两箱零件, 第一箱装 50 件, 其中 10 件是一等品; 第二箱装 30 件, 其中 18 件是一等品, 现从两箱中随意挑出一箱,然而从该箱中任取两个零件,试求  \n(1) 第一次取出的零件是一等品的概率;  \n(2) 在第一次取出的是一等品的条件下,第二次取出的零件仍然是一等品的概率.  \n19. 学生在做一道有 4 个选项的单项选择题时, 如果他不知道问题的正确答案时, 就作随机猪测. 现从卷面上看题是答对了, 试在以下情况下求学生确实知道正确答案的概率.  \n(1) 学生知道正确答案和胡乱猜测的概率都是 $1 / 2$.  \n(2) 学生知道正确答案的概率是 0.2 .",
        "metadata": {
            "Header 2": "如 题 1.4"
        },
        "type": "Document"
    },
    {
        "page_content": "16. 钥匙掉了, 掉在宿舍里、掉在教室里、掉在路上的概率分别是 $40 \\% 、 30 \\%$ 和 $20 \\%$, 而掉在上述三处地方被找到的概率分别是 $0.8 、 0.3$ 和 0.1 . 试求找到钥匙的概率.\n17. 口袋中有 $a$ 个白球, $b$ 个黑球和 $n$ 个红球, 现从中一个一个不返回地取球. 试证白球比黑球出现\n得早的概率为 $a /(a+b)$, 与 $n$ 无关.\n18. 有两箱零件, 第一箱装 50 件, 其中 10 件是一等品; 第二箱装 30 件, 其中 18 件是一等品, 现从两箱中随意挑出一箱,然而从该箱中任取两个零件,试求  \n(1) 第一次取出的零件是一等品的概率;  \n(2) 在第一次取出的是一等品的条件下,第二次取出的零件仍然是一等品的概率.  \n19. 学生在做一道有 4 个选项的单项选择题时, 如果他不知道问题的正确答案时, 就作随机猪测. 现从卷面上看题是答对了, 试在以下情况下求学生确实知道正确答案的概率.  \n(1) 学生知道正确答案和胡乱猜测的概率都是 $1 / 2$.  \n(2) 学生知道正确答案的概率是 0.2 .  \n20. 口袋中有一只球, 不知它的颜色是黑的还是白的. 现再往口袋中放人一只白球, 然后从口袋中任意取出一只,发现取出的是白球,试问口袋中原来那只球是白球的可能性为多少?\n21. 将 $n$ 根绳子的 $2 n$ 个头任意两两相接,求恰好结成 $n$ 个圈的概率.\n22. $m$ 个人相互传球, 球从甲手中开始传出, 每次传球时,传球者等可能地把球传给其余 $m-1$ 个人中的任何一个. 求第 $n$ 次传球时仍由甲传出的概率.\n23. 甲、乙两人轮流掷一颗骰子, 甲先郑. 每当某人郑出 1 点时,则交给对方郑, 否则此人继续郑. 试求第 $n$ 次由甲郑的概率.\n24. 甲口袋有 1 只黑球、 2 只白球,乙口袋有 3 只白球. 每次从两口袋中各任取一球,交换后放人另一口袋. 求交换 $n$ 次后, 黑球仍在甲口袋中的概率.\n25. 假设只考虑天气的两种情况: 有雨或无雨. 若已知今天的天气情况, 明天天气保持不变的概率为 $p$, 变的概率为 $1-p$. 设第一天无雨, 试求第 $n$ 天也无雨的概率.",
        "metadata": {
            "Header 2": "如 题 1.4"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) 学生知道正确答案的概率是 0.2 .  \n20. 口袋中有一只球, 不知它的颜色是黑的还是白的. 现再往口袋中放人一只白球, 然后从口袋中任意取出一只,发现取出的是白球,试问口袋中原来那只球是白球的可能性为多少?\n21. 将 $n$ 根绳子的 $2 n$ 个头任意两两相接,求恰好结成 $n$ 个圈的概率.\n22. $m$ 个人相互传球, 球从甲手中开始传出, 每次传球时,传球者等可能地把球传给其余 $m-1$ 个人中的任何一个. 求第 $n$ 次传球时仍由甲传出的概率.\n23. 甲、乙两人轮流掷一颗骰子, 甲先郑. 每当某人郑出 1 点时,则交给对方郑, 否则此人继续郑. 试求第 $n$ 次由甲郑的概率.\n24. 甲口袋有 1 只黑球、 2 只白球,乙口袋有 3 只白球. 每次从两口袋中各任取一球,交换后放人另一口袋. 求交换 $n$ 次后, 黑球仍在甲口袋中的概率.\n25. 假设只考虑天气的两种情况: 有雨或无雨. 若已知今天的天气情况, 明天天气保持不变的概率为 $p$, 变的概率为 $1-p$. 设第一天无雨, 试求第 $n$ 天也无雨的概率.\n26. 设罐中有 $b$ 个黑球、 $r$ 个红球, 每次随机取出一个球, 取出后将原球放回, 再加人 $c(>0)$ 个同色的球. 试证:第 $k$ 次取到黑球的概率为 $b /(b+r), k=1,2, \\cdots$.\n27. 设 $P(A)>)$, 试证  \n$$\nP(B \\mid A) \\geqslant 1-\\frac{P(\\bar{B})}{P(A)} .\n$$  \n28. 若事件 $A$ 与 $B$ 互不相容,且 $P(\\bar{B}) \\neq 0$, 证明  \n$$\nP(A \\mid \\bar{B})=\\frac{P(A)}{1-P(B)} .\n$$  \n29. 设 $A, B$ 为任意两个事件, 且 $A \\subset B, P(B)>0$, 则成立  \n$$\nP(A) \\leqslant P(A \\mid B) .\n$$  \n30. 若 $P(A \\mid B)>P(A \\mid \\bar{B})$, 试证 $P(B \\mid A)>P(B \\mid \\bar{A})$.\n31. 设 $P(A)=p, P(B)=1-\\varepsilon$, 证明  \n$$",
        "metadata": {
            "Header 2": "如 题 1.4"
        },
        "type": "Document"
    },
    {
        "page_content": "26. 设罐中有 $b$ 个黑球、 $r$ 个红球, 每次随机取出一个球, 取出后将原球放回, 再加人 $c(>0)$ 个同色的球. 试证:第 $k$ 次取到黑球的概率为 $b /(b+r), k=1,2, \\cdots$.\n27. 设 $P(A)>)$, 试证  \n$$\nP(B \\mid A) \\geqslant 1-\\frac{P(\\bar{B})}{P(A)} .\n$$  \n28. 若事件 $A$ 与 $B$ 互不相容,且 $P(\\bar{B}) \\neq 0$, 证明  \n$$\nP(A \\mid \\bar{B})=\\frac{P(A)}{1-P(B)} .\n$$  \n29. 设 $A, B$ 为任意两个事件, 且 $A \\subset B, P(B)>0$, 则成立  \n$$\nP(A) \\leqslant P(A \\mid B) .\n$$  \n30. 若 $P(A \\mid B)>P(A \\mid \\bar{B})$, 试证 $P(B \\mid A)>P(B \\mid \\bar{A})$.\n31. 设 $P(A)=p, P(B)=1-\\varepsilon$, 证明  \n$$\n\\frac{p-\\varepsilon}{1-\\varepsilon} \\leqslant P(A \\mid B) \\leqslant \\frac{p}{1-\\varepsilon} .\n$$",
        "metadata": {
            "Header 2": "如 题 1.4"
        },
        "type": "Document"
    },
    {
        "page_content": "独立性是概率论中又一个重要概念, 利用独立性可以简化概率的计算. 下面先讨论两个事件之间的独立性,然后讨论多个事件之间的相互独立性,最后讨论试验之间的独立性.",
        "metadata": {
            "Header 2": "1.5 独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "两个事件之间的独立性是指: 一个事件的发生不影响另一个事件的发生. 这在实际问题中是很多的,譬如在郑两颗骰子的试验中, 记事件 $A$ 为 “第一颗骰子的点数为 1 ”, 记事件 $B$ 为 “第二颗骰子的点数为 4 ”. 则显然 $A$ 与 $B$ 的发生是相互不影响的.\n另外, 从概率的角度看, 事件 $A$ 的条件概率 $P(A \\mid B)$ 与无条件概率 $P(A)$ 的差别在于: 事件 $B$的发生改变了事件 $A$ 发生的概率, 也即事件 $B$ 对事件 $A$ 有某种 “影响”. 如果事件 $B$ 的发生对事件 $\\mathrm{A}$ 的发生毫无影响, 即有 $P(A \\mid B)=P(A)$. 由此又可推出 $P(B \\mid A)=P(B)$, 即事件 $A$ 发生对 $B$也无影响, 可见独立性是相互的, 它们都等价于  \n$$\n\\begin{equation*}\nP(A B)=P(A) P(B) . \\tag{1.5.1}\n\\end{equation*}\n$$  \n另外对 $P(B)=0$, 或 $P(A)=0,(1.5 .1)$ 式仍然成立. 为此, 我们用 (1.5.1) 式作为两个事件相互独立的定义.  \n定义 1.5.1. 如果 (1.5.1) 式成立, 则称事件 $A$ 与 $B$ 相互独立, 简称 $A$ 与 $B$ 独立, 否则称 $A$ 与 $B$ 不独立或相依.  \n在许多实际问题中,两个事件相互独立大多是根据经验 (相互有无影响 ) 来判断的,如上述掷两颗骰子问题中 $\\mathrm{A}$ 与 $\\mathrm{B}$ 的独立性. 但在有些问题中, 有时也用 (1.5.1) 式来判断两个事件间的独立性.  \n例 1.5 .1 事件独立的例子:  \n(1) 从一副 52 张的扑克牌中任取 1 张, 以 $A$ 记事件 “取到黑桃”, 以 $B$ 记事件 “取到爱司”,则因为 $P(A)=1 / 4, P(B)=4 / 52=1 / 13$, 而 $A B$ 表示 “取到黑桃爱司”,故 $P(A B)=1 / 52$, 所以 $A$与 $B$ 相互独立.  \n(2) 考虑有三个小孩的家庭,并设所有 8 种情况  \n$$",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.1 两个事件的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "另外对 $P(B)=0$, 或 $P(A)=0,(1.5 .1)$ 式仍然成立. 为此, 我们用 (1.5.1) 式作为两个事件相互独立的定义.  \n定义 1.5.1. 如果 (1.5.1) 式成立, 则称事件 $A$ 与 $B$ 相互独立, 简称 $A$ 与 $B$ 独立, 否则称 $A$ 与 $B$ 不独立或相依.  \n在许多实际问题中,两个事件相互独立大多是根据经验 (相互有无影响 ) 来判断的,如上述掷两颗骰子问题中 $\\mathrm{A}$ 与 $\\mathrm{B}$ 的独立性. 但在有些问题中, 有时也用 (1.5.1) 式来判断两个事件间的独立性.  \n例 1.5 .1 事件独立的例子:  \n(1) 从一副 52 张的扑克牌中任取 1 张, 以 $A$ 记事件 “取到黑桃”, 以 $B$ 记事件 “取到爱司”,则因为 $P(A)=1 / 4, P(B)=4 / 52=1 / 13$, 而 $A B$ 表示 “取到黑桃爱司”,故 $P(A B)=1 / 52$, 所以 $A$与 $B$ 相互独立.  \n(2) 考虑有三个小孩的家庭,并设所有 8 种情况  \n$$\nb b b, b b g, b g b, g b b, b g g, g b g, g g b, g g g\n$$  \n是等可能的,其中 $b$ 表示男孩, $g$ 表示女孩. 以 $A$ 记事件 “家中男女孩都有”,以 $B$ 记事件 “家中至多一个女孩”. 则因为 $P(A)=6 / 8, P(B)=4 / 8$, 而 $A B$ 表示 “家中恰有一个女孩”, 故 $P(A B)=3 / 8$,所以 $A$ 与 $B$ 相互独立.  \n(3) 当考察的家庭有两个小孩时, 样本空间只含 4 个样本点, 它们是  \n$$\nb b, b g, g b, g g\n$$  \n若事件 $A 、 B$ 仍如 (2) 所设, 则 $P(A)=2 / 4, P(B)=3 / 4$, 而 $P(A B)=2 / 4$, 由于 $P(A B) \\neq$ $P(A) P(B)$,所以 $A$ 与 $B$ 不独立.  \n性质 1.5.1: 若事件 $A$ 与 $B$ 独立, 则 $A$ 与 $\\bar{B}$ 独立; $\\bar{A}$ 与 $B$ 独立; $\\bar{A}$ 与 $\\bar{B}$ 独立.",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.1 两个事件的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n是等可能的,其中 $b$ 表示男孩, $g$ 表示女孩. 以 $A$ 记事件 “家中男女孩都有”,以 $B$ 记事件 “家中至多一个女孩”. 则因为 $P(A)=6 / 8, P(B)=4 / 8$, 而 $A B$ 表示 “家中恰有一个女孩”, 故 $P(A B)=3 / 8$,所以 $A$ 与 $B$ 相互独立.  \n(3) 当考察的家庭有两个小孩时, 样本空间只含 4 个样本点, 它们是  \n$$\nb b, b g, g b, g g\n$$  \n若事件 $A 、 B$ 仍如 (2) 所设, 则 $P(A)=2 / 4, P(B)=3 / 4$, 而 $P(A B)=2 / 4$, 由于 $P(A B) \\neq$ $P(A) P(B)$,所以 $A$ 与 $B$ 不独立.  \n性质 1.5.1: 若事件 $A$ 与 $B$ 独立, 则 $A$ 与 $\\bar{B}$ 独立; $\\bar{A}$ 与 $B$ 独立; $\\bar{A}$ 与 $\\bar{B}$ 独立.  \n证明: 由概率的性质知  \n$$\nP(A \\bar{B})=P(A)-P(A B) .\n$$  \n又由 $A$ 与 $B$ 的独立性知  \n$$\nP(A B)=P(A) P(B),\n$$  \n所以  \n$$\nP(A \\bar{B})=P(A)-P(A) P(B)=P(A)[1-P(B)]=P(A) P(\\bar{B})\n$$  \n这表明 $A$ 与 $\\bar{B}$ 独立. 类似可证 $\\bar{A}$ 与 $\\bar{B}$ 独立, $\\bar{A}$ 与 $B$ 独立.",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.1 两个事件的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "首先研究三个事件的相互独立性, 对此我们先给出以下的  \n定义 1.5.2. 设 $A, B, C$ 是三个事件, 如果有  \n$$\n\\left\\{\\begin{array}{l}\nP(A B)=P(A) P(B)  \\tag{1.5.2}\\\\\nP(A C)=P(A) P(C) \\\\\nP(B C)=P(B) P(C)\n\\end{array}\\right.\n$$  \n则称 $A, B, C$ 两两独立. 若还有  \n$$\n\\begin{equation*}\nP(A B C)=P(A) P(B) P(C) \\tag{1.5.3}\n\\end{equation*}\n$$  \n则称 $A, B, C$ 相互独立.  \n由此我们可以定义三个以上事件的相互独立性.  \n定义 1.5.3. 设有 $n$ 个事件 $A_{1}, A_{2}, \\cdots, A_{n}$, 对任意的 $1 \\leqslant i<j<k \\cdots \\leqslant n$, 如果以下等式均成立  \n$$\n\\left\\{\\begin{array}{l}\nP\\left(A_{i} A_{j}\\right)=P\\left(A_{i}\\right) P\\left(A_{j}\\right),  \\tag{1.5.4}\\\\\nP\\left(A_{i} A_{j} A_{k}\\right)=P\\left(A_{i}\\right) P\\left(A_{j}\\right) P\\left(A_{k}\\right), \\\\\n\\vdots \\\\\nP\\left(A_{1} A_{2} \\cdots A_{n}\\right)=P\\left(A_{1}\\right) P\\left(A_{2}\\right) \\cdots P\\left(A_{n}\\right),\n\\end{array}\\right.\n$$  \n则称此 $n$ 个事件 $A_{1}, A_{2}, \\cdots, A_{n}$ 相互独立.  \n从上述定义可以看出, $n$ 个相互独立的事件中的任意一部分内仍是相互独立的,而且任意一部分与另一部分也是独立的. 与性质 1.5.1 类似, 可以证明: 将相互独立事件中的任一部分换为对立事件, 所得的诸事件仍为相互独立的.",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "P\\left(A_{i} A_{j}\\right)=P\\left(A_{i}\\right) P\\left(A_{j}\\right),  \\tag{1.5.4}\\\\\nP\\left(A_{i} A_{j} A_{k}\\right)=P\\left(A_{i}\\right) P\\left(A_{j}\\right) P\\left(A_{k}\\right), \\\\\n\\vdots \\\\\nP\\left(A_{1} A_{2} \\cdots A_{n}\\right)=P\\left(A_{1}\\right) P\\left(A_{2}\\right) \\cdots P\\left(A_{n}\\right),\n\\end{array}\\right.\n$$  \n则称此 $n$ 个事件 $A_{1}, A_{2}, \\cdots, A_{n}$ 相互独立.  \n从上述定义可以看出, $n$ 个相互独立的事件中的任意一部分内仍是相互独立的,而且任意一部分与另一部分也是独立的. 与性质 1.5.1 类似, 可以证明: 将相互独立事件中的任一部分换为对立事件, 所得的诸事件仍为相互独立的.  \n例 1.5.2: 设 $A, B, C$ 三事件相互独立, 试证 $A \\cup B$ 与 $C$ 相互独立.  \n证明: 因为  \n$$\n\\begin{aligned}\nP((A \\cup B) C) & =P(A C \\cup B C)=P(A C)+P(B C)-P(A B C) \\\\\n& =P(A) P(C)+P(B) P(C)-P(A) P(B) P(C) \\\\\n& =[P(A)+P(B)-P(A) P(B)] P(C)=P(A \\cup B) P(C),\n\\end{aligned}\n$$  \n所以 $A \\cup B$ 与 $C$ 相互独立.  \n仿照此题的证明,可很容易推得: $A B$ 与 $C$ 独立; $A-B$ 与 $C$ 独立.  \n例 1.5.3: 两射手彼此独立地向同一目标射击, 设甲射中目标的概率为 0.9 , 乙射中目标的概率为 0.8 , 求目标被击中的概率是多少?  \n解：记 $A$ 为事件 “甲射中目标”, $B$ 为事件 “乙射中目标”. 注意到事件 “目标被击中” $=A \\cup B$, 故  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "例 1.5.2: 设 $A, B, C$ 三事件相互独立, 试证 $A \\cup B$ 与 $C$ 相互独立.  \n证明: 因为  \n$$\n\\begin{aligned}\nP((A \\cup B) C) & =P(A C \\cup B C)=P(A C)+P(B C)-P(A B C) \\\\\n& =P(A) P(C)+P(B) P(C)-P(A) P(B) P(C) \\\\\n& =[P(A)+P(B)-P(A) P(B)] P(C)=P(A \\cup B) P(C),\n\\end{aligned}\n$$  \n所以 $A \\cup B$ 与 $C$ 相互独立.  \n仿照此题的证明,可很容易推得: $A B$ 与 $C$ 独立; $A-B$ 与 $C$ 独立.  \n例 1.5.3: 两射手彼此独立地向同一目标射击, 设甲射中目标的概率为 0.9 , 乙射中目标的概率为 0.8 , 求目标被击中的概率是多少?  \n解：记 $A$ 为事件 “甲射中目标”, $B$ 为事件 “乙射中目标”. 注意到事件 “目标被击中” $=A \\cup B$, 故  \n$$\n\\begin{aligned}\nP(A \\cup B) & =P(A)+P(B)-P(A) P(B) \\\\\n& =0.9+0.8-0.9 \\times 0.8=0.98\n\\end{aligned}\n$$  \n例 1.5.4: 某零件用两种工艺加工, 第一种工艺有三道工序, 各道工序出现不合格品的概率分别为 $0.3,0.2,0.1$;第二章工艺有两道工序, 各道工序出现不合格品的概率分别为 $0.3,0.2$. 试问 :  \n(1) 用哪种工艺加工得到合格品的概率较大些?  \n（2）第二种工艺两道工序出现不合格品的概率都是 0.3 时, 情况又如何?  \n解: 以 $A_{i}$ 记事件 “用第 $i$ 种工艺加工得到合格品”, $i=1,2$.  \n(1) 由于各道工序可看作是独立工作的,所以  \n$$\n\\begin{aligned}\n& P\\left(A_{1}\\right)=0.7 \\times 0.8 \\times 0.9=0.504, \\\\\n& P\\left(A_{2}\\right)=0.7 \\times 0.8=0.56,\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nP(A \\cup B) & =P(A)+P(B)-P(A) P(B) \\\\\n& =0.9+0.8-0.9 \\times 0.8=0.98\n\\end{aligned}\n$$  \n例 1.5.4: 某零件用两种工艺加工, 第一种工艺有三道工序, 各道工序出现不合格品的概率分别为 $0.3,0.2,0.1$;第二章工艺有两道工序, 各道工序出现不合格品的概率分别为 $0.3,0.2$. 试问 :  \n(1) 用哪种工艺加工得到合格品的概率较大些?  \n（2）第二种工艺两道工序出现不合格品的概率都是 0.3 时, 情况又如何?  \n解: 以 $A_{i}$ 记事件 “用第 $i$ 种工艺加工得到合格品”, $i=1,2$.  \n(1) 由于各道工序可看作是独立工作的,所以  \n$$\n\\begin{aligned}\n& P\\left(A_{1}\\right)=0.7 \\times 0.8 \\times 0.9=0.504, \\\\\n& P\\left(A_{2}\\right)=0.7 \\times 0.8=0.56,\n\\end{aligned}\n$$  \n即第二种工艺得到合格品的概率较大些. 这个结果也是可以理解的, 因为第二种工艺前两道工序出现不合格品的概率与第一种工艺相同, 但少了一道工序, 所以减少了出现不合格品的机会.  \n(2) 当第二种工艺两道工序出现不合格品的概率都是 0.3 时,  \n$$\nP\\left(A_{2}\\right)=0.7 \\times 0.7=0.49\n$$  \n即第一种工艺得到合格品的概率较大些.  \n例 1.5.5: 有两名选手比赛射击, 轮流对同一目标进行射击, 甲命中目标的概率为 $\\alpha$, 乙命中目标的概率为 $\\beta$. 甲先射, 谁先命中谁得胜. 问甲、乙两人获胜的概率各为多少?\n解: 记事件 $A_{i}$ 为 “第 $\\mathrm{i}$ 次射击命中目标”, $i=1,2$, 因为甲先射,所以事件 “甲获胜”可以表示为  \n$$\nA_{1} \\cup \\bar{A}_{1} \\bar{A}_{2} A_{3} \\cup \\bar{A}_{1} \\bar{A}_{2} \\bar{A}_{3} \\bar{A}_{4} A_{5} \\cup \\cdots,\n$$",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n即第二种工艺得到合格品的概率较大些. 这个结果也是可以理解的, 因为第二种工艺前两道工序出现不合格品的概率与第一种工艺相同, 但少了一道工序, 所以减少了出现不合格品的机会.  \n(2) 当第二种工艺两道工序出现不合格品的概率都是 0.3 时,  \n$$\nP\\left(A_{2}\\right)=0.7 \\times 0.7=0.49\n$$  \n即第一种工艺得到合格品的概率较大些.  \n例 1.5.5: 有两名选手比赛射击, 轮流对同一目标进行射击, 甲命中目标的概率为 $\\alpha$, 乙命中目标的概率为 $\\beta$. 甲先射, 谁先命中谁得胜. 问甲、乙两人获胜的概率各为多少?\n解: 记事件 $A_{i}$ 为 “第 $\\mathrm{i}$ 次射击命中目标”, $i=1,2$, 因为甲先射,所以事件 “甲获胜”可以表示为  \n$$\nA_{1} \\cup \\bar{A}_{1} \\bar{A}_{2} A_{3} \\cup \\bar{A}_{1} \\bar{A}_{2} \\bar{A}_{3} \\bar{A}_{4} A_{5} \\cup \\cdots,\n$$  \n又因为各次射击是独立的, 所以得  \n$$\n\\begin{aligned}\nP(\\text { 甲获胜 }) & =\\alpha+(1-\\alpha)(1-\\beta) \\alpha+(1-\\alpha)^{2}(1-\\beta)^{2} \\alpha+\\cdots \\\\\n& =\\alpha \\sum_{i=0}^{+\\infty}(1-\\alpha)^{i}(1-\\beta)^{i} \\\\\n& =\\frac{\\alpha}{1-(1-\\alpha)(1-\\beta)} .\n\\end{aligned}\n$$  \n同理可得  \n$$\n\\begin{aligned}\nP(\\text { 乙获胜 }) & =P\\left(\\bar{A}_{1} A_{2} \\cup \\bar{A}_{1} \\bar{A}_{2} \\bar{A}_{3} A_{4} \\cup \\cdot\\right) \\\\\n& =(1-\\alpha) \\beta+(1-\\alpha)(1-\\beta)(1-\\alpha) \\beta+\\cdots \\\\",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n又因为各次射击是独立的, 所以得  \n$$\n\\begin{aligned}\nP(\\text { 甲获胜 }) & =\\alpha+(1-\\alpha)(1-\\beta) \\alpha+(1-\\alpha)^{2}(1-\\beta)^{2} \\alpha+\\cdots \\\\\n& =\\alpha \\sum_{i=0}^{+\\infty}(1-\\alpha)^{i}(1-\\beta)^{i} \\\\\n& =\\frac{\\alpha}{1-(1-\\alpha)(1-\\beta)} .\n\\end{aligned}\n$$  \n同理可得  \n$$\n\\begin{aligned}\nP(\\text { 乙获胜 }) & =P\\left(\\bar{A}_{1} A_{2} \\cup \\bar{A}_{1} \\bar{A}_{2} \\bar{A}_{3} A_{4} \\cup \\cdot\\right) \\\\\n& =(1-\\alpha) \\beta+(1-\\alpha)(1-\\beta)(1-\\alpha) \\beta+\\cdots \\\\\n& \\beta(1-\\alpha) \\sum_{i=0}^{+\\infty}(1-\\alpha)^{i}(1-\\beta)^{i} \\\\\n& =\\frac{\\beta(1-\\alpha)}{1-(1-\\alpha)(1-\\beta)} .\n\\end{aligned}\n$$  \n此题在等比级数求和时, 应该有条件: 公比 $|(1-\\alpha)(1-\\beta)| M 1$. 这一点不难从题目的实际意义中得到. 因为对本题而言, $\\alpha, \\beta$ 取值为零或 1 均是无意义的.  \n例 1.5.6: 系统由多个元件组成, 且所有元件都独立地工作. 设每个元件正常工作的概率都为 $p=$ 0.9 ,试求以下系统正常工作的概率.  \n(1) 串联系统 $S_{1}: 12$.  \n(3) 5 个元件组成的桥式系统 $S_{3}$ :  \n!  \n解：设 $S_{i}=$ “第 $i$ 个系统正常工作”, $A_{i}=$ “第 $i$ 个元件正常工作”.  \n(1) 对申联系统而言, “系统正常工作”相当于 “所有元件正常工作”, 即 $S_{1}=A_{1} A_{2}$, 所以  \n$$",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{\\beta(1-\\alpha)}{1-(1-\\alpha)(1-\\beta)} .\n\\end{aligned}\n$$  \n此题在等比级数求和时, 应该有条件: 公比 $|(1-\\alpha)(1-\\beta)| M 1$. 这一点不难从题目的实际意义中得到. 因为对本题而言, $\\alpha, \\beta$ 取值为零或 1 均是无意义的.  \n例 1.5.6: 系统由多个元件组成, 且所有元件都独立地工作. 设每个元件正常工作的概率都为 $p=$ 0.9 ,试求以下系统正常工作的概率.  \n(1) 串联系统 $S_{1}: 12$.  \n(3) 5 个元件组成的桥式系统 $S_{3}$ :  \n!  \n解：设 $S_{i}=$ “第 $i$ 个系统正常工作”, $A_{i}=$ “第 $i$ 个元件正常工作”.  \n(1) 对申联系统而言, “系统正常工作”相当于 “所有元件正常工作”, 即 $S_{1}=A_{1} A_{2}$, 所以  \n$$\nP\\left(S_{1}\\right)=P\\left(A_{1} A_{2}\\right)=P\\left(A_{1}\\right) P\\left(A_{2}\\right)=p^{2}=0.81\n$$  \n这也可看出: 两个正常工作概率为 0.9 的元件组成的串联系统, 其系统正常工作的概率下降为 0.81 .  \n(2) 对并联系统而言, “系统正常工作” 相当于 “至少一个元件正常工作”, 即 $S_{2}=A_{1} \\cup A_{2}$, 所以  \n$$\n\\begin{gathered}\nP\\left(S_{2}\\right) P\\left(A_{1} \\cup A_{2}\\right)=P\\left(A_{1}\\right)+P\\left(A_{2}\\right)-P\\left(A_{1} A_{2}\\right) \\\\\n=p+p-p^{2}=0.99\n\\end{gathered}\n$$  \n或  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 对申联系统而言, “系统正常工作”相当于 “所有元件正常工作”, 即 $S_{1}=A_{1} A_{2}$, 所以  \n$$\nP\\left(S_{1}\\right)=P\\left(A_{1} A_{2}\\right)=P\\left(A_{1}\\right) P\\left(A_{2}\\right)=p^{2}=0.81\n$$  \n这也可看出: 两个正常工作概率为 0.9 的元件组成的串联系统, 其系统正常工作的概率下降为 0.81 .  \n(2) 对并联系统而言, “系统正常工作” 相当于 “至少一个元件正常工作”, 即 $S_{2}=A_{1} \\cup A_{2}$, 所以  \n$$\n\\begin{gathered}\nP\\left(S_{2}\\right) P\\left(A_{1} \\cup A_{2}\\right)=P\\left(A_{1}\\right)+P\\left(A_{2}\\right)-P\\left(A_{1} A_{2}\\right) \\\\\n=p+p-p^{2}=0.99\n\\end{gathered}\n$$  \n或  \n$$\n\\begin{aligned}\nP\\left(S_{2}\\right) & =1-P\\left(\\bar{S}_{2}\\right)=1-P\\left(\\overline{A_{1} \\cup A_{2}}\\right)=1-P\\left(\\bar{A}_{1} \\cap \\bar{A}_{2}\\right) \\\\\n& =1-P\\left(\\bar{A}_{1}\\right) P\\left(\\bar{A}_{2}\\right)=1-(1-p)^{2}=0.99\n\\end{aligned}\n$$  \n这也可看出: 两个正常工作概率为 0.9 的元件组成的并联系统, 其系统正常工作的概率提高至 0.99 .  \n(3) 在桥式系统中, 第 3 个元件是关键, 我们先用全概率公式得  \n$$\nP\\left(S_{3}\\right)=P\\left(A_{3}\\right) P\\left(S_{3} \\mid A_{3}\\right)+P\\left(\\bar{A}_{3}\\right) P\\left(S_{3} \\mid \\bar{A}_{3}\\right)\n$$",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n或  \n$$\n\\begin{aligned}\nP\\left(S_{2}\\right) & =1-P\\left(\\bar{S}_{2}\\right)=1-P\\left(\\overline{A_{1} \\cup A_{2}}\\right)=1-P\\left(\\bar{A}_{1} \\cap \\bar{A}_{2}\\right) \\\\\n& =1-P\\left(\\bar{A}_{1}\\right) P\\left(\\bar{A}_{2}\\right)=1-(1-p)^{2}=0.99\n\\end{aligned}\n$$  \n这也可看出: 两个正常工作概率为 0.9 的元件组成的并联系统, 其系统正常工作的概率提高至 0.99 .  \n(3) 在桥式系统中, 第 3 个元件是关键, 我们先用全概率公式得  \n$$\nP\\left(S_{3}\\right)=P\\left(A_{3}\\right) P\\left(S_{3} \\mid A_{3}\\right)+P\\left(\\bar{A}_{3}\\right) P\\left(S_{3} \\mid \\bar{A}_{3}\\right)\n$$  \n因为在 “第 3 个元件正常工作”的条件下, 系统成为先并后串系统 (见图 1.5.1). 所以  \n$$\nP\\left(S_{3} \\mid A_{3}\\right)=P\\left(\\left(A_{1} \\cup A_{4}\\right)\\left(A_{2} \\cup A_{5}\\right)\\right)=P\\left(A_{1} \\cup A_{4}\\right) P\\left(A_{2} \\cup A_{5}\\right)\n$$  \n$$\n=\\left[1-(1-p)^{2}\\right]^{2}=0.9801 \\text {. }\n$$  \n又因为在“第 3 个元件不正常工作”的条件下, 系统成为先串后并系统 (见图 1.5.2). 所以  \n!  \n图 1.5.1: 先并后串系统  \n!  \n图 1.5.2: 先串后并系统  \n$$\nP\\left(S_{3} \\mid \\bar{A}_{3}\\right)=P\\left(A_{1} A_{2} \\mid \\cup A_{4} A_{5}\\right)=1-\\left(1-p^{2}\\right)^{2}=0.9639",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "因为在 “第 3 个元件正常工作”的条件下, 系统成为先并后串系统 (见图 1.5.1). 所以  \n$$\nP\\left(S_{3} \\mid A_{3}\\right)=P\\left(\\left(A_{1} \\cup A_{4}\\right)\\left(A_{2} \\cup A_{5}\\right)\\right)=P\\left(A_{1} \\cup A_{4}\\right) P\\left(A_{2} \\cup A_{5}\\right)\n$$  \n$$\n=\\left[1-(1-p)^{2}\\right]^{2}=0.9801 \\text {. }\n$$  \n又因为在“第 3 个元件不正常工作”的条件下, 系统成为先串后并系统 (见图 1.5.2). 所以  \n!  \n图 1.5.1: 先并后串系统  \n!  \n图 1.5.2: 先串后并系统  \n$$\nP\\left(S_{3} \\mid \\bar{A}_{3}\\right)=P\\left(A_{1} A_{2} \\mid \\cup A_{4} A_{5}\\right)=1-\\left(1-p^{2}\\right)^{2}=0.9639\n$$  \n最后我们得  \n$$\n\\begin{aligned}\nP\\left(S_{3}\\right) & =p\\left[1-(1-p)^{2}\\right]^{2}+(1-p)\\left[1-\\left(1-p^{2}\\right)^{2}\\right] \\\\\n& =0.9 \\times 0.9801+0.1 \\times 0.9639=0.9785\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.2 多个事件的相互独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "利用事件的独立性可以定义两个或更多个试验的独立性.  \n定义 1.5.4. 设有两个试验 $E_{1}$ 和 $E_{2}$, 假如试验 $E_{1}$ 的任一结果(事件)与试验 $E_{2}$ 的任一结果(事件)都是相互独立的事件,则称这两个试验相互独立.  \n例如掷一枚硬币 (试验 $E_{1}$ ) 与掷一颗骰子 (试验 $E_{2}$ ) 是相互独立的试验.  \n类似地可以定义 $n$ 个试验 $E_{1}, E_{2}, \\cdots, E_{n}$ 的相互独立性: 如果 $E_{1}$ 的任一结果、 $E_{2}$ 的任一结果 $\\cdots \\cdots E_{n}$ 的任一结果都是相互独立的事件, 则称试验 $E_{1}, E_{2}, \\cdots, E_{n}$ 相互独立. 如果这 $n$ 个独立试验还是相同的, 则称其为 $n$ 重独立重复试验. 如果在 $n$ 重独立重复试验中,每次试验的可能结果为两个: $A$ 或 $\\bar{A}$,则称这种试验为 $n$ 重伯努利试验.  \n例如掷 $n$ 枚硬币、掷 $n$ 颗骰子、检查 $n$ 个产品等,都是 $n$ 重独立重复试验.  \n例 1.5.7: 某彩票每周开奖一次, 每次提供十万分之一的中奖机会, 且各周开奖是相互独立的. 若你每周买一张彩票, 尽管你坚持十年 (每年 52 周) 之久, 你从未中奖的可能性是多少?  \n解: 按假设, 每次中奖的可能性是 $10^{-5}$,于是每次不中奖的可能性是 $1-10^{-5}$. 另外, 十年中你共购买彩票 520 次,每次开奖都是相互独立的,相当于进行了 520 次独立重复试验. 记 $A_{i}$ 为 “第 $i$ 次开奖不中奖”, $i=1,2, \\cdots, 520$, 则 $A_{1}, A_{2}, \\cdots, A_{520}$ 相互独立, 由此得十年中你从未中奖的可能性是  \n$$\nP\\left(A_{1} A_{2} \\cdots A_{520}\\right)=\\left(1-10^{-5}\\right)^{520}=0.9948 .\n$$  \n这个概率表明十年中你从未中奖是很正常的事.  \n如果将上例中每次中奖机会改成 “万分之一”, 则十年中从未中奖的可能性还是很大的, 为 0.9493",
        "metadata": {
            "Header 2": "1.5 独立性",
            "Header 3": "1.5.3 试验的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 三人独立地破译一个密码, 他们能单独译出的概率分别为 $1 / 5,1 / 3,1 / 4$, 求此密码被译出的概率.\n2. 有甲乙两批种子, 发芽率分别为 0.8 和 0.7 , 在两批种子中各任取一粒, 求:  \n(1) 两粒种子都能发芽的概率;  \n（2）至少有一粒种子能发芽的概率;  \n(3) 恰好有一粒种子能发芽的概率.  \n3. 甲、乙两人独立地对同一目标射击一次, 其命中率分别为 0.6 和 0.7 , 现已知目标被击中, 求它是甲射中的概率.\n4. 设电路由 $A, B, C$ 三个元件组成, 若元件 $A, B, C$ 发生故障的概率分别是 $0.3,0.2,0.2$, 且各元件独立工作, 试在以下情况下, 求此电路发生故障的概率:  \n(1) $A, B, C$ 三个元件串联;  \n(2) $A, B, C$ 三个元件并联;  \n(3) 元件 $A$ 与两个并联的元件 $B$ 及 $C$ 串联而成.  \n5. 在一小时内甲,乙,丙三台机床需维修的概率分别是 $0.9,0.8$ 和 0.85 , 求一小时内  \n(1) 没有一台机床需要维修的概率;  \n(2) 至少有一台机床不需要维修的概率;  \n(3) 至多只有一台机床需要维修的概率.  \n6. 设 $A_{1}, A_{2}, A_{3}$ 相互独立, 且 $P\\left(A_{i}\\right)=1 / 3, i=1,2,3$. 试求 $A_{1}, A_{2}, A_{3}$ 中  \n(1) 至少出现一个的概率;  \n(2) 恰好出现一个的概率;  \n(3) 最多出现一个的概率.  \n7. 若事件 $A$ 与 $B$ 相互独立且互不相容, 试求 $\\min \\{P(A), P(B)\\}$.\n8. 假设 $P(A)=0.4, P(A \\cup B)=0.7$, 在以下情况下求 $P(B):$  \n(1) $A, B$ 互不相容;  \n(2) $A, B$ 独立；  \n(3) $A \\subset B$.  \n9. 设 $A, B, C$ 两两独立, 且 $A B C=\\varnothing$.  \n(1) 如果 $P(A)=P(B)=P(C)=x$, 试求 $x$ 的最大值;",
        "metadata": {
            "Header 2": "如 题 1.5"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 没有一台机床需要维修的概率;  \n(2) 至少有一台机床不需要维修的概率;  \n(3) 至多只有一台机床需要维修的概率.  \n6. 设 $A_{1}, A_{2}, A_{3}$ 相互独立, 且 $P\\left(A_{i}\\right)=1 / 3, i=1,2,3$. 试求 $A_{1}, A_{2}, A_{3}$ 中  \n(1) 至少出现一个的概率;  \n(2) 恰好出现一个的概率;  \n(3) 最多出现一个的概率.  \n7. 若事件 $A$ 与 $B$ 相互独立且互不相容, 试求 $\\min \\{P(A), P(B)\\}$.\n8. 假设 $P(A)=0.4, P(A \\cup B)=0.7$, 在以下情况下求 $P(B):$  \n(1) $A, B$ 互不相容;  \n(2) $A, B$ 独立；  \n(3) $A \\subset B$.  \n9. 设 $A, B, C$ 两两独立, 且 $A B C=\\varnothing$.  \n(1) 如果 $P(A)=P(B)=P(C)=x$, 试求 $x$ 的最大值;  \n(2) 如果 $P(A)=P(B)=P(C)<1 / 2$, 且 $P(A \\cup B \\cup C)=9 / 16$, 求 $P(A)$.  \n10. 事件 $A, B$ 独立, 两个事件仅 $A$ 发生的概率或仅 $B$ 发生的概率都是 $1 / 4$, 求 $P(A)$ 及 $P(B)$.\n11. 一实习生用同一台机器接连独立地制造 3 个同种零件, 第 $i$ 个零件是不合格品的概率为 $p_{i}=$ $1 /(i+1), i=1,2,3$, 以 $X$ 表示 3 个零件中合格品的个数, 求 $P(X=2)$.\n12. 同时抛郑 3 枚均匀的硬币,试求恰好有两枚正面向上的概率.\n13. 一射手对同一目标独立地进行四次射击, 若至少命中一次的概率为 $80 / 81$, 试求该射手进行一一次射击的命中率.\n14. 每次射击命中率为 0.2 , 试求: 射击多少次才能使至少击中一次的概率不小于 0.9 ?",
        "metadata": {
            "Header 2": "如 题 1.5"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 如果 $P(A)=P(B)=P(C)=x$, 试求 $x$ 的最大值;  \n(2) 如果 $P(A)=P(B)=P(C)<1 / 2$, 且 $P(A \\cup B \\cup C)=9 / 16$, 求 $P(A)$.  \n10. 事件 $A, B$ 独立, 两个事件仅 $A$ 发生的概率或仅 $B$ 发生的概率都是 $1 / 4$, 求 $P(A)$ 及 $P(B)$.\n11. 一实习生用同一台机器接连独立地制造 3 个同种零件, 第 $i$ 个零件是不合格品的概率为 $p_{i}=$ $1 /(i+1), i=1,2,3$, 以 $X$ 表示 3 个零件中合格品的个数, 求 $P(X=2)$.\n12. 同时抛郑 3 枚均匀的硬币,试求恰好有两枚正面向上的概率.\n13. 一射手对同一目标独立地进行四次射击, 若至少命中一次的概率为 $80 / 81$, 试求该射手进行一一次射击的命中率.\n14. 每次射击命中率为 0.2 , 试求: 射击多少次才能使至少击中一次的概率不小于 0.9 ?\n15. 设猎人在猎物 100 米处对猎物打第一枪, 命中猎物的概率为 0.5 . 若第一枪未命中, 则猎人继续打第二枪, 此时猎物与猎人已相距 150 米. 若第二枪仍未命中, 则猎人继续打第三枪, 此时猎物与猎人已相距 200 米. 若第三枪还未命中, 则猎物逃逸. 假如该猎人命中猎物的概率与距离成反比,试求该猎物被击中的概率.\n16. 已知某商场一天内来 $k$ 个顾客的概率为 $\\lambda^{k} \\mathrm{e}^{-\\lambda} / k !, k=0,1, \\cdots$, 其中 $\\lambda>0$. 又设每个到达商场的顾客购买商品是独立的, 其概率为 $p$, 试证: 这个商场一天内有 $r$ 个顾客购买商品的概率为: $(\\lambda p)^{r} \\mathrm{e}^{-\\lambda p} / r !$.\n17. 一个人的血型为 $A, A, A B, O$ 型的概率分别为 $0.37,0.21,0.08,0.34$. 现任意挑选四个人, 试求:  \n(1) 此四人的血型全不相同的概率;  \n(2) 此四人的血型全部相同的概率.",
        "metadata": {
            "Header 2": "如 题 1.5"
        },
        "type": "Document"
    },
    {
        "page_content": "15. 设猎人在猎物 100 米处对猎物打第一枪, 命中猎物的概率为 0.5 . 若第一枪未命中, 则猎人继续打第二枪, 此时猎物与猎人已相距 150 米. 若第二枪仍未命中, 则猎人继续打第三枪, 此时猎物与猎人已相距 200 米. 若第三枪还未命中, 则猎物逃逸. 假如该猎人命中猎物的概率与距离成反比,试求该猎物被击中的概率.\n16. 已知某商场一天内来 $k$ 个顾客的概率为 $\\lambda^{k} \\mathrm{e}^{-\\lambda} / k !, k=0,1, \\cdots$, 其中 $\\lambda>0$. 又设每个到达商场的顾客购买商品是独立的, 其概率为 $p$, 试证: 这个商场一天内有 $r$ 个顾客购买商品的概率为: $(\\lambda p)^{r} \\mathrm{e}^{-\\lambda p} / r !$.\n17. 一个人的血型为 $A, A, A B, O$ 型的概率分别为 $0.37,0.21,0.08,0.34$. 现任意挑选四个人, 试求:  \n(1) 此四人的血型全不相同的概率;  \n(2) 此四人的血型全部相同的概率.  \n18. 甲、乙两选手进行乓球单打比赛, 已知在每局中甲胜的概率为 0.6 , 乙胜的概率为 0.4 . 比赛可采用三局二胜制或五局三胜制, 问哪一种比赛制度对甲更有利?\n19. 甲、乙、丙三人进行比赛, 规定每局两个人比赛, 胜者与第三人比赛, 依次循环, 直至有一人连胜两次为止, 此人即为冠军. 而每次比赛双方取胜的概率都是 $1 / 2$, 现假定甲、乙两人先比, 试求各人得冠军的概率.\n20. 甲、乙两个奢徒在每一局获胜的概率都是 $1 / 2$. 两人约定谁先赢得一定的局数就获得全部奢本.但奢博在中途被打断了,请问在以下各种情况下,应如何合理分配奢本:  \n（1）甲、乙两个者徒都各需赢 $k$ 局才能获胜;  \n（2）甲者徒还需赢 2 局才能获胜, 乙赌徒还需赢 3 局才能获胜;  \n(3) 甲者徒还需赢 $n$ 局才能获胜, 乙赌徒还需赢 $m$ 局才能获胜.  \n21. 试证:概率为零的事件与任何事件都是独立的.\n22. 设 $A, B, C$ 三事件相互独立, 试证 $A-B$ 与 $C$ 独立.\n23. 设 $0<P(B)<1$, 试证事件 $A$ 与 $B$ 独立的充要条件是",
        "metadata": {
            "Header 2": "如 题 1.5"
        },
        "type": "Document"
    },
    {
        "page_content": "19. 甲、乙、丙三人进行比赛, 规定每局两个人比赛, 胜者与第三人比赛, 依次循环, 直至有一人连胜两次为止, 此人即为冠军. 而每次比赛双方取胜的概率都是 $1 / 2$, 现假定甲、乙两人先比, 试求各人得冠军的概率.\n20. 甲、乙两个奢徒在每一局获胜的概率都是 $1 / 2$. 两人约定谁先赢得一定的局数就获得全部奢本.但奢博在中途被打断了,请问在以下各种情况下,应如何合理分配奢本:  \n（1）甲、乙两个者徒都各需赢 $k$ 局才能获胜;  \n（2）甲者徒还需赢 2 局才能获胜, 乙赌徒还需赢 3 局才能获胜;  \n(3) 甲者徒还需赢 $n$ 局才能获胜, 乙赌徒还需赢 $m$ 局才能获胜.  \n21. 试证:概率为零的事件与任何事件都是独立的.\n22. 设 $A, B, C$ 三事件相互独立, 试证 $A-B$ 与 $C$ 独立.\n23. 设 $0<P(B)<1$, 试证事件 $A$ 与 $B$ 独立的充要条件是  \n$$\nP(A \\mid B)=P(A \\mid \\bar{B})\n$$  \n24. 设 $0<P(A)<1,0<P(B)<1, P(A \\mid B)+P(\\bar{A} \\mid \\bar{B})=1$, 试证 $A$ 与 $B$ 独立.\n25. 若 $P(A)>0, P(B)>)$, 如果 $A, B$ 相互独立, 试证 $A, B$ 相容.",
        "metadata": {
            "Header 2": "如 题 1.5"
        },
        "type": "Document"
    },
    {
        "page_content": "为了进行定量的数学处理, 必须把随机现象的结果数量化. 这就是引进随机变量的原因随机变量的引进使得对随机现象的处理更简单与直接, 也更统一而有力. 本章我们将主要讨论一维随机变量及其分布.",
        "metadata": {
            "Header 2": "第 2 章 随机变量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "在第一章中我们曾提及随机变量, 在那里我们把 “用来表示随机现象结果的变量“称为随机变量, 其中“表示”一词的含义是什么? 这是要进一步探讨的问题.",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "在随机现象中有很多样本点本身就是用数量表示的, 由于样本点出现的随机性, 其数量呈现为随机变量, 譬如  \n- 郑一颗散子, 出现的点数 $X$ 是一个随机变量.\n- 每天进人某超市的顾客数 $Y$; 顾客购买商品的件数 $U$; 顾客排队等候付款的时间 $V, Y, L U, V$是三个不同的随机变量,\n- 电视机的寿命 $T$ 是一个随机变量.\n- 测量的误差 $\\varepsilon$ 是一个随机变量.  \n在随机现象中还有不少样本点本身不是数, 这时可根据研究需要设计随机变量, 譬如  \n- 检查一个产品, 只考察其合格与否, 则其样本空间为 $\\Omega=\\{$ 合格品, 不合格品 $\\}$, 这时可设计一个随机变量 $X$ 如下：  \n$$\n\\begin{array}{ccc}\n\\text { 样本点 } & & X \\text { 的取值 } \\\\\n\\hline \\text { 合格品 } & \\longrightarrow & 0 \\\\\n\\text { 不合格品 } & \\longrightarrow & 1\n\\end{array}\n$$  \n在此可将 $X$ 解释为 “检查一个产品中不合格品数”. 若此种产品的不合格品率为 $p$, 则 $X$ 取各种值的概率可列表如下:  \n$$\n\\begin{array}{c|cc}\nX & 0 & 1 \\\\\n\\hline P & 1-p & p\n\\end{array}\n$$  \n- 检查三个产品, 则有 8 个样本点, 若记 $X$ 为 “三个产品中的不合格品数”, 则 $X$ 与样本点之间有如下对应关系:  \n| 样本点 |  | $X$ 的取值 |\n| :---: | :---: | :---: |\n| $\\omega_{1}=(0,0,0)$ | $\\longrightarrow$ | 0 |\n| $\\omega_{2}=(1,0,0)$ | $\\longrightarrow$ | 1 |\n| $\\omega_{3}=(0,1,0)$ | $\\longrightarrow$ | 1 |\n| $\\omega_{4}=(0,0,1)$ | $\\longrightarrow$ | 1 |\n| $\\omega_{5}=(0,1,1)$ | $\\longrightarrow$ | 2 |",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.1 随机变量的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{array}{c|cc}\nX & 0 & 1 \\\\\n\\hline P & 1-p & p\n\\end{array}\n$$  \n- 检查三个产品, 则有 8 个样本点, 若记 $X$ 为 “三个产品中的不合格品数”, 则 $X$ 与样本点之间有如下对应关系:  \n| 样本点 |  | $X$ 的取值 |\n| :---: | :---: | :---: |\n| $\\omega_{1}=(0,0,0)$ | $\\longrightarrow$ | 0 |\n| $\\omega_{2}=(1,0,0)$ | $\\longrightarrow$ | 1 |\n| $\\omega_{3}=(0,1,0)$ | $\\longrightarrow$ | 1 |\n| $\\omega_{4}=(0,0,1)$ | $\\longrightarrow$ | 1 |\n| $\\omega_{5}=(0,1,1)$ | $\\longrightarrow$ | 2 |\n| $\\omega_{6}=(1,0,1)$ | $\\longrightarrow$ | 2 |\n| $\\omega_{7}=(1,1,0)$ | $\\longrightarrow$ | 2 |\n| $\\omega_{8}=(1,1,1)$ | $\\longrightarrow$ | 3 |  \n这样 $X$ 取各种值就是如下的互不相容的事件:  \n$$\n\\begin{array}{ll}\n\\{X=0\\}=\\left\\{\\omega_{1}\\right\\} ; & \\{X=1\\}=\\left\\{\\omega_{2}, \\omega_{3}, \\omega_{4}\\right\\} ;  \\tag{2.1.1}\\\\\n\\{X=2\\}=\\left\\{\\omega_{5}, \\omega_{6}, \\omega_{7}\\right\\} ; & \\{X=3\\}=\\left\\{\\omega_{8}\\right\\} .\n\\end{array}\n$$  \n若此种产品的不合格品率为 $p$, 则 $X$ 取各种值的概率可列表如下:  \n$$\n\\begin{array}{c|cccc}\nx & 0 & 1 & 2 & 3 \\\\",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.1 随机变量的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\omega_{7}=(1,1,0)$ | $\\longrightarrow$ | 2 |\n| $\\omega_{8}=(1,1,1)$ | $\\longrightarrow$ | 3 |  \n这样 $X$ 取各种值就是如下的互不相容的事件:  \n$$\n\\begin{array}{ll}\n\\{X=0\\}=\\left\\{\\omega_{1}\\right\\} ; & \\{X=1\\}=\\left\\{\\omega_{2}, \\omega_{3}, \\omega_{4}\\right\\} ;  \\tag{2.1.1}\\\\\n\\{X=2\\}=\\left\\{\\omega_{5}, \\omega_{6}, \\omega_{7}\\right\\} ; & \\{X=3\\}=\\left\\{\\omega_{8}\\right\\} .\n\\end{array}\n$$  \n若此种产品的不合格品率为 $p$, 则 $X$ 取各种值的概率可列表如下:  \n$$\n\\begin{array}{c|cccc}\nx & 0 & 1 & 2 & 3 \\\\\n\\hline P & (1-p)^{3} & 3 p(1-p)^{2} & 3 p^{2}(1-p) & p^{3}\n\\end{array}\n$$  \n定义 2.1.1. 定义在样本空间 $\\Omega$ 上的实值函数 $X=X(\\omega)$ 称为随机变量, 常用大写字母 $X, Y, Z$ 等表示随机变量, 其取值用小写字母 $x, y, z$ 等表示. 假如一个随机变量仅取有限个或可列个值, 则称其为离散随机变量. 假如一个随机变量的可能取值充满数轴上的一个区间 $(a, b)$, 则称其为连续随机变量, 其中 $a$ 可以是 $-\\infty, b$ 可以是 $+\\infty$.  \n这个定义表明: 随机变量 $X$ 是样本点 $\\omega$ 的一个函数, 这个函数可以是不同样本点对应不同的实数, 也允许多个样本点对应同一个实数. 这个函数的自变量 (样本点) 可以是数, 也可以不是数,但因变量一定是实数.",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.1 随机变量的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{array}{c|cccc}\nx & 0 & 1 & 2 & 3 \\\\\n\\hline P & (1-p)^{3} & 3 p(1-p)^{2} & 3 p^{2}(1-p) & p^{3}\n\\end{array}\n$$  \n定义 2.1.1. 定义在样本空间 $\\Omega$ 上的实值函数 $X=X(\\omega)$ 称为随机变量, 常用大写字母 $X, Y, Z$ 等表示随机变量, 其取值用小写字母 $x, y, z$ 等表示. 假如一个随机变量仅取有限个或可列个值, 则称其为离散随机变量. 假如一个随机变量的可能取值充满数轴上的一个区间 $(a, b)$, 则称其为连续随机变量, 其中 $a$ 可以是 $-\\infty, b$ 可以是 $+\\infty$.  \n这个定义表明: 随机变量 $X$ 是样本点 $\\omega$ 的一个函数, 这个函数可以是不同样本点对应不同的实数, 也允许多个样本点对应同一个实数. 这个函数的自变量 (样本点) 可以是数, 也可以不是数,但因变量一定是实数.  \n与微积分中的变量不同, 概率论中的随机变量 $X$ 是一种 “随机取值的变量”. 以认识离散随机变例, 我们不仅要知道 $Y$ 取哪些值, 而且还要知道它取这些值的概率各是多少, 这就需要分布的概念. 有没有分布是区分一般变量与随机变量的主要标志.",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.1 随机变量的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "随机变量 $X$ 是样个点 $\\omega$ 的一个值函数. 若 $B$ 是某些实数组成的集合, 即 $B \\subset \\mathbb{R}, \\mathbb{R}$ 表示实数集、则 $X \\in B$ 表示如下的随机事件  \n$$\n\\{\\omega: X(\\omega) \\in B\\} \\subset \\Omega\n$$  \n这就是我们可以用随性变立量得某些取值来表示随机事件的依据. 臂如  \n- 记 $X$ 表示郑一颗骰子出现的点数, 明 $X$ 的可能取值为 $1,2, \\cdots, 6$. 这是一个离散随机变量.事件 $A=$ “点数小于等于 3 ”, 可以表示为 $A=\\{X \\leqslant 3\\}$.\n- 记 $Y$ 表示一天内到达某商场的顾客数. 则 $Y$ 的可能取值为 $0,1,2 \\cdots, n \\cdots$ 这也是一个离散随机变量. 事件 $B=$ “至少来 1000 位顾客”, 可以表示为 $B=\\{X \\geqslant 1000\\}$.\n- 记 $T$ 表示某电器品的使目寿命, 则 $T$ 的可能取值充满区间 $[0,+o \\infty)$. 这楚一个连续随机变量. 事件 $C=$ “使用寿命在 40000 至 50000 小时之间”, 可以表示为 $C=\\{40000 \\leqslant T \\leqslant$ $50000\\}$  \n为了掌握 $X$ 的统计规律性, 我们只要掌握 $X$ 取各种值的概率. 由于  \n$$\n\\{a<X \\leqslant b\\}=\\{X \\leqslant b\\}-\\{x \\leqslant a\\},\n$$  \n因此只要对任意实数 $x$, 知道了件 $X \\geqslant x$ 的概率就够了, 这个概率具有累积特性, 常用 $F$ 表示. 另外这个概率与 $x$ 有关, 不同的 $x$, 此累积概率的值也不同, 为此记  \n$$\nF(x)=P(X \\leqslant x),\n$$  \n于是 $F(x)$ 所有 $x \\in(-\\infty,+\\infty)$ 都有定义, 而 $F(x)$ 是定义在 $(\\infty,+\\infty)$ 上、取值于 $[0,1]$ 的一个函数. 这就是我们下面要引入的分布函数.",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.2 随机变量的分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "为了掌握 $X$ 的统计规律性, 我们只要掌握 $X$ 取各种值的概率. 由于  \n$$\n\\{a<X \\leqslant b\\}=\\{X \\leqslant b\\}-\\{x \\leqslant a\\},\n$$  \n因此只要对任意实数 $x$, 知道了件 $X \\geqslant x$ 的概率就够了, 这个概率具有累积特性, 常用 $F$ 表示. 另外这个概率与 $x$ 有关, 不同的 $x$, 此累积概率的值也不同, 为此记  \n$$\nF(x)=P(X \\leqslant x),\n$$  \n于是 $F(x)$ 所有 $x \\in(-\\infty,+\\infty)$ 都有定义, 而 $F(x)$ 是定义在 $(\\infty,+\\infty)$ 上、取值于 $[0,1]$ 的一个函数. 这就是我们下面要引入的分布函数.  \n定义 2.1.2. 设 $X$ 是一个随机变量, 对任意实数 $x$, 称  \n$$\n\\begin{equation*}\nF(x)=P(X \\leqslant x) \\tag{2.1.2}\n\\end{equation*}\n$$  \n为随机变量 $X$ 的分布函数. 且称 $X$ 服从 $F(x)$, 记为 $X \\sim F(x)$. 有时也可用 $F_{X}(x)$ 以表明是 $X$ 的分布函数(把 $X$ 作为 $F$ 的下标).  \n例 2.1.1: 向半径为 $r$ 的圆内随机抛一点, 求此点到圆心之距离 $X$ 的分布函数 $F(x)$, 并求 $P\\left(X>\\frac{2 r}{3}\\right)$.  \n解: 事件 “ $X \\leqslant x$ ” 表示所抛之点落在半径为 $x(0 \\leqslant x \\leqslant r)$ 的圆内, 故由几何概率知  \n$$\nF(x)=P(X \\leqslant x)=\\frac{\\pi x^{2}}{\\pi r^{2}}=\\left(\\frac{x}{r}\\right)^{2},\n$$  \n从而  \n$$\nP\\left(X>\\frac{2 r}{3}\\right)=1-P\\left(X \\leqslant \\frac{2 r}{3}\\right)=1-\\left(\\frac{2}{3}\\right)^{2}=\\frac{5}{9} .\n$$",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.2 随机变量的分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "例 2.1.1: 向半径为 $r$ 的圆内随机抛一点, 求此点到圆心之距离 $X$ 的分布函数 $F(x)$, 并求 $P\\left(X>\\frac{2 r}{3}\\right)$.  \n解: 事件 “ $X \\leqslant x$ ” 表示所抛之点落在半径为 $x(0 \\leqslant x \\leqslant r)$ 的圆内, 故由几何概率知  \n$$\nF(x)=P(X \\leqslant x)=\\frac{\\pi x^{2}}{\\pi r^{2}}=\\left(\\frac{x}{r}\\right)^{2},\n$$  \n从而  \n$$\nP\\left(X>\\frac{2 r}{3}\\right)=1-P\\left(X \\leqslant \\frac{2 r}{3}\\right)=1-\\left(\\frac{2}{3}\\right)^{2}=\\frac{5}{9} .\n$$  \n从分布函数的定义可见, 任一随机变量 $X$ (离散的或连续的) 都有一个分布函数. 有了分布函数, 就可据此算得与随机变量 $X$ 有关事件的概率. 下面先证明分布函数的三个基本性质.  \n定理 2.1.1. 任一分布函数 $F(x)$ 都具有如下三条基本性质:  \n1. 单调性 $F(x)$ 是定义在整个实数轴 $(-\\infty,+\\infty)$ 上的单调非减函数, 即对任意的 $x_{1}<x_{2}$, 有 $F\\left(x_{1}\\right) \\leqslant F\\left(x_{2}\\right)$.\n2. 有界性对任意的 $x$, 有 $0 \\leqslant F(x) \\leqslant 1$, 且  \n$$\n\\begin{aligned}\n& F(-\\infty)=\\lim _{x \\rightarrow-\\infty} F(x)=0, \\\\\n& F(+\\infty)=\\lim _{x \\rightarrow+\\infty} F(x)=1 .\n\\end{aligned}\n$$  \n3. 右连续性 $F(x)$ 是 $x$ 的右连续函数, 即对任意的 $x_{0}$, 有  \n$$\n\\lim _{x \\rightarrow x_{0}+} F(x)=F\\left(x_{0}\\right),\n$$  \n即  \n$$",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.2 随机变量的分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "定理 2.1.1. 任一分布函数 $F(x)$ 都具有如下三条基本性质:  \n1. 单调性 $F(x)$ 是定义在整个实数轴 $(-\\infty,+\\infty)$ 上的单调非减函数, 即对任意的 $x_{1}<x_{2}$, 有 $F\\left(x_{1}\\right) \\leqslant F\\left(x_{2}\\right)$.\n2. 有界性对任意的 $x$, 有 $0 \\leqslant F(x) \\leqslant 1$, 且  \n$$\n\\begin{aligned}\n& F(-\\infty)=\\lim _{x \\rightarrow-\\infty} F(x)=0, \\\\\n& F(+\\infty)=\\lim _{x \\rightarrow+\\infty} F(x)=1 .\n\\end{aligned}\n$$  \n3. 右连续性 $F(x)$ 是 $x$ 的右连续函数, 即对任意的 $x_{0}$, 有  \n$$\n\\lim _{x \\rightarrow x_{0}+} F(x)=F\\left(x_{0}\\right),\n$$  \n即  \n$$\nF\\left(x_{0}+0\\right)=F\\left(x_{0}\\right)\n$$  \n证明: (1) 是显然的, 下证 (2). 由于 $F(x)$ 是事件 $\\{X \\leqslant x\\}$ 的概率, 所以 $0 \\leqslant F(x) \\leqslant 1$. 由 $F(x)$ 的单调性知, 对任意整数 $m$ 和 $n$, 有  \n$$\n\\lim _{x \\rightarrow-\\infty} F(x)=\\lim _{m \\rightarrow-\\infty} F(m), \\lim _{x \\rightarrow+\\infty} F(x)=\\lim _{n \\rightarrow+\\infty} F(n)\n$$  \n都存在. 又由概率的可列可加性得  \n$$\n\\begin{aligned}\n1 & =P(-\\infty<X<+\\infty)=P\\left(\\bigcup_{i=-\\infty}^{+\\infty}\\{i-1<X \\leqslant i\\}\\right) \\\\",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.2 随机变量的分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n即  \n$$\nF\\left(x_{0}+0\\right)=F\\left(x_{0}\\right)\n$$  \n证明: (1) 是显然的, 下证 (2). 由于 $F(x)$ 是事件 $\\{X \\leqslant x\\}$ 的概率, 所以 $0 \\leqslant F(x) \\leqslant 1$. 由 $F(x)$ 的单调性知, 对任意整数 $m$ 和 $n$, 有  \n$$\n\\lim _{x \\rightarrow-\\infty} F(x)=\\lim _{m \\rightarrow-\\infty} F(m), \\lim _{x \\rightarrow+\\infty} F(x)=\\lim _{n \\rightarrow+\\infty} F(n)\n$$  \n都存在. 又由概率的可列可加性得  \n$$\n\\begin{aligned}\n1 & =P(-\\infty<X<+\\infty)=P\\left(\\bigcup_{i=-\\infty}^{+\\infty}\\{i-1<X \\leqslant i\\}\\right) \\\\\n& =\\sum_{i=-\\infty}^{+\\infty} P(i-1<X \\leqslant i)=\\lim _{\\substack{n \\rightarrow+\\infty \\\\\nm \\rightarrow-\\infty}} \\sum_{i=m}^{n} P(i-1<X \\leqslant i) \\\\\n& =\\lim _{n \\rightarrow+\\infty} F(n)-\\lim _{m \\rightarrow-\\infty} F(m)\n\\end{aligned}\n$$  \n再证 (3), 因为 $F(x)$ 是单调有界非降函数, 所以其任一点 $x_{0}$ 的右极限 $F\\left(x_{0}+0\\right)$ 必存在. 为证右连续性, 只要对单调下降的数列 $x_{1}>x_{2}>\\cdots>x_{n}>\\cdots>x_{0}$, 当 $x_{n} \\rightarrow x_{0}(n \\rightarrow+\\infty)$ 时, 证明 $\\lim _{n \\rightarrow+\\infty} F\\left(x_{n}\\right)=F\\left(x_{0}\\right)$成立即可. 因为  \n$$",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.2 随机变量的分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "m \\rightarrow-\\infty}} \\sum_{i=m}^{n} P(i-1<X \\leqslant i) \\\\\n& =\\lim _{n \\rightarrow+\\infty} F(n)-\\lim _{m \\rightarrow-\\infty} F(m)\n\\end{aligned}\n$$  \n再证 (3), 因为 $F(x)$ 是单调有界非降函数, 所以其任一点 $x_{0}$ 的右极限 $F\\left(x_{0}+0\\right)$ 必存在. 为证右连续性, 只要对单调下降的数列 $x_{1}>x_{2}>\\cdots>x_{n}>\\cdots>x_{0}$, 当 $x_{n} \\rightarrow x_{0}(n \\rightarrow+\\infty)$ 时, 证明 $\\lim _{n \\rightarrow+\\infty} F\\left(x_{n}\\right)=F\\left(x_{0}\\right)$成立即可. 因为  \n$$\nF\\left(x_{1}\\right)-F\\left(x_{0}\\right)=P\\left(x_{0}<X \\leqslant x_{1}\\right)=P\\left(\\bigcup_{r=1}^{+\\infty}\\left\\{x_{i+1}<X \\leqslant x_{i}\\right\\}\\right)\n$$  \n$$\n\\begin{aligned}\n& =\\sum_{i=1}^{+\\infty} P\\left(x_{i+1}<X \\leqslant x_{i}\\right)=\\sum_{i=1}^{+\\infty}\\left[F\\left(x_{i}\\right)-F\\left(x_{t+1}\\right)\\right] \\\\\n& =\\lim _{n \\rightarrow \\infty}\\left[F\\left(x_{1}\\right)-F\\left(x_{n}\\right)\\right]=F\\left(x_{1}\\right)-\\lim _{n \\rightarrow \\infty} F\\left(x_{n}\\right)\n\\end{aligned}\n$$  \n由此得  \n$$",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.2 随机变量的分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n$$\n\\begin{aligned}\n& =\\sum_{i=1}^{+\\infty} P\\left(x_{i+1}<X \\leqslant x_{i}\\right)=\\sum_{i=1}^{+\\infty}\\left[F\\left(x_{i}\\right)-F\\left(x_{t+1}\\right)\\right] \\\\\n& =\\lim _{n \\rightarrow \\infty}\\left[F\\left(x_{1}\\right)-F\\left(x_{n}\\right)\\right]=F\\left(x_{1}\\right)-\\lim _{n \\rightarrow \\infty} F\\left(x_{n}\\right)\n\\end{aligned}\n$$  \n由此得  \n$$\nF\\left(x_{0}\\right)=\\lim _{x \\rightarrow+\\infty} F\\left(x_{n}\\right)=F\\left(x_{0}+0\\right)\n$$  \n至此三条基本性质全部证得.  \n以上三条基本性质是分布函数必须具有的性质, 还可以证明: 满足这三个基本性质的函数一定是某个随机变量的分布函数. 从而这三个基本性质成为判别某个函数是否能成为分布函数的充要条件.  \n有了随机变量 $X$ 的分布函数, 那么有关 $X$ 的各种事件的概率都能方便地用分布函数来表示了, 例如, 对任意的实数 $a$ 与 $b$, 有  \n$$\n\\begin{aligned}\n& P(a<X \\leqslant b)=F(b)-F(a), \\\\\n& P(X=a)=F(a)-F(a-0), \\\\\n& P(X \\geqslant b)=1-F(b-0), \\\\\n& P(X>b)=1-F(b), \\\\\n& P(a<x<b)=F(b-0)-F(a), \\\\\n& P(a \\leqslant X \\leqslant b)=F(b)-F(a-0), \\\\\n& P(a \\leqslant X<b)=F(b-0)-F(a-0) .\n\\end{aligned}\n$$  \n特别当 $F(x)$ 在 $a$ 与 $b$ 处连续时, 有  \n$$\nF(a-0)=F\\langle a), \\quad F(b-0)=F(b) .\n$$  \n这些公式将会在今后的概率计算中经常遇到.",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.2 随机变量的分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "有了随机变量 $X$ 的分布函数, 那么有关 $X$ 的各种事件的概率都能方便地用分布函数来表示了, 例如, 对任意的实数 $a$ 与 $b$, 有  \n$$\n\\begin{aligned}\n& P(a<X \\leqslant b)=F(b)-F(a), \\\\\n& P(X=a)=F(a)-F(a-0), \\\\\n& P(X \\geqslant b)=1-F(b-0), \\\\\n& P(X>b)=1-F(b), \\\\\n& P(a<x<b)=F(b-0)-F(a), \\\\\n& P(a \\leqslant X \\leqslant b)=F(b)-F(a-0), \\\\\n& P(a \\leqslant X<b)=F(b-0)-F(a-0) .\n\\end{aligned}\n$$  \n特别当 $F(x)$ 在 $a$ 与 $b$ 处连续时, 有  \n$$\nF(a-0)=F\\langle a), \\quad F(b-0)=F(b) .\n$$  \n这些公式将会在今后的概率计算中经常遇到.  \n例 2.1.2: 设有一反正切函数  \n$$\nF(x)=\\frac{1}{\\pi}\\left[\\arctan x+\\frac{\\pi}{2}\\right], \\quad-\\infty<x<+\\infty\n$$  \n它在整个数轴上是连续、单调严增函数, 且 $F(+\\infty)=1, F(-\\infty)=0$. 由于此 $F(x)$ 满足分布函数的三个基本性质, 故 $F(x)$ 是一个分布函数. 称这个分布函数为柯西分布函数, 其图形见图 2.1.1.  \n!  \n图 2.1.1: 柯西分布函数  \n若 $X$ 服从柯西分布, 则  \n$$\n\\begin{aligned}\nP(-1 \\leqslant X \\leqslant 1) & =F(1)-F(-1) \\\\\n& =\\frac{1}{\\pi}[\\arctan (1)-\\arctan (-1)] \\\\\n& =\\frac{1}{\\pi}\\left[\\frac{\\pi}{4}-\\left(-\\frac{\\pi}{4}\\right)\\right]=\\frac{1}{2}\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.2 随机变量的分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "对离散随机变量而言, 常用以下定义的分布列来表示其分布.  \n定义 2.1.3. 设 $X$ 是一个离散随机变量, 如果 $X$ 的所有可能取值是 $x_{1}, x_{2}, \\cdots, x_{n}, \\cdots$ 则称 $X$ 取 $x_{i}$,的概率  \n$$\n\\begin{equation*}\np_{i}=p\\left(x_{i}\\right)=P\\left(X=x_{i}\\right), i=1,2, \\cdots, n, \\cdots \\tag{2.1.3}\n\\end{equation*}\n$$  \n为 $X$ 的概率分布列或简称为分布列, 记为 $X \\sim\\left|p_{t}\\right|$, 分布列也可用如下列表方式来表示:  \n$$\n\\begin{array}{l|ccccc}\nX & x_{1} & x_{2} & \\cdots & x_{n} & \\cdots \\\\\n\\hline P & p\\left(x_{1}\\right) & p\\left(x_{2}\\right) & \\cdots & p\\left(x_{n}\\right) & \\cdots\n\\end{array}\n$$  \n或记成  \n$$\n\\left(\\begin{array}{ccccc}\nx_{1} & x_{2} & \\cdots & x_{n} & \\cdots \\\\\np\\left(x_{1}\\right) & p\\left(x_{2}\\right) & \\cdots & p\\left(x_{n}\\right) & \\cdots\n\\end{array}\\right]\n$$  \n第一章中我们已见过多个分布列, 不同的离散随机变量可能有不同的分布列, 甚至在一个样本空间上可以定义几个服从不同分布列的随机变量, 这要看我们的研究需要, 下面就是在同一样本空间上给出几个不同随机变量的具体例子.  \n例 2.1.3: 郑两颗骰子, 其样本空间 $\\Omega$ 含有 36 个等可能的样本点  \n$$\n\\Omega=\\{(x, y) ; x, y=1,2, \\cdots, 6\\}\n$$  \n在 $\\Omega$ 上定义如下 3 个随机变量 $X, Y$ 和 $Z$ :",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.3 离散随机变量的概率分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array}\n$$  \n或记成  \n$$\n\\left(\\begin{array}{ccccc}\nx_{1} & x_{2} & \\cdots & x_{n} & \\cdots \\\\\np\\left(x_{1}\\right) & p\\left(x_{2}\\right) & \\cdots & p\\left(x_{n}\\right) & \\cdots\n\\end{array}\\right]\n$$  \n第一章中我们已见过多个分布列, 不同的离散随机变量可能有不同的分布列, 甚至在一个样本空间上可以定义几个服从不同分布列的随机变量, 这要看我们的研究需要, 下面就是在同一样本空间上给出几个不同随机变量的具体例子.  \n例 2.1.3: 郑两颗骰子, 其样本空间 $\\Omega$ 含有 36 个等可能的样本点  \n$$\n\\Omega=\\{(x, y) ; x, y=1,2, \\cdots, 6\\}\n$$  \n在 $\\Omega$ 上定义如下 3 个随机变量 $X, Y$ 和 $Z$ :  \n- $X$ 为点数之和, 其可能取值为 $2,3, \\cdots, 12$ 等共 11 个值, 其定义见 2.1.2(a)\n- $Y$ 为 6 点的个数, 其可能取值为 $0,1,2$ 等共 3 个值, 其定义见图 2.1.2(b).\n- $Z$ 为最大点数, 其可能取值为 $1,2, \\cdots, 6$ 等共 6 个值, 其定义见图 2.1.2(c)  \n!  \n(a) 点数之和 $X$ 的定义  \n!  \n(b) 6 点的个数 $Y$ 的定义  \n!  \n(c) 最大点数 $Z$ 的定义  \n图 2.1.2: 同一样本空间上不同随机变量  \n这三个随机变量的分布列可用古典方法算得如下: ・.  \n类似地, 还可以在这个样本空间上定义其他的离散随机变量.  \n分布列的基本性质  \n(1) 非负性: $: p\\left(x_{t}\\right) \\geqslant 0, i=1,2, \\cdots$; (2) 正则性: $\\sum_{i=1}^{\\infty} p\\left(x_{i}\\right)=1$.  \n!  \n图 2.1.3: 离散随机变量的分布函数",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.3 离散随机变量的概率分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "- $X$ 为点数之和, 其可能取值为 $2,3, \\cdots, 12$ 等共 11 个值, 其定义见 2.1.2(a)\n- $Y$ 为 6 点的个数, 其可能取值为 $0,1,2$ 等共 3 个值, 其定义见图 2.1.2(b).\n- $Z$ 为最大点数, 其可能取值为 $1,2, \\cdots, 6$ 等共 6 个值, 其定义见图 2.1.2(c)  \n!  \n(a) 点数之和 $X$ 的定义  \n!  \n(b) 6 点的个数 $Y$ 的定义  \n!  \n(c) 最大点数 $Z$ 的定义  \n图 2.1.2: 同一样本空间上不同随机变量  \n这三个随机变量的分布列可用古典方法算得如下: ・.  \n类似地, 还可以在这个样本空间上定义其他的离散随机变量.  \n分布列的基本性质  \n(1) 非负性: $: p\\left(x_{t}\\right) \\geqslant 0, i=1,2, \\cdots$; (2) 正则性: $\\sum_{i=1}^{\\infty} p\\left(x_{i}\\right)=1$.  \n!  \n图 2.1.3: 离散随机变量的分布函数  \n以上两条基本性质是分布列必须具有的性质, 也是判别某个数列是否成为分布列的充要条件由离散随机变量 $\\mathrm{X}$ 的分布列很容易写出 $\\mathrm{X}$ 的分布函数:  \n$$\nF(x)=\\sum_{x_{1} \\leqslant x} p\\left(x_{i}\\right)\n$$  \n它的图形是有限级 (成无穷级) 的阶梯函数, 具体见下面的例子. 不过在离散场合, 常用来描述其分布的是分布列, 很少用到分布函数. 因为求离散随机变量 $\\mathrm{X}$ 的有关事件的概率时, 用分布列比用分布函数来得更方便.  \n例 2.1.4: 设离散随机变量 $X$ 的分布列为  \n$$\n\\begin{array}{c|ccc}\nx & -1 & 2 & 3 \\\\\n\\hline P & 0.25 & 0.5 & 0.25\n\\end{array}\n$$  \n试求 $P(X \\leqslant 0.5), P(1.5<X \\leqslant 2.5)$, 并写出 $X$ 的分布函数.  \n解:  \n$$\n\\begin{gathered}",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.3 离散随机变量的概率分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "以上两条基本性质是分布列必须具有的性质, 也是判别某个数列是否成为分布列的充要条件由离散随机变量 $\\mathrm{X}$ 的分布列很容易写出 $\\mathrm{X}$ 的分布函数:  \n$$\nF(x)=\\sum_{x_{1} \\leqslant x} p\\left(x_{i}\\right)\n$$  \n它的图形是有限级 (成无穷级) 的阶梯函数, 具体见下面的例子. 不过在离散场合, 常用来描述其分布的是分布列, 很少用到分布函数. 因为求离散随机变量 $\\mathrm{X}$ 的有关事件的概率时, 用分布列比用分布函数来得更方便.  \n例 2.1.4: 设离散随机变量 $X$ 的分布列为  \n$$\n\\begin{array}{c|ccc}\nx & -1 & 2 & 3 \\\\\n\\hline P & 0.25 & 0.5 & 0.25\n\\end{array}\n$$  \n试求 $P(X \\leqslant 0.5), P(1.5<X \\leqslant 2.5)$, 并写出 $X$ 的分布函数.  \n解:  \n$$\n\\begin{gathered}\nP(X \\leqslant 0.5)=P(X=-1)=0.25 \\\\\nP(1.5<X \\leqslant 2.5)=P(X=2)=0.5 \\\\\nF(x)= \\begin{cases}0, & x<-1 ; \\\\\n0.25, & -1 \\leqslant x<2 ; \\\\\n0.25+0.5=0.75, & 2 \\leqslant x<3 ; \\\\\n0.25+0.5+0.25=1, & x \\geqslant 3 .\\end{cases}\n\\end{gathered}\n$$  \n$F(x)$ 的图形如图 2.1.3 所示, 它是一条阶梯形的曲线, 在 $X$ 的可能取值 $-1,2,3$ 处有跳跃点,其跳跃度分别为 $0.25,0.5,0.25$.  \n特别, 常量 $c$ 可看作仅取一个值的随机变量 $X$, 即  \n$$\nP(X=c)=1\n$$  \n这个分布常称为单点分布或退化分布, 它的分布函数是  \n$$\nF(x)= \\begin{cases}0, & x<c  \\tag{2.1.4}\\\\ 1, & x \\geqslant c\\end{cases}\n$$  \n其图形为  \n!  \n图 2.1.4: 单点分布函数",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.3 离散随机变量的概率分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "P(1.5<X \\leqslant 2.5)=P(X=2)=0.5 \\\\\nF(x)= \\begin{cases}0, & x<-1 ; \\\\\n0.25, & -1 \\leqslant x<2 ; \\\\\n0.25+0.5=0.75, & 2 \\leqslant x<3 ; \\\\\n0.25+0.5+0.25=1, & x \\geqslant 3 .\\end{cases}\n\\end{gathered}\n$$  \n$F(x)$ 的图形如图 2.1.3 所示, 它是一条阶梯形的曲线, 在 $X$ 的可能取值 $-1,2,3$ 处有跳跃点,其跳跃度分别为 $0.25,0.5,0.25$.  \n特别, 常量 $c$ 可看作仅取一个值的随机变量 $X$, 即  \n$$\nP(X=c)=1\n$$  \n这个分布常称为单点分布或退化分布, 它的分布函数是  \n$$\nF(x)= \\begin{cases}0, & x<c  \\tag{2.1.4}\\\\ 1, & x \\geqslant c\\end{cases}\n$$  \n其图形为  \n!  \n图 2.1.4: 单点分布函数  \n以下例子说明: 在具体求离散随机变量 $X$ 的分布列时, 关键是求出 $X$ 的所有可能取值及取这些值的概率.  \n例 2.1.5: 一汽车沿一街道行驶, 需要经过 3 个设有红绿信号灯的路口, 若设每个信号灯显示红绿两种信号的时间相等, 且各个估号灯工作相互独立. 以 $X$ 表示该汽车首次遇到红灯前已通过的路口数. 试求 $X$ 的概率分布列.  \n解: 由题设可知, $X$ 的可能取值为 $0,1.2$. 又 记 $A=$ “汽车在第 $\\mathrm{i}$ 个路口遇到红灯”, $i=1,2,3$. 因为 $A_{1}, A_{2}, A_{3}$ 相互独立, 且  \n$$\nP\\left(A_{t}\\right)=P\\left(A_{t}\\right)=\\frac{1}{2}, \\quad i=1.2 .3\n$$  \n所以得  \n$$\n\\begin{aligned}\n& P(X=0)=P\\left(A_{1}\\right)=\\frac{1}{2} \\\\",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.3 离散随机变量的概率分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其图形为  \n!  \n图 2.1.4: 单点分布函数  \n以下例子说明: 在具体求离散随机变量 $X$ 的分布列时, 关键是求出 $X$ 的所有可能取值及取这些值的概率.  \n例 2.1.5: 一汽车沿一街道行驶, 需要经过 3 个设有红绿信号灯的路口, 若设每个信号灯显示红绿两种信号的时间相等, 且各个估号灯工作相互独立. 以 $X$ 表示该汽车首次遇到红灯前已通过的路口数. 试求 $X$ 的概率分布列.  \n解: 由题设可知, $X$ 的可能取值为 $0,1.2$. 又 记 $A=$ “汽车在第 $\\mathrm{i}$ 个路口遇到红灯”, $i=1,2,3$. 因为 $A_{1}, A_{2}, A_{3}$ 相互独立, 且  \n$$\nP\\left(A_{t}\\right)=P\\left(A_{t}\\right)=\\frac{1}{2}, \\quad i=1.2 .3\n$$  \n所以得  \n$$\n\\begin{aligned}\n& P(X=0)=P\\left(A_{1}\\right)=\\frac{1}{2} \\\\\n& P(X=1)=P\\left(\\bar{A}_{1} A_{2}\\right)=P\\left(\\bar{A}_{1}\\right) P\\left(\\Lambda_{2}\\right)=\\frac{1}{4} \\\\\n& \\left.P(X=2)=P\\left(\\bar{A}_{1} \\bar{A}_{2} A_{3}\\right)=P\\left(A_{1}\\right) P\\left(\\dot{A}_{2}\\right) P\\left(A_{J}\\right)=\\frac{1}{8}\\right) \\\\\n& P(X=3)=P\\left(\\bar{A}_{1} \\bar{A}_{2} \\bar{A}_{3}\\right)=P\\left(\\bar{A}_{1}\\right) P\\left(\\bar{A}_{2}\\right) P\\left(\\bar{A}_{2}\\right)=\\frac{1}{8}\n\\end{aligned}\n$$  \n故 $X$ 的分布列如下:  \n| $X$ | 0 | 1 | 2 | 3 |\n| :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.3 离散随机变量的概率分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "& \\left.P(X=2)=P\\left(\\bar{A}_{1} \\bar{A}_{2} A_{3}\\right)=P\\left(A_{1}\\right) P\\left(\\dot{A}_{2}\\right) P\\left(A_{J}\\right)=\\frac{1}{8}\\right) \\\\\n& P(X=3)=P\\left(\\bar{A}_{1} \\bar{A}_{2} \\bar{A}_{3}\\right)=P\\left(\\bar{A}_{1}\\right) P\\left(\\bar{A}_{2}\\right) P\\left(\\bar{A}_{2}\\right)=\\frac{1}{8}\n\\end{aligned}\n$$  \n故 $X$ 的分布列如下:  \n| $X$ | 0 | 1 | 2 | 3 |\n| :---: | :---: | :---: | :---: | :---: |\n| $P$ | $1 / 2$ | $1 / 4$ | $1 / 8$ | $1 / 8$ |",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.3 离散随机变量的概率分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "连续随机变量的一切可能取值是充满某个区间 $(a, b)$, 在这个区间内有无穷不可列个实数, 因此描述连续随机变量的概率分布不能再用分布列形式表示, 而要改用概率密度函数表示. 下面用一个实例来导出概率密度函数的由来.  \n例 2.1.6: 新生婴儿的体重 $\\mathrm{X}$ 是一个随机变量. 假如记录很多个 (例如:十万个) 新生婴儿的体重, 我们将各种体重的频率用直方图形式表示出来, $x$ 轴表示体重 (单位: $500 \\mathrm{~g}$ ), $y$ 轴表示单位长度上的频率, 则以下图 2.1.5 的 (a) 至 (c) 表明: 当 $\\Delta x=1$ 越来越小, 其频率直方图形越来越光滑.  \n1. 当 $\\Delta x=1$, 体重的频率直方图见图 2.1.5(a). 注意, 图中矩形宽度为 1 , 高度为频率, 所以所有矩形面积之和为 1 . 此时体重 $X$ 的取值为 $1,2, \\cdots$,即 $X$ 是一个离散随机变量.\n2. 当 $\\Delta x=0.1$, 体重的频率直方图见图 2.1.5(b). 注意, 图中矩形宽度为 0.1 , 高度为: 频率 $/ 0.1$,所有小矩形面积之和仍为 1 .\n3. 当 $\\Delta x \\rightarrow 0$ 则体重的频率图趋于图 2.1.5(c) 所示的一条光滑的曲线, 其高度为概率密度值.如果记这条曲线为 $p(x)$, 则 $p(x)$ 与 $x$ 轴所夹面积仍为 1 . 此时体重 $X$ 的取值充满了某一区间, 即 $\\mathrm{X}$ 是一个连续随机变量. 图中 $p(x)$ 就是连续随机变量 $\\mathrm{X}$ 的概率密度函数.  \n下面给出连续随机变量的概率密度函数的定义.  \n!  \n(a) $\\Delta x=1$  \n!  \n(b) $\\Delta x=0.1$  \n!  \n(c) $\\Delta x \\rightarrow 0$  \n图 2.1.5: 新生婴儿体重 $X$ 的频率分布  \n定义 2.1.4. 设随机变量 $X$ 的分布函数为 $F(x)$, 如果存在实数轴上的一个非负可积函数 $p(x)$, 使得对任意实数 $x$ 有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.4 连续随机变量的概率密度函数"
        },
        "type": "Document"
    },
    {
        "page_content": "3. 当 $\\Delta x \\rightarrow 0$ 则体重的频率图趋于图 2.1.5(c) 所示的一条光滑的曲线, 其高度为概率密度值.如果记这条曲线为 $p(x)$, 则 $p(x)$ 与 $x$ 轴所夹面积仍为 1 . 此时体重 $X$ 的取值充满了某一区间, 即 $\\mathrm{X}$ 是一个连续随机变量. 图中 $p(x)$ 就是连续随机变量 $\\mathrm{X}$ 的概率密度函数.  \n下面给出连续随机变量的概率密度函数的定义.  \n!  \n(a) $\\Delta x=1$  \n!  \n(b) $\\Delta x=0.1$  \n!  \n(c) $\\Delta x \\rightarrow 0$  \n图 2.1.5: 新生婴儿体重 $X$ 的频率分布  \n定义 2.1.4. 设随机变量 $X$ 的分布函数为 $F(x)$, 如果存在实数轴上的一个非负可积函数 $p(x)$, 使得对任意实数 $x$ 有  \n$$\n\\begin{equation*}\nF(x)=\\int_{-\\infty}^{x} p(t) \\mathrm{d} t \\tag{2.1.5}\n\\end{equation*}\n$$  \n从 2.1.5式可以看出, 在 $F(x)$ 导数存在的点上有  \n$$\n\\begin{equation*}\nF^{\\prime}(x)=p(x) \\tag{2.1.6}\n\\end{equation*}\n$$  \n$F(x)$ 是 (累积) 概率函数, 其导数 $F^{\\prime}(x)$ 是概率密度函数, 由此可看出 $p(x)$ 被称为概率密度函数的理由.  \n由 (2.1.6) 式, 可从分布函数求得密度函数. 譬如例 2.1 .2 给出的柯西分布函数处处可导, 故柯西分布的密度函数为  \n$$\np(x)=\\frac{1}{\\pi} \\frac{1}{1+x^{2}},-\\infty<x<+\\infty .\n$$",
        "metadata": {
            "Header 2": "2.1 随机变量及其分布",
            "Header 3": "2.1.4 连续随机变量的概率密度函数"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 非负性: $p(x) \\geqslant 0$;  \n(2) 正则性:: $\\int_{-\\infty}^{+\\infty} p(x) \\mathrm{d} x=1$.  \n以上两条基本性质是密度函数必须具有的性质, 也是确定或判别某个函数是否成为密度函数的充要条件. 譬如已知某个函数 $p(x)$ 为密度函数, 若 $p(x)$ 中有待定常数, 则该常数必定是利用正则性 $\\int_{-\\infty}^{+\\infty} p(x) \\mathrm{d} x=1$ 来确定的, 见下面例子.  \n例 2.1.7: 已知随机变量 $\\mathrm{X}$ 的密度函数为  \n$$\np(x)= \\begin{cases}c, & -1 \\leqslant x \\leqslant 1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求常数 $c$.  \n解: 由密度函数的正则性知  \n$$\n1=\\int_{-\\infty}^{+\\infty} p(x) \\mathrm{d} x=\\int_{-1}^{1} c \\mathrm{~d} x=2 c .\n$$  \n所以由 $2 c=1$ 得 $c=0.5$. 利用分段积分, 我们还可求出 $X$ 的分布函数.  \n当 $x<-1$ 时,  \n$$\nF(x)=\\int_{-\\infty}^{x} 0 \\mathrm{~d} t=0 .\n$$  \n当 $-1 \\leqslant x<1$ 时,  \n$$\nF(x)=\\int_{-3}^{x} 0.5 \\mathrm{~d} t=(x+1) / 2 .\n$$  \n当 $x \\geqslant 1$ 时,  \n$$\nF(x)=\\int_{1}^{1} 0.5 \\mathrm{~d} t+\\int_{1}^{x} 0 \\mathrm{~d} t=1 .\n$$  \n所以得 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x<-1 \\\\ \\frac{x+1}{2}, & -1 \\leqslant x<1 \\\\ 1, & x \\geqslant 1\\end{cases}\n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n所以由 $2 c=1$ 得 $c=0.5$. 利用分段积分, 我们还可求出 $X$ 的分布函数.  \n当 $x<-1$ 时,  \n$$\nF(x)=\\int_{-\\infty}^{x} 0 \\mathrm{~d} t=0 .\n$$  \n当 $-1 \\leqslant x<1$ 时,  \n$$\nF(x)=\\int_{-3}^{x} 0.5 \\mathrm{~d} t=(x+1) / 2 .\n$$  \n当 $x \\geqslant 1$ 时,  \n$$\nF(x)=\\int_{1}^{1} 0.5 \\mathrm{~d} t+\\int_{1}^{x} 0 \\mathrm{~d} t=1 .\n$$  \n所以得 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x<-1 \\\\ \\frac{x+1}{2}, & -1 \\leqslant x<1 \\\\ 1, & x \\geqslant 1\\end{cases}\n$$  \n由密度函数求分布函数的关键是; 分布函数是一种 “累积” 概率, 所以在计算积分时要注意积分限的合理运用. 此例密度函数和分布函数的图形如图 2.1.6 (a) 与 (b) 所示, 这个分布称为区间 $(-1,1)$ 上的均匀分布, 记为 $U(-1,1)$.  \n!  \n(a) $p(x)$ 的图形  \n!  \n(b) $F(x)$ 的图形  \n图 2.1.6: 均匀分布 $U(-1,1)$ 的密度函数和分布函数的图形  \n例 2.1.8: 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}x, & 0 \\leqslant x<1 ; \\\\ 2-x, & 1 \\leqslant x<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $X$ 的分布函数 $F(x)$.  \n解: 当 $x<0$ 时,  \n$$\nF(x)=\\int_{-\\infty}^{x} p(x) \\mathrm{d} x=0\n$$  \n当 $0 \\leqslant x<1$ 时,  \n$$\nF(x)=\\int_{0}^{x} x \\mathrm{~d} x=\\frac{x^{2}}{2}\n$$  \n当 $1 \\leqslant x<2$ 时,  \n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n(a) $p(x)$ 的图形  \n!  \n(b) $F(x)$ 的图形  \n图 2.1.6: 均匀分布 $U(-1,1)$ 的密度函数和分布函数的图形  \n例 2.1.8: 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}x, & 0 \\leqslant x<1 ; \\\\ 2-x, & 1 \\leqslant x<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $X$ 的分布函数 $F(x)$.  \n解: 当 $x<0$ 时,  \n$$\nF(x)=\\int_{-\\infty}^{x} p(x) \\mathrm{d} x=0\n$$  \n当 $0 \\leqslant x<1$ 时,  \n$$\nF(x)=\\int_{0}^{x} x \\mathrm{~d} x=\\frac{x^{2}}{2}\n$$  \n当 $1 \\leqslant x<2$ 时,  \n$$\nF(x)=\\int_{-\\infty}^{x} p(x) \\mathrm{d} x=\\int_{0}^{1} x \\mathrm{~d} x+\\int_{1}^{x}(2-x) \\mathrm{d} x=-\\frac{x^{2}}{2}+2 x-1\n$$  \n当 $\\mathrm{I} \\leqslant x<2$ 时,  \n$$\nF(x)=\\int_{-\\infty}^{x} p(x) \\mathrm{d} x=\\int_{0}^{1} x \\mathrm{~d} x+\\int_{1}^{2}(2-x) \\mathrm{d} x=1\n$$  \n综上所述, 得 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ \\frac{x^{2}}{2}, & 0 \\leqslant x<1 \\\\ -\\frac{x^{2}}{2}+2 x-1, & 1 \\leqslant x<2 \\\\ 1, & x \\geqslant 2\\end{cases}\n$$  \n这个分布被称为辛普森分布或三角分布, 其密度函数 $p(x)$ 和分布函数 $F(x)$ 的图形见下图 2.1.7. 从图形上可看出: 在区间 $(0,1)$ 上 $F(x)$ 是下凸函数, 在区间 $(1,2)$ 上 $F(x)$ 是上凸函数.",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n当 $\\mathrm{I} \\leqslant x<2$ 时,  \n$$\nF(x)=\\int_{-\\infty}^{x} p(x) \\mathrm{d} x=\\int_{0}^{1} x \\mathrm{~d} x+\\int_{1}^{2}(2-x) \\mathrm{d} x=1\n$$  \n综上所述, 得 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ \\frac{x^{2}}{2}, & 0 \\leqslant x<1 \\\\ -\\frac{x^{2}}{2}+2 x-1, & 1 \\leqslant x<2 \\\\ 1, & x \\geqslant 2\\end{cases}\n$$  \n这个分布被称为辛普森分布或三角分布, 其密度函数 $p(x)$ 和分布函数 $F(x)$ 的图形见下图 2.1.7. 从图形上可看出: 在区间 $(0,1)$ 上 $F(x)$ 是下凸函数, 在区间 $(1,2)$ 上 $F(x)$ 是上凸函数.  \n以下我们对密度函数与分布列的异同点作一些说明.  \n在离散随机变量场合,  \n!  \n(a) $p(x)$ 的图形  \n!  \n(b) $\\boldsymbol{F}(x)$ 的图形  \n图 2.1.7: 辛普森分布  \n$$\nP(a<X \\leqslant b)=\\sum_{a<x_{i} \\leqslant b} p\\left(x_{i}\\right)\n$$  \n其中诸 $x_{i}$; 为 $X$ 的可能取值.  \n而在连续随机变量场合,  \n$$\nP(a<X \\leqslant b)=\\int_{a}^{b} p(x) \\mathrm{d} x\n$$  \n其含义见下图.  \n!  \n图 2.1.8: 连续随机变量场合的概率  \n从这个意义上讲, 概率密度函数与概率分布列所起的作用是类似的, 但它们之间的差别也是明显的, 具体有  \n1. 离散随机变量的分布函数 $\\mathrm{F}(\\mathrm{x})$ 总是右连续的阶梯函数, 而连续随机变量的分布函数 $F(x)$ 一定是整个数轴上的连续函数, 因为对任意点 $x$ 的增量 $\\Delta x$, 相应分布函数的增量总有  \n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "在离散随机变量场合,  \n!  \n(a) $p(x)$ 的图形  \n!  \n(b) $\\boldsymbol{F}(x)$ 的图形  \n图 2.1.7: 辛普森分布  \n$$\nP(a<X \\leqslant b)=\\sum_{a<x_{i} \\leqslant b} p\\left(x_{i}\\right)\n$$  \n其中诸 $x_{i}$; 为 $X$ 的可能取值.  \n而在连续随机变量场合,  \n$$\nP(a<X \\leqslant b)=\\int_{a}^{b} p(x) \\mathrm{d} x\n$$  \n其含义见下图.  \n!  \n图 2.1.8: 连续随机变量场合的概率  \n从这个意义上讲, 概率密度函数与概率分布列所起的作用是类似的, 但它们之间的差别也是明显的, 具体有  \n1. 离散随机变量的分布函数 $\\mathrm{F}(\\mathrm{x})$ 总是右连续的阶梯函数, 而连续随机变量的分布函数 $F(x)$ 一定是整个数轴上的连续函数, 因为对任意点 $x$ 的增量 $\\Delta x$, 相应分布函数的增量总有  \n$$\nF(x+\\Delta x)-F(x)=\\int_{x}^{x+\\Delta x} p(x) \\mathrm{d} x \\longrightarrow 0, \\quad(\\Delta x \\rightarrow 0)\n$$  \n2. 离散随机变量 $X$ 在其可能取值的点 $x_{1}, x_{2}, \\cdots, x_{n}, \\cdots$ 上的概率不为 0 , 而连续随机变量 $X$在 $(-\\infty,+\\infty)$ 上任一点 $a$ 的概率恒为 0 , 即  \n$$\nP(X=a)=\\int_{a}^{a} p(x) \\mathrm{d} x=0\n$$  \n这表明: 不可能事件的概率为 0 , 但概率为 0 的事件不一定是不可能事件; 类似地, 必然事件的概率为 1 , 但概率为 1 的事件不一定是必然事件.  \n3. 由于连续随机变量 $X$ 仅取一点的概率恒为 0 , 从而在事件 “ $a \\leqslant X \\leqslant b$ ” 中减去 $x=a$ 或减去 $X=b$, 不影响其概率, 即  \n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nF(x+\\Delta x)-F(x)=\\int_{x}^{x+\\Delta x} p(x) \\mathrm{d} x \\longrightarrow 0, \\quad(\\Delta x \\rightarrow 0)\n$$  \n2. 离散随机变量 $X$ 在其可能取值的点 $x_{1}, x_{2}, \\cdots, x_{n}, \\cdots$ 上的概率不为 0 , 而连续随机变量 $X$在 $(-\\infty,+\\infty)$ 上任一点 $a$ 的概率恒为 0 , 即  \n$$\nP(X=a)=\\int_{a}^{a} p(x) \\mathrm{d} x=0\n$$  \n这表明: 不可能事件的概率为 0 , 但概率为 0 的事件不一定是不可能事件; 类似地, 必然事件的概率为 1 , 但概率为 1 的事件不一定是必然事件.  \n3. 由于连续随机变量 $X$ 仅取一点的概率恒为 0 , 从而在事件 “ $a \\leqslant X \\leqslant b$ ” 中减去 $x=a$ 或减去 $X=b$, 不影响其概率, 即  \n$$\nP(a \\leqslant x \\leqslant b)=P(a<X \\leqslant b)=P(a \\leqslant X<b)=P(a<X<b)\n$$  \n这给计算带来很大方便. 而这个性质在离散随机变量场合是不存在的, 在离散随机变量场合计算概率要“点点计较”.  \n4. 由于在若干点上改变密度函数 $p(x)$ 的值并不影响其积分的值, 从而不影响其分布函数 $F(x)$的值, 这意味着一个连续分布的密度函数不唯一. 譬如在例 2.1.7 中, 改变 $x=-1$ 和 $\\mathrm{x}=1$ 处 $p(x)$ 的值如下:  \n$$\np_{1}(x)=\\left\\{\\begin{array}{ll}\n0.5, & -1 \\leqslant x \\leqslant 1 \\\\\n0, & \\text { 其他 th }\n\\end{array} \\quad p_{2}(x)= \\begin{cases}0.5, & -1<x<1 \\\\\n0 & \\neq 4\\end{cases}\\right.\n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(a \\leqslant x \\leqslant b)=P(a<X \\leqslant b)=P(a \\leqslant X<b)=P(a<X<b)\n$$  \n这给计算带来很大方便. 而这个性质在离散随机变量场合是不存在的, 在离散随机变量场合计算概率要“点点计较”.  \n4. 由于在若干点上改变密度函数 $p(x)$ 的值并不影响其积分的值, 从而不影响其分布函数 $F(x)$的值, 这意味着一个连续分布的密度函数不唯一. 譬如在例 2.1.7 中, 改变 $x=-1$ 和 $\\mathrm{x}=1$ 处 $p(x)$ 的值如下:  \n$$\np_{1}(x)=\\left\\{\\begin{array}{ll}\n0.5, & -1 \\leqslant x \\leqslant 1 \\\\\n0, & \\text { 其他 th }\n\\end{array} \\quad p_{2}(x)= \\begin{cases}0.5, & -1<x<1 \\\\\n0 & \\neq 4\\end{cases}\\right.\n$$  \n它们都是 $(-1,1)$ 上均匀分布的密度函数. 但仔细考察这两个函数 $p_{1}(x)$ 和 $p_{2}(x)$, 可以发现  \n$$\nP\\left(p_{1}(x) \\neq p_{2}(x)\\right)=P(X=-1)+P(X=1)=0\n$$  \n可见这两个函数在概率意义上是无差别的, 在此称 $p_{1}(x)$ 与 $p_{2}(x)$ 是 “几乎处处相等”, 其含义是: 它们不相等处的点组成集合的概率为 0 . 这就是概率论与微积分不同之处, 也是概率论的魅力之处. 除了离散分布和连续分布之外, 还有既非离散又非连续的分布, 见下例.  \n例 2.1.9: 以下的函数 $F(x)$ 确是一个分布, 它的图形如图 2.1.9所示.  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ \\frac{1+x}{2}, & 0 \\leqslant x<1 \\\\ 1, & x \\geqslant 1\\end{cases}\n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "0 & \\neq 4\\end{cases}\\right.\n$$  \n它们都是 $(-1,1)$ 上均匀分布的密度函数. 但仔细考察这两个函数 $p_{1}(x)$ 和 $p_{2}(x)$, 可以发现  \n$$\nP\\left(p_{1}(x) \\neq p_{2}(x)\\right)=P(X=-1)+P(X=1)=0\n$$  \n可见这两个函数在概率意义上是无差别的, 在此称 $p_{1}(x)$ 与 $p_{2}(x)$ 是 “几乎处处相等”, 其含义是: 它们不相等处的点组成集合的概率为 0 . 这就是概率论与微积分不同之处, 也是概率论的魅力之处. 除了离散分布和连续分布之外, 还有既非离散又非连续的分布, 见下例.  \n例 2.1.9: 以下的函数 $F(x)$ 确是一个分布, 它的图形如图 2.1.9所示.  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ \\frac{1+x}{2}, & 0 \\leqslant x<1 \\\\ 1, & x \\geqslant 1\\end{cases}\n$$  \n从图上可以看出: 它既不是阶梯函数, 又不是连续图 2.1.9既非离散、又非函数, 所以它既非离散的又非连续的分布. 它是新的一连续的分布函数示例类分布, 本书将不研究此类分布, 只让大家知道山外有山, 需要不断学习与研究.  \n下面我们再给出一些连续随机变量的例子.  \n!  \n图 2.1.9: 既非离散、又非连续的分布函数示例  \n例 2.1.10: 某种型号电子元件的寿命 $X$ (以小时计) 具有以下的概率密度函数  \n$$\np(x)= \\begin{cases}\\frac{1000}{x^{2}}, & x>1000 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n现有一大批此种元件 (设各元件工作相互独立), 问  \n1. 任取 1 只, 其寿命大于 1500 小时的概率是多少?\n2. 任取 4 只, 4 只寿命都大于 1500 小时的概率是多少?\n3. 任取 4 只, 4 只中至少有 1 只寿命大于 1500 小时的概率是多少?\n4. 若已知一只元件的寿命大于 1500 小时, 则该元件的寿命大于 2000 小时的概率是多少?解:\n5.  \n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "下面我们再给出一些连续随机变量的例子.  \n!  \n图 2.1.9: 既非离散、又非连续的分布函数示例  \n例 2.1.10: 某种型号电子元件的寿命 $X$ (以小时计) 具有以下的概率密度函数  \n$$\np(x)= \\begin{cases}\\frac{1000}{x^{2}}, & x>1000 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n现有一大批此种元件 (设各元件工作相互独立), 问  \n1. 任取 1 只, 其寿命大于 1500 小时的概率是多少?\n2. 任取 4 只, 4 只寿命都大于 1500 小时的概率是多少?\n3. 任取 4 只, 4 只中至少有 1 只寿命大于 1500 小时的概率是多少?\n4. 若已知一只元件的寿命大于 1500 小时, 则该元件的寿命大于 2000 小时的概率是多少?解:\n5.  \n$$\nP\\{X>1500\\}=\\int_{1500}^{+\\infty} \\frac{1000}{x^{2}} \\mathrm{~d} x=\\left(-\\frac{1000}{x}\\right)_{1500}^{+\\infty}=\\frac{2}{3}\n$$  \n2. 各元件工作独立, 因此所求概率为  \n$$\nP\\{\\text { 四只原件寿命都大于 } 1500\\}=[P(X>1500)]^{4}=\\left(\\frac{2}{3}\\right)^{4}=\\frac{16}{81}\n$$  \n3. 所求概率为  \n$$\n\\begin{aligned}\n& P\\{\\text { 四只中至少一只寿命大于 } 1500\\} \\\\\n& =1-P\\{4 \\text { 只元件寿命都小于等于 } 1500\\} \\\\\n& =1-\\left(1-\\frac{2}{3}\\right)^{4}=\\frac{80}{81}\n\\end{aligned}\n$$  \n4. 这是求条件概率 $P\\{X>2000 \\mid X>1500\\}$, 记  \n$$\nA=\\{X>1500 \\mid, B=\\{X>2000\\}\n$$  \n因为 $P(A)=2 / 3, P(B)=1 / 2$, 且 $B \\subset A$, 所以  \n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n2. 各元件工作独立, 因此所求概率为  \n$$\nP\\{\\text { 四只原件寿命都大于 } 1500\\}=[P(X>1500)]^{4}=\\left(\\frac{2}{3}\\right)^{4}=\\frac{16}{81}\n$$  \n3. 所求概率为  \n$$\n\\begin{aligned}\n& P\\{\\text { 四只中至少一只寿命大于 } 1500\\} \\\\\n& =1-P\\{4 \\text { 只元件寿命都小于等于 } 1500\\} \\\\\n& =1-\\left(1-\\frac{2}{3}\\right)^{4}=\\frac{80}{81}\n\\end{aligned}\n$$  \n4. 这是求条件概率 $P\\{X>2000 \\mid X>1500\\}$, 记  \n$$\nA=\\{X>1500 \\mid, B=\\{X>2000\\}\n$$  \n因为 $P(A)=2 / 3, P(B)=1 / 2$, 且 $B \\subset A$, 所以  \n$$\nP(B \\mid A)=\\frac{P(A B)}{P(A)}=\\frac{P(B)}{P(A)}=\\frac{3}{4}\n$$  \n例 2.1.11: 向区间 $(0, a)$ 上任意投点, 用 $X$ 表示这个点的坐标. 设这个点落在 $(0, a)$ 中任一小区间的概率与这个小区间的长度成正比, 而与小区间位置无关. 求 $X$ 的分布函数和密度函数.  \n解: 记 $X$ 的分布函数为 $F(x)$, 则当 $x<0$ 时, 因为 $\\{X \\leqslant x\\}$ 是不可能事件, 所以 $F(x)=P(X \\leqslant$ $x)=0$;  \n当 $x \\geqslant a$ 时, 因为 $\\{X \\leqslant x\\}$ 是必然事件, 所以 $F(x)=P(X \\leqslant x)=1$; 当 $0 \\leqslant x<a$ 时, 有 $F(x)=P(X \\leqslant x)=P(0 \\leqslant X \\leqslant x)=k x$, 其中 $k$ 为比例系数. 因为 $1=F(a)=k a$, 所以得 $k=1 / a$. 于是 $X$ 的分布函数为  \n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n例 2.1.11: 向区间 $(0, a)$ 上任意投点, 用 $X$ 表示这个点的坐标. 设这个点落在 $(0, a)$ 中任一小区间的概率与这个小区间的长度成正比, 而与小区间位置无关. 求 $X$ 的分布函数和密度函数.  \n解: 记 $X$ 的分布函数为 $F(x)$, 则当 $x<0$ 时, 因为 $\\{X \\leqslant x\\}$ 是不可能事件, 所以 $F(x)=P(X \\leqslant$ $x)=0$;  \n当 $x \\geqslant a$ 时, 因为 $\\{X \\leqslant x\\}$ 是必然事件, 所以 $F(x)=P(X \\leqslant x)=1$; 当 $0 \\leqslant x<a$ 时, 有 $F(x)=P(X \\leqslant x)=P(0 \\leqslant X \\leqslant x)=k x$, 其中 $k$ 为比例系数. 因为 $1=F(a)=k a$, 所以得 $k=1 / a$. 于是 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ \\frac{x}{a}, & 0 \\leqslant x<a \\\\ 1, & x \\geqslant a\\end{cases}\n$$  \n下求 $X$ 的密度函数 $p(x)$.  \n当 $x<0$ 或 $x>a$ 时, $p(x)=F^{\\prime}(x)=0$;  \n当 $0<x<a$ 时, $p(x)=F^{\\prime}(x)=1 / a$ ；  \n而在 $x=0$ 和 $x=a$ 处, $p(x)$ 可取任意值,一般就近取值为宜, 这不会影响概率的计算, 因为它们是几乎处处相等的密度函数. 于是 $x$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{a}, & 0<x<a ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n这个分布就是区间 $(0, a)$ 上的均匀分布, 记为 $U(0, a)$, 其密度函数 $p(x)$ 和分布函数 $F(x)$ 的图形见下图 2.1.10.  \n!  \n(a) $p(x)$ 的图形  \n!  \n(b) $F(x)$ 的图形  \n图 2.1.10: $(0, a)$ 上的均匀分布",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n下求 $X$ 的密度函数 $p(x)$.  \n当 $x<0$ 或 $x>a$ 时, $p(x)=F^{\\prime}(x)=0$;  \n当 $0<x<a$ 时, $p(x)=F^{\\prime}(x)=1 / a$ ；  \n而在 $x=0$ 和 $x=a$ 处, $p(x)$ 可取任意值,一般就近取值为宜, 这不会影响概率的计算, 因为它们是几乎处处相等的密度函数. 于是 $x$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{a}, & 0<x<a ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n这个分布就是区间 $(0, a)$ 上的均匀分布, 记为 $U(0, a)$, 其密度函数 $p(x)$ 和分布函数 $F(x)$ 的图形见下图 2.1.10.  \n!  \n(a) $p(x)$ 的图形  \n!  \n(b) $F(x)$ 的图形  \n图 2.1.10: $(0, a)$ 上的均匀分布  \n其实此例就是第一章中所说的几何概率, 这也建立了几何概率与均匀分布的联系.  \n例 2.1.12: 设连续随机变量 $\\mathrm{X}$ 的密度函数为  \n$$\np(x)= \\begin{cases}4 x^{3}, & 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n(1) 已知 $P(X<a)=P(X>a)$, 试求常数 $a$ (此 $a$ 称为该分布的中位数).  \n(2) 已知 $P(X>b)=0.05$, 试求常数 $b$.  \n解: (1) 因为 $X$ 为连续随机变量, 所以有 $P(X=a)=0$, 从而  \n$$\nP(X<a)+P(X>a)=1 .\n$$  \n由 $P(X<a)=P(X>a)$, 可以得 $P(X<a)=0.5$. 而  \n$$\nP(X<a)=\\int_{0}^{a} 4 x^{3} \\mathrm{~d} x=a^{4},\n$$  \n所以从 $a^{4}=0.5$ 解得 $a=\\sqrt[4]{0.5}=0.8409$. 这里的 $a=0.8409$ 把该分布的密度函数下的面积分为两部分, $a$ 点左侧与右侧面积各为 0.5 , 故称 $a$ 点为该分布的中位数（详见 2.7.4）.  \n(2) 因为  \n$$",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np(x)= \\begin{cases}4 x^{3}, & 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n(1) 已知 $P(X<a)=P(X>a)$, 试求常数 $a$ (此 $a$ 称为该分布的中位数).  \n(2) 已知 $P(X>b)=0.05$, 试求常数 $b$.  \n解: (1) 因为 $X$ 为连续随机变量, 所以有 $P(X=a)=0$, 从而  \n$$\nP(X<a)+P(X>a)=1 .\n$$  \n由 $P(X<a)=P(X>a)$, 可以得 $P(X<a)=0.5$. 而  \n$$\nP(X<a)=\\int_{0}^{a} 4 x^{3} \\mathrm{~d} x=a^{4},\n$$  \n所以从 $a^{4}=0.5$ 解得 $a=\\sqrt[4]{0.5}=0.8409$. 这里的 $a=0.8409$ 把该分布的密度函数下的面积分为两部分, $a$ 点左侧与右侧面积各为 0.5 , 故称 $a$ 点为该分布的中位数（详见 2.7.4）.  \n(2) 因为  \n$$\nP(X>b)=\\int_{b}^{1} 4 x^{3} \\mathrm{~d} x=1-b^{4}\n$$  \n所以从 $1-b^{4}=0.05$ 解得 $b=\\sqrt[4]{0.95}=0.9873$.",
        "metadata": {
            "Header 2": "密度函数的基本性质"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 口袋中有 5 只球, 编号为 $1,2,3,4,5$. 从中任取 3 只, 以 $\\mathrm{X}$ 表示取出的 3 只球中的最大号码.  \n(1) 试求 $X$ 的分布列;  \n(2) 写出 $X$ 的分布函数, 并作图.  \n2. 一颗骰子拌两次, 以 $X$ 表示两次中所得的最小点数.  \n(1) 试求 $X$ 的分布列;  \n(2) 写出 $\\mathrm{X}$ 的分布函数.  \n3. 口袋中有 7 个白球、3 个黑球.  \n（1）每次从中任取一个不放回, 求首次取出白球的取球次数 $X$ 的概率分布列;  \n（2）如果取出的是黑球则不放回, 而另外放人一个白球, 此时 $X$ 的概率分布列如何.  \n4. 有 3 个盒子, 第一个盒子装有 1 只白球、 4 只黑球; 第二个盒子装有 2 只白球、 3 只黑球; 第三个盒子装有 3 只白球、 2 只黑球. 现任取一个盒子, 从中任取 3 只球. 以 $X$ 表示所取到的白球数.  \n(1) 试求 $X$ 的概率分布列;  \n(2) 取到的白球数不少于 2 只的概率是多少?  \n5. 一批产品共有 100 件, 其中 10 件是不合格品. 根据验收规则, 从中任取 5 件产品进行质量检验,假如 5 件中无不合格品, 则这批产品被接收, 否则就要重新对这批产品逐个检验.  \n(1) 试求 5 件中不合格品数 $X$ 的分布列;  \n(2) 需要对这批产品进行逐个检验的概率是多少?  \n6. 设随机变量 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x \\leqslant 0 \\\\ 1 / 4, & 0 \\leqslant x<1 \\\\ 1 / 3, & 1 \\leqslant x<3 \\\\ 1 / 2, & 3 \\leqslant x<6 \\\\ 1, & x \\geqslant 6 .\\end{cases}\n$$  \n试求 $\\mathrm{X}$ 的概率分布列及 $P(X<3), P(X \\leqslant 3), P(X>1), P(X \\geqslant 1)$.  \n7. 设随机变量 $X$ 的分布函数为  \n$$",
        "metadata": {
            "Header 2": "的题 2.1"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 试求 $X$ 的概率分布列;  \n(2) 取到的白球数不少于 2 只的概率是多少?  \n5. 一批产品共有 100 件, 其中 10 件是不合格品. 根据验收规则, 从中任取 5 件产品进行质量检验,假如 5 件中无不合格品, 则这批产品被接收, 否则就要重新对这批产品逐个检验.  \n(1) 试求 5 件中不合格品数 $X$ 的分布列;  \n(2) 需要对这批产品进行逐个检验的概率是多少?  \n6. 设随机变量 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x \\leqslant 0 \\\\ 1 / 4, & 0 \\leqslant x<1 \\\\ 1 / 3, & 1 \\leqslant x<3 \\\\ 1 / 2, & 3 \\leqslant x<6 \\\\ 1, & x \\geqslant 6 .\\end{cases}\n$$  \n试求 $\\mathrm{X}$ 的概率分布列及 $P(X<3), P(X \\leqslant 3), P(X>1), P(X \\geqslant 1)$.  \n7. 设随机变量 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x<1 \\\\ \\ln x, & 1 \\leqslant x<\\mathrm{e} \\\\ 1, & x \\geqslant \\mathrm{e}\\end{cases}\n$$  \n试求 $P(X<2), P(0<X \\leqslant 3), P(2<X<2.5)$.  \n8. 若 $P\\left\\{X \\geqslant x_{1}\\right\\}=1-\\alpha, P\\left\\{X \\leqslant x_{2}\\right\\}=1-\\beta$, 其中 $x_{1}<x_{2}$, 试求 $P\\left\\{x_{1} \\leqslant X \\leqslant x_{2}\\right\\}$.\n9. 从 1, 2,3,4,5 五个数中任取三个, 按大小排列记为 $x_{1}<x_{2}<x_{3}$, 令 $X=x_{2}$, 试求  \n(1) $X$ 的分布函数;  \n(2) $P(X<2)$ 及 $P(X>4)$.  \n10. 设随机变量 $X$ 的密度函数为  \n$$",
        "metadata": {
            "Header 2": "的题 2.1"
        },
        "type": "Document"
    },
    {
        "page_content": "7. 设随机变量 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}0, & x<1 \\\\ \\ln x, & 1 \\leqslant x<\\mathrm{e} \\\\ 1, & x \\geqslant \\mathrm{e}\\end{cases}\n$$  \n试求 $P(X<2), P(0<X \\leqslant 3), P(2<X<2.5)$.  \n8. 若 $P\\left\\{X \\geqslant x_{1}\\right\\}=1-\\alpha, P\\left\\{X \\leqslant x_{2}\\right\\}=1-\\beta$, 其中 $x_{1}<x_{2}$, 试求 $P\\left\\{x_{1} \\leqslant X \\leqslant x_{2}\\right\\}$.\n9. 从 1, 2,3,4,5 五个数中任取三个, 按大小排列记为 $x_{1}<x_{2}<x_{3}$, 令 $X=x_{2}$, 试求  \n(1) $X$ 的分布函数;  \n(2) $P(X<2)$ 及 $P(X>4)$.  \n10. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}1-|x|, & -1 \\leqslant x \\leqslant 1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $X$ 的分布函数.  \n11. 如果 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}x, & 0 \\leqslant x<1 ; \\\\ 2-x, & 1 \\leqslant x<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $P(X \\leqslant 1.5)$.  \n12. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}A \\cos x, & |x| \\leqslant \\frac{\\pi}{2} \\\\ 0, & |x|>\\frac{\\pi}{2}\\end{cases}\n$$  \n试求  \n(1) 系数 $A$;  \n(2) $X$ 落在区间 $(0, \\pi / 4)$ 内的概率.  \n13. 设随机变量 $X$ 的密度函数为  \n$$",
        "metadata": {
            "Header 2": "的题 2.1"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np(x)= \\begin{cases}1-|x|, & -1 \\leqslant x \\leqslant 1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $X$ 的分布函数.  \n11. 如果 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}x, & 0 \\leqslant x<1 ; \\\\ 2-x, & 1 \\leqslant x<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $P(X \\leqslant 1.5)$.  \n12. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}A \\cos x, & |x| \\leqslant \\frac{\\pi}{2} \\\\ 0, & |x|>\\frac{\\pi}{2}\\end{cases}\n$$  \n试求  \n(1) 系数 $A$;  \n(2) $X$ 落在区间 $(0, \\pi / 4)$ 内的概率.  \n13. 设随机变量 $X$ 的密度函数为  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ A x^{2}, & 0 \\leqslant x<1 \\\\ 1, & x \\geqslant 1\\end{cases}\n$$  \n试求  \n(1) 系数 $A$;  \n(2) $X$ 落在区间 $(0.3,0.7)$ 内的概率;  \n(3) $X$ 的密度函数.  \n14. 学生完成一道作业的时间 $X$ 是一个随机变量, 单位为小时. 它的密度函数为  \n$$\np(x)= \\begin{cases}c x^{2}+x, & 0 \\leqslant x \\leqslant 0.5 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n(1) 确定常数 $c$;  \n(2) 写出 $X$ 的分布函数;  \n（3）试求在 $20 \\mathrm{~min}$ 内完成一道作业的概率;  \n（4）试求 $10 \\mathrm{~min}$ 以上完成一道作业的概率.  \n15. 设随机变量 $X$ 和 $Y$ 同分布, $X$ 的密度函数为  \n$$",
        "metadata": {
            "Header 2": "的题 2.1"
        },
        "type": "Document"
    },
    {
        "page_content": "13. 设随机变量 $X$ 的密度函数为  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ A x^{2}, & 0 \\leqslant x<1 \\\\ 1, & x \\geqslant 1\\end{cases}\n$$  \n试求  \n(1) 系数 $A$;  \n(2) $X$ 落在区间 $(0.3,0.7)$ 内的概率;  \n(3) $X$ 的密度函数.  \n14. 学生完成一道作业的时间 $X$ 是一个随机变量, 单位为小时. 它的密度函数为  \n$$\np(x)= \\begin{cases}c x^{2}+x, & 0 \\leqslant x \\leqslant 0.5 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n(1) 确定常数 $c$;  \n(2) 写出 $X$ 的分布函数;  \n（3）试求在 $20 \\mathrm{~min}$ 内完成一道作业的概率;  \n（4）试求 $10 \\mathrm{~min}$ 以上完成一道作业的概率.  \n15. 设随机变量 $X$ 和 $Y$ 同分布, $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\frac{3}{8} x^{2}, & 0<x<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n已知事件 $A=\\{X>a\\}$ 和 $B=\\{Y>a\\}$ 独立, 且 $P(A \\cup B)=3 / 4$, 求常数 $a$.  \n16. 设连续随机变量 $\\mathrm{X}$ 的密度函数 $p(x)$ 是一个偶函数, $F(x)$ 为 $X$ 的分布函数, 求证对任意实数 $a>0$, 有  \n(1) $F(-a)=1-F(a)=0.5-\\int_{0}^{a} p(x) d x_{i}$;  \n(2) $P(|X|<a)=2 F(a)-1$;  \n(3) $P(|X|>a)=2[1-F(a)]$.",
        "metadata": {
            "Header 2": "的题 2.1"
        },
        "type": "Document"
    },
    {
        "page_content": "我们已经知道, 每个随机变量都有一个分布 (分布列、密度函数或分布函数), 不同的随机变量可能拥有不同的分布, 也可能拥有相同的分布. 分布全面地描述了随机变量取值的统计规律性, 由分布可以算出有关随机变量事件的概率. 除此以外由分布还可以算得相应随机变量的均值、方差、分位数等特征数. 这些特征数各从一个侧面描述了分布的特征. 譬如, 初生婴儿的体重是一个随机变量, 其平均重量就是从一个侧面描述了体重的特征. 已知随机变量的分布, 如何求其均值, 是本节需要研究的问题.  \n本节将介绍随机变量最重要的特征数: 数学期望.",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "“期望” 在我们日常生活中常指有根据的希望, 而在概率论中, 数学期望源于历史上一个著名的分奢本问题. 例 2.2.1(分奢本问题) 17 世纪中叶, 一位奢徒向法国数学家帕斯卡 ( 1623 - 1662$)$提出一个使他苦恼长久的分奢本问题: 甲、乙两奢徒奢技相同, 各出奢注 50 法郎, 每局中无平局.他们约定, 谁先赢三局, 则得全部奢本 100 法郎. 当甲赢了二局、乙赢了一局时, 因故要中止奢博. 现问这 100 法郎如何分才算公平?  \n这个问题引起了不少人的兴趣. 首先大家都认识到: 平均分对甲不公平;全部归甲对乙不公平;合理的分法是, 按一定的比例, 甲多分些, 乙少分些. 所以问题的焦点在于: 按怎样的比例来分. 以下有两种分法:  \n(1) 甲得 100 法郎中的 $2 / 3$, 乙得 100 法郎中的 $1 / 3$. 这是基于已赌局数: 甲赢了二局、乙赢了一局.  \n(2)1654 年帕斯卡提出如下的分法: 设想再奢下去, 则甲最终所得 $X$ 为一个随机变量, 其可能取值为 0 或 100 . 再奢二局必可结束, 其结果不外乎以下四种情况之一:  \n甲甲、甲乙、乙甲、乙乙  \n其中 “甲乙” 表示第一局甲胜第二局乙胜. 因为奢技相同, 所以在这四种情况中有三种可使甲获 100 法郎, 只有一种情况 (乙乙) 下甲获 0 法郎. 所以甲获得 100 法郎的可能性为 $3 / 4$, 获得 0 法郎的可能性为 $1 / 4$, 即 $X$ 的分布列为  \n$$\n\\begin{array}{l|cc}\nx & 0 & 100 \\\\\n\\hline P & 0.25 & 0.75\n\\end{array}\n$$  \n经上述分析, 帕斯卡认为, 甲的 “期望”所得应为: $0 \\times 0.25+100 \\times 0.75=75$ (法郎). 即甲得 75 法郎, 乙得 25 法郎. 这种分法不仅考虑了已者局数, 而且还包括了对再奢下去的一种 “期望”, 它比 (1) 的分法更为合理.  \n这就是数学期望这个名称的由来, 其实这个名称称为 “均值”更形象易懂. 对上例而言, 也就是再奢下去的话, 甲 “平均”可以赢 75 法郎.  \n现在我们来逐步分析如何由分布来求“均值”.",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.1 数学期望的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "甲甲、甲乙、乙甲、乙乙  \n其中 “甲乙” 表示第一局甲胜第二局乙胜. 因为奢技相同, 所以在这四种情况中有三种可使甲获 100 法郎, 只有一种情况 (乙乙) 下甲获 0 法郎. 所以甲获得 100 法郎的可能性为 $3 / 4$, 获得 0 法郎的可能性为 $1 / 4$, 即 $X$ 的分布列为  \n$$\n\\begin{array}{l|cc}\nx & 0 & 100 \\\\\n\\hline P & 0.25 & 0.75\n\\end{array}\n$$  \n经上述分析, 帕斯卡认为, 甲的 “期望”所得应为: $0 \\times 0.25+100 \\times 0.75=75$ (法郎). 即甲得 75 法郎, 乙得 25 法郎. 这种分法不仅考虑了已者局数, 而且还包括了对再奢下去的一种 “期望”, 它比 (1) 的分法更为合理.  \n这就是数学期望这个名称的由来, 其实这个名称称为 “均值”更形象易懂. 对上例而言, 也就是再奢下去的话, 甲 “平均”可以赢 75 法郎.  \n现在我们来逐步分析如何由分布来求“均值”.  \n(1) 算术平均: 如果有 $n$ 个数 $x_{1}, x_{2}, \\cdots, x_{n}$., 那么求这 $n$ 个数的算术平均是很简单的事, 只需将此 $n$ 个数相加后除 $\\mathrm{n}$ 即可.  \n(2) 加权平均: 如果这 $n$ 个数中有相同的, 不妨设其中有 $n$; 个取值为 $x_{i}, i=1,2, \\cdots, k$. 将其列表为  \n| 取值 | $x_{1}$ | $x_{1}$ | $\\cdots$ | $x_{k}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 频数 | $n_{1}$ | $n_{2}$ | $\\cdots$ | $n_{k}$ |\n| 频率 | $n_{1} / n$ | $n_{2} / n$ | $\\cdots$ | $n_{k} / n$ |  \n则其“均值”应为  \n$$\n\\frac{1}{n} \\sum_{i=1}^{k} n_{\\dot{r}} x_{i}=\\sum_{i=1}^{k} \\frac{n_{i}}{n} x_{i}\n$$",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.1 数学期望的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 算术平均: 如果有 $n$ 个数 $x_{1}, x_{2}, \\cdots, x_{n}$., 那么求这 $n$ 个数的算术平均是很简单的事, 只需将此 $n$ 个数相加后除 $\\mathrm{n}$ 即可.  \n(2) 加权平均: 如果这 $n$ 个数中有相同的, 不妨设其中有 $n$; 个取值为 $x_{i}, i=1,2, \\cdots, k$. 将其列表为  \n| 取值 | $x_{1}$ | $x_{1}$ | $\\cdots$ | $x_{k}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 频数 | $n_{1}$ | $n_{2}$ | $\\cdots$ | $n_{k}$ |\n| 频率 | $n_{1} / n$ | $n_{2} / n$ | $\\cdots$ | $n_{k} / n$ |  \n则其“均值”应为  \n$$\n\\frac{1}{n} \\sum_{i=1}^{k} n_{\\dot{r}} x_{i}=\\sum_{i=1}^{k} \\frac{n_{i}}{n} x_{i}\n$$  \n其实这个 “加权” 平均的权数 “就是出现数值 $x$; 的频率, 而频率在 $n$ 很大时, 就稳定在其概率附近.  \n(3) 对于一个离散随机变量 $X$, 如果其可能取值为 $x_{1}, x_{2}, \\cdots, x_{n}$. 若将这 $n$ 个数相加后除 $n$ 作为 “均值”, 则肯定是不妥的. 其原因在于 $X$ 取各个值的概率是不同的, 概率大的出现的机会就大,则在计算中其权也应该大. 而上例分配奢本问题启示我们: 用取值的概率作为一种 “权数” 作加权平均是十分合理的.  \n经以上分析, 我们就可以给出数学期望的定义.",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.1 数学期望的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "定义2.2.1. 设离散随机变量 $X$ 的分布列为  \n$$\np\\left(x_{i}\\right)=P\\left(X=x_{i}\\right), i=1,2, \\cdots, n, \\cdots\n$$  \n如果  \n$$\n\\sum_{i=1}^{+\\infty}\\left|x_{i}\\right| p\\left(x_{i}\\right)<+\\infty\n$$  \n则称  \n$$\n\\begin{equation*}\nE(X)=\\sum_{i=1}^{+\\infty} x_{i} p\\left(x_{i}\\right) \\tag{2.2.1}\n\\end{equation*}\n$$  \n为随机变量 $X$ 的数学期望, 或称为该分布的数学期望, 简称期望或均值. 若级数 $\\sum_{k=1}^{+\\infty}\\left|x_{k}\\right| p\\left(x_{k}\\right)$ 不收玫, 则称 $X$ 的数学期望不存在.  \n以上定义中, 要求级数绝对收玫的目的在于使数学期望唯一. 因为随机变量的取值可正可负,取值次序可先可后, 由无穷级数的理论知道, 如果此无穷级数绝对收玫, 则可保证其和不受次序变动的影响. 由于有限项的和不受次序变动的影响, 故其数学期望总是存在的.  \n连续随机变量数学期望的定义和含义完全类似于离散随机变景场合, 只要将分布列 $p\\left(x_{i}\\right)$ 改为密度函数、将求和改为求积就可.  \n定义 2.2.2. 设连续随机变量 $X$ 的密度函数为 $p(x)$. 如果  \n$$\n\\int_{-\\infty}^{+\\infty}|x| p(x) \\mathrm{d} x<+\\infty\n$$  \n则称  \n$$\n\\begin{equation*}\nE(X)=\\int_{-\\infty}^{+\\infty} x p(x) \\mathrm{d} x \\tag{2.2.2}\n\\end{equation*}\n$$  \n为 $X$ 的数学期望, 或称为该分布 $p(x)$ 的数学期望, 简称期望或均值. 若 $\\int_{-\\infty}^{+\\infty}|x| p(x) \\mathrm{d} x$ 不收玫, 则称 $X$ 的数学期望不存在.",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.2 数学期望的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "连续随机变量数学期望的定义和含义完全类似于离散随机变景场合, 只要将分布列 $p\\left(x_{i}\\right)$ 改为密度函数、将求和改为求积就可.  \n定义 2.2.2. 设连续随机变量 $X$ 的密度函数为 $p(x)$. 如果  \n$$\n\\int_{-\\infty}^{+\\infty}|x| p(x) \\mathrm{d} x<+\\infty\n$$  \n则称  \n$$\n\\begin{equation*}\nE(X)=\\int_{-\\infty}^{+\\infty} x p(x) \\mathrm{d} x \\tag{2.2.2}\n\\end{equation*}\n$$  \n为 $X$ 的数学期望, 或称为该分布 $p(x)$ 的数学期望, 简称期望或均值. 若 $\\int_{-\\infty}^{+\\infty}|x| p(x) \\mathrm{d} x$ 不收玫, 则称 $X$ 的数学期望不存在.  \n例 2.2.1: 在一个人数为 $N$ 的人群中普查某种疾病, 为此要抽验 $N$ 个人的血. 如果将每个人的血分别检验, 则共需检验 $N$ 次. 为了能减少工作量, 一位统计学家提出一种方法: 按 $k$ 个人一组进行分组, 把同组 $k$ 个人的血样混合后检验, 如果这混合血样呈阴性反应, 就说明此 $k$ 个人的血都呈阴性反应, 此 $k$ 个人都无此疾病, 因而这 $k$ 个人只要检验 1 次就够了, 相当于每个人检验 $1 / k$ 次, 检验的工作量明显减少了. 如果这混合血样呈阳性反应, 就说明此 $k$ 个人中至少有一人的血呈阳性反应, 则再对此 $k$ 个人的血样分别进行检验, 因而这 $k$ 个人的血要检验 $1+k$ 次, 相当于每个人检验 $1+1 / k$ 次, 这时增加了检验次数. 假设该疾病的发病率为 $p$, 且得此疾病相互独立. 试问此种方法能否减少平均检验次数?  \n解:  \n令 $X$ 为该人群中每个人需要的验血次数, 则 $X$ 的分布列为  \n$$\n\\begin{array}{c|cc}\nx & 1 / k & 1+1 / k \\\\\n\\hline P & (1-p)^{k} & 1-(1-p)^{k}\n\\end{array}\n$$  \n所以每人平均验血次数为  \n$$",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.2 数学期望的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "解:  \n令 $X$ 为该人群中每个人需要的验血次数, 则 $X$ 的分布列为  \n$$\n\\begin{array}{c|cc}\nx & 1 / k & 1+1 / k \\\\\n\\hline P & (1-p)^{k} & 1-(1-p)^{k}\n\\end{array}\n$$  \n所以每人平均验血次数为  \n$$\nE(X)=\\frac{1}{k}(1-p)^{k}+\\left(1+\\frac{1}{k}\\right)\\left[1-(1-p)^{k}\\right]=1-(1-p)^{k}+\\frac{1}{k}\n$$  \n去由此可知, 只要选择 $k$ 使  \n$$\n1-(1-p)^{k}+\\frac{1}{k}<1 \\text {, 或 }(1-p)^{k}>\\frac{1}{k}\n$$  \n, 就可减少验血次数, 而且还可适当选择 $k$ 使其达到最小. 譬如, 当 $p=0.1$ 时对不同的 $k, E(X)$的值如表 2.2.1所示. 从表中可以看出: 当 $k \\geqslant 34$ 时, 平均验血次数超过 1 , 即比分别检验增加工作量; 而当 $k \\leqslant 33$ 时, 平均验血次数在不同程度上得到了减少, 特别在 $k_{0}=4$ 时, 平均验血次数最少, 验血工作量可减少 $40 \\%$.  \n表 2.2.1: $p=0.1$ 时的 $E(X)$ 值  \n| $\\mathrm{k}$ | 2 | 3 | 4 | 5 | 8 | 10 | 30 | 33 | 34 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $\\mathrm{E}(\\mathrm{x})$ | 0.69 | 0.604 | 0.594 | 0.61 | 0.695 | 0.751 | 0.991 | 0.994 | 1.0016 |",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.2 数学期望的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n, 就可减少验血次数, 而且还可适当选择 $k$ 使其达到最小. 譬如, 当 $p=0.1$ 时对不同的 $k, E(X)$的值如表 2.2.1所示. 从表中可以看出: 当 $k \\geqslant 34$ 时, 平均验血次数超过 1 , 即比分别检验增加工作量; 而当 $k \\leqslant 33$ 时, 平均验血次数在不同程度上得到了减少, 特别在 $k_{0}=4$ 时, 平均验血次数最少, 验血工作量可减少 $40 \\%$.  \n表 2.2.1: $p=0.1$ 时的 $E(X)$ 值  \n| $\\mathrm{k}$ | 2 | 3 | 4 | 5 | 8 | 10 | 30 | 33 | 34 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $\\mathrm{E}(\\mathrm{x})$ | 0.69 | 0.604 | 0.594 | 0.61 | 0.695 | 0.751 | 0.991 | 0.994 | 1.0016 |  \n我们也可以对不同的发病率 $p$ 计算出最佳的分组人数 $k_{0}$, 见下表 2.2.2. 从表中也可以看出:发病率 $p$ 越小, 则分组检验的效益越大. 譬如在 $p=0.01$ 时, 若取 11 人为一组进行验血, 则验血工作量可减少 $80 \\%$ 左右. 这正是美国二战期间大量征兵时, 对新兵验血所采用的减少工作量的措施.  \n表 2.2.2: 不同发病率 $p$ 时的最佳分组人数 $k_{0}$ 及其 $E(x)$  \n| $p$ | 0.14 | 0.1 | 0.08 | 0.06 | 0.04 | 0.02 | 0.01 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $k_{0}$ | 3 | 4 | 4 | 5 | 6 | 8 | 11 |\n| $E(x)$ | 0.697 | 0.594 | 0.534 | 0.466 | 0.384 | 0.274 | 0.205 |",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.2 数学期望的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "我们也可以对不同的发病率 $p$ 计算出最佳的分组人数 $k_{0}$, 见下表 2.2.2. 从表中也可以看出:发病率 $p$ 越小, 则分组检验的效益越大. 譬如在 $p=0.01$ 时, 若取 11 人为一组进行验血, 则验血工作量可减少 $80 \\%$ 左右. 这正是美国二战期间大量征兵时, 对新兵验血所采用的减少工作量的措施.  \n表 2.2.2: 不同发病率 $p$ 时的最佳分组人数 $k_{0}$ 及其 $E(x)$  \n| $p$ | 0.14 | 0.1 | 0.08 | 0.06 | 0.04 | 0.02 | 0.01 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $k_{0}$ | 3 | 4 | 4 | 5 | 6 | 8 | 11 |\n| $E(x)$ | 0.697 | 0.594 | 0.534 | 0.466 | 0.384 | 0.274 | 0.205 |  \n例 2.2.2: 每张福利彩票售价 5 元, 各有一个对奖号. 每售出 100 万张设一个开奖组, 用摇奖器当众摇出一个 6 位数的中奖号码 (可以认为从 000000 到 999999 的每个数都等可能出现), 对奖规则如下:  \n1. 对奖号与中奖号码的最后一位相同者获六等奖, 奖金 10 元.\n2. 对奖号与中奖号码的最后二位相同者获五等奖, 奖金 50 元.\n3. 对奖号与中奖号码的最后三位相同者获四等奖, 奖金 500 元.\n4. 对奖号与中奖号码的最后四位相同者获三等奖,奖金 5000 元.\n5. 对奖号与中奖号码的最后五位相同者获二等奖, 奖金 50000 元.\n6. 对奖号与中奖号码的全部相同者获一等奖, 奖金 500000 元. 另外规定, 只领取其中最高额的奖金. 试求每张彩票的平均所得奖金额.  \n解: 以 $X$ 记一张彩票的奖金额,则 $X$ 的分布列如下:  \n| $X$ | 500000 | 50000 | 5000 | 500 | 50 | 10 | 0 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.2 数学期望的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 对奖号与中奖号码的最后一位相同者获六等奖, 奖金 10 元.\n2. 对奖号与中奖号码的最后二位相同者获五等奖, 奖金 50 元.\n3. 对奖号与中奖号码的最后三位相同者获四等奖, 奖金 500 元.\n4. 对奖号与中奖号码的最后四位相同者获三等奖,奖金 5000 元.\n5. 对奖号与中奖号码的最后五位相同者获二等奖, 奖金 50000 元.\n6. 对奖号与中奖号码的全部相同者获一等奖, 奖金 500000 元. 另外规定, 只领取其中最高额的奖金. 试求每张彩票的平均所得奖金额.  \n解: 以 $X$ 记一张彩票的奖金额,则 $X$ 的分布列如下:  \n| $X$ | 500000 | 50000 | 5000 | 500 | 50 | 10 | 0 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P$ | 0.000001 | 0.00009 | 0.00009 | 0.0009 | 0.009 | 0.09 | 0.9 |  \n所以每张彩票的平均所得为  \n$$\nE(X)=0.5+0.45+0.45+0.45+0.45+0.9+0=3.2\n$$  \n这也意味:每一开奖组把筹得的 500 万元中的 320 万元以奖金形式返回给彩民,其余 180 万元则可用于福利事业及管理费用.  \n从这个例子也可以看出, 彩票中奖与否是随机的, 但一种彩票的平均所得是可以预先算出的,计算平均所得也是设计一种彩票的基础.  \n例 2.2.3: 设 $X$ 服从区间 $(a, b)$ 上的均匀分布, 求 $E(x)$.  \n解: 由例 2.1.11 知 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{b-a}, & a<x<b ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n所以  \n$$\nE(X)=\\int_{a}^{b} x \\cdot \\frac{1}{b-a} d x=\\left.\\frac{1}{b-a} \\cdot \\frac{x^{2}}{2}\\right|_{a} ^{b}=\\frac{a+b}{2}\n$$",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.2 数学期望的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "所以每张彩票的平均所得为  \n$$\nE(X)=0.5+0.45+0.45+0.45+0.45+0.9+0=3.2\n$$  \n这也意味:每一开奖组把筹得的 500 万元中的 320 万元以奖金形式返回给彩民,其余 180 万元则可用于福利事业及管理费用.  \n从这个例子也可以看出, 彩票中奖与否是随机的, 但一种彩票的平均所得是可以预先算出的,计算平均所得也是设计一种彩票的基础.  \n例 2.2.3: 设 $X$ 服从区间 $(a, b)$ 上的均匀分布, 求 $E(x)$.  \n解: 由例 2.1.11 知 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{b-a}, & a<x<b ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n所以  \n$$\nE(X)=\\int_{a}^{b} x \\cdot \\frac{1}{b-a} d x=\\left.\\frac{1}{b-a} \\cdot \\frac{x^{2}}{2}\\right|_{a} ^{b}=\\frac{a+b}{2}\n$$  \n这个结果是可以理解的, 因为 $\\mathrm{X}$ 在区间 $(a, b)$ 上的取值是均匀的, 所以它的平均取值当然应该是 $(a, b)$ 的“中点”, 即 $(a+b) / 2$.  \n例 2.2.4: 柯西分布的数学期望不存在. 因为柯西分布的密度函数为  \n$$\np(x)=\\frac{1}{\\pi} \\frac{1}{1+x^{2}},-\\infty<x<+\\infty\n$$  \n所以由  \n$$\n\\int_{-\\infty}^{+\\infty}|x| \\cdot \\frac{1}{\\pi} \\frac{1}{1+x^{2}} \\mathrm{~d} x=+\\infty .\n$$  \n知 $E(X)$ 不存在.",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.2 数学期望的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "按照随机变量 $\\mathrm{X}$ 的数学期望 $E(X)$ 的定义, $E(X)$ 由其分布唯一确定. 如今若要求随机变量 $\\mathrm{x}$的一个函数 $g(X)$ 的数学期望, 当然要先求出 $Y=g(X)$ 的分布, 再用此分布来求 $E(Y)$. 这一过程可用下面例子说明.  \n例 2.2.5: 已知随机变量 $X$ 的分布列如下  \n$$\n\\begin{array}{c|ccccc}\nX & -2 & -1 & 0 & 1 & 2 \\\\\n\\hline P & 0.2 & 0.1 & 0.1 & 0.3 & 0.3\n\\end{array}\n$$  \n要求 $Y=X^{2}$ 的数学期望, 为此要分两步进行:  \n第一步, 先求 $Y=X^{2}$ 的分布, 这可从 $X$ 的分布导出, 即  \n$$\n\\begin{array}{c|ccccc}\nX^{2} & (-2)^{2} & (-1)^{2} & 0^{2} & 1^{2} & 2^{2} \\\\\n\\hline P & 0.2 & 0.1 & 0.1 & 0.3 & 0.3\n\\end{array}\n$$  \n然后对相等的值进行合并, 并把对应的概率相加, 可得  \n$$\n\\begin{array}{c|ccc}\nX^{2} & 0 & 1 & 4 \\\\\n\\hline P & 0.1 & 0.4 & 0.5\n\\end{array}\n$$  \n第二步,利用 $X^{2}$ 的分布求 $E\\left(X^{2}\\right)$, 即得  \n$$\nE\\left(X^{2}\\right)=0 \\times 0.1+1 \\times 0.4+4 \\times 0.5=2.4 \\text {. }\n$$  \n假如我们用等值合并前的分布求 $E\\left(X^{2}\\right)$, 可得相同的结果  \n$$\nE\\left(X^{2}\\right)=(-2)^{2} \\times 0.2+(-1)^{2} \\times 0.1+0^{2} \\times 0.1+1^{2} \\times 0.3+2^{2} \\times 0.3=2.4\n$$",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.3 数学期望的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "\\hline P & 0.2 & 0.1 & 0.1 & 0.3 & 0.3\n\\end{array}\n$$  \n然后对相等的值进行合并, 并把对应的概率相加, 可得  \n$$\n\\begin{array}{c|ccc}\nX^{2} & 0 & 1 & 4 \\\\\n\\hline P & 0.1 & 0.4 & 0.5\n\\end{array}\n$$  \n第二步,利用 $X^{2}$ 的分布求 $E\\left(X^{2}\\right)$, 即得  \n$$\nE\\left(X^{2}\\right)=0 \\times 0.1+1 \\times 0.4+4 \\times 0.5=2.4 \\text {. }\n$$  \n假如我们用等值合并前的分布求 $E\\left(X^{2}\\right)$, 可得相同的结果  \n$$\nE\\left(X^{2}\\right)=(-2)^{2} \\times 0.2+(-1)^{2} \\times 0.1+0^{2} \\times 0.1+1^{2} \\times 0.3+2^{2} \\times 0.3=2.4\n$$  \n这两种算法本质上是一回事, 但后者的计算实质上是在 $X$ 的分布 $(0.2,0.1,0.1,0.3,0.3)$ 基础上、而将取值改为 $\\left((-2)^{2},(-1)^{2}, 0^{2}, 1^{2}, 2^{2}\\right)$ 计算出来的. 由此启发我们: 若进一步要求 $E\\left(X^{3}\\right)$ 和 $E\\left(X^{4}\\right)$, 我们不需要先求 $X^{3}$ 的分布和 $E\\left(X^{4}\\right)$ 的分布, 而直接用 $X$ 的分布来求, 具体如下.  \n$$\n\\begin{aligned}\n& E\\left(X^{3}\\right)=(-2)^{3} \\times 0.2+(-1)^{3} \\times 0.1+0^{3} \\times 0.1+1^{3} \\times 0.3+2^{3} \\times 0.3=0, \\\\\n& E\\left(X^{4}\\right)=(-2)^{4} \\times 0.2+(-1)^{4} \\times 0.1+0^{4} \\times 0.1+1^{4} \\times 0.3+2^{4} \\times 0.3=8.4",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.3 数学期望的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n& E\\left(X^{3}\\right)=(-2)^{3} \\times 0.2+(-1)^{3} \\times 0.1+0^{3} \\times 0.1+1^{3} \\times 0.3+2^{3} \\times 0.3=0, \\\\\n& E\\left(X^{4}\\right)=(-2)^{4} \\times 0.2+(-1)^{4} \\times 0.1+0^{4} \\times 0.1+1^{4} \\times 0.3+2^{4} \\times 0.3=8.4\n\\end{aligned}\n$$  \n一般场合, 有如下定理:  \n定理 2.2.1. 若随机变量 $X$ 的分布用分布列 $p\\left(x_{i}\\right)$ 或用密度函数 $p(x)$ 表示, 则 $X$ 的某一函数 $g(X)$的数学期望为  \n$$\nE[g(X)]= \\begin{cases}\\sum_{i} g\\left(x_{i}\\right) p\\left(x_{i}\\right), & \\text { 在离散场合; }  \\tag{2.2.3}\\\\ \\int_{-\\infty}^{+\\infty} g(x) p(x) \\mathrm{d} x, & \\text { 在连续场合. }\\end{cases}\n$$  \n这里所涉及的数学期望都假设存在.  \n这个定理的证明涉及更多的工具, 在此省略了. 现基于这个定理来证明数学期望的几个常用性质, 以下均假定所涉及的数学期望是存在的.",
        "metadata": {
            "Header 2": "2.2 随机变量的数学期望",
            "Header 3": "2.2.3 数学期望的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "若 $c$ 是常数, 则 $E(c)=c$.  \n证明: 如果将常数 $c$ 看作仅取一个值的随机变量 $X$, 则有 $P(X=c)=1$, 从而其数学期望 $E(c)=E(X)=$ $c \\times 1=c$.  \n性质 2.2.2: 对任意常数 $a$, 有  \n$$\n\\begin{equation*}\nE(a X)=a E(X) . \\tag{2.2.4}\n\\end{equation*}\n$$  \n证明: 在 2.2.3 式中令 $g(x)=a x$, 然后把 $a$ 从求和号或积分号中提出来即得.  \n性质 2.2.3: 对任意的两个函数 $g_{1}(x)$ 和 $g_{2}(x)$, 有  \n$$\n\\begin{equation*}\nE\\left[g_{1}(X) \\pm g_{2}(X)\\right]=E\\left[g_{1}(X)\\right] \\pm E\\left[g_{2}(X) .\\right] \\tag{2.2.5}\n\\end{equation*}\n$$  \n证明: 在 2.2.3式中令 $g(x)=g_{1}(x) \\pm g_{2}(x)$, 然后把和式分解成两个和式, 或把积分分解成两个积分即得.  \n例 2.2.6: 某公司经销某种原料, 根据历史资料表明: 这种原料的市场需求量 $X$ (单位: 吨) 服从 $(300,500)$ 上的均匀分布. 每售出 1 吨该原料, 公司可获利 1.5 (千元); 若积压 1 吨, 则公司损失 0.5 (千元 ) . 问公司应该组织多少货源, 可使平均收益最大?  \n解: 设公司组织该货源 $a$ 吨. 则显然应该有 $300 \\leqslant a \\leqslant 500$. 又记 $\\mathrm{Y}$ 为在 $a$ 吨货源的条件下的收益额 (单位:千元), 则收益额 $Y$ 为需求量 $X$ 的函数, 即 $Y=g(X)$. 由题设条件知: 当 $x \\geqslant a$ 时, 则此 $a$ 吨货源全部售出, 共获利 $1.5 a$. 当 $X<a$ 时, 则售出 $X$ 吨 (获利 $1.5 X$ ), 且还有 $a-X$ 吨积压 (获利 $-0.5(a-x))$, 所以共获利 $1.5 X-0.5(a-X)$, 由此知  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "性质 2.2.1:"
        },
        "type": "Document"
    },
    {
        "page_content": "例 2.2.6: 某公司经销某种原料, 根据历史资料表明: 这种原料的市场需求量 $X$ (单位: 吨) 服从 $(300,500)$ 上的均匀分布. 每售出 1 吨该原料, 公司可获利 1.5 (千元); 若积压 1 吨, 则公司损失 0.5 (千元 ) . 问公司应该组织多少货源, 可使平均收益最大?  \n解: 设公司组织该货源 $a$ 吨. 则显然应该有 $300 \\leqslant a \\leqslant 500$. 又记 $\\mathrm{Y}$ 为在 $a$ 吨货源的条件下的收益额 (单位:千元), 则收益额 $Y$ 为需求量 $X$ 的函数, 即 $Y=g(X)$. 由题设条件知: 当 $x \\geqslant a$ 时, 则此 $a$ 吨货源全部售出, 共获利 $1.5 a$. 当 $X<a$ 时, 则售出 $X$ 吨 (获利 $1.5 X$ ), 且还有 $a-X$ 吨积压 (获利 $-0.5(a-x))$, 所以共获利 $1.5 X-0.5(a-X)$, 由此知  \n$$\n\\begin{aligned}\ng(X) & = \\begin{cases}1.5 a, & \\text { 若 } X \\geqslant a \\\\\n1.5 X-0.5(a-X), & \\text { 若 } x<a\\end{cases} \\\\\n& = \\begin{cases}1.5 a, & \\text { 若 } X \\geqslant a \\\\\n2 X-0.5 a, & \\text { 若 } X<a\\end{cases}\n\\end{aligned}\n$$  \n由定理?? 得  \n$$\n\\begin{aligned}\nE(Y) & =\\int_{-\\infty}^{+\\infty} g(x) p_{X}(x) \\mathrm{d} x=\\int_{300}^{500} g(x) \\frac{1}{200} \\mathrm{~d} x \\\\\n& =\\frac{1}{200}\\left\\{\\int_{a}^{500} 1.5 a \\mathrm{~d} x+\\int_{300}^{a}(2 x-0.5 a) \\mathrm{d} x\\right\\} \\\\\n& =\\frac{1}{200}\\left(-a^{2}+900 a-300^{2}\\right)",
        "metadata": {
            "Header 2": "性质 2.2.1:"
        },
        "type": "Document"
    },
    {
        "page_content": "1.5 X-0.5(a-X), & \\text { 若 } x<a\\end{cases} \\\\\n& = \\begin{cases}1.5 a, & \\text { 若 } X \\geqslant a \\\\\n2 X-0.5 a, & \\text { 若 } X<a\\end{cases}\n\\end{aligned}\n$$  \n由定理?? 得  \n$$\n\\begin{aligned}\nE(Y) & =\\int_{-\\infty}^{+\\infty} g(x) p_{X}(x) \\mathrm{d} x=\\int_{300}^{500} g(x) \\frac{1}{200} \\mathrm{~d} x \\\\\n& =\\frac{1}{200}\\left\\{\\int_{a}^{500} 1.5 a \\mathrm{~d} x+\\int_{300}^{a}(2 x-0.5 a) \\mathrm{d} x\\right\\} \\\\\n& =\\frac{1}{200}\\left(-a^{2}+900 a-300^{2}\\right)\n\\end{aligned}\n$$  \n上述计算表明 $E(Y)$ 是 $a$ 的二次函数, 用通常求极值的方法可以求得, 当 $a=450$ 吨时, 能使 $E(Y)$ 达到最大, 即公司应该组织货源 450 吨.",
        "metadata": {
            "Header 2": "性质 2.2.1:"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设离散型随机变量 $\\mathrm{X}$ 的分布列为  \n$$\n\\begin{array}{c|ccc}\nX & -2 & 0 & 2 \\\\\n\\hline P & 0.4 & 0.3 & 0.3\n\\end{array}\n$$  \n试求 $E(X)$ 和 $E(3 X+5)$.  \n2. 某服装店根据历年销售资料得知:一位顾客在商店中购买服装的件数 $X$ 的分布列为  \n| $X$ | 0 | 1 | 2 | 3 | 4 | 5 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P$ | 0.10 | 0.33 | 0.31 | 0.13 | 0.09 | 0.04 |  \n试求顾客在商店平均购买服装件数.  \n3. 某地区一个月内发生重大交通事故数 X 服从如下分布  \n$$\n\\begin{array}{c|ccccccc}\nX & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\\\\n\\hline P & 0.301 & 0.362 & 0.216 & 0.087 & 0.026 & 0.006 & 0.002\n\\end{array}\n$$  \n试求该地区发生重大交通事故的月平均数.  \n4. 一海运货船的甲板上放着 20 个装有化学原料的圆桶, 现已知其中有 5 桶被海水污染了. 若从中随机抽取 8 桶, 记 $X$ 为 8 桶中被污染的桶数, 试求 $X$ 的分布列, 并求 $E(X)$.\n5. 用天平称某种物品的重量 (砝码仅允许放在一个盘中), 现有三组砝码: 甲 ) $1,2,2,5,10$ ( $\\mathrm{g}$ ); (乙)  \n$1,2,3,4,10(\\mathrm{~g})$; (丙) $1,1,2,5,10(\\mathrm{~g})$, 称重时只能使用一组砝码, 问: 当物品的重量为 $1 \\mathrm{~g} 、 2 \\mathrm{~g} 、 \\cdots$ 、  \n$10 \\mathrm{~g}$ 的概率是相同的, 用哪一组砝码称重所用的平均砝码数最少?",
        "metadata": {
            "Header 2": "丑习题 2.2"
        },
        "type": "Document"
    },
    {
        "page_content": "X & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\\\\n\\hline P & 0.301 & 0.362 & 0.216 & 0.087 & 0.026 & 0.006 & 0.002\n\\end{array}\n$$  \n试求该地区发生重大交通事故的月平均数.  \n4. 一海运货船的甲板上放着 20 个装有化学原料的圆桶, 现已知其中有 5 桶被海水污染了. 若从中随机抽取 8 桶, 记 $X$ 为 8 桶中被污染的桶数, 试求 $X$ 的分布列, 并求 $E(X)$.\n5. 用天平称某种物品的重量 (砝码仅允许放在一个盘中), 现有三组砝码: 甲 ) $1,2,2,5,10$ ( $\\mathrm{g}$ ); (乙)  \n$1,2,3,4,10(\\mathrm{~g})$; (丙) $1,1,2,5,10(\\mathrm{~g})$, 称重时只能使用一组砝码, 问: 当物品的重量为 $1 \\mathrm{~g} 、 2 \\mathrm{~g} 、 \\cdots$ 、  \n$10 \\mathrm{~g}$ 的概率是相同的, 用哪一组砝码称重所用的平均砝码数最少?  \n6. 假设有十只同种电器元件, 其中有两只不合格品、装配仪器时, 从这批元件中任取一只, 如是不合格品, 则扔掉重新任取一只; 如仍是不合格品, 则扔掉再取一只, 试求在取到合格品之前, 已取出的不合格品只数的数学期望.\n7. 对一批产品进行检查, 如查到第 $a$ 件全为合格品, 就认为这批产品合格; 若在前 $a$ 件中发现不合格品即停止检查, 且认为这批产品不合格. 设产品的数量很大, 可认为每次查到不合格品的概率都是 $p$. 问每批产品平均要查多少件?\n8. 某厂推土机发生故障后的维修时间 $T$ 是一个随机变量, 其密度函数为  \n$$\np(t)= \\begin{cases}0.02 \\mathrm{e}^{-0.02 t}, & t>0 \\\\ 0, & t \\leqslant 0\\end{cases}\n$$  \n试求平均维修时间。  \n9. 某新产品在未来市场上的占有率 $X$ 是仪在区间 $(0,1)$ 上取值的随机变量, 它的密度函数为  \n$$",
        "metadata": {
            "Header 2": "丑习题 2.2"
        },
        "type": "Document"
    },
    {
        "page_content": "$10 \\mathrm{~g}$ 的概率是相同的, 用哪一组砝码称重所用的平均砝码数最少?  \n6. 假设有十只同种电器元件, 其中有两只不合格品、装配仪器时, 从这批元件中任取一只, 如是不合格品, 则扔掉重新任取一只; 如仍是不合格品, 则扔掉再取一只, 试求在取到合格品之前, 已取出的不合格品只数的数学期望.\n7. 对一批产品进行检查, 如查到第 $a$ 件全为合格品, 就认为这批产品合格; 若在前 $a$ 件中发现不合格品即停止检查, 且认为这批产品不合格. 设产品的数量很大, 可认为每次查到不合格品的概率都是 $p$. 问每批产品平均要查多少件?\n8. 某厂推土机发生故障后的维修时间 $T$ 是一个随机变量, 其密度函数为  \n$$\np(t)= \\begin{cases}0.02 \\mathrm{e}^{-0.02 t}, & t>0 \\\\ 0, & t \\leqslant 0\\end{cases}\n$$  \n试求平均维修时间。  \n9. 某新产品在未来市场上的占有率 $X$ 是仪在区间 $(0,1)$ 上取值的随机变量, 它的密度函数为  \n$$\np(x)= \\begin{cases}4(1-x)^{3}, & 0<x<1 \\\\ 0 & \\text { 其他. }\\end{cases}\n$$  \n试求平均市场占有率.  \n10. 设随机变量 $\\mathrm{X}$ 的密度函数如下, 试求 $E(2 X+5)$.  \n$$\np(x)= \\begin{cases}\\mathrm{e}^{-x}, & x>0 \\\\ 0, & x \\leqslant 0\\end{cases}\n$$  \n11. 设随机变量 $X$ 的分布函数如下, 试求 $E(X)$.  \n$$\nF(x)= \\begin{cases}\\frac{\\mathrm{e}^{x}}{2}, & x<0 ; \\\\ \\frac{1}{2}, & 0 \\leqslant x<1 \\\\ 1-\\frac{1}{2} \\mathrm{e}^{-\\frac{1}{2}(x-1)}, & x \\geqslant 1 .\\end{cases}\n$$  \n12. 某工程队完成某项工程的时间 $X$ (单位: 月) 是一个随机变量, 它的分布列为  \n$$\n\\begin{array}{c|cccc}",
        "metadata": {
            "Header 2": "丑习题 2.2"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试求平均市场占有率.  \n10. 设随机变量 $\\mathrm{X}$ 的密度函数如下, 试求 $E(2 X+5)$.  \n$$\np(x)= \\begin{cases}\\mathrm{e}^{-x}, & x>0 \\\\ 0, & x \\leqslant 0\\end{cases}\n$$  \n11. 设随机变量 $X$ 的分布函数如下, 试求 $E(X)$.  \n$$\nF(x)= \\begin{cases}\\frac{\\mathrm{e}^{x}}{2}, & x<0 ; \\\\ \\frac{1}{2}, & 0 \\leqslant x<1 \\\\ 1-\\frac{1}{2} \\mathrm{e}^{-\\frac{1}{2}(x-1)}, & x \\geqslant 1 .\\end{cases}\n$$  \n12. 某工程队完成某项工程的时间 $X$ (单位: 月) 是一个随机变量, 它的分布列为  \n$$\n\\begin{array}{c|cccc}\nX & 10 & 11 & 12 & 13 \\\\\n\\hline P & 0.4 & 0.3 & 0.2 & 0.1\n\\end{array}\n$$  \n(1) 试求该工程队完成此项工程的平均月数;  \n(2) 设该工程队所获利润为 $Y=50(13-X)$, 单位为万元. 试求工程队的平均利润;  \n(3) 若该工程队调整安排, 完成该项工程的时间 $X$ (单位:月) 的分布为  \n$$\n\\begin{array}{c|ccc}\nX & 10 & 11 & 12 \\\\\n\\hline P & 0.5 & 0.4 & 0.1\n\\end{array}\n$$  \n则其平均利润可增加多少?  \n13. 设随机变量 $X$ 的概率密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{2} \\cos \\frac{x}{2}, & 0 \\leqslant x \\leqslant \\pi ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n对 $X$ 独立重复观察 4 次, $Y$ 表示观察值大于 $\\pi / 3$ 的次数,求 $Y^{2}$ 的数学期望.  \n14. 设随机变量 $X$ 的概率密度函数为  \n$$",
        "metadata": {
            "Header 2": "丑习题 2.2"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array}\n$$  \n(1) 试求该工程队完成此项工程的平均月数;  \n(2) 设该工程队所获利润为 $Y=50(13-X)$, 单位为万元. 试求工程队的平均利润;  \n(3) 若该工程队调整安排, 完成该项工程的时间 $X$ (单位:月) 的分布为  \n$$\n\\begin{array}{c|ccc}\nX & 10 & 11 & 12 \\\\\n\\hline P & 0.5 & 0.4 & 0.1\n\\end{array}\n$$  \n则其平均利润可增加多少?  \n13. 设随机变量 $X$ 的概率密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{2} \\cos \\frac{x}{2}, & 0 \\leqslant x \\leqslant \\pi ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n对 $X$ 独立重复观察 4 次, $Y$ 表示观察值大于 $\\pi / 3$ 的次数,求 $Y^{2}$ 的数学期望.  \n14. 设随机变量 $X$ 的概率密度函数为  \n$$\np(x)= \\begin{cases}\\frac{3}{8} x^{2}, & 0<x<2 ; \\\\ 0, & \\text { 其他, }\\end{cases}\n$$  \n试求 $\\frac{1}{X^{2}}$ 的数学期望.  \n15. 设 $X$ 为仅取非负整数的离散随机变量, 若其数学期望存在, 证明  \n$$\nE(X)=\\sum_{k=1}^{+\\infty} P(X \\geqslant k)\n$$  \n16. 设连续随机变量 $X$ 的分布函数为 $F(x)$,且数学期望存在,证明  \n$$\nE(X)=\\int_{0}^{+\\infty}[1-F(x)] \\mathrm{d} x-\\int_{-\\infty}^{0} F(x) \\mathrm{d} x\n$$",
        "metadata": {
            "Header 2": "丑习题 2.2"
        },
        "type": "Document"
    },
    {
        "page_content": "随机变量 $X$ 的数学期望 $E(X)$ 是一种位置特征数, 它刻画了 $X$ 的取值总在 $E(X)$ 周围波动.但这个位置特征数无法反映出随机变量取值的“波动”大小, 譬如 $\\mathrm{X}$ 与 $\\mathrm{Y}$ 的分布列分别为  \n!  \n尽管它们的数学期望都是 0 , 但显然 $Y$ 取值的波动要比 X 取值的波动大. 如何用数值来反映出随机变量取值的 “波动” 大小, 是本节要研究的问题. 而以下定义的方差与标准差正是度量此种波动大小的最重要的两个特征数.",
        "metadata": {
            "Header 2": "2.3 随机变量的方差与标准差"
        },
        "type": "Document"
    },
    {
        "page_content": "设随机变量 $\\mathrm{X}$ 的均值为 $a=E(X), X$ 的取值当然不一定恰好是 $a$, 会有偏离. 偏离的量 $X-a$有正有负, 为了不使正负偏离彼此抵消, 我们一般考虑 $(X-a)^{2}$, 而不去考虑数学上难以处理的绝对值 $|X-a|$. 因为 $(X-a)^{2}$ 仍是一个随机变量, 所以取其均值 $E(X-a)^{2}$ 就可以作为刻画 $\\mathrm{X}$ 的 “波动”程度, 这个量被称作 $X$ 的方差, 其定义如下.  \n定义 2.3.1. 若随机变量 $X^{2}$ 的数学期望 $E\\left(X^{2}\\right)$ 存在, 则称偏差平方 $(X-E X)^{2}$ 的数学期望 $E(X-$ $E X)^{2}$ 为随机变量 $X$ (或相应分布) 的方差, 记为  \n$$\n\\operatorname{Var}(X)=E(X-E(X))^{2}= \\begin{cases}\\sum_{i}\\left[x_{i}-E(X)\\right]^{2} p\\left(x_{i}\\right), & \\text { 在离散场合; }  \\tag{2.3.1}\\\\ \\int_{-\\infty}^{+\\infty}[x-E(X)]^{2} p(x) \\mathrm{d} x, & \\text { 在连续场合. }\\end{cases}\n$$  \n称方差的正平方根 $\\sqrt{\\operatorname{Var}(X)}$ 为随机变量 $X$ (或相应分布) 的标准差, 记为 $\\sigma(X)$, 或 $\\sigma_{X}$.  \n方差与标准差的功能相似, 它们都是用来描述随机变量取值的集中与分散程度 (即散布大小)的两个特征数. 方差与标准差愈小, 随机变量的取值愈集中; 方差与标准差愈大, 随机变量的取值愈分散.  \n方差与标准差之间的差别主要在量纲上, 由于标准差与所讨论的随机变量、数学期望有相同的量纲, 所以在实际中, 人们比较乐意选用标准差, 但标准差的计算必须通过方差才能算得. 另外要指出的是: 如果随机变量 $\\mathrm{X}$ 的数学期望存在, 其方差不一定存在;而当 $X$ 的方差存在时, 则 $E(X)$必定存在, 其原因在于 $|x| \\leqslant x^{2}+1$ 总是成立的.",
        "metadata": {
            "Header 2": "2.3 随机变量的方差与标准差",
            "Header 3": "2.3.1 方差与标准差的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n称方差的正平方根 $\\sqrt{\\operatorname{Var}(X)}$ 为随机变量 $X$ (或相应分布) 的标准差, 记为 $\\sigma(X)$, 或 $\\sigma_{X}$.  \n方差与标准差的功能相似, 它们都是用来描述随机变量取值的集中与分散程度 (即散布大小)的两个特征数. 方差与标准差愈小, 随机变量的取值愈集中; 方差与标准差愈大, 随机变量的取值愈分散.  \n方差与标准差之间的差别主要在量纲上, 由于标准差与所讨论的随机变量、数学期望有相同的量纲, 所以在实际中, 人们比较乐意选用标准差, 但标准差的计算必须通过方差才能算得. 另外要指出的是: 如果随机变量 $\\mathrm{X}$ 的数学期望存在, 其方差不一定存在;而当 $X$ 的方差存在时, 则 $E(X)$必定存在, 其原因在于 $|x| \\leqslant x^{2}+1$ 总是成立的.  \n例 2.3.1: 图 2.3.1 上有三个分布:三角分布、均匀分布和倒三角分布的密度函数及它们的图形. 从图上可以看出, 这三个分布都位于区间 $(-1,1)$ 上, 并且关于纵轴对称, 从而得知这三个分布的期望均为 0 . 但它们的方差不等 (因此标准差也不等), 这可分别由各自的分布算得  \n$$\n\\begin{aligned}\n& \\operatorname{Var}\\left(X_{1}\\right)=E\\left(X_{1}^{2}\\right)=\\int_{-1}^{\\theta} x^{2}(1+x) \\mathrm{d} x+\\int_{0}^{1} x^{2}(1-x) \\mathrm{d} x=\\frac{1}{6} \\\\\n& \\operatorname{Var}\\left(X_{2}\\right)=E\\left(X_{2}^{2}\\right)=\\int_{-1}^{1} \\frac{x^{2}}{2} \\mathrm{~d} x=\\frac{1}{3} \\\\",
        "metadata": {
            "Header 2": "2.3 随机变量的方差与标准差",
            "Header 3": "2.3.1 方差与标准差的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "例 2.3.1: 图 2.3.1 上有三个分布:三角分布、均匀分布和倒三角分布的密度函数及它们的图形. 从图上可以看出, 这三个分布都位于区间 $(-1,1)$ 上, 并且关于纵轴对称, 从而得知这三个分布的期望均为 0 . 但它们的方差不等 (因此标准差也不等), 这可分别由各自的分布算得  \n$$\n\\begin{aligned}\n& \\operatorname{Var}\\left(X_{1}\\right)=E\\left(X_{1}^{2}\\right)=\\int_{-1}^{\\theta} x^{2}(1+x) \\mathrm{d} x+\\int_{0}^{1} x^{2}(1-x) \\mathrm{d} x=\\frac{1}{6} \\\\\n& \\operatorname{Var}\\left(X_{2}\\right)=E\\left(X_{2}^{2}\\right)=\\int_{-1}^{1} \\frac{x^{2}}{2} \\mathrm{~d} x=\\frac{1}{3} \\\\\n& \\operatorname{Var}\\left(X_{3}\\right)=E\\left(X_{3}^{2}\\right)=\\int_{-1}^{0} x^{2}(-x) \\mathrm{d} x+\\int_{0}^{1} x^{2} \\cdot x \\mathrm{~d} x=\\frac{1}{2}\n\\end{aligned}\n$$  \n这些计算结果与我们直观对分布的认识是一致的. 在这三个分布中, 三角分布在中间较为集\n中, 故方差最小; 而倒三角分布集中于两侧, 故方差最大; 均匀分布介于其中, 故方差也介于其中我们将三个分布的数学期望、方差和标准差都列于图 2.3.1 的相应分布的右侧, 以供比较.  \n1. 三角分布  \n!  \n2. 均匀分布  \n!  \n3. 倒三角分布  \n!  \n期望 方差 协方差  \n$$\np_{1}(x)=\\left\\{\\begin{array}{ll}\n1+x, & -1 \\leqslant x<0 ; \\\\\n1-x, & 0 \\leqslant x<1 ; \\\\\n0, & \\text { 其他. }\n\\end{array} \\quad 0 \\quad \\frac{1}{6} \\quad 0.4082\\right.\n$$  \n$$",
        "metadata": {
            "Header 2": "2.3 随机变量的方差与标准差",
            "Header 3": "2.3.1 方差与标准差的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n这些计算结果与我们直观对分布的认识是一致的. 在这三个分布中, 三角分布在中间较为集\n中, 故方差最小; 而倒三角分布集中于两侧, 故方差最大; 均匀分布介于其中, 故方差也介于其中我们将三个分布的数学期望、方差和标准差都列于图 2.3.1 的相应分布的右侧, 以供比较.  \n1. 三角分布  \n!  \n2. 均匀分布  \n!  \n3. 倒三角分布  \n!  \n期望 方差 协方差  \n$$\np_{1}(x)=\\left\\{\\begin{array}{ll}\n1+x, & -1 \\leqslant x<0 ; \\\\\n1-x, & 0 \\leqslant x<1 ; \\\\\n0, & \\text { 其他. }\n\\end{array} \\quad 0 \\quad \\frac{1}{6} \\quad 0.4082\\right.\n$$  \n$$\np_{2}(x)=\\left\\{\\begin{array}{lllll}\n1 / 2, & -1<x<1 ; & 0 & \\frac{1}{3} & 0.5774 \\\\\n0, & \\text { 其他. }\n\\end{array}\\right.\n$$  \n$$\np_{3}(x)= \\begin{cases}-x, & -1 \\leqslant x<0 ; \\\\ x, & 0 \\leqslant x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$",
        "metadata": {
            "Header 2": "2.3 随机变量的方差与标准差",
            "Header 3": "2.3.1 方差与标准差的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "例 2.3.2: 某人有一笔资金, 可投人两个项目:房产和商业, 其收益都与市场状态有关. 若把未来市场划分为好、中、差三个等级, 其发生的概率分别为 $0.2 、 0.7 、 0.1$. 通过调查, 该投资者认为投资于房产的收益 $X$ (万元) 和投资于商业的收益 $Y$ (万元 ) 的分布分别为  \n!  \n请问:该投资者如何投资为好?  \n解: 我们先考察数学期望 (平均收益)  \n$$\n\\begin{gathered}\nE(X)=11 \\times 0.2+3 \\times 0.7+(-3) \\times 0.1=4.0(\\text { 万元 }) \\\\\nE(Y)=6 \\times 0.2+4 \\times 0.7+(-1) \\times 0.1=3.9(\\text { 万元 })\n\\end{gathered}\n$$  \n从平均收益看, 投资房产收益大, 可比投资商业多收益 0.1 万元. 下面我们再来计算它们各自的方差  \n$$\n\\begin{aligned}\n& \\operatorname{Var}(X)=(11-4)^{2} 1 \\times 0.2+(3-4)^{2} \\times 0.7+(-3-4)^{2} \\times 0.1=15.4, \\\\\n& \\operatorname{Var}(Y)=(6-3.9)^{2} \\times 0.2+(4-3.9)^{2} \\times 0.7+(-1-3.9)^{2} \\times 0.1=3.29\n\\end{aligned}\n$$  \n及标准差  \n$$\n\\sigma(X)=\\sqrt{15.4}=3.92, \\sigma(Y)=\\sqrt{3.29}=1.81\n$$  \n因为标准差 (方差也一样) 愈大, 则收益的波动大, 从而风险也大. 所以从标准差看, 投资房产的风险比投资商业的风险大一倍多. 若收益与风险综合权衡, 该投资者还是应该选择投资商业为好, 虽然平均收益少 0.1 万元, 而风险要小一半以上.",
        "metadata": {
            "Header 2": "图 2.3.1: 比较三个分布的方差与标准差"
        },
        "type": "Document"
    },
    {
        "page_content": "以下均假定随机变量的方差是存在的.  \n性质 2.3.1:  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}\n$$  \n证明: 因为 $\\operatorname{Var}(X)=E[X-E(X)]^{2}=E\\left(X^{2}-2 X \\cdot E(X)+(E(X))^{2}\\right)$, 由数学期望的性质 2.2.3 可得  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-2 E(X) \\cdot E(X)+(E(X))^{2}=E\\left(X^{2}\\right)-(E(X))^{2}\n$$  \n在实际计算方差时, 这个性质往往比定义 $\\operatorname{Var}(X)=E(X-E X)^{2}$ 更常用.  \n性质 2.3.2: 常数的方差为 0 , 即 $\\operatorname{Var}(c)=0$, 其中 $c$ 是常数.  \n证明: 若 $c$ 是常数, 则  \n$$\n\\operatorname{Var}(c)=E(c-E(c))^{2}=E(c-c)^{2}=0\n$$  \n性质 2.3.3: 若 $a, b$ 是常数, 则 $\\operatorname{Var}(a X+b)=a^{2} \\operatorname{Var}(X)$.  \n证明: 若 $a, b$ 是常数, 则  \n$$\n\\begin{aligned}\n\\operatorname{Var}(a X+b) & =E(a X+b-E(a X+b))^{2} \\\\\n& =E(a(X-E(X)))^{2} \\\\\n& =a^{2} \\operatorname{Var}(X)\n\\end{aligned}\n$$  \n另外从 $\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2} \\geqslant 0$ 很容易看出: 若 $E\\left(X^{2}\\right)=0$, 则 $E(X)=0$, 且 $\\operatorname{Var}(X)=0$.  \n例 2.3.3: 设 $X$ 为掷一颗骰子出现的点数, 试求 $\\operatorname{Var}(X)$.  \n解:  \n$$",
        "metadata": {
            "Header 2": "图 2.3.1: 比较三个分布的方差与标准差",
            "Header 3": "2.3.2 方差的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n性质 2.3.3: 若 $a, b$ 是常数, 则 $\\operatorname{Var}(a X+b)=a^{2} \\operatorname{Var}(X)$.  \n证明: 若 $a, b$ 是常数, 则  \n$$\n\\begin{aligned}\n\\operatorname{Var}(a X+b) & =E(a X+b-E(a X+b))^{2} \\\\\n& =E(a(X-E(X)))^{2} \\\\\n& =a^{2} \\operatorname{Var}(X)\n\\end{aligned}\n$$  \n另外从 $\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2} \\geqslant 0$ 很容易看出: 若 $E\\left(X^{2}\\right)=0$, 则 $E(X)=0$, 且 $\\operatorname{Var}(X)=0$.  \n例 2.3.3: 设 $X$ 为掷一颗骰子出现的点数, 试求 $\\operatorname{Var}(X)$.  \n解:  \n$$\n\\begin{aligned}\n& E(X)=\\frac{1}{6}(1+2+3+4+5+6)=\\frac{7}{2}, \\\\\n& E\\left(X^{2}\\right)=\\frac{1}{6}\\left(1^{2}+2^{2}+3^{2}+4^{2}+5^{2}+6^{2}\\right)=\\frac{91}{6}, \\\\\n& \\operatorname{Var}(X)=\\frac{91}{6}-\\frac{49}{4}=\\frac{35}{12}=2.917 .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "图 2.3.1: 比较三个分布的方差与标准差",
            "Header 3": "2.3.2 方差的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "下面给出概率论中一个重要的基本不等式.  \n定理 2.3.1. (切比雪夫 $(1821--1894)$ 不等式) 设随机变量 $X$ 的数学期望和方差都存在, 则对任意常数 $e>0$, 有  \n$$\n\\begin{equation*}\nP(|X-E X| \\geqslant \\epsilon) \\leqslant \\frac{\\operatorname{Var}(X)}{\\varepsilon^{2}} \\tag{2.3.2}\n\\end{equation*}\n$$  \n或  \n$$\n\\begin{equation*}\nP(|X-E X|<\\varepsilon) \\geqslant 1-\\frac{\\operatorname{Var}(X)}{\\varepsilon^{2}} \\tag{2.3.3}\n\\end{equation*}\n$$  \n证明: 没 $X$ 是一个连续随机变量, 其密度函数为 $p(x)$. 记 $E(X)=a$, 我们有  \n$$\n\\begin{aligned}\nP(|X-a| \\geqslant \\varepsilon) & =\\int_{\\{x \\mid x-a \\geqslant \\epsilon\\}} p(x) \\mathrm{d} x \\leqslant \\int_{\\{x \\mid x-a>c\\}} \\frac{(x-a)^{2}}{\\varepsilon^{2}} p(x) \\mathrm{d} x \\\\\n& \\leqslant \\frac{1}{\\varepsilon^{2}} \\int_{-\\infty}^{+\\infty}(x-a)^{2} p(x) \\mathrm{d} x=\\frac{\\operatorname{Var}(X)}{\\varepsilon^{2}}\n\\end{aligned}\n$$  \n由此知 2.3.2 式对连续随机变量成立, 对于离散随机变量亦可类似进行证明.",
        "metadata": {
            "Header 2": "图 2.3.1: 比较三个分布的方差与标准差",
            "Header 3": "2.3.3 切比雪夫不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n证明: 没 $X$ 是一个连续随机变量, 其密度函数为 $p(x)$. 记 $E(X)=a$, 我们有  \n$$\n\\begin{aligned}\nP(|X-a| \\geqslant \\varepsilon) & =\\int_{\\{x \\mid x-a \\geqslant \\epsilon\\}} p(x) \\mathrm{d} x \\leqslant \\int_{\\{x \\mid x-a>c\\}} \\frac{(x-a)^{2}}{\\varepsilon^{2}} p(x) \\mathrm{d} x \\\\\n& \\leqslant \\frac{1}{\\varepsilon^{2}} \\int_{-\\infty}^{+\\infty}(x-a)^{2} p(x) \\mathrm{d} x=\\frac{\\operatorname{Var}(X)}{\\varepsilon^{2}}\n\\end{aligned}\n$$  \n由此知 2.3.2 式对连续随机变量成立, 对于离散随机变量亦可类似进行证明.\n在概率论中, 事件 “ $|X-E(X)| \\geqslant \\varepsilon$ ” 称为大偏差, 其概率 $P(1 X-E(X) 1 \\geqslant e)$ 称为大偏差发生概率. 切比雪夫不等式给出大偏差发生概率的上界, 这个上界与方差成正比, 方差愈大上界也愈大. 以下定理进一步说明了方差为 0 就意味着随机变量的取值集中在一点上.  \n定理 2.3.2. 若随机变量 $X$ 的方差存在, 则 $\\operatorname{Var}(X)=0$ 的充要条件是 $X$ 几乎处处为某个常数 $a$, 即 $P(X=a)=1$.  \n证明: 充分性是显然的, 下面证必要性. 设 $\\operatorname{Var}(X)=0$, 这时 $E(X)$ 存在. 因为  \n$$\n|| X-E(X)|>0|=\\bigcup_{n=1}^{+\\infty}\\left\\{|X-E(X)| \\geqslant \\frac{1}{n}\\right\\}\n$$  \n所以有  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "图 2.3.1: 比较三个分布的方差与标准差",
            "Header 3": "2.3.3 切比雪夫不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "由此知 2.3.2 式对连续随机变量成立, 对于离散随机变量亦可类似进行证明.\n在概率论中, 事件 “ $|X-E(X)| \\geqslant \\varepsilon$ ” 称为大偏差, 其概率 $P(1 X-E(X) 1 \\geqslant e)$ 称为大偏差发生概率. 切比雪夫不等式给出大偏差发生概率的上界, 这个上界与方差成正比, 方差愈大上界也愈大. 以下定理进一步说明了方差为 0 就意味着随机变量的取值集中在一点上.  \n定理 2.3.2. 若随机变量 $X$ 的方差存在, 则 $\\operatorname{Var}(X)=0$ 的充要条件是 $X$ 几乎处处为某个常数 $a$, 即 $P(X=a)=1$.  \n证明: 充分性是显然的, 下面证必要性. 设 $\\operatorname{Var}(X)=0$, 这时 $E(X)$ 存在. 因为  \n$$\n|| X-E(X)|>0|=\\bigcup_{n=1}^{+\\infty}\\left\\{|X-E(X)| \\geqslant \\frac{1}{n}\\right\\}\n$$  \n所以有  \n$$\n\\begin{aligned}\nP(|X-E(X)|>0) & =P\\left(\\bigcup_{n=1}^{n}\\left\\{|x-E(X)| \\geqslant \\frac{1}{n}\\right\\}\\right) \\\\\n& \\leqslant \\sum_{n=1}^{+\\infty} P\\left(|X-E(X)| \\geqslant \\frac{1}{n}\\right) \\leqslant \\sum_{n=1}^{+\\infty} \\frac{\\operatorname{Var}(X)}{(1 / n)^{2}}=0\n\\end{aligned}\n$$  \n其中最后一个不等式用到了切比雪夫不等式. 由此可知  \n$$\nP(|X-E(X)|>0)=0\n$$  \n因而有  \n$$\nP(|X-E(X)|=0)=1\n$$  \n即  \n$$\nP(X=E(X))=1\n$$  \n这就证明了结论, 且其中的常数 $a$ 就是 $E(X)$.",
        "metadata": {
            "Header 2": "图 2.3.1: 比较三个分布的方差与标准差",
            "Header 3": "2.3.3 切比雪夫不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设随机变量 $X$ 满足 $E(X)=\\operatorname{Var}(X)=\\lambda$, 已知 $E[(X-1)(x-2)]=1$, 试求 $\\lambda$.\n2. 假设有 10 只同种电器元件, 其中有两只不合格品. 装配仪器时, 从这批元件中任取一只, 如是不合格品, 则扔掉重新任取一只; 如仍是不合格品, 则扔掉再取一只, 试求在取到合格品之前, 已取出的不合格品只数的方差.\n3. 已知 $E(X)=-2, E(X 2)=5$, 求 $(\\operatorname{Var}(1-3 X)$.\n4. 设随机变量 $X$ 的分布函数为  \n$$\nF(x)= \\begin{cases}\\frac{\\mathrm{e}^{x}}{2}, & x<0 ; \\\\ \\frac{1}{2}, & 0 \\leqslant x<1 ; \\\\ 1-\\frac{1}{2} \\mathrm{e}^{-\\frac{1}{2}(x-1)}, & x \\geqslant 1\\end{cases}\n$$  \n试求 $\\operatorname{Var}(X)$.  \n5. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}1+x, & -1<x \\leqslant 0 ; \\\\ -1<x \\leqslant 0, & 0<x \\leqslant 1 ; \\\\ 0 & \\text { 其他. }\\end{cases}\n$$  \n试求 $\\operatorname{Var}(3 X+2)$.  \n6. 试证:对任意的常效 $c$ 关 $E(X)$, 有  \n$$\n\\operatorname{Var}(X)=E[X-E(X)]^{2}<E(X-c)^{2}\n$$  \n7. 设随机变量 $X$ 仅在区间 $[a, b]$ 上取值, 试证  \n$$\na \\leqslant E(X) \\leqslant b, \\operatorname{Var}(X) \\leqslant\\left(\\frac{b-a}{2}\\right)^{2}\n$$",
        "metadata": {
            "Header 2": "习 题 2.3"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试求 $\\operatorname{Var}(X)$.  \n5. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}1+x, & -1<x \\leqslant 0 ; \\\\ -1<x \\leqslant 0, & 0<x \\leqslant 1 ; \\\\ 0 & \\text { 其他. }\\end{cases}\n$$  \n试求 $\\operatorname{Var}(3 X+2)$.  \n6. 试证:对任意的常效 $c$ 关 $E(X)$, 有  \n$$\n\\operatorname{Var}(X)=E[X-E(X)]^{2}<E(X-c)^{2}\n$$  \n7. 设随机变量 $X$ 仅在区间 $[a, b]$ 上取值, 试证  \n$$\na \\leqslant E(X) \\leqslant b, \\operatorname{Var}(X) \\leqslant\\left(\\frac{b-a}{2}\\right)^{2}\n$$  \n8. 设随机变量 $X$ 取值 $x_{1} \\leqslant \\cdots \\leqslant x_{n}$ 的概率分别是 $p_{1}, \\cdots, p_{n}, \\sum_{k=1}^{n} p_{k}=1$. 证明  \n$$\n\\operatorname{Var}(X) \\leqslant\\left(\\frac{x_{\\mathrm{n}}-x_{1}}{2}\\right)^{2}\n$$  \n9. 设 $g(x)$ 为随机变量 $X$ 取值的集合上的非负不减函数, 且 $E(g(X))$ 存在, 证明:对任意的 $\\varepsilon>0$,有  \n$$\nP(X>\\varepsilon) \\leqslant \\frac{E(g(X))}{g(\\varepsilon)} .\n$$  \n10. 设 $X$ 为非负随机变量, $a>0$. 若 $E\\left(\\mathrm{e}^{a X}\\right)$ 存在, 证明: 对任意的 $x>0$, 有  \n$$\nP(X \\geqslant x) \\leqslant \\frac{E\\left(\\mathrm{e}^{a X}\\right)}{\\mathrm{e}^{a x}} .\n$$",
        "metadata": {
            "Header 2": "习 题 2.3"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\operatorname{Var}(X) \\leqslant\\left(\\frac{x_{\\mathrm{n}}-x_{1}}{2}\\right)^{2}\n$$  \n9. 设 $g(x)$ 为随机变量 $X$ 取值的集合上的非负不减函数, 且 $E(g(X))$ 存在, 证明:对任意的 $\\varepsilon>0$,有  \n$$\nP(X>\\varepsilon) \\leqslant \\frac{E(g(X))}{g(\\varepsilon)} .\n$$  \n10. 设 $X$ 为非负随机变量, $a>0$. 若 $E\\left(\\mathrm{e}^{a X}\\right)$ 存在, 证明: 对任意的 $x>0$, 有  \n$$\nP(X \\geqslant x) \\leqslant \\frac{E\\left(\\mathrm{e}^{a X}\\right)}{\\mathrm{e}^{a x}} .\n$$  \n11. 已知正常成人男性每毫升血液中的白细胞数平均是 7300 , 标准差是 700 . 试利用切比雪夫不等式估计每升血液中的白细胞数在 5200 至 9400 之间的概率的下界.",
        "metadata": {
            "Header 2": "习 题 2.3"
        },
        "type": "Document"
    },
    {
        "page_content": "每个随机变量都有一个分布, 不同的随机变量可以有不同的分布,也可以有相同的分布, 随机变量有千千万万个, 但常用分布并不多. 常用分布亦分为两类: 离散分布和连续分布, 本节讲常用离散分布,下节讲常用连续分布.",
        "metadata": {
            "Header 2": "2.4 常用离散分布"
        },
        "type": "Document"
    },
    {
        "page_content": "如果记 $X$ 为 $n$ 重伯努利试验中成功 (记为事件 $A$ ) 的次数,则 $X$ 的可能取值为 $0,1, \\cdots, n$. 记 $p$ 为每次试验中 $A$ 发生的概率, 即 $P(A)=p$, 则 $P(\\bar{A})=1-p$.  \n因为 $n$ 重伯努利试验的基本结果可以记作  \n$$\n\\omega=\\left(\\omega_{1}, \\omega_{2}, \\cdots, \\omega_{n}\\right),\n$$  \n其中 $\\omega_{i}$ 或者为 $A$, 或者为 $\\bar{A}$. 这样的 $\\omega$ 共有 $2^{n}$ 个, 这 $2^{n}$ 个样本点 $\\omega$ 组成了样本空间 $\\Omega$.  \n下面求 $X$ 的分布列, 即求事件 $\\{X=k\\}$ 的概率. 若某个样本点  \n$$\n\\omega=\\left(\\omega_{1}, \\omega_{2}, \\cdots, \\omega_{n}\\right) \\in\\{X=k\\}\n$$  \n意味着 $\\omega_{1}, \\omega_{2}, \\cdots, \\omega_{n}$ 中有 $k$ 个 $A, n-k$ 个 $\\bar{A}$, 所以由独立性知  \n$$\nP(\\omega)=p^{k}(1-p)^{n-k} .\n$$  \n而事件 $\\{X=k\\}$ 中这样的 $\\omega$ 共有 $\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right)$ 个,所以 $X$ 的分布列为  \n$$\nP(X=k)=\\left(\\begin{array}{l}\nn  \\tag{2.4.1}\\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}, k=0,1, \\cdots, n .\n$$  \n这个分布称为二项分布, 记为 $X \\sim b(n, p)$.  \n容易验证其和恒为 1 ,即  \n$$\n\\sum_{k=0}^{n}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}=[p+(1-p)]^{n}=1\n$$",
        "metadata": {
            "Header 2": "二、二项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n意味着 $\\omega_{1}, \\omega_{2}, \\cdots, \\omega_{n}$ 中有 $k$ 个 $A, n-k$ 个 $\\bar{A}$, 所以由独立性知  \n$$\nP(\\omega)=p^{k}(1-p)^{n-k} .\n$$  \n而事件 $\\{X=k\\}$ 中这样的 $\\omega$ 共有 $\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right)$ 个,所以 $X$ 的分布列为  \n$$\nP(X=k)=\\left(\\begin{array}{l}\nn  \\tag{2.4.1}\\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}, k=0,1, \\cdots, n .\n$$  \n这个分布称为二项分布, 记为 $X \\sim b(n, p)$.  \n容易验证其和恒为 1 ,即  \n$$\n\\sum_{k=0}^{n}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}=[p+(1-p)]^{n}=1\n$$  \n由此可见, 二项概率 $\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right) p^{k}(1-p)^{n-k}$ 恰好是二项式 $[p+(1-p)]^{n}$ 的展开式中的第 $k+1$ 项, 这正是其名称的由来.\n二项分布是一种常用的离散分布,譬如，  \n- 检查 10 个产品, 10 个产品中不合格品的个数 $X$ 服从二项分布 $b(10, p)$, 其中 $p$ 为不合格品率;\n- 调查 50 个人, 50 个人中患色育的人数 $Y$ 跟从二项分布 $b(50, p)$, 其中 $p$ 为色盲率;\n- 射击 5 次, 5 次中命中次数 $\\mathrm{Z}$ 服从二项分布 $b(5, p)$, 其中 $p$ 为射手的命中率.  \n例 2.4.1: 某特效药的临床有效率为 0.95 , 今有 10 人服用, 问至少有 8 人治愈的概率是多少?  \n解: 设 $X$ 为 10 人中被治愈的人数,则 $X \\sim b(10,0.95)$, 而所求概率为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "二、二项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由此可见, 二项概率 $\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right) p^{k}(1-p)^{n-k}$ 恰好是二项式 $[p+(1-p)]^{n}$ 的展开式中的第 $k+1$ 项, 这正是其名称的由来.\n二项分布是一种常用的离散分布,譬如，  \n- 检查 10 个产品, 10 个产品中不合格品的个数 $X$ 服从二项分布 $b(10, p)$, 其中 $p$ 为不合格品率;\n- 调查 50 个人, 50 个人中患色育的人数 $Y$ 跟从二项分布 $b(50, p)$, 其中 $p$ 为色盲率;\n- 射击 5 次, 5 次中命中次数 $\\mathrm{Z}$ 服从二项分布 $b(5, p)$, 其中 $p$ 为射手的命中率.  \n例 2.4.1: 某特效药的临床有效率为 0.95 , 今有 10 人服用, 问至少有 8 人治愈的概率是多少?  \n解: 设 $X$ 为 10 人中被治愈的人数,则 $X \\sim b(10,0.95)$, 而所求概率为  \n$$\n\\begin{aligned}\nP(X \\geqslant 8) & =P(X=8)+P(X=9)+P(X=10) \\\\\n& =\\left(\\begin{array}{c}\n10 \\\\\n8\n\\end{array}\\right) 0.95^{8} 0.05^{2}+\\left(\\begin{array}{c}\n10 \\\\\n9\n\\end{array}\\right) 0.95^{9} 0.05+\\left(\\begin{array}{c}\n10 \\\\\n10\n\\end{array}\\right) 0.95^{10} \\\\\n& =0.0746+0.3151+0.5988=0.9885 .\n\\end{aligned}\n$$  \n10 人中有 8 人以上被治愈的概率为 0.9885 .  \n例 2.4.2: 设 $X \\sim b(2, p), Y \\sim b(3, p)$. 若 $X \\geqslant 1=5 / 9$, 试求 $P(Y \\geqslant 1)$.",
        "metadata": {
            "Header 2": "二、二项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 设 $X$ 为 10 人中被治愈的人数,则 $X \\sim b(10,0.95)$, 而所求概率为  \n$$\n\\begin{aligned}\nP(X \\geqslant 8) & =P(X=8)+P(X=9)+P(X=10) \\\\\n& =\\left(\\begin{array}{c}\n10 \\\\\n8\n\\end{array}\\right) 0.95^{8} 0.05^{2}+\\left(\\begin{array}{c}\n10 \\\\\n9\n\\end{array}\\right) 0.95^{9} 0.05+\\left(\\begin{array}{c}\n10 \\\\\n10\n\\end{array}\\right) 0.95^{10} \\\\\n& =0.0746+0.3151+0.5988=0.9885 .\n\\end{aligned}\n$$  \n10 人中有 8 人以上被治愈的概率为 0.9885 .  \n例 2.4.2: 设 $X \\sim b(2, p), Y \\sim b(3, p)$. 若 $X \\geqslant 1=5 / 9$, 试求 $P(Y \\geqslant 1)$.  \n解: 由 $X \\geqslant 1=5 / 9$, 知 $P(X=0)=4 / 9$, 所以 $(1-p)^{2}=4 / 9$, 由此得 $p=1 / 3$. 再由 $Y \\sim b(3, p)$可得  \n$$\nP(Y \\geqslant 1)=1-P(Y=0)=1-\\left(1-\\frac{1}{3}\\right)^{3}=\\frac{19}{27} .\n$$  \n二。二点分布  \n$n=1$ 时的二项分布 $b(1, p)$ 称为二点分布,或称 $0-1$ 分布,其分布列为:  \n$$\n\\begin{equation*}\nP(X=x)=p^{x}(1-p)^{1-x}, x=0,1 . \\tag{2.4.2}\n\\end{equation*}\n$$  \n或记为  \n| $X$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1-p$ | $\\mathrm{p}$ |  \n二点分布 $b(1, p)$ 主要用来描述一次伯努利试验中成功 (记为 $A$ ) 出现次数 ( 0 或 1 ).",
        "metadata": {
            "Header 2": "二、二项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 由 $X \\geqslant 1=5 / 9$, 知 $P(X=0)=4 / 9$, 所以 $(1-p)^{2}=4 / 9$, 由此得 $p=1 / 3$. 再由 $Y \\sim b(3, p)$可得  \n$$\nP(Y \\geqslant 1)=1-P(Y=0)=1-\\left(1-\\frac{1}{3}\\right)^{3}=\\frac{19}{27} .\n$$  \n二。二点分布  \n$n=1$ 时的二项分布 $b(1, p)$ 称为二点分布,或称 $0-1$ 分布,其分布列为:  \n$$\n\\begin{equation*}\nP(X=x)=p^{x}(1-p)^{1-x}, x=0,1 . \\tag{2.4.2}\n\\end{equation*}\n$$  \n或记为  \n| $X$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1-p$ | $\\mathrm{p}$ |  \n二点分布 $b(1, p)$ 主要用来描述一次伯努利试验中成功 (记为 $A$ ) 出现次数 ( 0 或 1 ).  \n很多随机现象的样本空间 $\\Omega$ 常可一分为二, 记为 $A$ 与 $\\bar{A}$, 由此形成伯努利试验. $n$ 重伯努利试验是由 $n$ 个相同的、独立进行的伯努利试验组成, 若将第 $i$ 个伯努利试验中 $A$ 出现的次数记为 $X_{i}(i=1,2, \\cdots, n)$, 则 $X_{i}$ 相互独立, 且服从相同的二点分布 $b(1, p)$. 此时其和  \n$$\nX=X_{1}+X_{2}+\\cdots+X_{n}\n$$  \n就是 $\\mathrm{n}$ 重伯努利试验中 $A$ 出现的总次数, 它服从二项分布 $b(n, p)$. 这就是二项分布 $b(n, p)$ 与二点分布 $b(1, p)$ 之间的联系, 即二项分布随机变量是 $n$ 个独立同分布的二点分布随机变量之和.",
        "metadata": {
            "Header 2": "二、二项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "设随机变量 $X \\sim b(n, p)$, 则  \n$$\n\\begin{aligned}\nE(X) & =\\sum_{k=0}^{n} k\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k} \\\\\n& =n p \\sum_{k=1}^{n}\\left(\\begin{array}{l}\nn-1 \\\\\nk-1\n\\end{array}\\right) p^{k-1}(1-p)^{(n-1)-(k-1)} \\\\\n& =n p[p+(1-p)]^{n-1}=n p .\n\\end{aligned}\n$$  \n又因为  \n$$\nE\\left(X^{2}\\right)=\\sum_{k=0}^{n} k^{2}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}\n$$  \n$$\n\\begin{aligned}\n& =\\sum_{k=1}^{n}(k-1+1) k\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k} \\\\\n& =\\sum_{k=1}^{n} k(k-1)\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}+\\sum_{k=1}^{n} k\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k} \\\\\n& =\\sum_{k=2}^{n} k(k-1)\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}+n p \\\\\n& =n(n-1) p^{2} \\sum_{k=2}^{n}\\left(\\begin{array}{l}\nn-2 \\\\\nk-2\n\\end{array}\\right) p^{k-2}(1-p)^{(n-2)-(k-2)}+n p \\\\\n& =n(n-1) p^{2}+n p .\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$",
        "metadata": {
            "Header 2": "三、二项分布的期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "n \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k} \\\\\n& =\\sum_{k=1}^{n} k(k-1)\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}+\\sum_{k=1}^{n} k\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k} \\\\\n& =\\sum_{k=2}^{n} k(k-1)\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}+n p \\\\\n& =n(n-1) p^{2} \\sum_{k=2}^{n}\\left(\\begin{array}{l}\nn-2 \\\\\nk-2\n\\end{array}\\right) p^{k-2}(1-p)^{(n-2)-(k-2)}+n p \\\\\n& =n(n-1) p^{2}+n p .\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=n(n-1) p^{2}+n p-(n p)^{2}=n p(1-p) .\n$$  \n因为二点分布是 $n=1$ 时的二项分布 $b(1, p)$, 所以二点分布的数学期望为 $p$, 方差为 $p(1-p)$.为了看出不同的 $p$ 的值, 其二项分布 $b(n, p)$ 的变化情况, 表 2.4.1 给出了 $n=10$ 时, 不同 $p$值的二项分布的概率值, 其线条图见图 2.4.1.  \n表 2.4.1: 一些二项分布的概率值  \n| $k$ | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "三、二项分布的期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "& =n(n-1) p^{2}+n p .\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=n(n-1) p^{2}+n p-(n p)^{2}=n p(1-p) .\n$$  \n因为二点分布是 $n=1$ 时的二项分布 $b(1, p)$, 所以二点分布的数学期望为 $p$, 方差为 $p(1-p)$.为了看出不同的 $p$ 的值, 其二项分布 $b(n, p)$ 的变化情况, 表 2.4.1 给出了 $n=10$ 时, 不同 $p$值的二项分布的概率值, 其线条图见图 2.4.1.  \n表 2.4.1: 一些二项分布的概率值  \n| $k$ | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $b(10,0.2)$ | 0.107 | 0.268 | 0.302 | 0.201 | 0.088 | 0.027 | 0.006 | 0.001 |  |  |  |\n| $b(10,0.5)$ | 0.001 | 0.010 | 0.044 | 0.117 | 0.205 | 0.246 | 0.205 | 0.117 | 0.044 | 0.010 | 0.001 |\n| $b(10,0.8)$ |  |  |  | 0.001 | 0.006 | 0.027 | 0.088 | 0.201 | 0.302 | 0.368 | 0.107 |  \n!  \n(a) $b(10,0,2)$ 的线条图 (右偏)  \n!  \n(b) $b(10,0,5)$ 的线条图 (对称)  \n!  \n(c) $b(10,0,8)$ 的线条图 (左偏)  \n图 2.4.1: 二项分布 $b(n, p)$ 的线条图",
        "metadata": {
            "Header 2": "三、二项分布的期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "。位于均值 $n p$ 附近概率较大;  \n- 随着 $p$ 的增加,分布的峰逐渐右移.  \n例 2.4.3: 甲、乙两棋手约定进行 10 局比赛, 以赢的局数多者为胜. 设在每局中甲赢的概率为 0.6 , 乙赢的概率为 0.4. 如果各局比赛是独立进行的, 试问甲胜、乙胜、不分胜负的概率各为多少?  \n解: 以 $X$ 表示 10 局比赛中甲赢的局数, 则 $X \\sim b(10,0.6)$. 所以  \n$$\n\\begin{aligned}\n& P(\\text { 甲胜 })=P(X \\geqslant 6)=\\sum_{k=6}^{10}\\left(\\begin{array}{c}\n10 \\\\\nk\n\\end{array}\\right) 0.6^{k} 0.4^{10-k}=0.6330, \\\\\n& P(\\text { 乙胜 })=P(X \\leqslant 4)=\\sum_{k=0}^{4}\\left(\\begin{array}{c}\n10 \\\\\nk\n\\end{array}\\right) 0.6^{k} 0.4^{10-k}=0.1663,\n\\end{aligned}\n$$  \n$$\nP(\\text { 不分胜负 })=P(X=5)=\\left(\\begin{array}{c}\n10 \\\\\n5\n\\end{array}\\right) 0.6^{5} 0.4^{5}=0.2007 \\text {. }\n$$  \n可见甲胜的可能性达 $63.3 \\%$, 而乙胜的可能性只有 $16.63 \\%$, 它比不分胜负的可能性还要小. 最后两个概率之和 0.3670 表示乙不输的概率.",
        "metadata": {
            "Header 2": "从上图可以看出"
        },
        "type": "Document"
    },
    {
        "page_content": "一、泊松分布  \n泊松分布是 1837 年由法国数学家泊松 (Poisson S.D.1781-1840) 首次提出的. 泊松分布的概率分布列是  \n$$\n\\begin{equation*}\nP(X=k)=\\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}, k=0,1,2, \\cdots, \\tag{2.4.3}\n\\end{equation*}\n$$  \n其中参数 $\\lambda>0$, 记为 $X \\sim P(\\lambda)$.  \n对泊松分布而言, 很容易验证其和为 1 :  \n$$\n\\sum_{k=0}^{+\\infty} \\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}=\\mathrm{e}^{-\\lambda} \\sum_{k=0}^{+\\infty} \\frac{\\lambda^{k}}{k !}=\\mathrm{e}^{-\\lambda} \\mathrm{e}^{\\lambda}=1\n$$  \n泊松分布是一种常用的离散分布, 它常与单位时间 (或单位面积、单位产品等) 上的计数过程相联系,譬如，  \n○在单位时间内,电话总机接到用户呼唤的次数;  \n- 在单位时间内,一电路受到外界电磁波的冲击次数;\n- 1 平方米内,玻璃上的气泡数;  \n-一铸件上的砂眼数;  \n- $\\cdot$在单位时间内, 某种放射性物质分裂到某区域的质点数, 等等. 都服从泊松分布. 因此泊松分布的应用面是十分广泛的.  \n二。泊松分布的数学期望和方差  \n设随机变量 $X \\sim P(\\lambda)$, 则  \n$$\nE(X)=\\sum_{k=0}^{+\\infty} k \\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}=\\lambda \\mathrm{e}^{-\\lambda} \\sum_{k=1}^{+\\infty} \\frac{\\lambda^{k-1}}{(k-1) !}=\\lambda \\mathrm{e}^{-\\lambda} \\mathrm{e}^{\\lambda}=\\lambda\n$$  \n这表明: 泊松分布 $P(\\lambda)$ 的数学期望就是参数 $\\lambda$.  \n又因为  \n$$",
        "metadata": {
            "Header 2": "从上图可以看出",
            "Header 3": "2.4.2 泊松分布"
        },
        "type": "Document"
    },
    {
        "page_content": "○在单位时间内,电话总机接到用户呼唤的次数;  \n- 在单位时间内,一电路受到外界电磁波的冲击次数;\n- 1 平方米内,玻璃上的气泡数;  \n-一铸件上的砂眼数;  \n- $\\cdot$在单位时间内, 某种放射性物质分裂到某区域的质点数, 等等. 都服从泊松分布. 因此泊松分布的应用面是十分广泛的.  \n二。泊松分布的数学期望和方差  \n设随机变量 $X \\sim P(\\lambda)$, 则  \n$$\nE(X)=\\sum_{k=0}^{+\\infty} k \\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}=\\lambda \\mathrm{e}^{-\\lambda} \\sum_{k=1}^{+\\infty} \\frac{\\lambda^{k-1}}{(k-1) !}=\\lambda \\mathrm{e}^{-\\lambda} \\mathrm{e}^{\\lambda}=\\lambda\n$$  \n这表明: 泊松分布 $P(\\lambda)$ 的数学期望就是参数 $\\lambda$.  \n又因为  \n$$\n\\begin{aligned}\nE\\left(X^{2}\\right) & =\\sum_{k=0}^{+\\infty} k^{2} \\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}=\\sum_{k=1}^{+\\infty} k \\frac{\\lambda^{k}}{(k-1) !} \\mathrm{e}^{-\\lambda} \\\\\n& =\\sum_{k=1}^{+\\infty}[(k-1)+1] \\frac{\\lambda^{k}}{(k-1) !} \\mathrm{e}^{-\\lambda} \\\\\n& =\\lambda^{2} \\mathrm{e}^{-\\lambda} \\sum_{k=2}^{+\\infty} \\frac{\\lambda^{k-2}}{(k-2) !}+\\lambda \\mathrm{e}^{-\\lambda} \\sum_{k=1}^{+\\infty} \\frac{\\lambda^{k-1}}{(k-1) !} \\\\\n& =\\lambda^{2}+\\lambda\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$",
        "metadata": {
            "Header 2": "从上图可以看出",
            "Header 3": "2.4.2 泊松分布"
        },
        "type": "Document"
    },
    {
        "page_content": "E\\left(X^{2}\\right) & =\\sum_{k=0}^{+\\infty} k^{2} \\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}=\\sum_{k=1}^{+\\infty} k \\frac{\\lambda^{k}}{(k-1) !} \\mathrm{e}^{-\\lambda} \\\\\n& =\\sum_{k=1}^{+\\infty}[(k-1)+1] \\frac{\\lambda^{k}}{(k-1) !} \\mathrm{e}^{-\\lambda} \\\\\n& =\\lambda^{2} \\mathrm{e}^{-\\lambda} \\sum_{k=2}^{+\\infty} \\frac{\\lambda^{k-2}}{(k-2) !}+\\lambda \\mathrm{e}^{-\\lambda} \\sum_{k=1}^{+\\infty} \\frac{\\lambda^{k-1}}{(k-1) !} \\\\\n& =\\lambda^{2}+\\lambda\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=\\lambda^{2}+\\lambda-\\lambda^{2}=\\lambda\n$$  \n也就是说, 泊松分布 $P(\\lambda)$ 中的参数 A 既是数学期望又是方差.  \n为了看出不同的 $\\lambda$ 的值, 其泊松分布 $P(\\lambda)$ 的变化情况, 表 2.4.2 给出了 $\\lambda=0.8,2.0,4.0$ 时, 泊\n松分布的概率值,其线条图见图 2.4.2.  \n表 2.4.2: 一些泊松分布的概率值  \n| $k$ | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P(0.8)$ | 0.449 | 0.360 | 0.144 | 0.038 | 0.008 | 0.001 |  |  |  |  |  |",
        "metadata": {
            "Header 2": "从上图可以看出",
            "Header 3": "2.4.2 泊松分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n也就是说, 泊松分布 $P(\\lambda)$ 中的参数 A 既是数学期望又是方差.  \n为了看出不同的 $\\lambda$ 的值, 其泊松分布 $P(\\lambda)$ 的变化情况, 表 2.4.2 给出了 $\\lambda=0.8,2.0,4.0$ 时, 泊\n松分布的概率值,其线条图见图 2.4.2.  \n表 2.4.2: 一些泊松分布的概率值  \n| $k$ | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P(0.8)$ | 0.449 | 0.360 | 0.144 | 0.038 | 0.008 | 0.001 |  |  |  |  |  |\n| $P(2.0)$ | 0.135 | 0.271 | 0.271 | 0.180 | 0.090 | 0.036 | 0.012 | 0.004 | 0.001 |  |  |\n| $P(4.0)$ | 0.018 | 0.074 | 0.146 | 0.195 | 0.196 | 0.156 | 0.104 | 0.060 | 0.030 | 0.013 | 0.005 |  \n!  \n(a) $P(0.8)$ 的线条图  \n!  \n(b) $P(2.0)$ 的线条图  \n!  \n(c) $b(10,0,8)$ 的线条图 (左偏)  \n图 2.4.2: 泊松分布 $P(\\lambda)$ 的线条图  \n从上图可以看出  \n- 位于均值 $\\lambda$ 附近概率较大;\n- 随着 $\\lambda$ 的增加,分布逐渐趋于对称.  \n例 2.4.4: 一铸件的砂眼 (缺陷) 数服从参数为 $\\lambda=0.5$ 的泊松分布, 试求此铸件上至多有 1 个砂眼 (合格品) 的概率和至少有 2 个砂眼 (不合格品) 的概率,  \n解: 以 $X$ 表示这种铸件的砂眼数, 由题意知 $X \\sim P(0.5)$. 则此种铸件上至多有 1 个砂眼的概率为  \n$$",
        "metadata": {
            "Header 2": "从上图可以看出",
            "Header 3": "2.4.2 泊松分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| $P(4.0)$ | 0.018 | 0.074 | 0.146 | 0.195 | 0.196 | 0.156 | 0.104 | 0.060 | 0.030 | 0.013 | 0.005 |  \n!  \n(a) $P(0.8)$ 的线条图  \n!  \n(b) $P(2.0)$ 的线条图  \n!  \n(c) $b(10,0,8)$ 的线条图 (左偏)  \n图 2.4.2: 泊松分布 $P(\\lambda)$ 的线条图  \n从上图可以看出  \n- 位于均值 $\\lambda$ 附近概率较大;\n- 随着 $\\lambda$ 的增加,分布逐渐趋于对称.  \n例 2.4.4: 一铸件的砂眼 (缺陷) 数服从参数为 $\\lambda=0.5$ 的泊松分布, 试求此铸件上至多有 1 个砂眼 (合格品) 的概率和至少有 2 个砂眼 (不合格品) 的概率,  \n解: 以 $X$ 表示这种铸件的砂眼数, 由题意知 $X \\sim P(0.5)$. 则此种铸件上至多有 1 个砂眼的概率为  \n$$\nP(X \\leqslant 1)=\\frac{0.5^{0}}{0 !} \\mathrm{e}^{-0.5}+\\frac{0.5^{1}}{1 !} \\mathrm{e}^{-0.5}=0.91 .\n$$  \n至少有 2 个砂眼的概率为  \n$$\nP(X \\geqslant 2)=1-P(X \\leqslant 1)=0.09 .\n$$  \n例 2.4.5: 某商店出售某种商品, 由历史销售记录分析表明, 月销售量 (件) 服从参数为 8 的泊松分布, 问在月初进货时,需要多少库存量,才能有 $90 \\%$ 的把握可以满足顾客的需求.  \n解: 以 $X$ 表示这种商品的月销售量, 则 $X \\sim P(8)$. 那么满足要求的是使下式成立的最小正整数 $n$.  \n$$\nP(X \\leqslant n) \\geqslant 0.90 \\text {. }\n$$",
        "metadata": {
            "Header 2": "从上图可以看出",
            "Header 3": "2.4.2 泊松分布"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 以 $X$ 表示这种铸件的砂眼数, 由题意知 $X \\sim P(0.5)$. 则此种铸件上至多有 1 个砂眼的概率为  \n$$\nP(X \\leqslant 1)=\\frac{0.5^{0}}{0 !} \\mathrm{e}^{-0.5}+\\frac{0.5^{1}}{1 !} \\mathrm{e}^{-0.5}=0.91 .\n$$  \n至少有 2 个砂眼的概率为  \n$$\nP(X \\geqslant 2)=1-P(X \\leqslant 1)=0.09 .\n$$  \n例 2.4.5: 某商店出售某种商品, 由历史销售记录分析表明, 月销售量 (件) 服从参数为 8 的泊松分布, 问在月初进货时,需要多少库存量,才能有 $90 \\%$ 的把握可以满足顾客的需求.  \n解: 以 $X$ 表示这种商品的月销售量, 则 $X \\sim P(8)$. 那么满足要求的是使下式成立的最小正整数 $n$.  \n$$\nP(X \\leqslant n) \\geqslant 0.90 \\text {. }\n$$  \n为了寻求此种 $n$, 可以利用泊松分布表, 附表 1 对各种 $\\lambda$ 的值, 给出了泊松分布函数 $P(X \\leqslant x)=$ $\\sum_{k=0}^{n} \\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}$ 的数值表. 在 $\\lambda=8$ 时, 可从附表 1 中查得  \n$$\nP(X \\leqslant 11)=0.888, P(X \\leqslant 12)=0.936 .\n$$  \n所以月初进货 12 (件) 时, 能满足 $93.6 \\%$ 的顾客的需求.",
        "metadata": {
            "Header 2": "从上图可以看出",
            "Header 3": "2.4.2 泊松分布"
        },
        "type": "Document"
    },
    {
        "page_content": "泊松分布还有一个非常实用的特性, 即可以用泊松分布作为二项分布的一种近似. 在二项分布 $b(n, p)$ 中, 当 $n$ 较大时, 计算量是令人烦恼的. 而在 $p$ 较小时使用以下的泊松定理, 可以减少二项分布中的计算量.\n定理 2.4 .1 (泊松定理). 在 $n$ 重伯努利试验中, 记事件 $A$ 在一次试验中发生的概率为 $p_{n}$ (与试验次数 $n$ 有关), 如果当 $n \\rightarrow+\\infty$ 时, 有 $n p_{n} \\rightarrow \\lambda$, 则  \n$$\n\\lim _{n \\rightarrow+\\infty}\\left(\\begin{array}{l}\nn  \\tag{2.4.4}\\\\\nk\n\\end{array}\\right) p_{n}^{k}\\left(1-p_{n}\\right)^{n-k}=\\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}\n$$  \n证明: 记 $n p_{n}=\\lambda_{n}$, 记 $p_{n}=\\lambda_{n} / n$,我们可得  \n$$\n\\begin{aligned}\n\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p_{n}^{k}\\left(1-p_{n}\\right)^{n-k} & =\\frac{n(n-1) \\cdots(n-k+1)}{k !}\\left(\\frac{\\lambda_{n}}{n}\\right)^{k}\\left(1-\\frac{\\lambda_{n}}{n}\\right)^{n-k} \\\\\n& =\\frac{\\lambda_{n}^{k}}{k !}\\left(1-\\frac{1}{n}\\right)\\left(1-\\frac{2}{n}\\right) \\cdots\\left(1-\\frac{k-1}{n}\\right)\\left(1-\\frac{\\lambda_{n}}{n}\\right)^{n-k} .\n\\end{aligned}\n$$  \n对固定的 $k$ 有  \n$$",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n证明: 记 $n p_{n}=\\lambda_{n}$, 记 $p_{n}=\\lambda_{n} / n$,我们可得  \n$$\n\\begin{aligned}\n\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p_{n}^{k}\\left(1-p_{n}\\right)^{n-k} & =\\frac{n(n-1) \\cdots(n-k+1)}{k !}\\left(\\frac{\\lambda_{n}}{n}\\right)^{k}\\left(1-\\frac{\\lambda_{n}}{n}\\right)^{n-k} \\\\\n& =\\frac{\\lambda_{n}^{k}}{k !}\\left(1-\\frac{1}{n}\\right)\\left(1-\\frac{2}{n}\\right) \\cdots\\left(1-\\frac{k-1}{n}\\right)\\left(1-\\frac{\\lambda_{n}}{n}\\right)^{n-k} .\n\\end{aligned}\n$$  \n对固定的 $k$ 有  \n$$\n\\lim _{n \\rightarrow+\\infty} \\lambda_{n}=\\lambda ; \\quad \\lim _{n \\rightarrow+\\infty}\\left(1-\\frac{\\lambda_{n}}{n}\\right)^{n-k}=\\mathrm{e}^{-\\lambda} ; \\lim _{n \\rightarrow+\\infty}\\left(1-\\frac{1}{n}\\right) \\cdots\\left(1-\\frac{k-1}{n}\\right)=1\n$$  \n从而  \n$$\n\\lim _{n \\rightarrow+\\infty}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p_{n}^{k}\\left(1-p_{n}\\right)^{n-k}=\\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}\n$$  \n对任意的 $k(k=0,1,2, \\cdots)$ 成立. 定理得证.",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n对固定的 $k$ 有  \n$$\n\\lim _{n \\rightarrow+\\infty} \\lambda_{n}=\\lambda ; \\quad \\lim _{n \\rightarrow+\\infty}\\left(1-\\frac{\\lambda_{n}}{n}\\right)^{n-k}=\\mathrm{e}^{-\\lambda} ; \\lim _{n \\rightarrow+\\infty}\\left(1-\\frac{1}{n}\\right) \\cdots\\left(1-\\frac{k-1}{n}\\right)=1\n$$  \n从而  \n$$\n\\lim _{n \\rightarrow+\\infty}\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p_{n}^{k}\\left(1-p_{n}\\right)^{n-k}=\\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}\n$$  \n对任意的 $k(k=0,1,2, \\cdots)$ 成立. 定理得证.  \n由于泊松定理是在 $n p_{n} \\rightarrow \\lambda$ 条件下获得的,故在计算二项分布 $b(n, p)$ 时, 当 $n$ 很大, $p$ 很小,而乘积 $\\lambda=n p$ 大小适中时,可以用泊松分布作近似, 即  \n$$\n\\left(\\begin{array}{l}\nn  \\tag{2.4.5}\\\\\nk\n\\end{array}\\right) p_{n}^{k}\\left(1-p_{n}\\right)^{n-k} \\approx \\frac{(n p)^{k}}{k !} \\mathrm{e}^{-n p}, k=0,1,2, \\cdots .\n$$  \n| $k$ | ! |  |  |  | 泊松近似 <br> 按 $\\frac{(n p)^{k}}{k !} \\mathrm{e}^{-n p}$ 计算 |\n| :---: | :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n对任意的 $k(k=0,1,2, \\cdots)$ 成立. 定理得证.  \n由于泊松定理是在 $n p_{n} \\rightarrow \\lambda$ 条件下获得的,故在计算二项分布 $b(n, p)$ 时, 当 $n$ 很大, $p$ 很小,而乘积 $\\lambda=n p$ 大小适中时,可以用泊松分布作近似, 即  \n$$\n\\left(\\begin{array}{l}\nn  \\tag{2.4.5}\\\\\nk\n\\end{array}\\right) p_{n}^{k}\\left(1-p_{n}\\right)^{n-k} \\approx \\frac{(n p)^{k}}{k !} \\mathrm{e}^{-n p}, k=0,1,2, \\cdots .\n$$  \n| $k$ | ! |  |  |  | 泊松近似 <br> 按 $\\frac{(n p)^{k}}{k !} \\mathrm{e}^{-n p}$ 计算 |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  | $n=10$ <br> $p=0.1$ | $n=20$ <br> $p=0.05$ | $n=40$ <br> $p=0.025$ | $n=100$ <br> $p=0.01$ | $\\lambda=n p=1$ |\n| 0 | 0.349 | 0.358 | 0.363 | 0.366 | 0.368 |\n| 1 | 0.385 | 0.377 | 0.372 | 0.370 | 0.368 |\n| 2 | 0.194 | 0.189 | 0.186 | 0.185 | 0.184 |\n| 3 | 0.057 | 0.060 | 0.060 | 0.061 | 0.061 |\n| 4 | 0.011 | 0.013 | 0.014 | 0.015 | 0.004 |\n| $>4$ | 0.004 | 0.003 | 0.005 | 0.003 | 0.004 |  \n表 2.4 .3 给出了按二项分布直接计算与利用泊松分布作近似的一些具体数据. 从表中可以看出,两者的结果是很接近的,而且当 $\\mathrm{n}$ 愈大和 $\\mathrm{p}$ 意小时,近似程度越好.  \n表 2.4.3: 二项分布与泊松近似的比较",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "| 0 | 0.349 | 0.358 | 0.363 | 0.366 | 0.368 |\n| 1 | 0.385 | 0.377 | 0.372 | 0.370 | 0.368 |\n| 2 | 0.194 | 0.189 | 0.186 | 0.185 | 0.184 |\n| 3 | 0.057 | 0.060 | 0.060 | 0.061 | 0.061 |\n| 4 | 0.011 | 0.013 | 0.014 | 0.015 | 0.004 |\n| $>4$ | 0.004 | 0.003 | 0.005 | 0.003 | 0.004 |  \n表 2.4 .3 给出了按二项分布直接计算与利用泊松分布作近似的一些具体数据. 从表中可以看出,两者的结果是很接近的,而且当 $\\mathrm{n}$ 愈大和 $\\mathrm{p}$ 意小时,近似程度越好.  \n表 2.4.3: 二项分布与泊松近似的比较  \n以下给出一些利用泊松分布作近似计算的例子.  \n例 2.4.6: 已知某种疾病的发病率为 0.001 , 某单位共有 5000 人. 问该单位患有这种疾病的人数不超过 5 人的概率为多少?  \n解: 设该单位患有这种疾病的人数为 $X$, 则有 $X \\sim b(5000,0.001)$, 而我们所求的为  \n$$\nP(X \\leqslant 5)=\\sum_{k=0}^{5}\\left(\\begin{array}{c}\n5000 \\\\\nk\n\\end{array}\\right) 0.001^{k} 0.999^{5000-k},\n$$  \n这个概率的计算量很大. 由于 $n$ 很大, $p$ 很小, 且 $\\lambda=n p=5$. 所以用泊松近似得  \n$$\nP(X \\leqslant 5) \\approx \\sum_{k=0}^{5} \\frac{5^{k}}{k !} \\mathrm{e}^{-5}=0.616\n$$  \n解: 有 10000 名同年龄段且同社会阶层的人参加了某保险公司的一项人寿保险. 每个投保人在每\n年初需交纳 200 元保费,而在这一年中若投保人死亡,则受益人可从保险公司获得 100000 元的赔偿费. 据生命表知这类人的年死亡率为 0.001 . 试求保险公司在这项业务上  \n(1) 亏本的概率.",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 设该单位患有这种疾病的人数为 $X$, 则有 $X \\sim b(5000,0.001)$, 而我们所求的为  \n$$\nP(X \\leqslant 5)=\\sum_{k=0}^{5}\\left(\\begin{array}{c}\n5000 \\\\\nk\n\\end{array}\\right) 0.001^{k} 0.999^{5000-k},\n$$  \n这个概率的计算量很大. 由于 $n$ 很大, $p$ 很小, 且 $\\lambda=n p=5$. 所以用泊松近似得  \n$$\nP(X \\leqslant 5) \\approx \\sum_{k=0}^{5} \\frac{5^{k}}{k !} \\mathrm{e}^{-5}=0.616\n$$  \n解: 有 10000 名同年龄段且同社会阶层的人参加了某保险公司的一项人寿保险. 每个投保人在每\n年初需交纳 200 元保费,而在这一年中若投保人死亡,则受益人可从保险公司获得 100000 元的赔偿费. 据生命表知这类人的年死亡率为 0.001 . 试求保险公司在这项业务上  \n(1) 亏本的概率.  \n(2) 至少获利 500000 元的概率.  \n解：设 $X$ 为 10000 名投保人在一年中死亡的人数, 则 $X$ 服从二项分布 $b(10000,0.001)$. 保险公司在这项业务上一年的总收人为 $200 \\times 10000=2000000$ (元). 因为 $n=10000$ 很大, $p=0.001$ 很小,所以用 $\\lambda=n p=10$ 的泊松分布进行近似计算.  \n(1) 保险公司在这项业务上“亏本”就相当于 $\\{X>20\\}$. 因此所求概率为  \n$$\nP(X>20)=1-P(X \\leqslant 20) \\approx 1-\\sum_{k=0}^{20} \\frac{10^{k}}{k !} \\mathrm{e}^{-10}=1-0.998=0.002 .\n$$  \n由此可看出, 保险公司在这项业务上亏本的可能性是微小的.  \n(2) 保险公司在这项业务上 “至少获利 500000 元”就相当于是 $\\{X \\leqslant 15\\}$. 因此所求概率为  \n$$",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 亏本的概率.  \n(2) 至少获利 500000 元的概率.  \n解：设 $X$ 为 10000 名投保人在一年中死亡的人数, 则 $X$ 服从二项分布 $b(10000,0.001)$. 保险公司在这项业务上一年的总收人为 $200 \\times 10000=2000000$ (元). 因为 $n=10000$ 很大, $p=0.001$ 很小,所以用 $\\lambda=n p=10$ 的泊松分布进行近似计算.  \n(1) 保险公司在这项业务上“亏本”就相当于 $\\{X>20\\}$. 因此所求概率为  \n$$\nP(X>20)=1-P(X \\leqslant 20) \\approx 1-\\sum_{k=0}^{20} \\frac{10^{k}}{k !} \\mathrm{e}^{-10}=1-0.998=0.002 .\n$$  \n由此可看出, 保险公司在这项业务上亏本的可能性是微小的.  \n(2) 保险公司在这项业务上 “至少获利 500000 元”就相当于是 $\\{X \\leqslant 15\\}$. 因此所求概率为  \n$$\nP(X \\leqslant 15) \\approx \\sum_{k=0}^{15} \\frac{20^{k}}{k !} \\mathrm{e}^{-10}=0.951\n$$  \n由此可看出, 保险公司在这项业务上至少获利 500000 元的可能性很大.  \n例 2.4.7: 为保证设备正常工作, 需要配备一些维修工. 如果各台设备发生故障是相互独立的, 且每台设备发生故障的概率都是 0.01. 试在以下各种情况下, 求设备发生故障而不能及时修理的概率.  \n(1) 一名维修工负责 20 台设备.  \n(2) 3 名维修工负责 90 台设备.  \n(3) 10 名维修工负责 500 台设备.  \n解: (1) 以 $X_{1}$ 表示 20 台设备中同时发生故障的台数, 则 $X_{1} \\sim b(20,0.01)$. 用参数为 $\\lambda=n p=$ $20 \\times 0.01=0.2$ 的泊松分布作近似计算, 得所求概率为  \n$$",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(X \\leqslant 15) \\approx \\sum_{k=0}^{15} \\frac{20^{k}}{k !} \\mathrm{e}^{-10}=0.951\n$$  \n由此可看出, 保险公司在这项业务上至少获利 500000 元的可能性很大.  \n例 2.4.7: 为保证设备正常工作, 需要配备一些维修工. 如果各台设备发生故障是相互独立的, 且每台设备发生故障的概率都是 0.01. 试在以下各种情况下, 求设备发生故障而不能及时修理的概率.  \n(1) 一名维修工负责 20 台设备.  \n(2) 3 名维修工负责 90 台设备.  \n(3) 10 名维修工负责 500 台设备.  \n解: (1) 以 $X_{1}$ 表示 20 台设备中同时发生故障的台数, 则 $X_{1} \\sim b(20,0.01)$. 用参数为 $\\lambda=n p=$ $20 \\times 0.01=0.2$ 的泊松分布作近似计算, 得所求概率为  \n$$\nP\\left(X_{1}>1\\right) \\approx 1-\\sum_{k=0}^{1} \\frac{0.2^{k}}{k !} \\mathrm{e}^{-0.2}=1-0.982=0.018\n$$  \n(2) 以 $X_{2}$ 表示 90 台设备中同时发生故障的台数, 则 $X_{2} \\sim b(90,0.01)$. 用参数为 $\\lambda=n p=$ $90 \\times 0.01=0.9$ 的泊松分布作近似计算, 得所求概率为  \n$$\nP\\left(X_{2}>3\\right) \\approx 1-\\sum_{k=0}^{3} \\frac{0.9^{k}}{k !} \\mathrm{e}^{-0.9}=1-0.0987=0.013\n$$  \n注意, 此种情况下, 不但所求概率比 (1) 中有所降低, 而且 3 名维修工负责 90 台设备相当于每个维修工负责 30 台设备,工作效率是 (1) 中的 1.5 倍.  \n(3) 以 $X_{3}$ 表示 500 台设备中同时发生故障的台数, 则 $X_{3} \\sim b(500,0.01)$. 用参数为 $\\lambda=n p=$ $500 \\times 0.01=5$ 的泊松分布作近似计算, 得所求概率为  \n$$",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n(2) 以 $X_{2}$ 表示 90 台设备中同时发生故障的台数, 则 $X_{2} \\sim b(90,0.01)$. 用参数为 $\\lambda=n p=$ $90 \\times 0.01=0.9$ 的泊松分布作近似计算, 得所求概率为  \n$$\nP\\left(X_{2}>3\\right) \\approx 1-\\sum_{k=0}^{3} \\frac{0.9^{k}}{k !} \\mathrm{e}^{-0.9}=1-0.0987=0.013\n$$  \n注意, 此种情况下, 不但所求概率比 (1) 中有所降低, 而且 3 名维修工负责 90 台设备相当于每个维修工负责 30 台设备,工作效率是 (1) 中的 1.5 倍.  \n(3) 以 $X_{3}$ 表示 500 台设备中同时发生故障的台数, 则 $X_{3} \\sim b(500,0.01)$. 用参数为 $\\lambda=n p=$ $500 \\times 0.01=5$ 的泊松分布作近似计算, 得所求概率为  \n$$\nP\\left(X_{3}>10\\right) \\approx 1-\\sum_{k=0}^{10} \\frac{5^{k}}{k !} \\mathrm{e}^{-5}=1-0.0986=0.014\n$$  \n注意, 此种情况下所求概率与 (2) 中基本上一样, 而 10 名维修工负责 500 台设备相当于每个维修工负责 50 台设备,工作效率是 (2) 中的 1.67 倍,是 (1) 中的 2.5 倍.  \n由此可知:若干维修工共同负责大量设备的维修,将提高工作的效率.",
        "metadata": {
            "Header 2": "三、二项分布的泊松近似"
        },
        "type": "Document"
    },
    {
        "page_content": "从一个有限总体中进行不放回抽样常会遇到超几何分布.\n设有 $N$ 个产品, 其中有 $M$ 个不合格品. 若从中不放回地随机抽取 $n$ 个, 则其中含有的不合格品的个数 $X$ 服从超几何分布, 记为 $X \\sim h(n, N, M)$. 超几何分布的概率分布列为 (见第 ?? 章中例 ??)  \n$$\nP(X=k)=\\frac{\\left(\\begin{array}{c}\nM  \\tag{2.4.6}\\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}, k=0,1, \\cdots, r\n$$  \n其中 $r=\\min \\{M, n\\}$, 且 $M \\leqslant N, n \\leqslant N, n, N, M$ 均为正整数.  \n若要验证以上给出的确实为一个概率分布列, 只须注意到有组合等式 (见习题 ?? )  \n$$\n\\sum_{k=0}^{r}\\left(\\begin{array}{c}\nM \\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)=\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)\n$$  \n即可.  \n超几何分布是一种常用的离散分布,它在抽样理论中占有重要地位.",
        "metadata": {
            "Header 2": "一、超几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "若 $X \\sim h(n, N, M)$, 则 $X$ 的数学期望为  \n$$\nE(X)=\\sum_{k=0}^{r} k \\frac{\\left(\\begin{array}{c}\nM \\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{c}\nN \\\\\nn\n\\end{array}\\right)}=n \\frac{M}{N} \\sum_{k=1}^{r} \\frac{\\left(\\begin{array}{c}\nM-1 \\\\\nk-1\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{c}\nN-1 \\\\\nn-1\n\\end{array}\\right)}=n \\frac{M}{N}\n$$  \n又因为  \n$$\n\\begin{aligned}\nE\\left(X^{2}\\right) & =\\sum_{k=1}^{r} k^{2} \\frac{\\left(\\begin{array}{c}\nM \\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}=\\sum_{k=2}^{r} k(k-1) \\frac{\\left(\\begin{array}{c}\nM \\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}+n \\frac{M}{N} \\\\\n& =\\frac{M(M-1)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)} \\sum_{k=2}^{r} k(k-1)\\left(\\begin{array}{c}\nM-2 \\\\\nk-2",
        "metadata": {
            "Header 2": "二、超几何分布的数学期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "M \\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}=\\sum_{k=2}^{r} k(k-1) \\frac{\\left(\\begin{array}{c}\nM \\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}+n \\frac{M}{N} \\\\\n& =\\frac{M(M-1)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)} \\sum_{k=2}^{r} k(k-1)\\left(\\begin{array}{c}\nM-2 \\\\\nk-2\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)+n \\frac{M}{N} \\\\\n& =\\frac{M(M-1)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}\\left(\\begin{array}{l}\nN-2 \\\\\nn-2\n\\end{array}\\right)+n \\frac{M}{N}=\\frac{M(M-1) n(n-1)}{N(N-1)}+n \\frac{M}{N},\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=\\frac{n M(N-M)(N-n)}{N^{2}(N-1)}\n$$",
        "metadata": {
            "Header 2": "二、超几何分布的数学期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "当 $n \\ll N$ 时, 即抽取个数 $n$ 远小于产品总数 $N$ 时, 每次抽取后, 总体中的不合格品率 $p=M / N$ 改变甚徽, 所以不放回抽样可近似地看成放回抽样, 这时超几何分布可用二项分布近似:  \n$$\n\\frac{\\left(\\begin{array}{c}\nM  \\tag{2.4.7}\\\\\nk\n\\end{array}\\right)\\left(\\begin{array}{c}\nN-M \\\\\nn-k\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)} \\cong\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n-k}, \\text { 其中 } p=\\frac{M}{N} .\n$$",
        "metadata": {
            "Header 2": "三。超几何分布的二项近似"
        },
        "type": "Document"
    },
    {
        "page_content": "在伯努利试验序列中, 记每次试验中事件 $A$ 发生的概率为 $p$, 如果 $X$ 为事件 $A$ 首次出现时的试验次数, 则 $X$ 的可能取值为 $1,2, \\cdots$, 称 $X$ 服从几何分布, 记为 $X \\sim G e(p)$, 其分布列为  \n$$\n\\begin{equation*}\nP(X=k)=(1-p)^{k-1} p, k=1,2, \\cdots . \\tag{2.4.8}\n\\end{equation*}\n$$  \n实际中有不少随机变量服从几何分布,譬如,  \n- 某产品的不合格率为 0.05 , 则首次查到不合格品的检查次数 $X \\sim G e(0.05)$;\n- 某射手的命中率为 0.8 , 则首次击中目标的射击次数 $Y \\sim G e(0.8)$;\n- 掷一颗骰子,首次出现 6 点的投郑次数 $Z \\sim G e(1 / 6)$;\n- 同时郑两颗骰子, 首次达到两个点数之和为 8 的投郑次数 $W \\sim G e(5 / 36)$.  \n二、几何分布的数学期望和方差  \n设随机变量 $X$ 服从几何分布 $G e(p)$, 令 $q=1-p$, 利用逐项微分可得 $X$ 的数学期望为  \n$$\n\\begin{aligned}\nE(X) & =\\sum_{k=1}^{+\\infty} k p q^{k-1}=p \\sum_{k=1}^{+\\infty} k q^{k-1}=p \\sum_{k=1}^{+\\infty} \\frac{\\mathrm{d} q^{k}}{\\mathrm{~d} q} \\\\\n& =p \\frac{\\mathrm{d}}{\\mathrm{d} q}\\left(\\sum_{k=0}^{+\\infty} q^{k}\\right)=p \\frac{\\mathrm{d}}{\\mathrm{d} q}\\left(\\frac{1}{1-q}\\right)=\\frac{p}{(1-q)^{2}}=\\frac{1}{p}\n\\end{aligned}\n$$  \n又因为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "一。几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "二、几何分布的数学期望和方差  \n设随机变量 $X$ 服从几何分布 $G e(p)$, 令 $q=1-p$, 利用逐项微分可得 $X$ 的数学期望为  \n$$\n\\begin{aligned}\nE(X) & =\\sum_{k=1}^{+\\infty} k p q^{k-1}=p \\sum_{k=1}^{+\\infty} k q^{k-1}=p \\sum_{k=1}^{+\\infty} \\frac{\\mathrm{d} q^{k}}{\\mathrm{~d} q} \\\\\n& =p \\frac{\\mathrm{d}}{\\mathrm{d} q}\\left(\\sum_{k=0}^{+\\infty} q^{k}\\right)=p \\frac{\\mathrm{d}}{\\mathrm{d} q}\\left(\\frac{1}{1-q}\\right)=\\frac{p}{(1-q)^{2}}=\\frac{1}{p}\n\\end{aligned}\n$$  \n又因为  \n$$\n\\begin{aligned}\nE\\left(X^{2}\\right) & =\\sum_{k=1}^{+\\infty} k^{2} p q^{k-1}=p\\left[\\sum_{k=1}^{+\\infty} k(k-1) q^{k-1}+\\sum_{k=1}^{+\\infty} k q^{k-1}\\right] \\\\\n& =p q \\sum_{k=1}^{+\\infty} k(k-1) q^{k-2}+\\frac{1}{p}=p q \\sum_{k=1}^{+\\infty} \\frac{\\mathrm{d}^{2}}{\\mathrm{~d} q^{2}} q^{k}+\\frac{1}{p} \\\\\n& =p q \\frac{\\mathrm{d}^{2}}{\\mathrm{~d} q^{2}}\\left(\\sum_{k=1}^{+\\infty} q^{k}\\right)+\\frac{1}{p}=p q \\frac{\\mathrm{d}^{2}}{\\mathrm{~d} q^{2}}\\left(\\frac{1}{1-q}\\right)+\\frac{1}{p} \\\\\n& =p q \\frac{2}{(1-q)^{3}}+\\frac{1}{p}=\\frac{2 q}{p^{2}}+\\frac{1}{p},",
        "metadata": {
            "Header 2": "一。几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =p q \\sum_{k=1}^{+\\infty} k(k-1) q^{k-2}+\\frac{1}{p}=p q \\sum_{k=1}^{+\\infty} \\frac{\\mathrm{d}^{2}}{\\mathrm{~d} q^{2}} q^{k}+\\frac{1}{p} \\\\\n& =p q \\frac{\\mathrm{d}^{2}}{\\mathrm{~d} q^{2}}\\left(\\sum_{k=1}^{+\\infty} q^{k}\\right)+\\frac{1}{p}=p q \\frac{\\mathrm{d}^{2}}{\\mathrm{~d} q^{2}}\\left(\\frac{1}{1-q}\\right)+\\frac{1}{p} \\\\\n& =p q \\frac{2}{(1-q)^{3}}+\\frac{1}{p}=\\frac{2 q}{p^{2}}+\\frac{1}{p},\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=\\frac{2 q}{p^{2}}+\\frac{1}{p}-\\frac{1}{p^{2}}=\\frac{1-p}{p^{2}}\n$$  \n三、几何分布的无记忆性  \n定理 2.4.2 (几何分饰的无记忆性). 设 $X \\sim G e(p)$, 则对任意正整数 $m$ 与 $n$ 有  \n$$\n\\begin{equation*}\nP(X>m+n \\mid X>m)=P(X>n) \\text {. } \\tag{2.4.9}\n\\end{equation*}\n$$  \n在证明之前先解释上述概率等式的含义. 在一列伯努利试验序列中, 若首次成功 $(A)$ 出现的试验次数 X 服从几何分布,则事件 “ $X>m$ ”表示前 $m$ 次试验中 $A$ 没有出现. 假如在接下去的 $n$ 次试验中 $A$ 仍未出现, 这个事件记为 “ $X>m+n$ ”. 这个定理表明: 在前 $m$ 次试验中 $A$ 没有出现的条件下, 则在接下去的 $n$ 次试验中 $A$ 仍未出现的概率只与 $n$ 有关, 而与以前的 $m$ 次试验无关, 似乎忘记了前 $m$ 次试验结果, 这就是无记忆性.  \n证明: 因为  \n$$",
        "metadata": {
            "Header 2": "一。几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n三、几何分布的无记忆性  \n定理 2.4.2 (几何分饰的无记忆性). 设 $X \\sim G e(p)$, 则对任意正整数 $m$ 与 $n$ 有  \n$$\n\\begin{equation*}\nP(X>m+n \\mid X>m)=P(X>n) \\text {. } \\tag{2.4.9}\n\\end{equation*}\n$$  \n在证明之前先解释上述概率等式的含义. 在一列伯努利试验序列中, 若首次成功 $(A)$ 出现的试验次数 X 服从几何分布,则事件 “ $X>m$ ”表示前 $m$ 次试验中 $A$ 没有出现. 假如在接下去的 $n$ 次试验中 $A$ 仍未出现, 这个事件记为 “ $X>m+n$ ”. 这个定理表明: 在前 $m$ 次试验中 $A$ 没有出现的条件下, 则在接下去的 $n$ 次试验中 $A$ 仍未出现的概率只与 $n$ 有关, 而与以前的 $m$ 次试验无关, 似乎忘记了前 $m$ 次试验结果, 这就是无记忆性.  \n证明: 因为  \n$$\nP(X>n)=\\sum_{k=n+1}^{+\\infty}(1-p)^{k-1} p=\\frac{p(1-p)^{n}}{1-(1-p)}=(1-p)^{n}\n$$  \n所以对任意的正整数 $m$ 与 $n$,条件概率  \n$$\n\\begin{aligned}\nP(X>m+n \\mid X>m) & =\\frac{P(X>m+n)}{P(X>m)}=\\frac{(1-p)^{m+n}}{(1-p)^{m}} \\\\\n& =(1-p)^{n}=P(X>n)\n\\end{aligned}\n$$  \n这就证得了 (2.4.9) 式.  \n四、负二项分布  \n作为几何分布的一种延伸,我们注意下面的负二项分布,亦称巴斯卡分布：  \n在伯努利试验序列中, 记每次试验中事件 $A$ 发生的概率为 $p$, 如果 $X$ 为事件 $A$ 第 $r$ 次出现时\n的试验次数, 则 $X$ 的可能取值为 $r, r+1, \\cdots, r+m, \\cdots$. 称 $X$ 服从负二项分布或巴斯卡分布, 其分布列为  \n$$\nP(X=k)=\\left(\\begin{array}{l}\nk-1  \\tag{2.4.10}\\\\\nr-1",
        "metadata": {
            "Header 2": "一。几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n所以对任意的正整数 $m$ 与 $n$,条件概率  \n$$\n\\begin{aligned}\nP(X>m+n \\mid X>m) & =\\frac{P(X>m+n)}{P(X>m)}=\\frac{(1-p)^{m+n}}{(1-p)^{m}} \\\\\n& =(1-p)^{n}=P(X>n)\n\\end{aligned}\n$$  \n这就证得了 (2.4.9) 式.  \n四、负二项分布  \n作为几何分布的一种延伸,我们注意下面的负二项分布,亦称巴斯卡分布：  \n在伯努利试验序列中, 记每次试验中事件 $A$ 发生的概率为 $p$, 如果 $X$ 为事件 $A$ 第 $r$ 次出现时\n的试验次数, 则 $X$ 的可能取值为 $r, r+1, \\cdots, r+m, \\cdots$. 称 $X$ 服从负二项分布或巴斯卡分布, 其分布列为  \n$$\nP(X=k)=\\left(\\begin{array}{l}\nk-1  \\tag{2.4.10}\\\\\nr-1\n\\end{array}\\right) p^{r}(1-p)^{k-r}, k=r, r+1, \\cdots .\n$$  \n记为 $X \\sim N b(r, p)$. 当 $r=1$ 时,即为几何分布.  \n这是因为在次伯努利试验中, 最后一次一定是 $A$, 而前 $k-1$ 次中 $A$ 应出现 $r-1$ 次, 由二项分布知其概率为 $\\left(\\begin{array}{c}k-1 \\\\ r-1\\end{array}\\right) p^{r-1}(1-p)^{k-r}$, 再乘以最后一次出现 $A$ 的概率 $p$, 即得 (2.4.10).  \n可以算得负二项分布的数学期望为 $r / p$, 方差为 $r(1-p) / p^{2}$. 从直观上看这是合理的, 因为首次出现 $A$ 的平均试验次数是 $1 / p$, 那么第 $r$ 个 $A$ 出现所需的平均试验次数是 $r / p$.",
        "metadata": {
            "Header 2": "一。几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(X=k)=\\left(\\begin{array}{l}\nk-1  \\tag{2.4.10}\\\\\nr-1\n\\end{array}\\right) p^{r}(1-p)^{k-r}, k=r, r+1, \\cdots .\n$$  \n记为 $X \\sim N b(r, p)$. 当 $r=1$ 时,即为几何分布.  \n这是因为在次伯努利试验中, 最后一次一定是 $A$, 而前 $k-1$ 次中 $A$ 应出现 $r-1$ 次, 由二项分布知其概率为 $\\left(\\begin{array}{c}k-1 \\\\ r-1\\end{array}\\right) p^{r-1}(1-p)^{k-r}$, 再乘以最后一次出现 $A$ 的概率 $p$, 即得 (2.4.10).  \n可以算得负二项分布的数学期望为 $r / p$, 方差为 $r(1-p) / p^{2}$. 从直观上看这是合理的, 因为首次出现 $A$ 的平均试验次数是 $1 / p$, 那么第 $r$ 个 $A$ 出现所需的平均试验次数是 $r / p$.  \n如果将第一个 $A$ 出现的试验次数记为 $X_{1}$, 第二个 $A$ 出现的试验次数 (从第一个 $A$ 出现之后算起) 记为 $X_{2}$, 第 $r$ 个 $A$ 出现的试验次数 (从第 $r-1$ 个 $A$ 出现之后算起) 记为 $X_{r}$, 则 $X_{i}$ 独立同分布, 且 $X_{i} \\sim G e(p)$. 此时有 $X=X_{1}+X_{2}+\\cdots+X_{r} \\sim N b(r, p)$, 即负二项分布的随机变量可以表示成 $r$ 个独立同分布的几何分布随机变量之和.",
        "metadata": {
            "Header 2": "一。几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 一批产品中有 $10 \\%$ 的不合格品, 现从中任取 3 件, 求其中至多有一件不合格品的撕率.\n2. 一条自动化生产线上产品的一级品率为 0.8 , 现检查 5 件, 求至少有 2 件一级品的概率.\n3. 某优秀射手命中 10 环的概率为 0.7 , 命中 9 环的概率为 0.3 . 试求该射手三次射击所得的环数不少于 29 环的概率.\n4. 经验表明: 预定餐厅座位而不来就餐的顾客比例为 $20 \\%$. 如今餐厅有 50 个座位,但预定给了 52 位顾客, 问到时顾客来到餐厅而没有座位的概率是多少?\n5. 设随机变量 $X \\sim b(n, p)$, 已知 $E(X)=2.4, \\operatorname{Var}(X)=1.44$, 求两个参数 $n$ 与 $p$ 各为多少?\n6. 设随机变量 $X$ 服从二项分布 $b(2, p)$, 随机变量 $Y$ 服从二项分布 $b(4, p)$. 若 $P(X \\mid g e 1)=8 / 9$,试求 $P(Y \\geqslant 1)$.\n7. 一批产品的不合格品率为 0.02 , 现从中任取 40 只进行检查, 若发现两只或两只以土不合格品就拒收这批产品. 分别用以下方法求拒收的概率:(1) 用二项分布作精确计算;(2) 用泊松分布作近似计算.\n8. 设 $X$ 服从泊松分布, 且已知 $P(X=1)=P(X=2)$, 求 $P(X=4)$.\n9. 已知某商场一天来的顾客数 $X$ 服从参数为 $\\lambda$ 的泊松分布, 而每个来到商场的顾客购物的概率为 $p$, 证明: 此商场一天内购物的顾客数服从参数为 $\\lambda p$ 的泊松分布.\n10. 从一个装有 $m$ 个白球、 $n$ 个黑球的袋中返回地摸球, 直到摸到白球时停止. 试求取出黑球数的期望.\n11. 某种产品上的缺陷数 $X$ 服从下列分布列:  \n求此种产品上的平均缺陷数.  \n$$\nP(X=k)=\\frac{1}{2^{k+1}}, k=0,1, \\cdots,\n$$  \n12. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}2 x, & 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$",
        "metadata": {
            "Header 2": "■习题 2.4"
        },
        "type": "Document"
    },
    {
        "page_content": "8. 设 $X$ 服从泊松分布, 且已知 $P(X=1)=P(X=2)$, 求 $P(X=4)$.\n9. 已知某商场一天来的顾客数 $X$ 服从参数为 $\\lambda$ 的泊松分布, 而每个来到商场的顾客购物的概率为 $p$, 证明: 此商场一天内购物的顾客数服从参数为 $\\lambda p$ 的泊松分布.\n10. 从一个装有 $m$ 个白球、 $n$ 个黑球的袋中返回地摸球, 直到摸到白球时停止. 试求取出黑球数的期望.\n11. 某种产品上的缺陷数 $X$ 服从下列分布列:  \n求此种产品上的平均缺陷数.  \n$$\nP(X=k)=\\frac{1}{2^{k+1}}, k=0,1, \\cdots,\n$$  \n12. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}2 x, & 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n以 $Y$ 表示对 $X$ 的三次独立重复观察中事件 $\\{X \\leqslant 1 / 2\\}$ 出现的次数,试求 $P(Y=2)$.  \n13. 某产品的不合格品率为 0.1 , 每次随机抽取 10 件进行检验, 若发现其中不合格品数多于 1 , 就去调整设备, 若检验员每天检验 4 次, 试同每天平均要调整几次设备.",
        "metadata": {
            "Header 2": "■习题 2.4"
        },
        "type": "Document"
    },
    {
        "page_content": "正态分布是概率论与数理统计中最重要的一个分布, 高斯 (Gauss) 在研究误差理论时首先用正态分布来刻画误差的分布,所以正态分布又称为高斯分布. 本书第四章的中心极限定理表明:一个变量如果是由大量微小的、独立的随机因素的叠加结果, 那么这个变量一定是正态变量. 因此很多随机变量可以用正态分布描述或近似描述,譬如测量误差、产品重量、人的身高、年降雨量等都可用正态分布描述.",
        "metadata": {
            "Header 2": "2.5 常用连续分布",
            "Header 3": "2.5.1 正态分布"
        },
        "type": "Document"
    },
    {
        "page_content": "若随机变量 $X$ 的密度函数为  \n$$\n\\begin{equation*}\np(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\mathrm{e}^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}},-\\infty<x<+\\infty \\tag{2.5.1}\n\\end{equation*}\n$$  \n则称 $X$ 服从正态分布, 称 $X$ 为正态变量, 记作 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$. 其中参数 $-\\infty<\\mu<+\\infty, \\sigma>0$.其密度函数 $p(x)$ 的图形如图 2.5.1(a) 所示. $p(x)$ 是一条钟形曲线, 中间高、二边低、左右关于 $\\mu$ 对称, $\\mu$ 是正态分布的中心, 且在 $x=\\mu$ 附近取值的可能性大, 在两侧取值的可能性小. $\\mu \\pm \\sigma$ 是该曲线的拐点.  \n!  \n(a) 密度函数 $p(x)$  \n!  \n(b) 分布函数 $F(x)$  \n图 2.5.1: 正态分布  \n正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的分布函数为  \n$$\n\\begin{equation*}\nF(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\int_{-\\infty}^{x} \\mathrm{e}^{-\\frac{(t-\\mu)^{2}}{2 \\sigma^{2}}} \\mathrm{~d} t . \\tag{2.5.2}\n\\end{equation*}\n$$  \n它是一条光滑上升的 $S$ 形曲线,见图 2.5.1(b).  \n图 ?? 给出了在 $\\mu$ 和 $\\sigma$ 变化时,相应正态密度曲线的变化情况.  \n- 从图 ??(a) 中可以看出:如果固定,改变 $\\mu$ 的值,则图形沿 $x$ 轴平移,而不改变其形状. 也就是说正态密度函数的位置由参数 $\\mu$ 所确定,因此亦称 $\\mu$ 为位置参数.",
        "metadata": {
            "Header 2": "一、正态分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n(a) 密度函数 $p(x)$  \n!  \n(b) 分布函数 $F(x)$  \n图 2.5.1: 正态分布  \n正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的分布函数为  \n$$\n\\begin{equation*}\nF(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\int_{-\\infty}^{x} \\mathrm{e}^{-\\frac{(t-\\mu)^{2}}{2 \\sigma^{2}}} \\mathrm{~d} t . \\tag{2.5.2}\n\\end{equation*}\n$$  \n它是一条光滑上升的 $S$ 形曲线,见图 2.5.1(b).  \n图 ?? 给出了在 $\\mu$ 和 $\\sigma$ 变化时,相应正态密度曲线的变化情况.  \n- 从图 ??(a) 中可以看出:如果固定,改变 $\\mu$ 的值,则图形沿 $x$ 轴平移,而不改变其形状. 也就是说正态密度函数的位置由参数 $\\mu$ 所确定,因此亦称 $\\mu$ 为位置参数.  \n-从图 ??(b) 中可以看出: 如果固定 $\\mu$, 改变 $\\sigma$ 的值,则 $\\sigma$ 愈小, 曲线呈高而瘦; $\\sigma$ 愈大,曲线呈矮而胖. 也就是说正态密度函数的尺度由参数 $\\sigma$ 所确定, 因此称 $\\sigma$ 为尺度参数.  \n二、标准正态分布  \n称 $\\mu=0, \\sigma=1$ 时的正态分布 $N(0,1)$ 为标准正态分布.  \n通常记标准正态变量为 $U$, 记标准正态分布的密度函数为 $\\varphi(u)$, 分布函数为 $\\Phi(u)$, 即  \n$$\n\\begin{gathered}\n\\varphi(u)=\\frac{1}{\\sqrt{2 \\pi}} \\mathrm{e}^{-\\frac{u^{2}}{2}},-\\infty<u<+\\infty, \\\\\n\\Phi(u)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{u} \\mathrm{e}^{-\\frac{t^{2}}{2}} \\mathrm{~d} t,-\\infty<u<+\\infty .\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "一、正态分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "二、标准正态分布  \n称 $\\mu=0, \\sigma=1$ 时的正态分布 $N(0,1)$ 为标准正态分布.  \n通常记标准正态变量为 $U$, 记标准正态分布的密度函数为 $\\varphi(u)$, 分布函数为 $\\Phi(u)$, 即  \n$$\n\\begin{gathered}\n\\varphi(u)=\\frac{1}{\\sqrt{2 \\pi}} \\mathrm{e}^{-\\frac{u^{2}}{2}},-\\infty<u<+\\infty, \\\\\n\\Phi(u)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{u} \\mathrm{e}^{-\\frac{t^{2}}{2}} \\mathrm{~d} t,-\\infty<u<+\\infty .\n\\end{gathered}\n$$  \n由于标准正态分布的分布函数不含任何未知参数, 故其值 $\\Phi(u)=P(U \\leqslant u)$ 完全可以算出,附表 2 对 $u \\geqslant 0$ 给出了 $\\Phi(u)$ 的值,利用这张表可以算得  \n- $\\Phi(-u)=1-\\Phi(u)$.\n- $P(U>u)=1-\\Phi(u)$.\n- $P(a<U<b)=\\Phi(b)-\\Phi(a)$.\n- $P(|U|<c)=2 \\Phi(c)-1$.  \n这些等式都不难推得.  \n例 2.5.1: 设 $U \\sim N(0,1)$, 利用附表 2, 求下列事件的概率:  \n(1) $P(U<1.52)=\\Phi(1.52)=0.9357$.  \n(2) $P(U>1.52)=1-\\Phi(1.52)=1-0.9357=0.0642$.  \n(3) $P(U<-1.52)=1-\\Phi(1.52)=0.0643$.  \n(4) $P(-0.75 \\leqslant U \\leqslant 1.52)=\\Phi(1.52)-\\Phi(-0.75)=\\Phi(1.52)-[1-\\Phi(0.75)]=0.9357-1+$ $0.7734=0.7091$.  \n(5) $P(|U| \\leqslant 1.52)=2 \\Phi(1.52)-1=2 \\times 0.9357-1=0.8714$.",
        "metadata": {
            "Header 2": "一、正态分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "正态分布有一个家族  \n$$\n\\mathscr{P}=\\left\\{N\\left(\\mu, \\sigma^{2}\\right):-\\infty<\\mu<+\\infty, \\sigma>0\\right\\}\n$$  \n标准正态分布 $N(0,1)$ 是其一个成员. 实际上很少有随机变量恰好服从标准正态分布. 以下定理说明:对一般正态分布都可以通过一个线性变换 (标准化 ) 化成标准正态分布. 因此与正态变量有关的一切事件的概率都可通过查标准正态分布函数表获得. 由此可见标准正态分布 $N(0,1)$ 对一般正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的计算起着关键的作用.  \n定理 2.5.1. 若 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 则 $U=(X-\\mu) / \\sigma \\sim N(0,1)$.  \n证明: 记 $X$ 与 $U$ 的分布函数分别为 $\\mathrm{Fx}(\\mathrm{x})$ 与 $\\mathrm{Fu}(\\mathrm{u})$, 则由分布函数的定义知  \n$$\n\\begin{aligned}\nF_{U}(u) & =P(U \\leqslant u)=P\\left(\\frac{X-\\mu}{\\sigma} \\leqslant u\\right) \\\\\n& =P(X \\leqslant \\mu+\\sigma u)=F_{X}(\\mu+\\sigma u) .\n\\end{aligned}\n$$  \n由于正态分布函数是严格单调增函数, 且处处可导, 因此若记 $X$ 与 $U$ 的密度函数分别为 $p_{X}(x)$ 与 $P_{U}(u)$, 则有  \n$$\nP_{U}(u)=\\frac{\\mathrm{d}}{\\mathrm{d} u} F_{X}(\\mu+\\sigma u)=p_{X}(\\mu+\\sigma u) \\cdot \\sigma=\\frac{1}{\\sqrt{2 \\pi}} \\mathrm{e}^{-u^{2} / 2},\n$$  \n由此得  \n$$\nU=\\frac{X-\\mu}{\\sigma} \\sim N(0,1)\n$$",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nF_{U}(u) & =P(U \\leqslant u)=P\\left(\\frac{X-\\mu}{\\sigma} \\leqslant u\\right) \\\\\n& =P(X \\leqslant \\mu+\\sigma u)=F_{X}(\\mu+\\sigma u) .\n\\end{aligned}\n$$  \n由于正态分布函数是严格单调增函数, 且处处可导, 因此若记 $X$ 与 $U$ 的密度函数分别为 $p_{X}(x)$ 与 $P_{U}(u)$, 则有  \n$$\nP_{U}(u)=\\frac{\\mathrm{d}}{\\mathrm{d} u} F_{X}(\\mu+\\sigma u)=p_{X}(\\mu+\\sigma u) \\cdot \\sigma=\\frac{1}{\\sqrt{2 \\pi}} \\mathrm{e}^{-u^{2} / 2},\n$$  \n由此得  \n$$\nU=\\frac{X-\\mu}{\\sigma} \\sim N(0,1)\n$$  \n由以上定理, 我们马上可以得到一些在实际中有用的计算公式, 若 $N\\left(\\mu, \\sigma^{2}\\right)$,则  \n$$\n\\begin{align*}\n& P(X \\leqslant c)=\\Phi\\left(\\frac{c-\\mu}{\\sigma}\\right) .  \\tag{2.5.3}\\\\\n& P(a<X \\leqslant b)=\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right)-\\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right) . \\tag{2.5.4}\n\\end{align*}\n$$  \n例 2.5.2: 设随机变量 $X$ 服从正态分布 $N\\left(108,3^{2}\\right)$,试求  \n(1) $P(102<X<117)$;  \n(2) 常数 $a$, 使得 $P(X<a)=0.95$.  \n解: 利用公式 (2.5.4) 及查附表 2 得  \n(1)  \n$$\n\\begin{aligned}\nP(102<X<117) & =\\Phi\\left(\\frac{117-108}{3}\\right)-\\Phi\\left(\\frac{102-108}{3}\\right) \\\\",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{align*}\n& P(X \\leqslant c)=\\Phi\\left(\\frac{c-\\mu}{\\sigma}\\right) .  \\tag{2.5.3}\\\\\n& P(a<X \\leqslant b)=\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right)-\\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right) . \\tag{2.5.4}\n\\end{align*}\n$$  \n例 2.5.2: 设随机变量 $X$ 服从正态分布 $N\\left(108,3^{2}\\right)$,试求  \n(1) $P(102<X<117)$;  \n(2) 常数 $a$, 使得 $P(X<a)=0.95$.  \n解: 利用公式 (2.5.4) 及查附表 2 得  \n(1)  \n$$\n\\begin{aligned}\nP(102<X<117) & =\\Phi\\left(\\frac{117-108}{3}\\right)-\\Phi\\left(\\frac{102-108}{3}\\right) \\\\\n& =\\Phi(3)-\\Phi(-2)=\\Phi(3)+\\Phi(2)-1 \\\\\n& =0.9987+0.9772-1=0.9759 .\n\\end{aligned}\n$$  \n(2)  \n$$\n\\left.P(X<a)=\\Phi\\left(\\frac{a-108}{3}\\right)=0.95 \\text {, 或 } \\Phi^{-1}() .95\\right)=\\frac{a-108}{3} \\text {, }\n$$  \n其中 $\\Phi^{-1}$ 为 $\\Phi$ 的反函数, 从附表 2 由里向外反查得  \n$$\n\\Phi(1.64)=0.9495, \\quad \\Phi(1.65)=0.9505\n$$  \n再用线性内插法可得 $\\Phi(1.645)=0.95$, 即 $\\Phi^{-1}(0.95)=1.645$, 故  \n从中解得 $a=112.935$.  \n$$\n\\frac{a-108}{3}=1.645\n$$  \n从上例我们可以看出, 有些场合下给定 $\\Phi(x)$ 的值, 可以从附表 2 中由里向外反查表来得到 $a$的值,这种手段在统计中被大量使用.",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\Phi(3)-\\Phi(-2)=\\Phi(3)+\\Phi(2)-1 \\\\\n& =0.9987+0.9772-1=0.9759 .\n\\end{aligned}\n$$  \n(2)  \n$$\n\\left.P(X<a)=\\Phi\\left(\\frac{a-108}{3}\\right)=0.95 \\text {, 或 } \\Phi^{-1}() .95\\right)=\\frac{a-108}{3} \\text {, }\n$$  \n其中 $\\Phi^{-1}$ 为 $\\Phi$ 的反函数, 从附表 2 由里向外反查得  \n$$\n\\Phi(1.64)=0.9495, \\quad \\Phi(1.65)=0.9505\n$$  \n再用线性内插法可得 $\\Phi(1.645)=0.95$, 即 $\\Phi^{-1}(0.95)=1.645$, 故  \n从中解得 $a=112.935$.  \n$$\n\\frac{a-108}{3}=1.645\n$$  \n从上例我们可以看出, 有些场合下给定 $\\Phi(x)$ 的值, 可以从附表 2 中由里向外反查表来得到 $a$的值,这种手段在统计中被大量使用.  \n例 2.5.3: 恒温箱是靠温度调节器根据箱内温度的变化不断进行调整的, 所以恒温箱内的实际温度 $X$ (单位为 ${ }^{\\circ} \\mathrm{C}$ ) 是一个随机变量. 如果将温度调节器设定在 $d^{\\circ} \\mathrm{C}$, 且 $X \\sim N\\left(d, \\sigma^{2}\\right.$ ), 其中 $\\sigma$ 反映的是温度调节器的精度.  \n(1) 当 $d=90^{\\circ} \\mathrm{C}, \\sigma=0.5$ 时, 试求箱内的温度在 $89^{\\circ} \\mathrm{C}$ 至 $91^{\\circ} \\mathrm{C}$ 的概率.  \n(2) 当 $d=90^{\\circ} \\mathrm{C}, \\sigma=2$ 时, 试求箱内的温度在 $89^{\\circ} \\mathrm{C}$ 至 $91^{\\circ} \\mathrm{C}$ 的概率.",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "从上例我们可以看出, 有些场合下给定 $\\Phi(x)$ 的值, 可以从附表 2 中由里向外反查表来得到 $a$的值,这种手段在统计中被大量使用.  \n例 2.5.3: 恒温箱是靠温度调节器根据箱内温度的变化不断进行调整的, 所以恒温箱内的实际温度 $X$ (单位为 ${ }^{\\circ} \\mathrm{C}$ ) 是一个随机变量. 如果将温度调节器设定在 $d^{\\circ} \\mathrm{C}$, 且 $X \\sim N\\left(d, \\sigma^{2}\\right.$ ), 其中 $\\sigma$ 反映的是温度调节器的精度.  \n(1) 当 $d=90^{\\circ} \\mathrm{C}, \\sigma=0.5$ 时, 试求箱内的温度在 $89^{\\circ} \\mathrm{C}$ 至 $91^{\\circ} \\mathrm{C}$ 的概率.  \n(2) 当 $d=90^{\\circ} \\mathrm{C}, \\sigma=2$ 时, 试求箱内的温度在 $89^{\\circ} \\mathrm{C}$ 至 $91^{\\circ} \\mathrm{C}$ 的概率.  \n(3) 当 $\\sigma=0.5$ 时, 要有 $95 \\%$ 的可能性保证箱内温度不低于 $90^{\\circ} \\mathrm{C}$, 问应将温度调节器设定为多少度为宜?  \n解: (1) 随求概率为  \n$$\n\\begin{aligned}\nP(89 \\leqslant X<91) & =\\Phi\\left(\\frac{91-90}{0.5}\\right)-\\Phi\\left(\\frac{89-90}{0.5}\\right) \\\\\n& =2 \\Phi(2)-1=2 \\times 0.9772-1=0.9544\n\\end{aligned}\n$$  \n这说明如果温度调节器的精度 $\\sigma=0.5$ 时, 箱内温度在 $89^{\\circ} \\mathrm{C}$ 至 $91^{\\circ} \\mathrm{C}$ 的可能性是很大的.  \n(2) 所求概率为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "(3) 当 $\\sigma=0.5$ 时, 要有 $95 \\%$ 的可能性保证箱内温度不低于 $90^{\\circ} \\mathrm{C}$, 问应将温度调节器设定为多少度为宜?  \n解: (1) 随求概率为  \n$$\n\\begin{aligned}\nP(89 \\leqslant X<91) & =\\Phi\\left(\\frac{91-90}{0.5}\\right)-\\Phi\\left(\\frac{89-90}{0.5}\\right) \\\\\n& =2 \\Phi(2)-1=2 \\times 0.9772-1=0.9544\n\\end{aligned}\n$$  \n这说明如果温度调节器的精度 $\\sigma=0.5$ 时, 箱内温度在 $89^{\\circ} \\mathrm{C}$ 至 $91^{\\circ} \\mathrm{C}$ 的可能性是很大的.  \n(2) 所求概率为  \n$$\n\\begin{aligned}\nP(89 \\leqslant X<91) & =\\Phi\\left(\\frac{91-90}{2}\\right)-\\Phi\\left(\\frac{89-90}{2}\\right) \\\\\n& =2 \\Phi(0.5)-1=2 \\times 0.6915-1=0.3830 .\n\\end{aligned}\n$$  \n这说明如果温度调节器的精度 $\\sigma=2$ 时,箱内温度在 $89^{\\circ} \\mathrm{C}$ 至 $91^{\\circ} \\mathrm{C}$ 是较困难的.  \n(3) 按题意需求 $d$ 满足  \n$$\nP(X \\geqslant 90) \\geqslant 0.95, \\text { 即 } 1-\\Phi\\left(\\frac{90-d}{0.5}\\right) \\geqslant 0.95,\n$$  \n所以应该有  \n$$\n\\Phi\\left(\\frac{90-d}{0.5}\\right) \\leqslant 0.05\n$$  \n查附表 2 得  \n$$\n\\frac{90-d}{0.5} \\leqslant-1.645\n$$  \n所以  \n$$\nd \\geqslant 1.645 \\times 0.5+90=90.8225 .\n$$  \n故取 $d=91^{\\circ} \\mathrm{C}$ 可满足条件.",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "& =2 \\Phi(0.5)-1=2 \\times 0.6915-1=0.3830 .\n\\end{aligned}\n$$  \n这说明如果温度调节器的精度 $\\sigma=2$ 时,箱内温度在 $89^{\\circ} \\mathrm{C}$ 至 $91^{\\circ} \\mathrm{C}$ 是较困难的.  \n(3) 按题意需求 $d$ 满足  \n$$\nP(X \\geqslant 90) \\geqslant 0.95, \\text { 即 } 1-\\Phi\\left(\\frac{90-d}{0.5}\\right) \\geqslant 0.95,\n$$  \n所以应该有  \n$$\n\\Phi\\left(\\frac{90-d}{0.5}\\right) \\leqslant 0.05\n$$  \n查附表 2 得  \n$$\n\\frac{90-d}{0.5} \\leqslant-1.645\n$$  \n所以  \n$$\nd \\geqslant 1.645 \\times 0.5+90=90.8225 .\n$$  \n故取 $d=91^{\\circ} \\mathrm{C}$ 可满足条件.\n四、正态分布的数学期望与方善  \n设随机变量 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 由于 $U=(X-\\mu) / \\sigma \\sim N(0,1)$, 所以 $U$ 的数学期望为  \n$$\nE(U)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} u \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u\n$$  \n注意到上述积分的被积函数为一个奇函数, 所以其积分值等于 0 , 即 $E(U)=0$. 又因为 $X=$ $\\mu+\\sigma U$,所以由数学期望的线性性得  \n$$\nE(X)=\\mu+\\sigma \\times 0=\\mu .\n$$  \n也就是说,正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 中 $\\mu$ 为数学期望.  \n又因为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n故取 $d=91^{\\circ} \\mathrm{C}$ 可满足条件.\n四、正态分布的数学期望与方善  \n设随机变量 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 由于 $U=(X-\\mu) / \\sigma \\sim N(0,1)$, 所以 $U$ 的数学期望为  \n$$\nE(U)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} u \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u\n$$  \n注意到上述积分的被积函数为一个奇函数, 所以其积分值等于 0 , 即 $E(U)=0$. 又因为 $X=$ $\\mu+\\sigma U$,所以由数学期望的线性性得  \n$$\nE(X)=\\mu+\\sigma \\times 0=\\mu .\n$$  \n也就是说,正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 中 $\\mu$ 为数学期望.  \n又因为  \n$$\n\\begin{aligned}\n\\operatorname{Var}(U) & =E\\left(U^{2}\\right)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} u^{2} \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u \\\\\n& =\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} u^{2} \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u \\\\\n& \\frac{1}{\\sqrt{2 \\pi}}\\left(-\\left.u \\mathrm{e}^{-\\frac{u^{2}}{2}}\\right|_{-\\infty} ^{+\\infty}+\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u\\right) \\\\",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "又因为  \n$$\n\\begin{aligned}\n\\operatorname{Var}(U) & =E\\left(U^{2}\\right)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} u^{2} \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u \\\\\n& =\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} u^{2} \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u \\\\\n& \\frac{1}{\\sqrt{2 \\pi}}\\left(-\\left.u \\mathrm{e}^{-\\frac{u^{2}}{2}}\\right|_{-\\infty} ^{+\\infty}+\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u\\right) \\\\\n& =\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u=\\frac{1}{\\sqrt{2 \\pi}} \\sqrt{2 \\pi}=1\n\\end{aligned}\n$$  \n因为 $X=\\sigma U+\\mu$, 所以由方差的性质得  \n$$\n\\operatorname{Var}(X)=\\operatorname{Var}(\\sigma U+\\mu)=\\sigma^{2}\n$$  \n这说明,正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 中另一个参数 $\\sigma^{2}$ 就是方差.  \n在求正态分布的数学期望和方差中, 用到了一种变换: 令 $U=(X-\\mu) / \\sigma$, 由 $E(U)=$ $0, \\operatorname{Var}(U)=1$, 然后再去求出 $X$ 的数学期望和方差. 这个变换具有普遍意义, 也就是对任意随机变量 $X$,如果 $X$ 的数学期望为 $\\mu$,方差为 $\\sigma^{2}$, 则称  \n为 $X$ 的标准化随机变量,且可得  \n$$",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n因为 $X=\\sigma U+\\mu$, 所以由方差的性质得  \n$$\n\\operatorname{Var}(X)=\\operatorname{Var}(\\sigma U+\\mu)=\\sigma^{2}\n$$  \n这说明,正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 中另一个参数 $\\sigma^{2}$ 就是方差.  \n在求正态分布的数学期望和方差中, 用到了一种变换: 令 $U=(X-\\mu) / \\sigma$, 由 $E(U)=$ $0, \\operatorname{Var}(U)=1$, 然后再去求出 $X$ 的数学期望和方差. 这个变换具有普遍意义, 也就是对任意随机变量 $X$,如果 $X$ 的数学期望为 $\\mu$,方差为 $\\sigma^{2}$, 则称  \n为 $X$ 的标准化随机变量,且可得  \n$$\nX^{*}=\\frac{X-\\mu}{\\sigma}\n$$  \n$$\nE\\left(X^{*}\\right)=0, \\quad \\operatorname{Var}\\left(X^{*}\\right)=1 .\n$$  \n五、正态分布的 $3 \\sigma$ 原则  \n设 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 则  \n$$\nP(|X-\\mu|<k \\sigma)=\\Phi(k)-\\Phi(-k)= \\begin{cases}0.6826, & k=1  \\tag{2.5.5}\\\\ 0.9545, & k=2 \\\\ 0.9973, & k=3\\end{cases}\n$$  \n从上式中可以看出: 尽管正态变量的取值范围是 $(-\\infty,+\\infty)$, 但它的 $99.73 \\%$ 的值落在 $\\mu-$ $3 \\sigma, \\mu+3 \\sigma$ 内. 这个性质被实际工作者称作是正态分布的 “ $3 \\sigma$ 原则”. 正态分布的 $3 \\sigma$ 原则在实际工作中很有用, 工业生产上用的控制图, 和一些产品质量指数 (如 $C_{p}, C_{p k}$ ) 都是根据 $3 \\sigma$ 原则制定的.",
        "metadata": {
            "Header 2": "三、一般正态分布的标准化"
        },
        "type": "Document"
    },
    {
        "page_content": "若随机变量 $\\mathrm{X}$ 的密度函数 (见图 ??(a)) 为  \n$$\np(x)= \\begin{cases}\\frac{1}{b-a}, & a<x<b ;  \\tag{2.5.6}\\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n则称 $X$ 服从区间 $(a, b)$ 上的均匀分布, 记作 $X \\sim U(a, b)$, 其分布函数 (见图 ??(b)) 为  \n$$\nF(x)= \\begin{cases}0, & x<a ;  \\tag{2.5.7}\\\\ \\frac{x-a}{b-a}, & a \\leqslant x<b ; \\\\ 1, & x \\geqslant b .\\end{cases}\n$$  \n!  \n(a) 密度函数 $p(x)$  \n!  \n(b) 分布函数 $F(x)$  \n图 2.5.2: $(a, b)$ 上的均匀分布  \n均匀分布的背景可视作随机点 $X$ 落在区间 $(a, b)$ 上的位置. 均匀分布在实际中经常使用, 譬如一个半径为 $r$ 的汽车轮胎, 因为轮胎圆周上的任一点接触地面的可能性是相同的, 所以轮胎圆周接触地面的位置 $X$ 是服从 ( $), 2 \\pi r)$ 上的均匀分布, 这只要看一看报度轮胎的四周磨损程度几乎是相同的就可明白均匀分布的含义了.  \n例 2.5.4: 设随机变量 $X$ 服从 $(0,10)$ 上的均匀分布, 现对 $\\mathrm{X}$ 进行 4 次独立观测, 试求至少有 3 次观测值大于 5 的概率.  \n解: 设随机变量 $Y$ 是 4 次独立观测中观测值大于 5 的次数, 则 $Y \\sim b(4, p)$, 其中 $p=P(X>5)$.由 $X \\sim U(0,10)$, 知 $X$ 的密度函数  \n$$\np(x)= \\begin{cases}\\frac{1}{10}, & 0<x<10 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n所以  \n$$\np=P(X>5)=\\int_{5}^{10} \\frac{1}{10} \\mathrm{~d} x=\\frac{1}{2},\n$$  \n于是  \n$$\nP(Y \\geqslant 3)=\\left(\\begin{array}{l}\n4 \\\\\n3",
        "metadata": {
            "Header 2": "一、均匀分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "例 2.5.4: 设随机变量 $X$ 服从 $(0,10)$ 上的均匀分布, 现对 $\\mathrm{X}$ 进行 4 次独立观测, 试求至少有 3 次观测值大于 5 的概率.  \n解: 设随机变量 $Y$ 是 4 次独立观测中观测值大于 5 的次数, 则 $Y \\sim b(4, p)$, 其中 $p=P(X>5)$.由 $X \\sim U(0,10)$, 知 $X$ 的密度函数  \n$$\np(x)= \\begin{cases}\\frac{1}{10}, & 0<x<10 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n所以  \n$$\np=P(X>5)=\\int_{5}^{10} \\frac{1}{10} \\mathrm{~d} x=\\frac{1}{2},\n$$  \n于是  \n$$\nP(Y \\geqslant 3)=\\left(\\begin{array}{l}\n4 \\\\\n3\n\\end{array}\\right) p^{3}(1-p)+\\left(\\begin{array}{l}\n4 \\\\\n4\n\\end{array}\\right)=4\\left(\\frac{1}{2}\\right)^{4}+\\left(\\frac{1}{2}\\right)^{4}=\\frac{5}{16} .\n$$  \n二、均匀分布的数学期望和方差  \n设随机变量 $X \\sim U(a, b)$, 则  \n$$\nE(X)=\\int_{a}^{b} \\frac{x}{b-a} \\mathrm{~d} x=\\frac{b^{2}-a^{2}}{2(b-a)}=\\frac{a+b}{2}\n$$  \n这正是区间 $(a, b)$ 的终点.  \n又因为  \n$$\nE\\left(X^{2}\\right)=\\int_{a}^{b} \\frac{x^{2}}{b-a} \\mathrm{~d} x=\\frac{b^{3}-a^{3}}{3(b-a)}=\\frac{a^{2}+a b+b^{2}}{3},\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=\\frac{a^{2}+a b+b^{2}}{3}-\\frac{(a+b)^{2}}{4}=\\frac{(b-a)^{2}}{12}",
        "metadata": {
            "Header 2": "一、均匀分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n二、均匀分布的数学期望和方差  \n设随机变量 $X \\sim U(a, b)$, 则  \n$$\nE(X)=\\int_{a}^{b} \\frac{x}{b-a} \\mathrm{~d} x=\\frac{b^{2}-a^{2}}{2(b-a)}=\\frac{a+b}{2}\n$$  \n这正是区间 $(a, b)$ 的终点.  \n又因为  \n$$\nE\\left(X^{2}\\right)=\\int_{a}^{b} \\frac{x^{2}}{b-a} \\mathrm{~d} x=\\frac{b^{3}-a^{3}}{3(b-a)}=\\frac{a^{2}+a b+b^{2}}{3},\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=\\frac{a^{2}+a b+b^{2}}{3}-\\frac{(a+b)^{2}}{4}=\\frac{(b-a)^{2}}{12}\n$$",
        "metadata": {
            "Header 2": "一、均匀分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "若随机变量 $\\mathrm{X}$ 的密度函数 (见图 2.5.3) 为  \n$$\np(x)= \\begin{cases}\\lambda \\mathrm{e}^{-\\lambda x}, & x \\geqslant 0  \\tag{2.5.8}\\\\ 0, & x<0\\end{cases}\n$$  \n则称 $X$ 服从指数分布, 记作 $X \\sim \\operatorname{Exp}(\\lambda)$, 其中参数 $\\lambda>0$. 指数分布的分布函数为  \n$$\nF(x)= \\begin{cases}1-\\mathrm{e}^{-\\lambda x}, & x \\geqslant 0  \\tag{2.5.9}\\\\ 0, & x<0 .\\end{cases}\n$$  \n!  \n图 2.5.3: 参数为 $\\lambda$ 的指数分布密度函数  \n因为指数分布随机变量只可能取非负实数, 所以指数分布常被用作各种 “寿命” 分布, 臂如电子元器件的寿命、动物的寿命、电话的通话时间、随机服务系统中的服务时间等都可假定服从指数分布. 指数分布在可靠性与排队论中有着广泛的应用.  \n二。指数分布的数学期望和方差  \n设随机变量 $X \\sim \\operatorname{Exp}(\\lambda)$, 则  \n$$\n\\begin{aligned}\nE(X) & =\\int_{0}^{+\\infty} x \\lambda \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\int_{0}^{+\\infty} x \\mathrm{~d}\\left(-\\mathrm{e}^{-\\lambda x}\\right) \\\\\n& =-\\left.x \\mathrm{e}^{-\\lambda x}\\right|_{0} ^{+\\infty}+\\int_{0}^{+\\infty} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=-\\left.\\frac{1}{\\lambda} \\mathrm{e}^{-\\lambda x}\\right|_{0} ^{+\\infty}=\\frac{1}{\\lambda} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "一。指数分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "二。指数分布的数学期望和方差  \n设随机变量 $X \\sim \\operatorname{Exp}(\\lambda)$, 则  \n$$\n\\begin{aligned}\nE(X) & =\\int_{0}^{+\\infty} x \\lambda \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\int_{0}^{+\\infty} x \\mathrm{~d}\\left(-\\mathrm{e}^{-\\lambda x}\\right) \\\\\n& =-\\left.x \\mathrm{e}^{-\\lambda x}\\right|_{0} ^{+\\infty}+\\int_{0}^{+\\infty} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=-\\left.\\frac{1}{\\lambda} \\mathrm{e}^{-\\lambda x}\\right|_{0} ^{+\\infty}=\\frac{1}{\\lambda} .\n\\end{aligned}\n$$  \n在指数分布中, 有时记 $\\theta=1 / \\lambda$, 则 $\\theta$ 为指数分布的数学期望.  \n又因为  \n由此得 $X$ 的方差为  \n$$\n\\begin{aligned}\nE\\left(X^{2}\\right) & =\\int_{0}^{+\\infty} x^{2} \\lambda \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\int_{0}^{+\\infty} x^{2} \\mathrm{~d}\\left(-\\mathrm{e}^{-\\lambda x}\\right) \\\\\n& =-\\left.x^{2} \\mathrm{e}^{-\\lambda}\\right|_{0} ^{+\\infty}+2 \\int_{0}^{+\\infty} x \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\frac{2}{\\lambda^{2}}\n\\end{aligned}\n$$  \n$$",
        "metadata": {
            "Header 2": "一。指数分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n在指数分布中, 有时记 $\\theta=1 / \\lambda$, 则 $\\theta$ 为指数分布的数学期望.  \n又因为  \n由此得 $X$ 的方差为  \n$$\n\\begin{aligned}\nE\\left(X^{2}\\right) & =\\int_{0}^{+\\infty} x^{2} \\lambda \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\int_{0}^{+\\infty} x^{2} \\mathrm{~d}\\left(-\\mathrm{e}^{-\\lambda x}\\right) \\\\\n& =-\\left.x^{2} \\mathrm{e}^{-\\lambda}\\right|_{0} ^{+\\infty}+2 \\int_{0}^{+\\infty} x \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\frac{2}{\\lambda^{2}}\n\\end{aligned}\n$$  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=\\frac{2}{\\lambda^{2}}-\\frac{1}{\\lambda^{2}}=\\frac{1}{\\lambda^{2}} .\n$$",
        "metadata": {
            "Header 2": "一。指数分布的密度函数和分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "下面给出指数分布在连续分布类中所特有的一个性质.\n定理 2.5.2 (指数分布的无记忆性). 如果 $X \\sim \\operatorname{Exp}(\\lambda)$, 则对任意 $s>0, t>0$, 有  \n$$\n\\begin{equation*}\nP(X>s+t \\mid X>s)=P(X>t) . \\tag{2.5.10}\n\\end{equation*}\n$$  \n上式的含义为: 记 $X$ 是某种产品的使用寿命 $(\\mathrm{h})$,若 $X$ 服从指数分布,那么已知此产品使用了 $s \\mathrm{~h}$ 没发生故障, 则再能使用 $t \\mathrm{~h}$ 而不发生故障的概率与已使用的 $s \\mathrm{~h}$ 无关, 只相当于重新开始使用 $t \\mathrm{~h}$ 的概率, 即对已使用过的 $s \\mathrm{~h}$ 没有记忆.  \n证明: 因为 $X \\sim \\operatorname{Exp}(\\lambda)$, 所以 $P(X>s)=\\mathrm{e}^{-\\lambda s}, s>0$. 又因为  \n$$\n\\{X>s+t\\} \\subseteq\\{X>s\\}\n$$  \n于是条件概率  \n$$\nP(X>s+t \\mid X>s)=\\frac{P(X>s+t)}{P(X>s)}=\\frac{\\mathrm{e}^{-\\lambda(s+t)}}{\\mathrm{e}^{-\\lambda s}}=\\mathrm{e}^{-\\lambda t}=P(X>t) .\n$$  \n这就证明 (2.5.10) 式.  \n指数分布的无记忆性与几何分布的无记忆性是类似的.  \n以下例子说明了泊松分布与指数分布的关系.  \n例 2.5.5: 如果某设备在任何长为 $t$ 的时间 $[0, t]$ 内发生故障的次数 $N 9 t)$ 服从参数为 $\\lambda t$ 的泊松分布,则相继两次故障之间的时间间隔 $T$ 服从参数为 $\\lambda$ 的指数分布.  \n解: 设 $N(t) \\sim P(\\lambda t)$, 即  \n$$\nP(N(t)=k)=\\frac{(\\lambda t)^{k}}{k !} \\mathrm{e}^{-\\lambda t}, \\quad k=0,1, \\cdots .\n$$",
        "metadata": {
            "Header 2": "三、指数分布的无记忆性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n于是条件概率  \n$$\nP(X>s+t \\mid X>s)=\\frac{P(X>s+t)}{P(X>s)}=\\frac{\\mathrm{e}^{-\\lambda(s+t)}}{\\mathrm{e}^{-\\lambda s}}=\\mathrm{e}^{-\\lambda t}=P(X>t) .\n$$  \n这就证明 (2.5.10) 式.  \n指数分布的无记忆性与几何分布的无记忆性是类似的.  \n以下例子说明了泊松分布与指数分布的关系.  \n例 2.5.5: 如果某设备在任何长为 $t$ 的时间 $[0, t]$ 内发生故障的次数 $N 9 t)$ 服从参数为 $\\lambda t$ 的泊松分布,则相继两次故障之间的时间间隔 $T$ 服从参数为 $\\lambda$ 的指数分布.  \n解: 设 $N(t) \\sim P(\\lambda t)$, 即  \n$$\nP(N(t)=k)=\\frac{(\\lambda t)^{k}}{k !} \\mathrm{e}^{-\\lambda t}, \\quad k=0,1, \\cdots .\n$$  \n注意到两次故障之间的时间间隔 $T$ 是非负随机变量, 且事件 $\\{T \\geqslant t\\}$ 说明此设备在 $[0, t]$ 内没有发生故障,即 $\\{T \\geqslant t\\}=\\{N(t)=0\\}$,由此我们得  \n当 $t<0$ 时, 有 $F_{T}(t)=P(T \\leqslant t)=0$;  \n当 $t \\geqslant 0$ 时,有  \n$$\nF_{T}(t)=P(T \\leqslant t)=1-P(T>t)=1-P(N(t)=0)=1-\\mathrm{e}^{-\\lambda t} \\text {, }\n$$  \n所以 $T \\sim \\operatorname{Exp}(\\lambda)$, 相继两次故障之间的时间间隔 $T$ 服从参数为 $\\lambda$ 的指数分布.",
        "metadata": {
            "Header 2": "三、指数分布的无记忆性"
        },
        "type": "Document"
    },
    {
        "page_content": "称以下函数  \n$$\n\\begin{equation*}\n\\Gamma(\\alpha)=\\int_{0}^{+\\infty} x^{\\alpha-1} \\mathrm{e}^{-x} \\mathrm{~d} x \\tag{2.5.11}\n\\end{equation*}\n$$  \n为伽玛函数, , 其中参数 $\\alpha>0$. 伽玛函数具有如下性质:  \n(1) $\\Gamma(1)=1, \\Gamma\\left(\\frac{1}{2}\\right)=\\sqrt{\\pi}$;  \n(2) $\\Gamma(\\alpha+1)=\\alpha \\Gamma(\\alpha)$ (可用分部积分法证得). 当 $\\alpha$ 为自然数 $n$ 时,有  \n$$\n\\Gamma(n+1)=n \\Gamma(n)=n ! .\n$$",
        "metadata": {
            "Header 2": "一。伽马函数"
        },
        "type": "Document"
    },
    {
        "page_content": "若随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} x^{\\alpha-1} \\mathrm{e}^{-\\lambda x}, & x \\geqslant 0  \\tag{2.5.12}\\\\ 0, & x<0\\end{cases}\n$$  \n则称 $X$ 服从伽玛分布, 记作 $X \\sim G a(\\alpha, \\lambda)$, 其中 $\\alpha>0$ 为形状参数, $\\lambda>0$ 为尺度参数. 图 2.5 .4 给出若于条 $\\lambda$ 固定、 $\\alpha$ 不同的伽玛密度函数曲线, 从图中可以看出:  \n- $0<\\alpha<1$ 时, $p(x)$ 是严格下降函数,且在 $x=0$ 处有奇异点;\n- $\\alpha=1$ 时, $p(x)$ 是严格下降函数,且在 $x=0$ 处 $p(0)=\\lambda$;\n- $1<\\alpha \\leqslant 2, p(x)$ 是单峰函数, 向上凸、后下凸;\n- $2<\\alpha$ 时, $p(x)$ 是单峰函数, 先下凸、中间上凸、后下凸. 且 $\\alpha$ 越大, $p(x)$ 越近似于正态分布.\n!  \n图 2.5.4: $\\lambda$ 固定、不同 $\\alpha$ 的伽玛密度曲线  \n三。仍玛分布 $G a(\\alpha, \\lambda)$ 的数学期望和方差  \n利用伽玛函数的性质, 不难算得伽玛分布 $G a(\\alpha, \\lambda)$ 的数学期望为  \n$$\nE(X)=\\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} \\int_{0}^{+\\infty} x^{\\alpha} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\frac{\\Gamma(\\alpha+1)}{\\Gamma(\\alpha)} \\frac{1}{\\lambda}=\\frac{\\alpha}{\\lambda},\n$$  \n又因为  \n$$",
        "metadata": {
            "Header 2": "二、伽玛分布"
        },
        "type": "Document"
    },
    {
        "page_content": "- $1<\\alpha \\leqslant 2, p(x)$ 是单峰函数, 向上凸、后下凸;\n- $2<\\alpha$ 时, $p(x)$ 是单峰函数, 先下凸、中间上凸、后下凸. 且 $\\alpha$ 越大, $p(x)$ 越近似于正态分布.\n!  \n图 2.5.4: $\\lambda$ 固定、不同 $\\alpha$ 的伽玛密度曲线  \n三。仍玛分布 $G a(\\alpha, \\lambda)$ 的数学期望和方差  \n利用伽玛函数的性质, 不难算得伽玛分布 $G a(\\alpha, \\lambda)$ 的数学期望为  \n$$\nE(X)=\\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} \\int_{0}^{+\\infty} x^{\\alpha} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\frac{\\Gamma(\\alpha+1)}{\\Gamma(\\alpha)} \\frac{1}{\\lambda}=\\frac{\\alpha}{\\lambda},\n$$  \n又因为  \n$$\nE\\left(X^{2}\\right)=\\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} \\int_{0}^{+\\infty} x^{\\alpha+1} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\frac{\\Gamma(\\alpha+2)}{\\lambda^{2} \\Gamma(\\alpha)}=\\frac{\\alpha(\\alpha+1)}{\\lambda^{2}}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=\\frac{\\alpha(\\alpha+1)}{\\lambda^{2}}-\\left(\\frac{\\alpha}{\\lambda}\\right)^{2}=\\frac{\\alpha}{\\lambda^{2}} .\n$$  \n四、伽玛分布的两个特例  \n伽玛分布有两个常用的特例:  \n1. $\\alpha=1$ 时的伽玛分布就是指数分布, 即  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "二、伽玛分布"
        },
        "type": "Document"
    },
    {
        "page_content": "又因为  \n$$\nE\\left(X^{2}\\right)=\\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} \\int_{0}^{+\\infty} x^{\\alpha+1} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x=\\frac{\\Gamma(\\alpha+2)}{\\lambda^{2} \\Gamma(\\alpha)}=\\frac{\\alpha(\\alpha+1)}{\\lambda^{2}}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=E\\left(X^{2}\\right)-[E(X)]^{2}=\\frac{\\alpha(\\alpha+1)}{\\lambda^{2}}-\\left(\\frac{\\alpha}{\\lambda}\\right)^{2}=\\frac{\\alpha}{\\lambda^{2}} .\n$$  \n四、伽玛分布的两个特例  \n伽玛分布有两个常用的特例:  \n1. $\\alpha=1$ 时的伽玛分布就是指数分布, 即  \n$$\n\\begin{equation*}\nG a(1, \\lambda)=\\operatorname{Exp}(\\lambda) \\text {. } \\tag{2.5.13}\n\\end{equation*}\n$$  \n2. 称 $\\alpha=n / 2, \\lambda=1 / 2$ 时的伽玛分布是自由度为 $n$ 的 $\\chi^{2}$ (卡方)分布, 记为 $\\chi^{2}(n)$, 记  \n$$\n\\begin{equation*}\nG a\\left(\\frac{n}{2}, \\frac{1}{2}\\right)=\\chi^{2}(n) \\tag{2.5.14}\n\\end{equation*}\n$$  \n其密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{2^{\\frac{n}{2}} \\Gamma\\left(\\frac{n}{2}\\right)} \\mathrm{e}^{-\\frac{x}{2}} x^{\\frac{n}{2}-1}, & x>0  \\tag{2.5.15}\\\\ 0, & x \\leqslant 0\\end{cases}\n$$",
        "metadata": {
            "Header 2": "二、伽玛分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\begin{equation*}\nG a(1, \\lambda)=\\operatorname{Exp}(\\lambda) \\text {. } \\tag{2.5.13}\n\\end{equation*}\n$$  \n2. 称 $\\alpha=n / 2, \\lambda=1 / 2$ 时的伽玛分布是自由度为 $n$ 的 $\\chi^{2}$ (卡方)分布, 记为 $\\chi^{2}(n)$, 记  \n$$\n\\begin{equation*}\nG a\\left(\\frac{n}{2}, \\frac{1}{2}\\right)=\\chi^{2}(n) \\tag{2.5.14}\n\\end{equation*}\n$$  \n其密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{2^{\\frac{n}{2}} \\Gamma\\left(\\frac{n}{2}\\right)} \\mathrm{e}^{-\\frac{x}{2}} x^{\\frac{n}{2}-1}, & x>0  \\tag{2.5.15}\\\\ 0, & x \\leqslant 0\\end{cases}\n$$  \n这里 $n$ 是 $\\chi^{2}$ 分布的唯一参数, 称为自由度, 它可以是正实数, 但更多的是取正整数, 其统计含义以后再介绍.  \n因为 $\\chi^{2}$ 分布是特殊的伽玛分布, 故由伽玛分布的期望和方差, 很容易得到 $\\chi^{2}$ 分布的期望和方差为  \n$$\nE(X)=n, \\quad \\operatorname{Var}(X)=2 n\n$$  \n例 2.5.6: 电子产品的失效常常是由子外界的 “冲击引起”. 若在 $(0, t)$ 内发生冲击的次数 $N(t)$ 服从参数为 $\\lambda t$ 的泊松分布,试证第 $n$ 次冲击来到的时间 $S_{n}$ 服从伽玛分布 $G a(n, \\lambda)$.\n证明：因为事件 “第 $n$ 次冲击来到的时间 $S_{n}$ 小于等于 $t$ ”等价于事件 “ $(0, t)$ 内发生冲击的次数 $N(t)$ 大于等于 $n$ ”, 即  \n$$\n\\left\\{S_{n} \\leqslant t\\right\\}=\\{N(t) \\geqslant n\\} .\n$$  \n于是, $S_{n}$ 的分布函数为",
        "metadata": {
            "Header 2": "二、伽玛分布"
        },
        "type": "Document"
    },
    {
        "page_content": "这里 $n$ 是 $\\chi^{2}$ 分布的唯一参数, 称为自由度, 它可以是正实数, 但更多的是取正整数, 其统计含义以后再介绍.  \n因为 $\\chi^{2}$ 分布是特殊的伽玛分布, 故由伽玛分布的期望和方差, 很容易得到 $\\chi^{2}$ 分布的期望和方差为  \n$$\nE(X)=n, \\quad \\operatorname{Var}(X)=2 n\n$$  \n例 2.5.6: 电子产品的失效常常是由子外界的 “冲击引起”. 若在 $(0, t)$ 内发生冲击的次数 $N(t)$ 服从参数为 $\\lambda t$ 的泊松分布,试证第 $n$ 次冲击来到的时间 $S_{n}$ 服从伽玛分布 $G a(n, \\lambda)$.\n证明：因为事件 “第 $n$ 次冲击来到的时间 $S_{n}$ 小于等于 $t$ ”等价于事件 “ $(0, t)$ 内发生冲击的次数 $N(t)$ 大于等于 $n$ ”, 即  \n$$\n\\left\\{S_{n} \\leqslant t\\right\\}=\\{N(t) \\geqslant n\\} .\n$$  \n于是, $S_{n}$ 的分布函数为  \n$$\nF(t)=P\\left(S_{n} \\leqslant t\\right)=P(N(t) \\geqslant n)=\\sum_{k=n}^{+\\infty} \\frac{(\\lambda t)^{k}}{k !} \\mathrm{e}^{-\\lambda t}\n$$  \n用分部积分法可以验证下列等式  \n$$\n\\begin{equation*}\n\\sum_{k=n}^{+\\infty} \\frac{(\\lambda t)^{k}}{k !} \\mathrm{e}^{-\\lambda t}=\\frac{\\lambda^{n}}{\\Gamma(n)} \\int_{t}^{+\\infty} x^{n-1} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x \\tag{2.5.16}\n\\end{equation*}\n$$  \n所以  \n$$\nF(t)=\\frac{\\lambda^{n}}{\\Gamma(n)} \\int_{t}^{+\\infty} x^{n-1} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x\n$$",
        "metadata": {
            "Header 2": "二、伽玛分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nF(t)=P\\left(S_{n} \\leqslant t\\right)=P(N(t) \\geqslant n)=\\sum_{k=n}^{+\\infty} \\frac{(\\lambda t)^{k}}{k !} \\mathrm{e}^{-\\lambda t}\n$$  \n用分部积分法可以验证下列等式  \n$$\n\\begin{equation*}\n\\sum_{k=n}^{+\\infty} \\frac{(\\lambda t)^{k}}{k !} \\mathrm{e}^{-\\lambda t}=\\frac{\\lambda^{n}}{\\Gamma(n)} \\int_{t}^{+\\infty} x^{n-1} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x \\tag{2.5.16}\n\\end{equation*}\n$$  \n所以  \n$$\nF(t)=\\frac{\\lambda^{n}}{\\Gamma(n)} \\int_{t}^{+\\infty} x^{n-1} \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x\n$$  \n这就表明 $S_{n} \\sim G a(n, \\lambda)$. 证毕.",
        "metadata": {
            "Header 2": "二、伽玛分布"
        },
        "type": "Document"
    },
    {
        "page_content": "一、贝塔函数  \n称以下函数  \n$$\n\\begin{equation*}\n\\mathrm{B}(a, b)=\\int_{0}^{1} x^{a-1}(1-x)^{b-1} \\mathrm{~d} x \\tag{2.5.17}\n\\end{equation*}\n$$  \n为贝塔函数, 其中参数 $a>0, b>0$. 贝塔函数具有如下性质:  \n(1) $\\mathrm{B}(a, b)=\\mathrm{B}(b, a)$.  \n证明: 在 (2.5.17) 的积分中令 $y=1-x$, 即得  \n$$\n\\mathrm{B}(a, b)=\\int_{1}^{0}(1-y)^{a-1} y^{b-1}(-\\mathrm{d} y)=\\int_{0}^{1}(1-y)^{a-1} y^{b-1} \\mathrm{~d} y=\\mathrm{B}(b, a) .\n$$  \n(2) 贝塔函数与伽玛函数间有关系  \n$$\n\\begin{equation*}\n\\mathrm{B}(a, b)=\\frac{\\Gamma(a) \\Gamma(b)}{\\Gamma(a+b)} . \\tag{2.5.18}\n\\end{equation*}\n$$  \n证明: 由伽玛函数的定义知  \n$$\n\\Gamma(a) \\Gamma(b)=\\int_{0}^{+\\infty} \\int_{0}^{+\\infty} x^{a-1} y^{b-1} \\mathrm{e}^{-(x+y)} \\mathrm{d} x \\mathrm{~d} y,\n$$  \n作变量变换 $x=u v, y=u(1-v)$, 其雅可比行列式 $J=-u$, 故  \n$$\n\\begin{aligned}\n\\Gamma(a) \\Gamma(b) & =\\int_{0}^{+\\infty} \\int_{0}^{1}(u v)^{a-1}[u(1-v)]^{b-1} \\mathrm{e}^{-u} u \\mathrm{~d} u \\mathrm{~d} v \\\\\n& =\\int_{0}^{+\\infty} u^{a+b-1} \\mathrm{e}^{-u} \\int_{0}^{1} v^{a-1}(1-v)^{b-1} \\mathrm{~d} v=\\Gamma(a+b) \\mathrm{B}(a, b),\n\\end{aligned}",
        "metadata": {
            "Header 2": "2.5 .5 贝塔分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n证明: 由伽玛函数的定义知  \n$$\n\\Gamma(a) \\Gamma(b)=\\int_{0}^{+\\infty} \\int_{0}^{+\\infty} x^{a-1} y^{b-1} \\mathrm{e}^{-(x+y)} \\mathrm{d} x \\mathrm{~d} y,\n$$  \n作变量变换 $x=u v, y=u(1-v)$, 其雅可比行列式 $J=-u$, 故  \n$$\n\\begin{aligned}\n\\Gamma(a) \\Gamma(b) & =\\int_{0}^{+\\infty} \\int_{0}^{1}(u v)^{a-1}[u(1-v)]^{b-1} \\mathrm{e}^{-u} u \\mathrm{~d} u \\mathrm{~d} v \\\\\n& =\\int_{0}^{+\\infty} u^{a+b-1} \\mathrm{e}^{-u} \\int_{0}^{1} v^{a-1}(1-v)^{b-1} \\mathrm{~d} v=\\Gamma(a+b) \\mathrm{B}(a, b),\n\\end{aligned}\n$$  \n由此证得 (2.5.18) 式.  \n二、贝塔分布  \n若随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\frac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} x^{a-1}(1-x)^{b-1}, & 0<x<1 ;  \\tag{2.5.19}\\\\ 0, & \\text { 其他, }\\end{cases}\n$$  \n!  \n图 2.5.5: 贝塔密度函数曲线  \n则称 $X$ 服从贝塔分布, 记作 $X \\sim B e(a, b)$, 其中 $a>0, b>0$ 都是形状参数. 图 2.5 .5 给出几种典型的贝塔密度函数曲线.  \n从图 2.5.5 可以看出:  \n- $a<1, b<1$ 时, $p(x)$ 是下凸的单峰函数.\n- $a>1, b>1$ 时, $p(x)$ 是上凸的单峰函数.\n- $a<10, b \\geqslant 1$ 时, $p(x)$ 是下凸的单调减函数.\n- $a \\geqslant 1, b<1$ 时, $p(x)$ 是下凸的单调增函数.",
        "metadata": {
            "Header 2": "2.5 .5 贝塔分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n由此证得 (2.5.18) 式.  \n二、贝塔分布  \n若随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\frac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} x^{a-1}(1-x)^{b-1}, & 0<x<1 ;  \\tag{2.5.19}\\\\ 0, & \\text { 其他, }\\end{cases}\n$$  \n!  \n图 2.5.5: 贝塔密度函数曲线  \n则称 $X$ 服从贝塔分布, 记作 $X \\sim B e(a, b)$, 其中 $a>0, b>0$ 都是形状参数. 图 2.5 .5 给出几种典型的贝塔密度函数曲线.  \n从图 2.5.5 可以看出:  \n- $a<1, b<1$ 时, $p(x)$ 是下凸的单峰函数.\n- $a>1, b>1$ 时, $p(x)$ 是上凸的单峰函数.\n- $a<10, b \\geqslant 1$ 时, $p(x)$ 是下凸的单调减函数.\n- $a \\geqslant 1, b<1$ 时, $p(x)$ 是下凸的单调增函数.\n- $a=1, b=1$ 时, $p(x)$ 是常函数, 且 $B e(1,1)=U(0,1)$.  \n因为服从贝塔分布 $B e(a, b)$ 的随机变量是仅在区间 $(0,1)$ 取值的,所以不合格品率、机器的维修率、市场的占有率、射击的命中率等各种比率选用贝塔分布作为它们的概率分布是恰当的, 只要选择合适的参数 $a$ 与 $b$ 即可.",
        "metadata": {
            "Header 2": "2.5 .5 贝塔分布"
        },
        "type": "Document"
    },
    {
        "page_content": "利用贝塔函数的性质, 不难算得贝塔分布 $\\operatorname{Be}(a, b)$ 的数学期望为  \n$$\n\\begin{aligned}\nE(X) & =\\frac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} \\int_{0}^{1} x^{a}(1-x)^{b-1} \\mathrm{~d} x \\\\\n& =\\frac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} \\cdot \\frac{\\Gamma(a+1) \\Gamma(b)}{\\Gamma(a+b+1)}=\\frac{a}{a+b} .\n\\end{aligned}\n$$  \n又因为  \n$$\n\\begin{aligned}\nE\\left(X^{2}\\right) & =\\frac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} \\int_{0}^{1} x^{a+1}(1-x)^{b-1} \\mathrm{~d} x \\\\\n& =\\frac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} \\cdot \\frac{\\Gamma(a+2) \\Gamma(b)}{\\Gamma(a+b+2)} \\\\\n& =\\frac{a(a+1)}{(a+b)(a+b+1)} .\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=\\frac{a(a+1)}{(a+b)(a+b+1)}-\\left(\\frac{a}{a+b}\\right)^{2}=\\frac{a b}{(a+b)^{2}(a+b+1)}\n$$  \n以下我们将常用分布的期望和方差以表格形式放在一起.  \n表 2.5.1: 常用分布的数学期望和方差  \n| 分布 | 分布列 $p_{k}$ 或分布密度 $p(x)$ | 期望 | 方差 |\n| :---: | :---: | :---: | :---: |\n| $0-1$ 分布 | $p_{k}=p^{k}(1-p)^{1-k}, k=0,1$. | $p$ | $p(1-p)$ |",
        "metadata": {
            "Header 2": "三、贝塔分布 $B e(a, b)$ 的数学期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} \\cdot \\frac{\\Gamma(a+2) \\Gamma(b)}{\\Gamma(a+b+2)} \\\\\n& =\\frac{a(a+1)}{(a+b)(a+b+1)} .\n\\end{aligned}\n$$  \n由此得 $X$ 的方差为  \n$$\n\\operatorname{Var}(X)=\\frac{a(a+1)}{(a+b)(a+b+1)}-\\left(\\frac{a}{a+b}\\right)^{2}=\\frac{a b}{(a+b)^{2}(a+b+1)}\n$$  \n以下我们将常用分布的期望和方差以表格形式放在一起.  \n表 2.5.1: 常用分布的数学期望和方差  \n| 分布 | 分布列 $p_{k}$ 或分布密度 $p(x)$ | 期望 | 方差 |\n| :---: | :---: | :---: | :---: |\n| $0-1$ 分布 | $p_{k}=p^{k}(1-p)^{1-k}, k=0,1$. | $p$ | $p(1-p)$ |\n| 二项分布 <br> $b(n, p)$ | $p_{k}=\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right) p^{k}(1-p)^{n-k}, k=0,1, \\cdots, n$. | $n p$ | $n p(1-p)$ |  \n| 泊松分布 <br> $P(\\lambda)$ | $p_{k}=\\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}, k=0,1, \\cdots$ | $\\lambda$ | $\\lambda$ |\n| :---: | :---: | :---: | :---: |\n| 超几何分布 <br> $h(n, N, M)$ | {ff7b308a7-e783-4289-aab2-1d51cd31e997}$k=0,1, \\cdots, r$ <br> $r=\\min \\{M, n\\}$. | $n \\frac{M}{N}$ | $\\frac{n M(N-M)(N-n)}{N^{2}(N-1)}$ |",
        "metadata": {
            "Header 2": "三、贝塔分布 $B e(a, b)$ 的数学期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "| 二项分布 <br> $b(n, p)$ | $p_{k}=\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right) p^{k}(1-p)^{n-k}, k=0,1, \\cdots, n$. | $n p$ | $n p(1-p)$ |  \n| 泊松分布 <br> $P(\\lambda)$ | $p_{k}=\\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}, k=0,1, \\cdots$ | $\\lambda$ | $\\lambda$ |\n| :---: | :---: | :---: | :---: |\n| 超几何分布 <br> $h(n, N, M)$ | {ff7b308a7-e783-4289-aab2-1d51cd31e997}$k=0,1, \\cdots, r$ <br> $r=\\min \\{M, n\\}$. | $n \\frac{M}{N}$ | $\\frac{n M(N-M)(N-n)}{N^{2}(N-1)}$ |\n| 几何分布 <br> $G e(p)$ | $p_{k}=(1-p)^{k-1} p, k=1,2, \\cdots$ | $\\frac{1}{p}$ | $\\frac{1-p}{p^{2}}$ |\n| 负二项分布 <br> $N n(r, p)$ | $p_{k}=\\left(\\begin{array}{c}k-1 \\\\ r-1\\end{array}\\right)(1-p)^{k-r} p^{r}, k=r, r+1, \\cdots$ | $\\frac{r}{p}$ | $\\frac{r(1-p)}{p^{2}}$ |\n| 正态分布 <br> $N\\left(\\mu, \\sigma^{2}\\right)$ | $p(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right\\},-\\infty<x<+\\infty$ | $\\mu$ | $\\sigma^{2}$ |",
        "metadata": {
            "Header 2": "三、贝塔分布 $B e(a, b)$ 的数学期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "| 几何分布 <br> $G e(p)$ | $p_{k}=(1-p)^{k-1} p, k=1,2, \\cdots$ | $\\frac{1}{p}$ | $\\frac{1-p}{p^{2}}$ |\n| 负二项分布 <br> $N n(r, p)$ | $p_{k}=\\left(\\begin{array}{c}k-1 \\\\ r-1\\end{array}\\right)(1-p)^{k-r} p^{r}, k=r, r+1, \\cdots$ | $\\frac{r}{p}$ | $\\frac{r(1-p)}{p^{2}}$ |\n| 正态分布 <br> $N\\left(\\mu, \\sigma^{2}\\right)$ | $p(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right\\},-\\infty<x<+\\infty$ | $\\mu$ | $\\sigma^{2}$ |\n| 均匀分布 <br> $U(a, b)$ | $p(x)=\\frac{1}{b-a}, a<x<b$ | $\\frac{a+b}{2}$ | $\\frac{(b-a)^{2}}{12}$ |\n| 指数分布 <br> $\\operatorname{Exp}(\\lambda)$ | $p(x)=\\lambda \\mathrm{e}^{-\\lambda x}, x \\geqslant 0$. | $\\frac{1}{\\lambda}$ | $\\frac{1}{\\lambda^{2}}$ |\n| 伽马分布 <br> $G a(\\alpha, \\lambda)$ | $p(x)=\\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} x^{a-1} \\mathrm{e}^{-\\lambda x} \\cdot x \\geqslant 0$ | $\\frac{\\alpha}{\\lambda}$ | $\\frac{\\alpha}{\\lambda^{2}}$ |",
        "metadata": {
            "Header 2": "三、贝塔分布 $B e(a, b)$ 的数学期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "| 均匀分布 <br> $U(a, b)$ | $p(x)=\\frac{1}{b-a}, a<x<b$ | $\\frac{a+b}{2}$ | $\\frac{(b-a)^{2}}{12}$ |\n| 指数分布 <br> $\\operatorname{Exp}(\\lambda)$ | $p(x)=\\lambda \\mathrm{e}^{-\\lambda x}, x \\geqslant 0$. | $\\frac{1}{\\lambda}$ | $\\frac{1}{\\lambda^{2}}$ |\n| 伽马分布 <br> $G a(\\alpha, \\lambda)$ | $p(x)=\\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} x^{a-1} \\mathrm{e}^{-\\lambda x} \\cdot x \\geqslant 0$ | $\\frac{\\alpha}{\\lambda}$ | $\\frac{\\alpha}{\\lambda^{2}}$ |\n| $\\chi^{2}(n)$ 分布 | $p(x)=\\frac{x^{n / 2-1} \\mathrm{e}^{-x / 2}}{\\Gamma(n / 2) 2^{n / 2}}, x \\geqslant 0$. | $n$ | $2 n$ |\n| 贝塔分布 <br> $B e(a, b)$ | $p(x)=\\frac{\\Gamma(a+b)}{\\Gamma(a) \\Gamma(b)} x^{a-1}(1-x)^{b-1}, 0<x<1$ | $\\frac{a}{a+b}$ | $\\frac{a b}{(a+b)^{2}(a+b+1)}$ |  \n注:表中仅列出各分布密度函数的非零区城.",
        "metadata": {
            "Header 2": "三、贝塔分布 $B e(a, b)$ 的数学期望和方差"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设随机变量 $X$ 服从区间 $(2,5)$ 上的均匀分布,求对 $X$ 进行 3 次独立观测中,至少有 2 次的观测值大于 3 的概率.\n2. 在 $(0,1)$ 上任取一点记为 $X$, 试求 $P\\left(X^{2}-\\frac{3}{4} X+\\frac{1}{8} \\geqslant 0\\right)$.\n3. 设 $K$ 服从 $(1,6)$ 上的均匀分布, 求方程 $x^{2}+K x+1=0$ 有实根的概率.\n4. 设流经一个 $2 \\Omega$ 电阻上的电流 $I$ 是一个随机变量, 它均匀分布在 $9 \\mathrm{~A}$ 至 $11 \\mathrm{~A}$ 之间. 试求此电阻上消耗的平均功率, 其中功率 $W=2 I^{2}$.\n5. 某种圆盘的直径在区间 $(a, b)$ 上服从均匀分布, 试求此种圆盘的平均面积.\n6. 设某种商品每周的需求量 $X$ 服从区间 $(10,30)$ 上均匀分布, 而商店进货数为区间 $(10,30)$ 中的某一整数,商店每销售 1 单位商品可获利 500 元; 若供大于求则削价处理, 每处理 1 单位商品亏损 100 元; 若供不应求,则可从外部调剂供应, 此时每 1 单位商品仅获利 300 元. 为使商店所获利润期望值不少于 9280 元,试确定最少进货量.\n7. 已知 $X \\sim \\operatorname{Exp}(\\lambda)$, 试在 $\\lambda=0.1$ 下求 $P(5 \\leqslant X \\leqslant 20)$.\n8. 统计调查表明,英格兰在 1875 年至 1951 年期间, 在矿山发生 10 人或 10 人以上死亡的两次事故之间的时间 $T$ (以日计) 服从均值为 241 的指数分布, 试求 $P(50<T<100)$.\n9. 若一次电话通话时间 $X$ (分钟) 服从参数为 0.25 的指数分布, 试求一次通话的平均时间.\n10. 某种设备的使用寿命 $X$ (以年计) 服从指数分布, 其平均寿命为 4 年. 制造此种设备的厂家规定, 若设备在使用一年之内损坏, 则可以予以调换. 如果设备制造厂每售出一台设备可赢利 100 元, 而调换一台设备制造厂需花费 300 元. 试求每台设备的平均利润.",
        "metadata": {
            "Header 2": "习习题 2.5"
        },
        "type": "Document"
    },
    {
        "page_content": "7. 已知 $X \\sim \\operatorname{Exp}(\\lambda)$, 试在 $\\lambda=0.1$ 下求 $P(5 \\leqslant X \\leqslant 20)$.\n8. 统计调查表明,英格兰在 1875 年至 1951 年期间, 在矿山发生 10 人或 10 人以上死亡的两次事故之间的时间 $T$ (以日计) 服从均值为 241 的指数分布, 试求 $P(50<T<100)$.\n9. 若一次电话通话时间 $X$ (分钟) 服从参数为 0.25 的指数分布, 试求一次通话的平均时间.\n10. 某种设备的使用寿命 $X$ (以年计) 服从指数分布, 其平均寿命为 4 年. 制造此种设备的厂家规定, 若设备在使用一年之内损坏, 则可以予以调换. 如果设备制造厂每售出一台设备可赢利 100 元, 而调换一台设备制造厂需花费 300 元. 试求每台设备的平均利润.\n11. 设顾客在某银行的窗口等待的时间 $X$ (以 $\\min$ 计) 服从指数分布,其密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{5} \\mathrm{e}^{-\\frac{x}{5}}, & x>0 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n某顾客在窗口等待服务,若超过 $10 \\mathrm{~min}$,他就离开. 他一个月要到银行 5 次, 以 $Y$ 表示一个月内他未等到服务而离开窗口的次数,试求 $P(Y \\geqslant 1)$.  \n12. 某仪器装了 3 个独立工作的同型号电子元件, 其寿命 (单位: $h$ ) 都服从同一指数分布, 密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{600} \\mathrm{e}^{-\\frac{x}{600}}, & x>0 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求: 此仪器在最初使用的 $200 \\mathrm{~h}$ 内, 至少有一个此种电子元件损坏的概率.  \n13. 设随机变量 $X$ 的密度函数为  \n$$\np(x)=\\left\\{\\begin{array}{ll}\n\\lambda \\mathrm{e}^{-\\lambda x}, & x>0 ; \\\\",
        "metadata": {
            "Header 2": "习习题 2.5"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n某顾客在窗口等待服务,若超过 $10 \\mathrm{~min}$,他就离开. 他一个月要到银行 5 次, 以 $Y$ 表示一个月内他未等到服务而离开窗口的次数,试求 $P(Y \\geqslant 1)$.  \n12. 某仪器装了 3 个独立工作的同型号电子元件, 其寿命 (单位: $h$ ) 都服从同一指数分布, 密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{600} \\mathrm{e}^{-\\frac{x}{600}}, & x>0 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求: 此仪器在最初使用的 $200 \\mathrm{~h}$ 内, 至少有一个此种电子元件损坏的概率.  \n13. 设随机变量 $X$ 的密度函数为  \n$$\np(x)=\\left\\{\\begin{array}{ll}\n\\lambda \\mathrm{e}^{-\\lambda x}, & x>0 ; \\\\\n0, & x \\leqslant 0\n\\end{array} \\quad(\\lambda>0)\\right.\n$$  \n试求 $k$,使得 $P(X>k)=0.5$.  \n14. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}1 / 3, & 0 \\leqslant x \\leqslant 1 ; \\\\ 2 / 9, & 3 \\leqslant x \\leqslant 6 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n若 $P(x \\geqslant k)=2 / 3$, 试求 $k$ 的取值范围.  \n15. 写出以下正态分布的均值和标准差.  \n$$\np_{1}(x)=\\frac{1}{\\sqrt{\\pi}} \\mathrm{e}^{-\\left(x^{2}+4 x+4\\right)}, \\quad p_{2}(x)=\\sqrt{\\frac{2}{\\pi}} \\mathrm{e}^{-2 x^{2}}, \\quad p_{3}(x)=\\frac{1}{\\sqrt{\\pi}} \\mathrm{e}^{-x^{2}} .\n$$",
        "metadata": {
            "Header 2": "习习题 2.5"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array} \\quad(\\lambda>0)\\right.\n$$  \n试求 $k$,使得 $P(X>k)=0.5$.  \n14. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}1 / 3, & 0 \\leqslant x \\leqslant 1 ; \\\\ 2 / 9, & 3 \\leqslant x \\leqslant 6 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n若 $P(x \\geqslant k)=2 / 3$, 试求 $k$ 的取值范围.  \n15. 写出以下正态分布的均值和标准差.  \n$$\np_{1}(x)=\\frac{1}{\\sqrt{\\pi}} \\mathrm{e}^{-\\left(x^{2}+4 x+4\\right)}, \\quad p_{2}(x)=\\sqrt{\\frac{2}{\\pi}} \\mathrm{e}^{-2 x^{2}}, \\quad p_{3}(x)=\\frac{1}{\\sqrt{\\pi}} \\mathrm{e}^{-x^{2}} .\n$$  \n16. 某地区 18 岁女青年的血压 $X$ (收缩压, 以 $\\mathrm{mm}-\\mathrm{Hg}$ 计) 服从 $N\\left(110,12^{2}\\right)$. 试求该地区 18 岁女育年的血压在 100 至 120 的可能性有多大?\n17. 某地区成年男子的体重 $X(\\mathrm{~kg})$ 服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$. 若已知 $P(X \\leqslant 70)=0.5, P(X \\leqslant$ $60)=0.25$.  \n(1) 求 $\\mu$ 与 $\\sigma$ 各为多少?  \n(2) 若在这个地区随机地选出 5 名成年男子, 问其中至少有两人体重超过 $65 \\mathrm{~kg}$ 的概率是多少?  \n18. 由某机器生产的螺检的长度 $(\\mathrm{cm})$ 服从正态分布 $N\\left(10.05,0.06^{2}\\right)$, 若规定长度在范国 $10.05 \\pm$ 0.12 内为合格品, 求螺栓不合格的概率.",
        "metadata": {
            "Header 2": "习习题 2.5"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n16. 某地区 18 岁女青年的血压 $X$ (收缩压, 以 $\\mathrm{mm}-\\mathrm{Hg}$ 计) 服从 $N\\left(110,12^{2}\\right)$. 试求该地区 18 岁女育年的血压在 100 至 120 的可能性有多大?\n17. 某地区成年男子的体重 $X(\\mathrm{~kg})$ 服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$. 若已知 $P(X \\leqslant 70)=0.5, P(X \\leqslant$ $60)=0.25$.  \n(1) 求 $\\mu$ 与 $\\sigma$ 各为多少?  \n(2) 若在这个地区随机地选出 5 名成年男子, 问其中至少有两人体重超过 $65 \\mathrm{~kg}$ 的概率是多少?  \n18. 由某机器生产的螺检的长度 $(\\mathrm{cm})$ 服从正态分布 $N\\left(10.05,0.06^{2}\\right)$, 若规定长度在范国 $10.05 \\pm$ 0.12 内为合格品, 求螺栓不合格的概率.\n19. 某地抽样调查结果表明, 考生的外语成绩 (百分制) 近似地凝从 $\\mu=72$ 的正态分布, 已知 96 分以上的人数占总数的 $2.3 \\%$, 试求考生的成绩在 60 分至 84 分之间的概率.\n20. 设 $X \\sim N\\left(3,2^{2}\\right)$,(1) $P(2<X \\leqslant 5)$;(2) $P(|X|>2)$;(3) 确定 $c$ 使得 $P(X>c)=P(X, c)$.\n21. 若 $X \\sim N\\left(4,3^{2}\\right)$,(1) $P(-2<X \\leqslant 10)$;(2) $P(X>3)$;(3) 设 $d$ 满足 $P(X>d) \\geqslant 0.9$, 问 $d$ 至多为多少?\n22. 测量到某一目标的距离时, 发生的随机误差 $X(\\mathrm{~m})$ 具有密度函数  \n$$\np(x)=\\frac{1}{40 \\sqrt{2 \\pi}} \\mathrm{e}^{-\\frac{(x-20)^{2}}{3200}}, \\quad-\\infty<x<+\\infty\n$$",
        "metadata": {
            "Header 2": "习习题 2.5"
        },
        "type": "Document"
    },
    {
        "page_content": "19. 某地抽样调查结果表明, 考生的外语成绩 (百分制) 近似地凝从 $\\mu=72$ 的正态分布, 已知 96 分以上的人数占总数的 $2.3 \\%$, 试求考生的成绩在 60 分至 84 分之间的概率.\n20. 设 $X \\sim N\\left(3,2^{2}\\right)$,(1) $P(2<X \\leqslant 5)$;(2) $P(|X|>2)$;(3) 确定 $c$ 使得 $P(X>c)=P(X, c)$.\n21. 若 $X \\sim N\\left(4,3^{2}\\right)$,(1) $P(-2<X \\leqslant 10)$;(2) $P(X>3)$;(3) 设 $d$ 满足 $P(X>d) \\geqslant 0.9$, 问 $d$ 至多为多少?\n22. 测量到某一目标的距离时, 发生的随机误差 $X(\\mathrm{~m})$ 具有密度函数  \n$$\np(x)=\\frac{1}{40 \\sqrt{2 \\pi}} \\mathrm{e}^{-\\frac{(x-20)^{2}}{3200}}, \\quad-\\infty<x<+\\infty\n$$  \n求在三次测量中,至少有一次误差的绝对值不超过 $30 \\mathrm{~m}$ 的概率.  \n23. 从甲地飞往乙地的航班,每天上午 $10: 10$ 起飞,飞行时间 $X$ 服从均值是 $4 \\mathrm{~h}$,标准差是 $20 \\mathrm{~min}$ 的正态分布。  \n(1) 该机在下午 2:30 以后到达乙地的概率是多少?  \n(2) 该机在下午 $2: 20$ 以前到达乙地的概率是多少?  \n(3) 该机在下午 $1: 50$ 至 $2: 30$ 之间到达乙地的概率是多少?  \n24. 某单位招聘员工,共有 10000 人报考. 假设考试成绩服从正态分布, 且已知 90 分以上有 359 人, 60 分以下有 1151 人. 现按考试成绩从高分到低分依次录用 2500 人,试问被录用者中最低分为多少?\n25. 设随机变量 $X$ 服从正态分布 $N\\left(60,3^{2}\\right)$, 试求实数 $a, b, c, d$ 使得 $X$ 落在如下五个区间中的概率之比为 $7: 24: 38: 24: 7$.  \n$$",
        "metadata": {
            "Header 2": "习习题 2.5"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n求在三次测量中,至少有一次误差的绝对值不超过 $30 \\mathrm{~m}$ 的概率.  \n23. 从甲地飞往乙地的航班,每天上午 $10: 10$ 起飞,飞行时间 $X$ 服从均值是 $4 \\mathrm{~h}$,标准差是 $20 \\mathrm{~min}$ 的正态分布。  \n(1) 该机在下午 2:30 以后到达乙地的概率是多少?  \n(2) 该机在下午 $2: 20$ 以前到达乙地的概率是多少?  \n(3) 该机在下午 $1: 50$ 至 $2: 30$ 之间到达乙地的概率是多少?  \n24. 某单位招聘员工,共有 10000 人报考. 假设考试成绩服从正态分布, 且已知 90 分以上有 359 人, 60 分以下有 1151 人. 现按考试成绩从高分到低分依次录用 2500 人,试问被录用者中最低分为多少?\n25. 设随机变量 $X$ 服从正态分布 $N\\left(60,3^{2}\\right)$, 试求实数 $a, b, c, d$ 使得 $X$ 落在如下五个区间中的概率之比为 $7: 24: 38: 24: 7$.  \n$$\n(-\\infty, a], \\quad(a, b], \\quad(b, c], \\quad(c, d], \\quad(d,+\\infty)\n$$  \n26. 设随机变量 $X$ 与 $Y$ 均服从正态分布, $X$ 服从 $N\\left(\\mu, 4^{2}\\right), Y$ 服从 $N\\left(\\mu, 5^{2}\\right)$, 试比较以下 $p_{1}$ 和 $p_{2}$的大小.  \n$$\np_{1}=P(X \\leqslant \\mu-4), \\quad p_{2}=P(Y \\geqslant \\mu+5) .\n$$  \n27. 设随机变量 $X$ 服从正态分布 $N\\left(0, \\sigma^{2}\\right)$, 若 $P(|X|>k)=0.1$, 求 $P(X<k)$.\n28. 设随机变量 $X$ 服从正态分布 $N\\left(0, \\sigma^{2}\\right)$, 试问: 随着 $\\sigma$ 的增大, 概率 $P(|X-\\mu|<\\sigma)$ 是如何变化的?",
        "metadata": {
            "Header 2": "习习题 2.5"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n(-\\infty, a], \\quad(a, b], \\quad(b, c], \\quad(c, d], \\quad(d,+\\infty)\n$$  \n26. 设随机变量 $X$ 与 $Y$ 均服从正态分布, $X$ 服从 $N\\left(\\mu, 4^{2}\\right), Y$ 服从 $N\\left(\\mu, 5^{2}\\right)$, 试比较以下 $p_{1}$ 和 $p_{2}$的大小.  \n$$\np_{1}=P(X \\leqslant \\mu-4), \\quad p_{2}=P(Y \\geqslant \\mu+5) .\n$$  \n27. 设随机变量 $X$ 服从正态分布 $N\\left(0, \\sigma^{2}\\right)$, 若 $P(|X|>k)=0.1$, 求 $P(X<k)$.\n28. 设随机变量 $X$ 服从正态分布 $N\\left(0, \\sigma^{2}\\right)$, 试问: 随着 $\\sigma$ 的增大, 概率 $P(|X-\\mu|<\\sigma)$ 是如何变化的?\n29. 设随机变量 $X$ 服从参数为 $\\mu=160$ 和 $\\sigma$ 的正态分布, 若要求 $P(120<X \\leqslant 200) \\geqslant 0.90$, 允许 $\\sigma$ 最大为多少?\n30. 设随机变量 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 求 $E|X-\\mu|$.\n31. 设 $X \\sim N\\left(0, \\sigma^{2}\\right)$, 证明: $E|X|=\\sigma \\sqrt{\\frac{2}{\\pi}}$.\n32. 设随机变量 $X$ 服从伽玛分布 $G a(2,0.5)$, 试求 $P(X<4)$.\n33. 某地区漏缴税款的比例 $\\mathrm{X}$ 服从参数 $a=2, b=9$ 的贝塔分布, 试求此比例小于 $10 \\%$ 的概率及平均漏缴税款的比例.\n34. 某班级学生中数学成绩不及格的比率 $X$ 服从 $a=1, b=4$ 的贝塔分布, 试求 $P(X>E(X))$.",
        "metadata": {
            "Header 2": "习习题 2.5"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $y=g(x)$ 是定义在直线上的一个函数, $X$ 是一个随机变量, 那么 $Y=g(X)$ 作为 $X$ 的函数, 同样也是一个随机变量. 我们要研究的问题是: 已知随机变量 $X$ 的分布, 如何求出另一个随机变量 $Y=g(X)$ 的分布.  \n寻求随机变量函数的分布, 是概率论的基本技巧, 在概率论与数理统计中经常要用到这些技巧.下面对离散和连续两种场合分别讨论随机变量函数的分布.",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "离散随机变量函数的分布是比较容易求得的. 设 $X$ 是离散随机变量, $X$ 的分布列为  \n!  \n则 $Y=g(X)$ 也是一个离散随机变量. 此时 $Y$ 的分布列就可很简单地表示为  \n$$\n\\begin{array}{l|lllll}\nY & g\\left(x_{1}\\right) & g\\left(x_{2}\\right) & \\cdots & g\\left(x_{n}\\right) & \\cdots \\\\\n\\hline P & p\\left(x_{1}\\right) & p\\left(x_{2}\\right) & \\cdots & p\\left(x_{n}\\right) & \\cdots\n\\end{array}\n$$  \n当 $g\\left(x_{1}\\right), g\\left(x_{2}\\right), \\cdots, g\\left(x_{n}\\right), \\cdots$ 中有某些值相等时, 则把那些相等的值分别合并, 并把对应的概率相加即可.  \n例 2.6.1: 已知随机变量 $X$ 的分布列如下, 求 $Y=X^{2}+X$ 的分布列.  \n解: $Y=X^{2}+X$ 的分布列为  \n$$\n\\begin{array}{c|ccccc}\nX & -2 & -1 & 0 & 1 & 2 \\\\\n\\hline P & 0.2 & 0.1 & 0.1 & 0.3 & 0.3\n\\end{array}\n$$  \n$$\n\\begin{array}{c|ccccc}\nY & 2 & 0 & 0 & 2 & 6 \\\\\n\\hline P & 0.2 & 0.1 & 0.1 & 0.3 & 0.3\n\\end{array}\n$$  \n再对相等的值合并, 得  \n$$\n\\begin{array}{c|ccc}\nY & 0 & 2 & 6 \\\\\n\\hline P & 0.2 & 0.5 & 0.3\n\\end{array}\n$$",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.1 离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "求离散随机变量函数的分布是很简单的事. 而对连续随机变量 $X$, 我们分以下几种情况讨论 $Y=g(X)$ 的分布.  \n一、当 $g(x)$ 为严格单调时  \n在这种情况下有以下定理.  \n定理 2.6.1. 设 $X$ 是连续随机变量, 其密度函数为 $p_{X}(x) . Y=g(X)$ 是另一个随机变量, 若 $y=g(x)$ 严格单调, 其反函数 $h(y)$ 有连续导函数, 则 $Y=g(X)$ 的密度函数为  \n$$\np_{Y}(y)= \\begin{cases}p_{X}[h(y)]\\left|h^{\\prime}(y)\\right|, & a<y<b ;  \\tag{2.6.1}\\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n其中 $a=\\min \\{g(-\\infty), g(+\\infty)\\}, b=\\max \\{g(-\\infty),+\\infty)\\}$.  \n证明: 不妨设 $g(x)$ 是严格单调增函数, 这时它的反函数 $h(y)$ 也是严格单调增函数, 且 $h(y)>0$. 记 $a=$ $g(-\\infty), b=g(+\\infty)$, 这意味着 $y=g(x)$ 仅在区间 $(a, b)$ 取值, 于是  \n当 $y<a$ 时,  \n$$\nF_{Y}(y)=P(Y \\leqslant y)=0 \\text {; }\n$$  \n当 $y>b$ 时,  \n$$\nF_{Y}(y)=P(Y \\leqslant y)=1 ;\n$$  \n当 $a \\leqslant y \\leqslant b$ 时,  \n$$\n\\begin{aligned}\nF_{Y}(y) & =P(Y \\leqslant y)=P(g(X) \\leqslant y) \\\\\n& =P(X \\leqslant h(y))=\\int_{-\\infty}^{h(y)} p(x) \\mathrm{d} x .\n\\end{aligned}\n$$  \n由此得 $Y$ 的密度函数为  \n$$\np_{Y}(y)= \\begin{cases}p_{X}[h(y)] h^{\\prime}(y), & a<y<b ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "当 $y<a$ 时,  \n$$\nF_{Y}(y)=P(Y \\leqslant y)=0 \\text {; }\n$$  \n当 $y>b$ 时,  \n$$\nF_{Y}(y)=P(Y \\leqslant y)=1 ;\n$$  \n当 $a \\leqslant y \\leqslant b$ 时,  \n$$\n\\begin{aligned}\nF_{Y}(y) & =P(Y \\leqslant y)=P(g(X) \\leqslant y) \\\\\n& =P(X \\leqslant h(y))=\\int_{-\\infty}^{h(y)} p(x) \\mathrm{d} x .\n\\end{aligned}\n$$  \n由此得 $Y$ 的密度函数为  \n$$\np_{Y}(y)= \\begin{cases}p_{X}[h(y)] h^{\\prime}(y), & a<y<b ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n同理可证当 $g(x)$ 是严格单调减函数时, 结论也成立. 但此时要注意 $h^{\\prime}(y)<0$, 故要加绝对值符号, 这时 $a=g(+\\infty), b=g(-\\infty)$.  \n利用以上定理,我们来证明几个很有用的结论,并用定理形式表示.  \n定理 2.6.2. 设随机变量 $X$ 服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$, 则当 $a \\neq 0$ 时, 有 $Y=a X+b \\sim N(a \\mu+$ $b, a^{2} \\sigma^{2}$.  \n证明: 当 $a>0$ 时, $Y=a X+b$ 是严格增函数, 仍在 $(-\\infty,+\\infty)$ 上取值, 其反函数为 $X=(Y-b) / a$, 故由定理 2.6.1 可得  \n$$\n\\begin{aligned}\np_{Y}(y) & =p_{X}\\left(\\frac{y-b}{a}\\right) \\frac{1}{a}=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\mathrm{e}^{-\\frac{1}{2 \\sigma^{2}}\\left(\\frac{y-b}{a}-\\mu\\right)} \\frac{1}{a} \\\\",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "利用以上定理,我们来证明几个很有用的结论,并用定理形式表示.  \n定理 2.6.2. 设随机变量 $X$ 服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$, 则当 $a \\neq 0$ 时, 有 $Y=a X+b \\sim N(a \\mu+$ $b, a^{2} \\sigma^{2}$.  \n证明: 当 $a>0$ 时, $Y=a X+b$ 是严格增函数, 仍在 $(-\\infty,+\\infty)$ 上取值, 其反函数为 $X=(Y-b) / a$, 故由定理 2.6.1 可得  \n$$\n\\begin{aligned}\np_{Y}(y) & =p_{X}\\left(\\frac{y-b}{a}\\right) \\frac{1}{a}=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\mathrm{e}^{-\\frac{1}{2 \\sigma^{2}}\\left(\\frac{y-b}{a}-\\mu\\right)} \\frac{1}{a} \\\\\n& =\\frac{1}{\\sqrt{2 \\pi}(a \\sigma)} \\mathrm{e}^{-\\frac{(y-a \\mu-b)^{2}}{2 a^{2} b^{2}}} .\n\\end{aligned}\n$$  \n这就是正态分布 $N\\left(a \\mu+b, a^{2} \\sigma^{2}\\right)$ 的密度函数.  \n当 $a<0$ 时, $Y=a X+b$ 是严格减函数, 仍在 $(-\\infty,+\\infty)$ 上取值, 其反函数为 $X=(Y-b) / a$, 由定理 ?? 可得  \n$$\np_{Y}(y)=\\frac{1}{\\sqrt{2 \\pi}(|a| \\sigma)} \\mathrm{e}^{-\\frac{(y-a \\mu-b)^{2}}{2 a^{2} b^{2}}} .\n$$  \n这个定理表明: 正态变量的线性变换仍为正态变量, 其数学期望和方差可直接从线性变换求得. 若取 $a=1 / \\sigma, b=-\\mu / \\sigma$, 则 $Y=a X+b \\sim N(0,1)$, 此即上一节的定理 2.5.1.",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{1}{\\sqrt{2 \\pi}(a \\sigma)} \\mathrm{e}^{-\\frac{(y-a \\mu-b)^{2}}{2 a^{2} b^{2}}} .\n\\end{aligned}\n$$  \n这就是正态分布 $N\\left(a \\mu+b, a^{2} \\sigma^{2}\\right)$ 的密度函数.  \n当 $a<0$ 时, $Y=a X+b$ 是严格减函数, 仍在 $(-\\infty,+\\infty)$ 上取值, 其反函数为 $X=(Y-b) / a$, 由定理 ?? 可得  \n$$\np_{Y}(y)=\\frac{1}{\\sqrt{2 \\pi}(|a| \\sigma)} \\mathrm{e}^{-\\frac{(y-a \\mu-b)^{2}}{2 a^{2} b^{2}}} .\n$$  \n这个定理表明: 正态变量的线性变换仍为正态变量, 其数学期望和方差可直接从线性变换求得. 若取 $a=1 / \\sigma, b=-\\mu / \\sigma$, 则 $Y=a X+b \\sim N(0,1)$, 此即上一节的定理 2.5.1.  \n例 2.6.2: (1) 设随机变量 $X \\sim N\\left(10,2^{2}\\right)$, 试求 $Y=2 X+5$ 的分布.  \n(2) 设随机变量 $X \\sim N\\left(0,2^{2}\\right)$, 试求 $Y=-X$ 的分布.  \n解: 由定理 2.6.2 知 $Y$ 仍是正态变量, 其数学期望和方差分别为  \n$$\n\\begin{aligned}\n& E(Y)=E(3 X+5)=3 \\times 10+5=35 \\\\\n& \\operatorname{Var}(Y)=\\operatorname{Var}(3 X+5)=9 \\times 2^{2}=36\n\\end{aligned}\n$$  \n所以 $Y=3 X+5$ 的分布为 $N\\left(35,6^{2}\\right)$.  \n(1) $Y$ 仍是正态变量, 其数学期望和方差分别为  \n$$\n\\begin{aligned}\n& E(Y)=E(-X)=0, \\\\\n& \\operatorname{Var}(Y)=\\operatorname{Var}(-X)=2^{2} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) 设随机变量 $X \\sim N\\left(0,2^{2}\\right)$, 试求 $Y=-X$ 的分布.  \n解: 由定理 2.6.2 知 $Y$ 仍是正态变量, 其数学期望和方差分别为  \n$$\n\\begin{aligned}\n& E(Y)=E(3 X+5)=3 \\times 10+5=35 \\\\\n& \\operatorname{Var}(Y)=\\operatorname{Var}(3 X+5)=9 \\times 2^{2}=36\n\\end{aligned}\n$$  \n所以 $Y=3 X+5$ 的分布为 $N\\left(35,6^{2}\\right)$.  \n(1) $Y$ 仍是正态变量, 其数学期望和方差分别为  \n$$\n\\begin{aligned}\n& E(Y)=E(-X)=0, \\\\\n& \\operatorname{Var}(Y)=\\operatorname{Var}(-X)=2^{2} .\n\\end{aligned}\n$$  \n所以 $Y=-X$ 的分布仍为 $N\\left(0,2^{2}\\right)$. 这表明 $X$ 与 $-X$ 有相同的分布, 但这两个随机变量是不相等的. 所以我们要明确, 分布相同与随机变量相等是两个完全不同的概念.  \n定理 2.6 .3 (对数正态分布). 设随机变量 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 则 $Y=\\mathrm{e}^{X}$ 的概率密度函数为  \n$$\np_{Y}(y)= \\begin{cases}\\frac{1}{\\sqrt{2 \\pi} y \\sigma} \\mathrm{e}^{-\\frac{(\\ln y-\\mu)^{2}}{2 \\sigma^{2}}}, & y>0  \\tag{2.6.2}\\\\ 0, & y \\leqslant 0 .\\end{cases}\n$$  \n证明: $Y=\\mathrm{e}^{x}$ 是严格增函数, 它仅在 $(0,+\\infty)$ 上取值, 其反函数为 $x=\\ln y$, 由定理 2.6.1 可得  \n当 $y \\leqslant 0$ 时, $F_{Y}(y)=0$, 从而 $p_{Y}(y)=0$.  \n当 $y>0$ 时, $Y$ 的密度函数为  \n$$",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "定理 2.6 .3 (对数正态分布). 设随机变量 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 则 $Y=\\mathrm{e}^{X}$ 的概率密度函数为  \n$$\np_{Y}(y)= \\begin{cases}\\frac{1}{\\sqrt{2 \\pi} y \\sigma} \\mathrm{e}^{-\\frac{(\\ln y-\\mu)^{2}}{2 \\sigma^{2}}}, & y>0  \\tag{2.6.2}\\\\ 0, & y \\leqslant 0 .\\end{cases}\n$$  \n证明: $Y=\\mathrm{e}^{x}$ 是严格增函数, 它仅在 $(0,+\\infty)$ 上取值, 其反函数为 $x=\\ln y$, 由定理 2.6.1 可得  \n当 $y \\leqslant 0$ 时, $F_{Y}(y)=0$, 从而 $p_{Y}(y)=0$.  \n当 $y>0$ 时, $Y$ 的密度函数为  \n$$\np_{Y}(y)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\mathrm{e}^{-\\frac{(\\ln y-\\mu)^{2}}{2 \\sigma^{2}}} \\frac{1}{y}=\\frac{1}{\\sqrt{2 \\pi} y \\sigma} \\mathrm{e}^{-\\frac{(\\ln y-\\mu)^{2}}{2 \\sigma^{2}}}\n$$  \n定理得证.  \n这个分布被称为对数正态分布, 记为 $L N\\left(\\mu, \\sigma^{2}\\right)$, 其中 $\\mu$ 称为对数均值, $\\sigma$ 称为对数方差. 对数正态分布 $L N\\left(\\mu, \\sigma^{2}\\right)$ 也是一个常用分布, 实际中有不少随机变量服从对数正态分布, 譬如  \n- 绝缘材料的寿命服从对数正态分布.  \n。设备故障的维修时间服从对数正态分布.  \n。家中两个小孩的年龄差服从对数正态分布.  \n定理 2.6.4. 设随机变量 $X$ 服从伽玛分布 $G a(\\alpha, \\lambda)$, 则当 $k>0$, 有 $Y=k X \\sim G a(a, \\lambda / k)$.",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n定理得证.  \n这个分布被称为对数正态分布, 记为 $L N\\left(\\mu, \\sigma^{2}\\right)$, 其中 $\\mu$ 称为对数均值, $\\sigma$ 称为对数方差. 对数正态分布 $L N\\left(\\mu, \\sigma^{2}\\right)$ 也是一个常用分布, 实际中有不少随机变量服从对数正态分布, 譬如  \n- 绝缘材料的寿命服从对数正态分布.  \n。设备故障的维修时间服从对数正态分布.  \n。家中两个小孩的年龄差服从对数正态分布.  \n定理 2.6.4. 设随机变量 $X$ 服从伽玛分布 $G a(\\alpha, \\lambda)$, 则当 $k>0$, 有 $Y=k X \\sim G a(a, \\lambda / k)$.  \n证明: 因为 $k>0$, 所以 $y=k x$ 是严格增函数, 它仍在 $(0,+\\infty)$ 上取值, 其反函数为 $x=y / k$, 由定理 2.6.1 可得  \n当 $y<0$ 时, $p_{Y}(y)=0$.  \n当 $y \\geqslant 0$ 时,  \n$$\np_{Y}(y)=p_{X}\\left(\\frac{y}{k}\\right) \\frac{1}{k}=\\frac{\\lambda^{\\alpha}}{k \\Gamma(\\alpha)}\\left(\\frac{y}{k}\\right)^{\\alpha-1} \\mathrm{e}^{-\\lambda \\frac{y}{k}}=\\frac{(\\lambda / k)^{\\alpha}}{\\Gamma(\\alpha)} y^{\\alpha-1} \\mathrm{e}^{-\\frac{\\lambda}{k} y} .\n$$  \n此即 $G a(\\alpha, \\lambda / k)$ 的密度函数, 结论得证.  \n这个结论是很有用的, 譬如当 $X \\sim G a(\\alpha, \\lambda)$, 则 $2 \\lambda X \\sim G a(\\alpha, 1 / 2)=\\chi^{2}(2 \\alpha)$, 即即任一伽玛分布可转化为 $\\chi^{2}$ 分布.",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "当 $y<0$ 时, $p_{Y}(y)=0$.  \n当 $y \\geqslant 0$ 时,  \n$$\np_{Y}(y)=p_{X}\\left(\\frac{y}{k}\\right) \\frac{1}{k}=\\frac{\\lambda^{\\alpha}}{k \\Gamma(\\alpha)}\\left(\\frac{y}{k}\\right)^{\\alpha-1} \\mathrm{e}^{-\\lambda \\frac{y}{k}}=\\frac{(\\lambda / k)^{\\alpha}}{\\Gamma(\\alpha)} y^{\\alpha-1} \\mathrm{e}^{-\\frac{\\lambda}{k} y} .\n$$  \n此即 $G a(\\alpha, \\lambda / k)$ 的密度函数, 结论得证.  \n这个结论是很有用的, 譬如当 $X \\sim G a(\\alpha, \\lambda)$, 则 $2 \\lambda X \\sim G a(\\alpha, 1 / 2)=\\chi^{2}(2 \\alpha)$, 即即任一伽玛分布可转化为 $\\chi^{2}$ 分布.  \n定理 2.6.5. 若 $X$ 的分布函数 $F_{X}(x)$ 为严格单调增的连续函数, 其反函数 $F_{X}^{-1}(y)$ 存在, 则 $Y=$ $F_{X}(x)$ 服从 $(0,1)$ 上的均匀分布 $U(0,1)$.  \n证明: 下求 $Y=F_{X}(x)$ 的分布函数. 由于分布函数 $F_{X}(x)$ 仅在 $[0,1]$ 区间上取值, 故  \n当 $y<0$ 时,因为 $\\left\\{F_{X}(X) \\leqslant y\\right\\}$ 是不可能事件, 所以  \n$$\nF_{Y}(y)=P(Y \\leqslant y)=F\\left(F_{X}(X) \\leqslant y\\right)=0 .\n$$  \n当 $0 \\leqslant y<1$ 时,有  \n$$\n\\begin{aligned}\nF_{Y}(y) & =P(Y \\leqslant y)=P\\left(F_{X}(X) \\leqslant y\\right) \\\\",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "定理 2.6.5. 若 $X$ 的分布函数 $F_{X}(x)$ 为严格单调增的连续函数, 其反函数 $F_{X}^{-1}(y)$ 存在, 则 $Y=$ $F_{X}(x)$ 服从 $(0,1)$ 上的均匀分布 $U(0,1)$.  \n证明: 下求 $Y=F_{X}(x)$ 的分布函数. 由于分布函数 $F_{X}(x)$ 仅在 $[0,1]$ 区间上取值, 故  \n当 $y<0$ 时,因为 $\\left\\{F_{X}(X) \\leqslant y\\right\\}$ 是不可能事件, 所以  \n$$\nF_{Y}(y)=P(Y \\leqslant y)=F\\left(F_{X}(X) \\leqslant y\\right)=0 .\n$$  \n当 $0 \\leqslant y<1$ 时,有  \n$$\n\\begin{aligned}\nF_{Y}(y) & =P(Y \\leqslant y)=P\\left(F_{X}(X) \\leqslant y\\right) \\\\\n& =F\\left(X \\leqslant F_{X}^{-1}(y)\\right)=F_{X}\\left(F_{X}^{-1}(y)\\right)=y .\n\\end{aligned}\n$$  \n当 $y \\geqslant 1$ 时, 因为 $\\left\\{F_{X}(X) \\leqslant y\\right\\}$ 是必然事件, 所以  \n$$\nF_{Y}(y)=P(Y \\leqslant y)=P\\left(F_{X}(X) \\leqslant y\\right)=1 .\n$$  \n综上所述, $Y=F_{X}(X)$ 的分布函数为  \n$$\nF_{Y}(y)= \\begin{cases}0, & y<0 \\\\ y, & 0 \\leqslant y<1 \\\\ 1, & y \\geqslant 1\\end{cases}\n$$  \n证正是 $(0,1)$ 上均匀分布的分布函数, 所以 $Y \\sim U(0,1)$.",
        "metadata": {
            "Header 2": "2.6 随机变量函数的分布",
            "Header 3": "2.6.2 连续随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "以上定理 2.6.1 在使用时的确很方便, 但它要求的条件 “ $g(x)$ 严格单调, 反函数连续可微”太高, 有些场合就无法满足这个条件, 例如 $\\mathrm{Y}=\\mathrm{X} 2$ 就无法满足条件. 对于无法满足定理 2.6.1 条件的情况, 可以先计算 $Y=g(X)$ 的分布函数, 使其用 $X$ 的分布函数表示, 然后再用求导的方法求出 $Y$的密度函数. 下面用两个例子来说明此种方法.  \n例 2.6.3: 设随机变量 $X$ 服从标准正态分布 $N(0,1)$, 试求 $Y=X^{2}$ 的分布.  \n解: 先求 $Y$ 的分布函数 $F_{Y}(y)$. 由于 $Y=X^{2} \\geqslant 0$, 故当 $y \\leqslant 0$ 时, 有 $F_{Y}(y)=0$, 从而 $p_{Y}(y)=0$.当 $y>0$ 时,有  \n$$\n\\begin{aligned}\nF_{Y}(y) & =P(Y \\leqslant y)=P\\left(X^{2} \\leqslant y\\right) \\\\\n& =P(-\\sqrt{y} \\leqslant X \\leqslant \\sqrt{y})=2 \\Phi(\\sqrt{y})-1 .\n\\end{aligned}\n$$  \n因此 $Y$ 的分布函数为  \n$$\nF_{Y}(y)= \\begin{cases}2 \\Phi(\\sqrt{y})-1, & y>0 \\\\ 0, & y \\leqslant 0\\end{cases}\n$$  \n再用求导的方法求出 $Y$ 的密度函数  \n$$\np_{Y}(y)= \\begin{cases}\\varphi(\\sqrt{y}) y^{\\frac{1}{2}}, & y>0 \\\\ 0, & y \\leqslant 0\\end{cases}\n$$  \n对照 $\\chi^{2}$ 分布的密度函数, 可以看出 $Y \\sim \\chi^{2}(1)$.  \n例 2.6.4: 设随机变量 $X$ 的密度函数为  \n$$\np_{X}(x)= \\begin{cases}\\frac{2 x}{\\pi^{2}}, & 0<x<\\pi \\\\ 0, & \\text { 其他. }\\end{cases}\n$$",
        "metadata": {
            "Header 2": "二、当 $g(x)$ 为其他形式时"
        },
        "type": "Document"
    },
    {
        "page_content": "& =P(-\\sqrt{y} \\leqslant X \\leqslant \\sqrt{y})=2 \\Phi(\\sqrt{y})-1 .\n\\end{aligned}\n$$  \n因此 $Y$ 的分布函数为  \n$$\nF_{Y}(y)= \\begin{cases}2 \\Phi(\\sqrt{y})-1, & y>0 \\\\ 0, & y \\leqslant 0\\end{cases}\n$$  \n再用求导的方法求出 $Y$ 的密度函数  \n$$\np_{Y}(y)= \\begin{cases}\\varphi(\\sqrt{y}) y^{\\frac{1}{2}}, & y>0 \\\\ 0, & y \\leqslant 0\\end{cases}\n$$  \n对照 $\\chi^{2}$ 分布的密度函数, 可以看出 $Y \\sim \\chi^{2}(1)$.  \n例 2.6.4: 设随机变量 $X$ 的密度函数为  \n$$\np_{X}(x)= \\begin{cases}\\frac{2 x}{\\pi^{2}}, & 0<x<\\pi \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $Y=\\sin X$ 的密度函数 $p_{Y}(y)$.  \n解：由于 $X$ 在 $(0, \\pi)$ 内取值, 所以 $Y=\\sin X$ 的可能取值区间为 $(0,1)$. 在 $Y$ 的可能取值区间外, $p_{Y}(y)=0$.  \n当 $0<y<1$ 时,使 $\\{Y \\leqslant y\\}$ 的 $x$ 取值范围为两个互不相交的区间,见图 2.6.1.  \n$$\n\\begin{aligned}\n& \\Delta_{1}(y)=\\left[0, x_{1}\\right]=[0 m \\arcsin y], \\\\\n& \\Delta_{2}(y)=\\left[x_{2}, \\pi\\right]=[\\pi-\\arcsin y, \\pi] .\n\\end{aligned}\n$$  \n于是  \n$$\n\\begin{aligned}\n\\{Y \\leqslant y\\} & =\\left\\{X \\in \\Delta_{1}(y)\\right\\} \\cup\\left\\{X \\in \\Delta_{2}(y)\\right\\} \\\\",
        "metadata": {
            "Header 2": "二、当 $g(x)$ 为其他形式时"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n求 $Y=\\sin X$ 的密度函数 $p_{Y}(y)$.  \n解：由于 $X$ 在 $(0, \\pi)$ 内取值, 所以 $Y=\\sin X$ 的可能取值区间为 $(0,1)$. 在 $Y$ 的可能取值区间外, $p_{Y}(y)=0$.  \n当 $0<y<1$ 时,使 $\\{Y \\leqslant y\\}$ 的 $x$ 取值范围为两个互不相交的区间,见图 2.6.1.  \n$$\n\\begin{aligned}\n& \\Delta_{1}(y)=\\left[0, x_{1}\\right]=[0 m \\arcsin y], \\\\\n& \\Delta_{2}(y)=\\left[x_{2}, \\pi\\right]=[\\pi-\\arcsin y, \\pi] .\n\\end{aligned}\n$$  \n于是  \n$$\n\\begin{aligned}\n\\{Y \\leqslant y\\} & =\\left\\{X \\in \\Delta_{1}(y)\\right\\} \\cup\\left\\{X \\in \\Delta_{2}(y)\\right\\} \\\\\n& =\\{0 \\leqslant X \\leqslant \\arcsin y\\} \\cup\\{\\pi-\\arcsin y \\leqslant X \\leqslant \\pi\\}\n\\end{aligned}\n$$  \n!  \n$\\arcsin y \\pi-\\arcsin y$  \n图 2.6.1: $y=\\sin x$ 的图形  \n故  \n$$\n\\begin{aligned}\nF_{Y}(y) & =P(Y \\leqslant y)=\\int_{0}^{\\arcsin y} P_{X}(x) \\mathrm{d} x+\\int_{\\pi-\\arcsin y}^{\\pi} p_{X}(x) \\mathrm{d} x \\\\\n& =\\int_{0}^{\\arcsin y} \\frac{2 x}{\\pi^{2}} d d x+\\int_{\\pi-\\arcsin y}^{\\pi} \\frac{2 x}{\\pi^{2}} \\mathrm{~d} x,\n\\end{aligned}\n$$  \n在上式两段对 $y$ 求导, 得  \n$$",
        "metadata": {
            "Header 2": "二、当 $g(x)$ 为其他形式时"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\{0 \\leqslant X \\leqslant \\arcsin y\\} \\cup\\{\\pi-\\arcsin y \\leqslant X \\leqslant \\pi\\}\n\\end{aligned}\n$$  \n!  \n$\\arcsin y \\pi-\\arcsin y$  \n图 2.6.1: $y=\\sin x$ 的图形  \n故  \n$$\n\\begin{aligned}\nF_{Y}(y) & =P(Y \\leqslant y)=\\int_{0}^{\\arcsin y} P_{X}(x) \\mathrm{d} x+\\int_{\\pi-\\arcsin y}^{\\pi} p_{X}(x) \\mathrm{d} x \\\\\n& =\\int_{0}^{\\arcsin y} \\frac{2 x}{\\pi^{2}} d d x+\\int_{\\pi-\\arcsin y}^{\\pi} \\frac{2 x}{\\pi^{2}} \\mathrm{~d} x,\n\\end{aligned}\n$$  \n在上式两段对 $y$ 求导, 得  \n$$\np_{Y}(y)=\\frac{2 \\arcsin y}{\\pi^{2} \\sqrt{1-y^{2}}}+\\frac{2(\\pi-\\arcsin y)}{\\pi^{2} \\sqrt{1-y^{2}}}=\\frac{2}{\\pi \\sqrt{1-y^{2}}} .\n$$",
        "metadata": {
            "Header 2": "二、当 $g(x)$ 为其他形式时"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 已知离散随机变量 $X$ 的分布列为  \n$$\n\\begin{array}{c|ccccc}\nX & -2 & -1 & 0 & 1 & 3 \\\\\n\\hline P & \\frac{1}{5} & \\frac{1}{6} & \\frac{1}{5} & \\frac{1}{15} & \\frac{11}{30}\n\\end{array}\n$$  \n试求 $Y=X^{2}$ 与 $Z=|X|$ 的分布列.  \n2. 已知随机变量 $X$ 的密度函数为  \n$$\np(x)=\\frac{2}{\\pi} \\cdot \\frac{1}{\\mathrm{e}^{x}+\\mathrm{e}^{-x}}, \\quad-\\infty<x<+\\infty\n$$  \n试求随机变量 $Y=g(X)$ 的概率分布. 其中  \n$$\ng(x)= \\begin{cases}-1, & \\text { 当 } x<0 ; \\\\ 1, & \\text { 当 } x \\geqslant 0 .\\end{cases}\n$$  \n3. 设随机变量 $X$ 服从 $(-1,2)$ 上的均匀分布, 记  \n$$\nY= \\begin{cases}1, & X \\geqslant 0 \\\\ -1, & X<0\\end{cases}\n$$  \n试求 $Y$ 的分布列.  \n4. 设 $X \\sim U(0,1)$, 试求 $1-X$ 的分布.\n5. 设随机变量 $X$ 服从 $(-\\pi / 2, \\pi / 2)$ 上的均匀分布, 求随机变量 $Y=\\cos X$ 的密度函数 $p_{Y}(y)$.\n6. 设圆的直径服从区间 $(0,1)$ 上的均匀分布,求圆的面积的密度函数.\n7. 设随机变量 $X$ 服从区间 $(1,2)$ 上的均匀分布, 试求 $Y=\\mathrm{e}^{2 X}$ 的密度函数.\n8. 设随机变量 $X$ 服从区间 $(0,2)$ 上的均匀分布, (1) 求 $Y=X^{2}$ 的密度函数. (2) $P(Y<2)$.\n9. 设随机变量 $X$ 服从区间 $(0,3)$ 上的均匀分布, 求 $Y=5 X+2$ 的密度函数.\n10. 设随机变量 $X$ 服从 $(0,1)$ 上的均匀分布, 试求以下 $Y$ 的密度函数\n(1) $Y=-2 \\ln X$\n(2) $Y=3 X+1$",
        "metadata": {
            "Header 2": "习题 2.6"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试求 $Y$ 的分布列.  \n4. 设 $X \\sim U(0,1)$, 试求 $1-X$ 的分布.\n5. 设随机变量 $X$ 服从 $(-\\pi / 2, \\pi / 2)$ 上的均匀分布, 求随机变量 $Y=\\cos X$ 的密度函数 $p_{Y}(y)$.\n6. 设圆的直径服从区间 $(0,1)$ 上的均匀分布,求圆的面积的密度函数.\n7. 设随机变量 $X$ 服从区间 $(1,2)$ 上的均匀分布, 试求 $Y=\\mathrm{e}^{2 X}$ 的密度函数.\n8. 设随机变量 $X$ 服从区间 $(0,2)$ 上的均匀分布, (1) 求 $Y=X^{2}$ 的密度函数. (2) $P(Y<2)$.\n9. 设随机变量 $X$ 服从区间 $(0,3)$ 上的均匀分布, 求 $Y=5 X+2$ 的密度函数.\n10. 设随机变量 $X$ 服从 $(0,1)$ 上的均匀分布, 试求以下 $Y$ 的密度函数\n(1) $Y=-2 \\ln X$\n(2) $Y=3 X+1$\n(3) $Y=\\mathrm{e}^{X}$.\n(4) $Y=|\\ln X|$.\n11. 设随机变量 $X$ 的密度函数为  \n$$\np_{X}(x)= \\begin{cases}\\frac{3}{2} x^{2}, & -1<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求下列随机变量的分布: (1) $Y_{1}=3 X$. (2) $Y_{2}=3-X$. (3) $Y_{3}=X^{2}$.  \n12. 设 $X \\sim N\\left(0, \\sigma^{2}\\right)$, 求 $Y=X^{2}$ 的分布.\n13. 设 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 求 $Y=\\mathrm{e}^{X}$ 的数学期望与方差.\n14. 设随机变量 $X$ 服从标准正态分布 $N(0,1)$, 试求以下 $Y$ 的密度函数.  \n(1) $Y=|X|$. (2) $Y=2 X^{2}+1$.  \n15. 设随机变量 $X$ 的密度函数为  \n$$",
        "metadata": {
            "Header 2": "习题 2.6"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) $Y=3 X+1$\n(3) $Y=\\mathrm{e}^{X}$.\n(4) $Y=|\\ln X|$.\n11. 设随机变量 $X$ 的密度函数为  \n$$\np_{X}(x)= \\begin{cases}\\frac{3}{2} x^{2}, & -1<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求下列随机变量的分布: (1) $Y_{1}=3 X$. (2) $Y_{2}=3-X$. (3) $Y_{3}=X^{2}$.  \n12. 设 $X \\sim N\\left(0, \\sigma^{2}\\right)$, 求 $Y=X^{2}$ 的分布.\n13. 设 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 求 $Y=\\mathrm{e}^{X}$ 的数学期望与方差.\n14. 设随机变量 $X$ 服从标准正态分布 $N(0,1)$, 试求以下 $Y$ 的密度函数.  \n(1) $Y=|X|$. (2) $Y=2 X^{2}+1$.  \n15. 设随机变量 $X$ 的密度函数为  \n$$\np(x)= \\begin{cases}\\mathrm{e}^{-x}, & \\text { 若 } x>0 ; \\\\ 0, & \\text { 若 } x \\leqslant 0 .\\end{cases}\n$$  \n试求以下 $Y$ 的密度函数.  \n(1) $Y=2 X+1$. (2) $Y=\\mathrm{e}^{X}$. (3) $Y=X^{2}$.  \n16. 设随机变量 $X$ 服从参数为 2 的指数分布,试证 $Y_{1}=\\mathrm{e}^{-2 X}$ 和 $Y_{2}=1-\\mathrm{e}^{-2 X}$ 都服从区间 $(0,1)$上的均匀分布.\n17. 设 $Y \\sim L N\\left(\\mu, \\sigma^{2}\\right)$, 试证: $X=\\ln Y \\sim N\\left(\\mu, \\sigma^{2}\\right)$.\n18. 设 $Y \\sim L N\\left(5,0.12^{2}\\right)$, 试求 $P(Y<188.7)$.",
        "metadata": {
            "Header 2": "习题 2.6"
        },
        "type": "Document"
    },
    {
        "page_content": "数学期望和方差是随机变量最重要的两个特征数. 此外, 随机变量还有一些其他的特征数, 以下逐一给出它们的定义.",
        "metadata": {
            "Header 2": "2.7 分布的其他特征数"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 2.7.1. 设 $X$ 为随机变量, $k$ 为正整数. 如果以下的数学期望都存在,则称  \n$$\n\\begin{equation*}\n\\mu_{k}=E\\left(X^{k}\\right) \\tag{2.7.1}\n\\end{equation*}\n$$  \n为 $X$ 的 $k$ 阶原点矩. 称  \n$$\n\\begin{equation*}\nv_{k}=E[X-E(X)]^{k} \\tag{2.7.2}\n\\end{equation*}\n$$  \n为 $X$ 的 $k$ 阶中心矩.  \n显然, 一阶原点矩就是数学期望, 二阶中心矩就是方差. 由于 $|X|^{k-1} \\leqslant|X|^{k}+1$, 故 $k$ 阶矩存在时, $k-1$ 阶矩也存在, 从而低于 $k$ 的各阶矩都存在.  \n中心矩和原点矩之间有一个简单的关系, 事实上  \n$$\nv_{k}=E[X-E(X)]^{k}=E\\left(X-\\mu_{1}\\right)^{k}=\\sum_{i=0}^{k}\\left(\\begin{array}{l}\nk \\\\\ni\n\\end{array}\\right) \\mu_{i}\\left(-\\mu_{1}\\right)^{k-i}\n$$  \n故前四阶中心矩可分别用原点矩表示如下:  \n$$\n\\begin{aligned}\n& v_{1}=0 ; \\\\\n& v_{2}=\\mu_{2}-\\mu_{1}^{2} ; \\\\\n& v_{3}=\\mu_{3}-3 \\mu_{2} \\mu_{1}+2 \\mu_{1}^{3} ; \\\\\n& v_{4}=\\mu_{4}-4 \\mu_{3} \\mu_{1}+6 \\mu_{2} \\mu_{1}^{2}-3 \\mu_{1}^{4} .\n\\end{aligned}\n$$  \n例 2.7.1: 设随机变量 $X \\sim N\\left(0, \\sigma^{2}\\right)$, 则  \n$$\n\\begin{aligned}\n\\mu_{k} & =E\\left(X^{k}\\right)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\int_{-\\infty}^{+\\infty} x^{k} \\mathrm{e}^{-\\frac{x^{2}}{2 \\sigma^{2}}} \\mathrm{~d} x \\\\",
        "metadata": {
            "Header 2": "$2.7 .1 k$ 阶矩"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n故前四阶中心矩可分别用原点矩表示如下:  \n$$\n\\begin{aligned}\n& v_{1}=0 ; \\\\\n& v_{2}=\\mu_{2}-\\mu_{1}^{2} ; \\\\\n& v_{3}=\\mu_{3}-3 \\mu_{2} \\mu_{1}+2 \\mu_{1}^{3} ; \\\\\n& v_{4}=\\mu_{4}-4 \\mu_{3} \\mu_{1}+6 \\mu_{2} \\mu_{1}^{2}-3 \\mu_{1}^{4} .\n\\end{aligned}\n$$  \n例 2.7.1: 设随机变量 $X \\sim N\\left(0, \\sigma^{2}\\right)$, 则  \n$$\n\\begin{aligned}\n\\mu_{k} & =E\\left(X^{k}\\right)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\int_{-\\infty}^{+\\infty} x^{k} \\mathrm{e}^{-\\frac{x^{2}}{2 \\sigma^{2}}} \\mathrm{~d} x \\\\\n& =\\frac{\\sigma^{k}}{\\sqrt{2 \\pi}} u^{k} \\mathrm{e}^{-\\frac{u^{2}}{2}} \\mathrm{~d} u .\n\\end{aligned}\n$$  \n在 $k$ 为奇数时, 上述被积函数是奇函数, 故  \n$$\n\\mu_{k}=0, k=1,3,5, \\cdots .\n$$  \n在 $k$ 为偶数时,上述被积函数是偶函数,再利用变换 $z=u^{2} / 2$, 可得  \n$$\n\\begin{aligned}\n\\mu_{k} & =\\sqrt{\\frac{2}{\\pi}} \\sigma^{k} 2^{(k-1) / 2} \\int_{0}^{+\\infty} z^{(k-1) / 2} \\mathrm{e}^{-z} \\mathrm{~d} z=\\sqrt{\\frac{2}{\\pi}} \\sigma^{k} 2^{(k-1) / 2} \\Gamma\\left(\\frac{k+1}{2}\\right) \\\\\n& =\\sigma^{k}(k-1)(k-3) \\cdots 1 . \\quad k=2,4,6, \\cdots .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "$2.7 .1 k$ 阶矩"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n在 $k$ 为奇数时, 上述被积函数是奇函数, 故  \n$$\n\\mu_{k}=0, k=1,3,5, \\cdots .\n$$  \n在 $k$ 为偶数时,上述被积函数是偶函数,再利用变换 $z=u^{2} / 2$, 可得  \n$$\n\\begin{aligned}\n\\mu_{k} & =\\sqrt{\\frac{2}{\\pi}} \\sigma^{k} 2^{(k-1) / 2} \\int_{0}^{+\\infty} z^{(k-1) / 2} \\mathrm{e}^{-z} \\mathrm{~d} z=\\sqrt{\\frac{2}{\\pi}} \\sigma^{k} 2^{(k-1) / 2} \\Gamma\\left(\\frac{k+1}{2}\\right) \\\\\n& =\\sigma^{k}(k-1)(k-3) \\cdots 1 . \\quad k=2,4,6, \\cdots .\n\\end{aligned}\n$$  \n故 $N\\left(0, \\sigma^{2}\\right)$ 分布的前四阶原点矩为  \n$$\n\\mu_{1}=0, \\quad \\mu_{2}=\\sigma^{2}, \\quad \\mu_{3}=0, \\quad \\mu_{4}=3 \\sigma^{4} .\n$$  \n又因为 $E(X)=0$, 所以有原点矩等于中心矩, 即 $\\mu_{k}=v_{k}, k=1,2, \\cdots$.",
        "metadata": {
            "Header 2": "$2.7 .1 k$ 阶矩"
        },
        "type": "Document"
    },
    {
        "page_content": "方差 (或标准差) 反映了随机变量取值的波动程度, 但在比较两个随机变量的波动大小时, 如果仅看方差 (或标准差) 的大小有时会产生不合理的现象. 这有两个原因: (1) 随机变量的取值有量纲, 不同量纲的随机变量用其方差 (或标准差) 去比较它们的波动大小不太合理. (2) 在取值的量纲相同的情况下, 取值的大小有一个相对性问题, 取值较大的随机变量的方差 (或标准差) 也允许大一些.  \n所以要比较两个随机变量的波动大小时, 在有些场合使用以下定义的变异系数来进行比较,更具可比性.  \n定义 2.7.2. 设随机变量 $X$ 的二阶矩存在,则称比值  \n$$\n\\begin{equation*}\nC_{v}(X)=\\frac{\\sqrt{\\operatorname{Var}(X)}}{E(X)}=\\frac{\\sigma(X)}{E(X)} \\tag{2.7.3}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "$2.7 .1 k$ 阶矩",
            "Header 3": "2.7.2 变异系数"
        },
        "type": "Document"
    },
    {
        "page_content": "因为变异系数是以其数学期望为单位去度量随机变量取值波动程度的特征数, 标准差的量纲与数学期望的量纲是一致的,所以变异系数是一个无量纲的量.  \n例 2.7.2: 用 $X$ 表示某种同龄树的高度,其量纲是米 ( $\\mathrm{m}$ ), 用 $Y$ 表示某年龄段儿童的身高,其量纲也是米 $(\\mathrm{m})$. 设 $E(X)=10, \\operatorname{Var}(X)=1, E(Y)=1, \\operatorname{Var}(Y)=0.04$, 你是否可以从 $\\operatorname{Var}(X)=1$ 和 $\\operatorname{Var}(Y)=0.04$ 就认为 $Y$ 的波动小? 这就有一个取值相对大小的问题. 在此用变异系数进行比较是恰当的. 因为 $X$ 的变异系数为  \n$$\nC_{v}(X)=\\frac{\\sigma(X)}{E(X)}=\\frac{1}{10}=0.1\n$$  \n而 $Y$ 的变异系数为  \n$$\nC_{v}(Y)=\\frac{\\sigma(Y)}{E(Y)}=\\frac{\\sqrt{0.04}}{1}=0.2,\n$$  \n这说明 $Y$ 的波动比 $X$ 的波动大.",
        "metadata": {
            "Header 2": "为 $X$ 的变异系数"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 2.7.3. 设连续随机变量 $X$ 的分布函数为 $F(x)$, 密度函数为 $p(x)$. 对任意 $p \\in(0,1)$, 称满足条件  \n$$\n\\begin{equation*}\nF\\left(x_{p}\\right)=\\int_{-\\infty}^{x_{p}} p(x) \\mathrm{d} x=p \\tag{2.7.4}\n\\end{equation*}\n$$  \n的 $x_{p}$ 为此分布的 $p$ 分位数, 又称下侧 $p$ 分位数.  \n分位数 $x_{p}$ 是把密度函数下的而积分为两块, 左侧面积恰好为 $p$ (见图 2.7.1(a)).  \n同理我们称满足条件  \n$$\n\\begin{equation*}\n1-F\\left(x_{p}^{\\prime}\\right)=\\int_{x_{p}^{\\prime}}^{+\\infty} p(x) d d x=p \\tag{2.7.5}\n\\end{equation*}\n$$  \n的 $x_{p}^{\\prime}$ 为此分布的上侧 $p$ 分位数.  \n上侧分位数 $x_{p}^{\\prime}$ 也是把密度函数下的面积分为两块, 但右侧面积恰好为 $p$ (见图 2.7.1(b)).  \n!  \n(a) (下侧) 分位数  \n!  \n(b) 上侧分位数  \n图 2.7.1: 分位数与上侧分位数的区别  \n要善于区分分位数与上侧分位数的差别, 本书指定用分位数表, 而有一些书使用的是上侧分位数表,无论用什么表,书中都有说明.  \n分位数与上侧分位数是可以相互转换的, 其转换公式如下.  \n$$\n\\begin{equation*}\nx_{p}^{\\prime}=x_{1-p} ; \\quad x_{p}=x_{1-p}^{\\prime} . \\tag{2.7.6}\n\\end{equation*}\n$$  \n例 2.7.3: 标准正态分布 $N(0,1)$ 的 $p$ 分位数记为 $u_{P}$, 它是方程  \n$$\n\\Phi\\left(u_{p}\\right)=p\n$$",
        "metadata": {
            "Header 2": "2.7 .3 分位数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n的 $x_{p}^{\\prime}$ 为此分布的上侧 $p$ 分位数.  \n上侧分位数 $x_{p}^{\\prime}$ 也是把密度函数下的面积分为两块, 但右侧面积恰好为 $p$ (见图 2.7.1(b)).  \n!  \n(a) (下侧) 分位数  \n!  \n(b) 上侧分位数  \n图 2.7.1: 分位数与上侧分位数的区别  \n要善于区分分位数与上侧分位数的差别, 本书指定用分位数表, 而有一些书使用的是上侧分位数表,无论用什么表,书中都有说明.  \n分位数与上侧分位数是可以相互转换的, 其转换公式如下.  \n$$\n\\begin{equation*}\nx_{p}^{\\prime}=x_{1-p} ; \\quad x_{p}=x_{1-p}^{\\prime} . \\tag{2.7.6}\n\\end{equation*}\n$$  \n例 2.7.3: 标准正态分布 $N(0,1)$ 的 $p$ 分位数记为 $u_{P}$, 它是方程  \n$$\n\\Phi\\left(u_{p}\\right)=p\n$$  \n的唯一解, 其解为 $u_{p}=\\Phi^{-1}(p)$, 其中 $\\Phi^{-1}(\\cdot)$ 是标准正态分布函数的反函数. 利用标准正态分布函数表 (见附表 2 ), 我们可由 $p$ 查得 $u_{p}$. 譬如 $u_{0.95}=1.96$. 由于标准正态分布的密度函数是偶函数,故其分位数有如下性质:  \n- 当 $p<0.5$ 时, $u_{p}<0$.\n- 当 $p>0.5$ 时, $u_{p}>0$.\n- 当 $p=0.5$ 时, $u_{0.5}=0$.\n- 当 $p_{1}<p_{2}$ 时, $u_{p_{1}}<u_{p_{2}}$.  \n又由定理 2.5.1 可知:一般正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的 $p$ 分位数 $x_{p}$ 是方程  \n$$\n\\Phi\\left(\\frac{x_{p}-\\mu}{\\sigma}\\right)=p\n$$  \n的解,所以由  \n$$\n\\frac{x_{p}-\\mu}{\\sigma}=u_{p}\n$$  \n可得 $x_{p}$ 与 $u_{p}$ 的关系式  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "2.7 .3 分位数"
        },
        "type": "Document"
    },
    {
        "page_content": "- 当 $p<0.5$ 时, $u_{p}<0$.\n- 当 $p>0.5$ 时, $u_{p}>0$.\n- 当 $p=0.5$ 时, $u_{0.5}=0$.\n- 当 $p_{1}<p_{2}$ 时, $u_{p_{1}}<u_{p_{2}}$.  \n又由定理 2.5.1 可知:一般正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的 $p$ 分位数 $x_{p}$ 是方程  \n$$\n\\Phi\\left(\\frac{x_{p}-\\mu}{\\sigma}\\right)=p\n$$  \n的解,所以由  \n$$\n\\frac{x_{p}-\\mu}{\\sigma}=u_{p}\n$$  \n可得 $x_{p}$ 与 $u_{p}$ 的关系式  \n$$\n\\begin{equation*}\nx_{p}=\\mu+\\sigma u_{p} \\tag{2.7.7}\n\\end{equation*}\n$$  \n譬如正态分布 $N\\left(10,2^{2}\\right)$ 的 0.95 分位数为  \n$$\nx_{0.95}=10+2 u_{0.95}=10+2 \\times 1.96=13.92 \\text {. }\n$$  \n分位数在统计中经常被使用，特别对统计中常用的三大分布： $\\chi^{2}$ 分布、 $t$ 分布和 $F$ 分布,都特地编制了它们的分位数表. 以后分别以 $\\chi_{\\alpha}^{2}(n) . t_{\\alpha}(n), F_{\\alpha}(n, m)$ 记这些分布的 $\\alpha$ 分位数. 例如 $\\alpha=0.05, n=10, m=15$ 时,查附表 3、附表 4、附表 5 ,可得  \n$$\n\\chi^{2} 1-\\alpha(n)=18.307 ; \\quad t_{1-\\alpha}=1.8125 ; \\quad F_{1-\\alpha}(n, m)=2.54\n$$",
        "metadata": {
            "Header 2": "2.7 .3 分位数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nx_{p}=\\mu+\\sigma u_{p} \\tag{2.7.7}\n\\end{equation*}\n$$  \n譬如正态分布 $N\\left(10,2^{2}\\right)$ 的 0.95 分位数为  \n$$\nx_{0.95}=10+2 u_{0.95}=10+2 \\times 1.96=13.92 \\text {. }\n$$  \n分位数在统计中经常被使用，特别对统计中常用的三大分布： $\\chi^{2}$ 分布、 $t$ 分布和 $F$ 分布,都特地编制了它们的分位数表. 以后分别以 $\\chi_{\\alpha}^{2}(n) . t_{\\alpha}(n), F_{\\alpha}(n, m)$ 记这些分布的 $\\alpha$ 分位数. 例如 $\\alpha=0.05, n=10, m=15$ 时,查附表 3、附表 4、附表 5 ,可得  \n$$\n\\chi^{2} 1-\\alpha(n)=18.307 ; \\quad t_{1-\\alpha}=1.8125 ; \\quad F_{1-\\alpha}(n, m)=2.54\n$$  \n譬如, 记某种轴承的寿命为 $T, t_{p}$ 为此寿命分布的 $p$ 分位数, 则 $t_{0.1}=1000(\\mathrm{~h})$, 表明此种轴承中约有 $90 \\%$ 寿命超过 1000 小时. 若记另一种轴承的寿命为 $Z, p$ 分位数为 $z_{p}$. 则当 $z_{0.1}=1500$ (h) 时, 从 0.1 的分位数上说明后者的质量比前者更高一些.",
        "metadata": {
            "Header 2": "2.7 .3 分位数"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 2.7.4. 设连续随机变量 $X$ 的分布函数为 $F(x)$, 密度函数为 $p(x)$. 称 $p=0.5$ 时的 $p$ 分位数 $x_{0.5}$ 为此分布的中位数, 即 $x_{0.5}$ 满足  \n$$\n\\begin{equation*}\nF_{\\left(x_{0.5}\\right)}=\\int_{-\\infty}^{0.5} p(x) \\mathrm{d} x=0.5 \\tag{2.7.8}\n\\end{equation*}\n$$  \n中位数的图形见下面图 2.7.2.\n!  \n图 2.7.2: 连续随机变量的中位数  \n中位数与均值一样都是随机变量位置的特征数, 但在某些场合可能中位数比均值更能说明问题. 譬如, 某班级学生的考试成绩的中位数为 80 分, 则表明班级中的有一半同学的成绩低于 80 分,另一半同学的成绩高于 80 分. 而如果考试成绩的均值是 80 分, 则无法得出如此明确的结论.  \n又譬如, 记 $X$ 为 $A$ 国人的年龄, $Y$ 为 $B$ 国人的年龄, $x_{0.5}$ 和 $y_{0.5}$ 分别为 $X$ 和 $Y$ 的中位数,则 $x_{0.5}=40$ (岁) 说明 $A$ 国约有一半的人年龄小于等于 40 岁、一半的人年龄大于等于 40 岁. 而 $y_{0.5}=50($ 岁 $)$ 则说明 $B$ 国更趋于老龄化.  \n例 2.7.4: 指数分布 $\\operatorname{Exp}(\\lambda)$ 的中位数 $x_{0.5}$ 是方程  \n$$\n1-\\mathrm{e}^{-\\lambda x_{0.5}}=0.5\n$$  \n的解, 解之得  \n$$\nx_{0.5}=\\frac{\\ln 2}{\\lambda} .\n$$  \n假如, 某城市电话的通话时间 $X(\\min )$ 服从均值 $E(X)=2(\\min )$ 的指数分布, 此时由 $\\lambda=0.5$ 可得中位数为  \n$$\nx_{0.5}=\\frac{\\ln 2}{0.5}=1.39 \\mathrm{~min}\n$$  \n它表明: 该城市中约有一半的电话在 $1.39 \\mathrm{~min}$ 内结束, 另一半的通话时间超过 $1.39 \\mathrm{~min}$.",
        "metadata": {
            "Header 2": "2.7 .3 分位数",
            "Header 3": "2.7.4 中位数"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 2.7.5. 设随机变量 $X$ 的三阶矩存在,则称比值  \n$$\n\\begin{equation*}\n\\beta_{1}=\\frac{E[X-E(X)]^{3}}{\\left[E(X-E(X))^{2}\\right]^{3 / 2}}=\\frac{v_{3}}{\\left(v_{2}\\right)^{3 / 2}} \\tag{2.7.9}\n\\end{equation*}\n$$  \n为 $X$ 的分布的偏度系数, 简称偏度.  \n偏度系数可以描述分布的形状特征,其取值的正负反映的是  \n- 当 $\\beta_{1}>0$ 时,分布为正偏或右偏,见图 ??(a).\n- 当 $\\beta_{1}=0$ 时, 分布关于其均值 $E(X)$ 对称, 见图 ??(b).\n- 当 $\\beta_{1}<0$ 时, 分布为负偏或左偏,见图 ??(c).  \n譬如, 正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 是关于其均值 $E(X)=\\mu$ 是对称的,所以正态分布的偏度 $\\beta_{1}=0$.  \n!  \n(a)  \n!  \n(b)  \n!  \n(c)  \n图 2.7.3: 三种不同偏度的分布",
        "metadata": {
            "Header 2": "2.7 .5 偏度系数"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 2.7.6. 设随机变量 $X$ 的四阶矩存在,则称比值  \n$$\n\\begin{equation*}\n\\beta_{2}=\\frac{E[X-E(X)]^{4}}{\\left[E(X-E(X))^{2}\\right]^{2}}-3=\\frac{v_{4}}{\\left(v_{2}\\right)^{2}}-3 \\tag{2.7.10}\n\\end{equation*}\n$$  \n为 $\\mathrm{X}$ 的分布的峰度系数, 简称峰度.  \n峰度系数也是用于描述分布的形状特征, 但峰度系数与偏度系数的差别是: 偏度系数刻画的是分布的对称性,而峰度系数刻画的是分布的蜂峭性.  \n峰度系数把正态分布的峰峭性作为标准, 因为正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的四阶中心矩为 $v_{4}=3 \\sigma^{4}$,所以其峰度系数为  \n$$\n\\beta_{2}=\\frac{\\nu_{4}}{\\left(v_{2}\\right)^{2}}-3=\\frac{3 \\sigma^{4}}{\\sigma^{4}}-3=0 .\n$$  \n这说明:任一正态分布的峰度 $\\beta_{2}=0$.  \n可见, 这里谈论的 “峰度” 不是指密度函数的峰值高低, 那么 “蜂度” 的含义到底是什么呢? 或者换句话说, 我们应该如何刻画密度函数的峰峭性呢? 我们知道从图形上看密度函数曲线下的面积等于 1 , 若随机变量取值较集中, 则其密度函数的峰值必高无疑, 所以密度函数峰值的高低含有随机变量取值的集中程度. 为了消除这个因素,我们不妨考察“标准化”后的分布的峰峭性,即用  \n$$\nX^{*}=\\frac{X-E(X)}{\\sqrt{\\operatorname{Var}(X)}}\n$$  \n的四阶原点矩 $E\\left[\\left(X^{*}\\right)^{4}\\right]$ 考察密度函数的峰值, 再考虑到任一标准正态分布的四阶原点矩等于 3 ,所以就有了以上峰度系数的定义.  \n综上所述,一个分布的峰度系数 $\\beta_{2}$ 反映了以下情况:  \n- 当 $\\beta_{2}<0$ 时,则标准化后的分布形状比标准正态分布更平坦,称为低峰度.\n- 当 $\\beta_{2}=0$ 时,则标准化后的分布形状与标准正态分布相当.",
        "metadata": {
            "Header 2": "2.7 .5 偏度系数",
            "Header 3": "2.7.6 峰度系数"
        },
        "type": "Document"
    },
    {
        "page_content": "可见, 这里谈论的 “峰度” 不是指密度函数的峰值高低, 那么 “蜂度” 的含义到底是什么呢? 或者换句话说, 我们应该如何刻画密度函数的峰峭性呢? 我们知道从图形上看密度函数曲线下的面积等于 1 , 若随机变量取值较集中, 则其密度函数的峰值必高无疑, 所以密度函数峰值的高低含有随机变量取值的集中程度. 为了消除这个因素,我们不妨考察“标准化”后的分布的峰峭性,即用  \n$$\nX^{*}=\\frac{X-E(X)}{\\sqrt{\\operatorname{Var}(X)}}\n$$  \n的四阶原点矩 $E\\left[\\left(X^{*}\\right)^{4}\\right]$ 考察密度函数的峰值, 再考虑到任一标准正态分布的四阶原点矩等于 3 ,所以就有了以上峰度系数的定义.  \n综上所述,一个分布的峰度系数 $\\beta_{2}$ 反映了以下情况:  \n- 当 $\\beta_{2}<0$ 时,则标准化后的分布形状比标准正态分布更平坦,称为低峰度.\n- 当 $\\beta_{2}=0$ 时,则标准化后的分布形状与标准正态分布相当.\n- 当 $\\beta_{2}>0$ 时,则标准化后的分布形状比标准正态分布更尖峭,称为高峰度.  \n例 2.7.5: (1) 均匀分布 $U(a, b)$ 的密度函数很平坦, 其峰度系数 $\\beta_{2}=-1.2$. 可以预计, 当一个分布的蜂度 $\\beta_{2}<-1.2$ 时, 其密度函数会呈 $U$ 形.  \n(2) 指数分布 $\\operatorname{Exp}(\\lambda)$ 的峰度系数 $\\beta_{2}=6$, 所以指数分布比正态分布更尖峭.",
        "metadata": {
            "Header 2": "2.7 .5 偏度系数",
            "Header 3": "2.7.6 峰度系数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n的四阶原点矩 $E\\left[\\left(X^{*}\\right)^{4}\\right]$ 考察密度函数的峰值, 再考虑到任一标准正态分布的四阶原点矩等于 3 ,所以就有了以上峰度系数的定义.  \n综上所述,一个分布的峰度系数 $\\beta_{2}$ 反映了以下情况:  \n- 当 $\\beta_{2}<0$ 时,则标准化后的分布形状比标准正态分布更平坦,称为低峰度.\n- 当 $\\beta_{2}=0$ 时,则标准化后的分布形状与标准正态分布相当.\n- 当 $\\beta_{2}>0$ 时,则标准化后的分布形状比标准正态分布更尖峭,称为高峰度.  \n例 2.7.5: (1) 均匀分布 $U(a, b)$ 的密度函数很平坦, 其峰度系数 $\\beta_{2}=-1.2$. 可以预计, 当一个分布的蜂度 $\\beta_{2}<-1.2$ 时, 其密度函数会呈 $U$ 形.  \n(2) 指数分布 $\\operatorname{Exp}(\\lambda)$ 的峰度系数 $\\beta_{2}=6$, 所以指数分布比正态分布更尖峭.  \n(3) 伽玛分布 $G a(\\alpha, \\lambda)$ 的偏度系数 $\\beta_{1}=2 / \\sqrt{\\alpha}$, 峰度系数 $\\beta_{2}=$, 可见伽玛分布 $G a(\\alpha, \\lambda)$ 的偏度与峰度只与形状参数 $\\alpha$ 有关, 而与尺度参数 $\\lambda$ 无关. 且 $\\alpha$ 越大, $\\beta_{1}$ 与 $\\beta_{2}$ 越小, 特别当 $\\alpha$ 很大时, $\\beta_{1}$ 与 $\\beta_{2}$ 越接近于零, 密度函数越近似于正态密度函数 (见图 2.5.4).",
        "metadata": {
            "Header 2": "2.7 .5 偏度系数",
            "Header 3": "2.7.6 峰度系数"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设 $X \\sim U(a, b)$, 对 $k=1,2,3,4$, 求 $\\mu_{k}=E\\left(X^{k}\\right)$ 与 $v_{k}=E[X-E(X)]^{k}$. 进一步求此分布的偏度系数和峰度系数.\n2. 设 $X \\sim U(0, a)$, 求此分布的变异系数.\n3. 设 $X \\sim G a(\\alpha, \\lambda)$, 对 $k=1,2,3$, 求 $\\mu_{k}=E\\left(X^{k}\\right)$ 与 $v_{k}=E[X-E(X)]^{k}$.\n4. 设 $X \\sim \\operatorname{Exp}(\\lambda)$, 对 $k=1,2,3,4$, 求 $\\mu_{k}=E\\left(X^{k}\\right)$ 与 $v_{k}=E[X-E(X)]^{k}$. 进一步求此分布的变异系数、偏度系数和峰度系数.\n5. 设随机变量 $X$ 服从正态分布 $N(10,9)$, 试求 $x_{0.1}$ 和 $x_{0.9}$.\n6. 设 $Y=\\ln X$, 且 $Y \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 试求 $x_{0.5}$.\n7. 设随机变量 $X$ 服从双参数威布尔分布,其分布函数为  \n$$\nF(x)=1-\\mathrm{e}^{-\\left(\\frac{x}{\\eta}\\right)^{m}}, \\quad x>0\n$$  \n其中 $\\eta>0, m>0$. 试写出该分布的 $p$ 分位数 $x_{p}$ 的表达式, 且求出当 $m=1.5, \\eta=1000$ 时的 $x_{0.1}, x_{0.5}, x_{0.8}$ 的值.  \n8. 自由度为 2 的 $\\chi^{2}$ 分布的密度函数为  \n$$\np(x)=\\frac{1}{2} \\mathrm{e}^{-\\frac{x}{2}}, \\quad x>0 .\n$$  \n试求出其分布函数及分位数 $x_{0.1}, x_{0.5}, x_{0.8}$.  \n9. 设随机变量 $X$ 的分布密度函数 $p(x)$ 关于 $c$ 点是对称的,且 $E(X)$ 存在, 试证  \n(1) 这个对称点 $c$ 既是均值又是中位数,即 $E(X)=x_{0.5}=c$;",
        "metadata": {
            "Header 2": "妇题 2.7"
        },
        "type": "Document"
    },
    {
        "page_content": "7. 设随机变量 $X$ 服从双参数威布尔分布,其分布函数为  \n$$\nF(x)=1-\\mathrm{e}^{-\\left(\\frac{x}{\\eta}\\right)^{m}}, \\quad x>0\n$$  \n其中 $\\eta>0, m>0$. 试写出该分布的 $p$ 分位数 $x_{p}$ 的表达式, 且求出当 $m=1.5, \\eta=1000$ 时的 $x_{0.1}, x_{0.5}, x_{0.8}$ 的值.  \n8. 自由度为 2 的 $\\chi^{2}$ 分布的密度函数为  \n$$\np(x)=\\frac{1}{2} \\mathrm{e}^{-\\frac{x}{2}}, \\quad x>0 .\n$$  \n试求出其分布函数及分位数 $x_{0.1}, x_{0.5}, x_{0.8}$.  \n9. 设随机变量 $X$ 的分布密度函数 $p(x)$ 关于 $c$ 点是对称的,且 $E(X)$ 存在, 试证  \n(1) 这个对称点 $c$ 既是均值又是中位数,即 $E(X)=x_{0.5}=c$;  \n(2) 如果 $c=0$, 则 $x_{p}=-x_{1-p}$.  \n10. 试证随机变量 $X$ 的偏度系数与峰度系数对位移和改变比例尺是不变的, 即对任意的实数 $a, b(b \\neq 0), Y=(X-a) / b$ 与 $X$ 有相同的偏度系数与峰度系数.",
        "metadata": {
            "Header 2": "妇题 2.7"
        },
        "type": "Document"
    },
    {
        "page_content": "在有些随机现象中, 对每个样本点 $\\omega$ 只用一个随机变量去描述是不够的, 譬如要研究儿童的生长发育情况, 仅研究儿童的身高 $X(\\omega)$ 或仅研究其体重 $Y(\\omega)$ 都是片面的, 有必要把 $X(\\omega)$ 和 $Y(\\omega)$ 作为一个整体来考虑, 讨论它们总体变化的统计规律性, 进一步可以讨论 $X(\\omega)$ 与 $Y(\\omega)$ 之间的关系, 在有些随机现象中, 甚至要同时研究二个以上随机变量.  \n如何来研究多维随机变量的统计规律性呢, 仿一维随机变量, 我们先研究联合分布函数, 然后研究离散随机变量的联合分布列、连续随机变量的联合密度函数.",
        "metadata": {
            "Header 2": "第 3 章 多维随机变量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "下面我们先给出 $n$ 维随机变量的定义.  \n定义 3.1.1 (随机变量). 如果 $X_{1}(\\omega), X_{2}(\\omega), \\ldots, X_{n}(\\omega)$ 是定义在同一样本空间 $\\Omega=\\{\\omega\\}$ 上的 $n$ 个随机变量, 则称  \n$$\nX(\\omega)=\\left(X_{1}(\\omega), X_{2}(\\omega), \\ldots, X_{n}(\\omega)\\right)\n$$  \n为 $n$ 维 (或 $n$ 元) 随机变量或随机向量.  \n注意, 多维随机变量的关键是定义在同一样本空间上, 对于不同样本空间上的两个随机变量,我们只能在乘积空间 $\\Omega_{1} \\times \\Omega_{2}=\\left\\{\\left(\\omega_{1}, \\omega_{2}\\right) ; \\omega_{1} \\in \\Omega_{1}, \\omega_{2} \\in \\Omega_{2}\\right\\}$ 上讨论, 这要用到更多的工具, 本章将不涉及这类问题.  \n在实际问题中, 多维随机变量的情况是经常会遇到的譬如  \n- 在研究四岁至六岁儿童的生长发育情况时, 我们感兴趣于每个儿童 (样本点 $\\omega$ ) 的身高 $X_{1}(\\omega)$和体重 $X_{2}(\\omega)$. 这里 $\\left(X_{1}(\\omega), X_{2}(\\omega)\\right)$ 是一个二维随机变量.\n- 在研究每个家庭的支出情况时, 我们感兴趣于每个家庭 (样本点 $\\omega$ ) 的衣食住行四个方面,若用 $X_{1}(\\omega), X_{2}(\\omega), X_{3}(\\omega), X_{4}(\\omega)$ 分别表示衣食住行的花费占其家庭总收人的百分比, 则 $\\left(X_{1}(\\omega), X_{2}(\\omega), X_{3}(\\omega), X_{4}(\\omega)\\right)$ 就是一个四维随机变量.",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.1 多维随机变量"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 3.1 .2 (联合分布函数). 对任意的 $n$ 个实数 $x_{1}, x_{2}, \\ldots, x_{n}$, 则 $n$ 个事件 $\\left\\{X_{1} \\leqslant x_{1}\\right\\},\\left\\{X_{2} \\leqslant\\right.$ $\\left.x_{2}\\right\\}, \\ldots,\\left\\{X_{n} \\leqslant x_{n}\\right\\}$ 同时发生的概率  \n$$\n\\begin{equation*}\nF\\left(x_{1}, x_{2}, \\cdots, x_{n}\\right)=P\\left(X_{1} \\leqslant x_{1}, X_{2} \\leqslant x_{2}, \\ldots, X_{n} \\leqslant x_{n}\\right) \\tag{3.1.1}\n\\end{equation*}\n$$  \n称为 $n$ 维随机变量 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的联合分布函数.  \n本章主要研究二维随机变量, 二维以上的情况可类似进行.  \n在二维随机变量 $(X, Y)$ 场合, 联合分布函数 $F(x, y)=P(X \\leqslant x, Y \\leqslant y)$ 是事件 $\\{X \\leqslant x\\}$ 与 $\\{Y \\leqslant y\\}$ 同时发生 (交) 的概率. 如果将二维随机变量 $(X, Y)$ 看成是平面上随机点的坐标, 那么联合分布函数 $F(x, y)$ 在 $(x, y)$ 处的函数值就是随机点 $(X, Y)$ 落在以 $(x, y)$ 为右上角的无穷矩形内的概率, 见图 3.1.1.  \n定理 3.1.1. 任一二维联合分布函数 $F(x, y)$ 必具有如下四条基本性质:  \n1. 单调性 $F(x, y)$ 分别对 $x$ 或 $y$ 是单调不减的, 即  \n!  \n图 3.1.1: 联合分布函数示意图  \n- 当 $x_{1}<x_{2}$ 时, 有 $F\\left(x_{1}, y\\right) \\leqslant F\\left(x_{2}, y\\right)$.",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.2 联合分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "本章主要研究二维随机变量, 二维以上的情况可类似进行.  \n在二维随机变量 $(X, Y)$ 场合, 联合分布函数 $F(x, y)=P(X \\leqslant x, Y \\leqslant y)$ 是事件 $\\{X \\leqslant x\\}$ 与 $\\{Y \\leqslant y\\}$ 同时发生 (交) 的概率. 如果将二维随机变量 $(X, Y)$ 看成是平面上随机点的坐标, 那么联合分布函数 $F(x, y)$ 在 $(x, y)$ 处的函数值就是随机点 $(X, Y)$ 落在以 $(x, y)$ 为右上角的无穷矩形内的概率, 见图 3.1.1.  \n定理 3.1.1. 任一二维联合分布函数 $F(x, y)$ 必具有如下四条基本性质:  \n1. 单调性 $F(x, y)$ 分别对 $x$ 或 $y$ 是单调不减的, 即  \n!  \n图 3.1.1: 联合分布函数示意图  \n- 当 $x_{1}<x_{2}$ 时, 有 $F\\left(x_{1}, y\\right) \\leqslant F\\left(x_{2}, y\\right)$.\n- 当 $y_{1}<y_{2}$ 时, 有 $F\\left(x, y_{1}\\right) \\leqslant F\\left(x, y_{2}\\right)$.  \n2. 有界性 对任意的 $x$ 和 $y$, 有 $0 \\leqslant F(x, y) \\leqslant 1$, 且  \n$$\n\\begin{aligned}\n& F(-\\infty, y)=\\lim _{x \\rightarrow-\\infty} F(x, y)=0, \\\\\n& F(x,-\\infty)=\\lim _{y \\rightarrow-\\infty} F(x, y)=0, \\\\\n& F(+\\infty,+\\infty)=\\lim _{x, y \\rightarrow+\\infty}(x, y)=1 .\n\\end{aligned}\n$$  \n3. 右连续性 对每个变量都是右连续的, 即  \n$$\n\\begin{aligned}\n& F(x+0, y)=F(x, y), \\\\\n& F(x, y+0)=F(x, y) .\n\\end{aligned}\n$$  \n4. 非负性 对任意的 $a<b, c<d$ 有  \n$$",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.2 联合分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "2. 有界性 对任意的 $x$ 和 $y$, 有 $0 \\leqslant F(x, y) \\leqslant 1$, 且  \n$$\n\\begin{aligned}\n& F(-\\infty, y)=\\lim _{x \\rightarrow-\\infty} F(x, y)=0, \\\\\n& F(x,-\\infty)=\\lim _{y \\rightarrow-\\infty} F(x, y)=0, \\\\\n& F(+\\infty,+\\infty)=\\lim _{x, y \\rightarrow+\\infty}(x, y)=1 .\n\\end{aligned}\n$$  \n3. 右连续性 对每个变量都是右连续的, 即  \n$$\n\\begin{aligned}\n& F(x+0, y)=F(x, y), \\\\\n& F(x, y+0)=F(x, y) .\n\\end{aligned}\n$$  \n4. 非负性 对任意的 $a<b, c<d$ 有  \n$$\nP(a<X \\leqslant b, c<Y \\leqslant d)=F(b, d)-F(a, d)-F(b, c)+F(a, c) \\geqslant 0 .\n$$  \n证明:  \n1. 因为当 $x_{1}<x_{2}$ 时, 有 $\\left\\{X_{1} \\leqslant x_{1}\\right\\} \\subset\\left\\{X_{2} \\leqslant x_{2}\\right\\}$, 所以对任意给定的 $y$ 有  \n$$\n\\left\\{X \\leqslant x_{1}, Y \\leqslant y\\right\\} \\subseteq\\left\\{X \\leqslant x_{2}, Y \\leqslant y\\right\\}\n$$  \n由此可得  \n$$\nF\\left(x_{1}, y\\right)=P\\left(X \\leqslant x_{1}, Y \\leqslant y\\right) \\leqslant P\\left(X \\leqslant x_{2}, Y \\leqslant y\\right)=F\\left(x_{2}, y\\right) \\text {, }\n$$  \n即 $F(x, y)$ 关于 $x$ 是单调不减的, 同理可证 $F(x, y)$ 关于 $y$ 是单调不减的.",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.2 联合分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n证明:  \n1. 因为当 $x_{1}<x_{2}$ 时, 有 $\\left\\{X_{1} \\leqslant x_{1}\\right\\} \\subset\\left\\{X_{2} \\leqslant x_{2}\\right\\}$, 所以对任意给定的 $y$ 有  \n$$\n\\left\\{X \\leqslant x_{1}, Y \\leqslant y\\right\\} \\subseteq\\left\\{X \\leqslant x_{2}, Y \\leqslant y\\right\\}\n$$  \n由此可得  \n$$\nF\\left(x_{1}, y\\right)=P\\left(X \\leqslant x_{1}, Y \\leqslant y\\right) \\leqslant P\\left(X \\leqslant x_{2}, Y \\leqslant y\\right)=F\\left(x_{2}, y\\right) \\text {, }\n$$  \n即 $F(x, y)$ 关于 $x$ 是单调不减的, 同理可证 $F(x, y)$ 关于 $y$ 是单调不减的.  \n2. 由概率的性质可知 $0 \\leqslant F(x, y) \\leqslant 1$. 又因为对任意的正整数 $n$ 有  \n$$\n\\begin{aligned}\n& \\lim _{x \\rightarrow-\\infty}\\{X \\leqslant x\\}=\\lim _{n \\rightarrow+\\infty} \\bigcap_{m=1}^{n}\\{X \\leqslant-m\\}=\\varnothing, \\\\\n& \\lim _{x \\rightarrow+\\infty}\\{X \\leqslant x\\}=\\lim _{n \\rightarrow+\\infty} \\bigcup_{m=1}^{n}\\{X \\leqslant m\\}=\\Omega,\n\\end{aligned}\n$$  \n对 $Y \\leqslant y$ 也类似可得. 再由概率的连续性, 就可得  \n$$\nF(-\\infty, y)=F(x,-\\infty)=0 ; \\quad F(+\\infty,+\\infty)=1\n$$",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.2 联合分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "2. 由概率的性质可知 $0 \\leqslant F(x, y) \\leqslant 1$. 又因为对任意的正整数 $n$ 有  \n$$\n\\begin{aligned}\n& \\lim _{x \\rightarrow-\\infty}\\{X \\leqslant x\\}=\\lim _{n \\rightarrow+\\infty} \\bigcap_{m=1}^{n}\\{X \\leqslant-m\\}=\\varnothing, \\\\\n& \\lim _{x \\rightarrow+\\infty}\\{X \\leqslant x\\}=\\lim _{n \\rightarrow+\\infty} \\bigcup_{m=1}^{n}\\{X \\leqslant m\\}=\\Omega,\n\\end{aligned}\n$$  \n对 $Y \\leqslant y$ 也类似可得. 再由概率的连续性, 就可得  \n$$\nF(-\\infty, y)=F(x,-\\infty)=0 ; \\quad F(+\\infty,+\\infty)=1\n$$  \n3. 固定 $y$, 仿一维分布函数右连续的证明, 就可得知 $F(x, y)$ 关于 $x$ 是右连续的. 同样固定 $x$ 可证得 $F(x, y)$ 关于 $y$ 是右连续的.\n4. 只需证  \n$$\nP(a<X \\leqslant b, c<Y \\leqslant d)=F(b, d)-F(a, d)-F(b, c)+F(a, c) .\n$$  \n为此记 (见图 3.1.2)  \n$$\nA=\\{X \\leqslant a\\}, \\quad B=\\{X \\leqslant b\\}, \\quad C=\\{Y \\leqslant c\\}, \\quad D=\\{Y \\leqslant d\\}\n$$  \n考虑到  \n$$\n\\{a<X \\leqslant b\\}=B-A=B \\cap \\bar{A}, \\quad\\{c<Y \\leqslant d\\}=D-C=D \\cap \\bar{C},\n$$  \n且 $A \\subset B, C \\subset D$, 由此可得  \n$$\n\\begin{aligned}\n0 & \\leqslant P(a<X \\leqslant b, c<Y \\leqslant d) \\\\",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.2 联合分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "4. 只需证  \n$$\nP(a<X \\leqslant b, c<Y \\leqslant d)=F(b, d)-F(a, d)-F(b, c)+F(a, c) .\n$$  \n为此记 (见图 3.1.2)  \n$$\nA=\\{X \\leqslant a\\}, \\quad B=\\{X \\leqslant b\\}, \\quad C=\\{Y \\leqslant c\\}, \\quad D=\\{Y \\leqslant d\\}\n$$  \n考虑到  \n$$\n\\{a<X \\leqslant b\\}=B-A=B \\cap \\bar{A}, \\quad\\{c<Y \\leqslant d\\}=D-C=D \\cap \\bar{C},\n$$  \n且 $A \\subset B, C \\subset D$, 由此可得  \n$$\n\\begin{aligned}\n0 & \\leqslant P(a<X \\leqslant b, c<Y \\leqslant d) \\\\\n& =P(B \\cap \\bar{A} \\cap D \\cap \\bar{C}) \\\\\n& =P(B D-(A \\cup C)) \\\\\n& =P(B D)-P(A B D \\cup B C D) \\\\\n& =P(B D)-P(A D \\cup B C) \\\\\n& =P(B D)-P(A D)-P(B C)+P(A B C D) \\\\\n& =P(B D)-P(A D)-P(B C)+P(A C) \\\\\n& =P(B D)-P(A D)-P(B C)+P(A B C D) \\\\\n& =F(b, d)-F(a, d)-F(b, c)+F(a, c) .\n\\end{aligned}\n$$  \n!  \n图 3.1.2: 二维随机变量 $(X, Y)$ 落在矩形中的情况  \n还可证明, 具有上述四条性质的二元函数 $F(x, y)$ 一定是某个二维随机变量的分布函数.  \n任一二维分布函数 $F(x, y)$ 必具有上述四条性质, 其中性质 4 是二维场合特有的, 也是合理的.但性质 4 不能由前三条性质推出, 必须单独列出, 且仅满足前三条性质是不够的, 因为存在这样的二元函数 $G(x, y)$ 满足以上性质 $1,2,3$, 但它不满足性质 4 , 见下面例子.  \n例 3.1.1: 二元函数  \n$$",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.2 联合分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "& =P(B D)-P(A B D \\cup B C D) \\\\\n& =P(B D)-P(A D \\cup B C) \\\\\n& =P(B D)-P(A D)-P(B C)+P(A B C D) \\\\\n& =P(B D)-P(A D)-P(B C)+P(A C) \\\\\n& =P(B D)-P(A D)-P(B C)+P(A B C D) \\\\\n& =F(b, d)-F(a, d)-F(b, c)+F(a, c) .\n\\end{aligned}\n$$  \n!  \n图 3.1.2: 二维随机变量 $(X, Y)$ 落在矩形中的情况  \n还可证明, 具有上述四条性质的二元函数 $F(x, y)$ 一定是某个二维随机变量的分布函数.  \n任一二维分布函数 $F(x, y)$ 必具有上述四条性质, 其中性质 4 是二维场合特有的, 也是合理的.但性质 4 不能由前三条性质推出, 必须单独列出, 且仅满足前三条性质是不够的, 因为存在这样的二元函数 $G(x, y)$ 满足以上性质 $1,2,3$, 但它不满足性质 4 , 见下面例子.  \n例 3.1.1: 二元函数  \n$$\nG(x, y)= \\begin{cases}0, & x+y<0 \\\\ 1, & x+y \\geqslant 0\\end{cases}\n$$  \n满足二维分布函数的性质 $1,2,3$, 但它不满足性质 4 .  \n这从 $G(x, y)$ 的定义可看出: 若用 $x+y=0$ 将平面 $x O y$ 一分为二, 则  \n$G(x, y)$ 在右上半平面 $(x+y \\geqslant 0)$ 取值为 1 ,  \n$G(x, y)$ 在左下半平面 $(x+y \\geqslant 0)$ 取值为 0,  \n$G(x, y)$ 具有非降性、有界性和右连续性, 但在正方形区域 $\\{(x, y) ;-1 \\leqslant x \\leqslant 1,-1 \\leqslant y \\leqslant 1\\}$的四个顶点上, 右上三个顶点位于右上半闭平面, 只有左下顶点 $(-1,-1)$ 位于左下半开平面, 故有  \n$$\nG(1,1)-G(1,-1)-G(-1,1)+G(-1,-1)=1-1-1+0=-1<0,\n$$",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.2 联合分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "例 3.1.1: 二元函数  \n$$\nG(x, y)= \\begin{cases}0, & x+y<0 \\\\ 1, & x+y \\geqslant 0\\end{cases}\n$$  \n满足二维分布函数的性质 $1,2,3$, 但它不满足性质 4 .  \n这从 $G(x, y)$ 的定义可看出: 若用 $x+y=0$ 将平面 $x O y$ 一分为二, 则  \n$G(x, y)$ 在右上半平面 $(x+y \\geqslant 0)$ 取值为 1 ,  \n$G(x, y)$ 在左下半平面 $(x+y \\geqslant 0)$ 取值为 0,  \n$G(x, y)$ 具有非降性、有界性和右连续性, 但在正方形区域 $\\{(x, y) ;-1 \\leqslant x \\leqslant 1,-1 \\leqslant y \\leqslant 1\\}$的四个顶点上, 右上三个顶点位于右上半闭平面, 只有左下顶点 $(-1,-1)$ 位于左下半开平面, 故有  \n$$\nG(1,1)-G(1,-1)-G(-1,1)+G(-1,-1)=1-1-1+0=-1<0,\n$$  \n所以 $G(x, y)$ 不满足性质 4 , 故 $G(x, y)$ 不能成为某二维随机变量的分布函数.",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.2 联合分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 3.1.3 (联合分布列). 如果二维随机变量 $(X, Y)$ 只取有限个或可列个数对 $\\left(x_{i}, y_{j}\\right)$, 则称 $(X, Y)$为二维离散随机变量, 称  \n$$\n\\begin{equation*}\np_{i j}=P\\left(X=x_{i}, Y=y_{j}\\right), \\quad i, j=1,2, \\ldots \\tag{3.1.2}\n\\end{equation*}\n$$  \n为 $(X, Y)$ 的联合分布列, 也可如下用表格形式记联合分布列.  \n|  | $Y$ |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $X$ | $y_{1}$ | $y_{2}$ | $\\cdots$ | $y_{j}$ | $\\cdots$ |\n| $x_{1}$ | $p_{11}$ | $p_{12}$ | $\\cdots$ | $p_{1 j}$ | $\\cdots$ |\n| $x_{2}$ | $p_{21}$ | $p_{22}$ | $\\cdots$ | $p_{2 j}$ | $\\cdots$ |\n| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\ddots$ | $\\vdots$ | $\\ddots$ |\n| $x_{i}$ | $p_{i 1}$ | $p_{i 2}$ | $\\cdots$ | $p_{i j}$ | $\\cdots$ |\n| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\ddots$ | $\\vdots$ | $\\ddots$ |  \n联合分布函数的基本性质:  \n1. 非负性: $p_{i j} \\geqslant 0$;\n2. 正则性: $\\sum_{i=1}^{+\\infty} \\sum_{j=1}^{+\\infty} p_{i j}=1$.  \n求二维离散随机变量的联合分布列, 关键是写出二维随机变量的可能取的数对及其发生的概率.  \n例 3.1.2: 从 $1,2,3,4$ 中任取一数记为 $X$, 再从 $1, \\ldots, X$ 中任取一数记为 $Y$. 求 $(X, Y)$ 的联合分布列及 $P(X=Y)$.",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.3 联合分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\ddots$ | $\\vdots$ | $\\ddots$ |\n| $x_{i}$ | $p_{i 1}$ | $p_{i 2}$ | $\\cdots$ | $p_{i j}$ | $\\cdots$ |\n| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\ddots$ | $\\vdots$ | $\\ddots$ |  \n联合分布函数的基本性质:  \n1. 非负性: $p_{i j} \\geqslant 0$;\n2. 正则性: $\\sum_{i=1}^{+\\infty} \\sum_{j=1}^{+\\infty} p_{i j}=1$.  \n求二维离散随机变量的联合分布列, 关键是写出二维随机变量的可能取的数对及其发生的概率.  \n例 3.1.2: 从 $1,2,3,4$ 中任取一数记为 $X$, 再从 $1, \\ldots, X$ 中任取一数记为 $Y$. 求 $(X, Y)$ 的联合分布列及 $P(X=Y)$.  \n解: $(X, Y)$ 为二维离散随机变量, 其中 $X$ 的分布列为  \n$$\nP(X=i)=1 / 4, i=1,2,3,4 .\n$$  \n$Y$ 的可能取值也是 $1,2,3,4$, 若记 $j$ 为 $Y$ 的取值,  \n则当 $j>i$ 时, 有 $P(X=i, Y=j)=P(B)=0$.  \n当 $1 \\leqslant j \\leqslant i \\leqslant 4$ 时, 由乘法公式  \n$$\nP(X=i, Y=j)=P(X=i) P(Y=j \\mid X=i)=\\frac{1}{4} \\times \\frac{1}{i} .\n$$  \n所以得 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $X$ | 1 | 2 | 3 | 4 |  |\n| 1 | $1 / 4$ | 0 | 0 | 0 |  |\n| 2 | $1 / 8$ | $1 / 8$ | 0 | 0 |  |\n| 3 | $1 / 12$ | $1 / 12$ | $1 / 12$ | 0 |  |",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.3 联合分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(X=i)=1 / 4, i=1,2,3,4 .\n$$  \n$Y$ 的可能取值也是 $1,2,3,4$, 若记 $j$ 为 $Y$ 的取值,  \n则当 $j>i$ 时, 有 $P(X=i, Y=j)=P(B)=0$.  \n当 $1 \\leqslant j \\leqslant i \\leqslant 4$ 时, 由乘法公式  \n$$\nP(X=i, Y=j)=P(X=i) P(Y=j \\mid X=i)=\\frac{1}{4} \\times \\frac{1}{i} .\n$$  \n所以得 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $X$ | 1 | 2 | 3 | 4 |  |\n| 1 | $1 / 4$ | 0 | 0 | 0 |  |\n| 2 | $1 / 8$ | $1 / 8$ | 0 | 0 |  |\n| 3 | $1 / 12$ | $1 / 12$ | $1 / 12$ | 0 |  |\n| 4 | $1 / 16$ | $1 / 16$ | $1 / 16$ | $1 / 16$ |  |  \n由此可算得事件 $\\{X=Y\\}$ 的概率为  \n$$\nP(X=Y)=p_{11}+p_{22}+p_{33}+p_{44}=\\frac{1}{4}+\\frac{1}{8}+\\frac{1}{12}+\\frac{1}{12}=\\frac{25}{48}=0.5208\n$$",
        "metadata": {
            "Header 2": "3.1 多维随机变量及其联合分布",
            "Header 3": "3.1.3 联合分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 3.1.4 (联合密度函数). 如果存在二元非负函数 $p(x, y)$, 使得二维随机变量 $(X, Y)$ 的分布函数 $F(x, y)$ 可表示为  \n$$\n\\begin{equation*}\nF(x, y)=\\int_{-\\infty}^{x} \\int_{-\\infty}^{y} p(u, v) \\mathrm{d} v \\mathrm{~d} u \\tag{3.1.3}\n\\end{equation*}\n$$  \n则称 $(X, Y)$ 为二维连续随机变量, 称 $p(u, v)$ 为 $(X, Y)$ 的联合密度函数.\n在 $F(x, y)$ 偏导数存在的点上有  \n$$\np(x, y)=\\frac{\\partial^{2}}{\\partial x \\partial y} F(x, y)\n$$  \n联合密度函数的基本性质：  \n1. 非负性: $p(u, v) \\geqslant 0$\n2. 正则性: $\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} p(u, v) \\mathrm{d} v \\mathrm{~d} u=1$  \n给出联合密度函数 $p(x, y)$, 就可以求有关事件的概率了. 若 $G$ 为平面上的一个区域, 则事件 $\\{(X, Y) \\in G\\}$ 的概率可表示为在 $G$ 上对 $p(x, y)$ 的二重积分:  \n$$\n\\begin{equation*}\nP((X, Y) \\in G)=\\iint_{G} p(x, y) \\mathrm{d} x \\mathrm{~d} y . \\tag{3.1.4}\n\\end{equation*}\n$$  \n在具体使用上式时, 要注意积分范围是 $p(x, y)$ 的非零区域与 $G$ 的交集部分, 然后设法化成累次积分, 最后计算出结果.  \n例 3.1.3: 设 $(X, Y)$ 联合密度函数为  \n$$\np(x, y)= \\begin{cases}6 \\mathrm{e}^{-2 x-3 y}, & x>0, y>0 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求: (1) $P(X<1, Y>1)$; (2) $P(X>Y)$.  \n解:",
        "metadata": {
            "Header 2": "3.1 .4 联合密度函数"
        },
        "type": "Document"
    },
    {
        "page_content": "给出联合密度函数 $p(x, y)$, 就可以求有关事件的概率了. 若 $G$ 为平面上的一个区域, 则事件 $\\{(X, Y) \\in G\\}$ 的概率可表示为在 $G$ 上对 $p(x, y)$ 的二重积分:  \n$$\n\\begin{equation*}\nP((X, Y) \\in G)=\\iint_{G} p(x, y) \\mathrm{d} x \\mathrm{~d} y . \\tag{3.1.4}\n\\end{equation*}\n$$  \n在具体使用上式时, 要注意积分范围是 $p(x, y)$ 的非零区域与 $G$ 的交集部分, 然后设法化成累次积分, 最后计算出结果.  \n例 3.1.3: 设 $(X, Y)$ 联合密度函数为  \n$$\np(x, y)= \\begin{cases}6 \\mathrm{e}^{-2 x-3 y}, & x>0, y>0 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求: (1) $P(X<1, Y>1)$; (2) $P(X>Y)$.  \n解:  \n1. 积分区域见图 3.1.3a 中的阴影部分,  \n$$\n\\begin{aligned}\nP(X<1, Y>1) & =\\int_{1}^{+\\infty} \\int_{0}^{1} 6 \\mathrm{e}^{-2 x-3 y} \\mathrm{~d} x \\mathrm{~d} y \\\\\n& =6 \\int_{0}^{1} \\mathrm{e}^{-2 x} \\mathrm{~d} x \\int_{1}^{+\\infty} \\mathrm{e}^{-3 x} \\mathrm{~d} y \\\\\n& =\\left(1-\\mathrm{e}^{-2}\\right) \\mathrm{e}^{-3}=0.0430 .\n\\end{aligned}\n$$  \n2. 积分区域见图 3.1.3b 中的阴影部分, 从而容易写出累次积分.  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "3.1 .4 联合密度函数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试求: (1) $P(X<1, Y>1)$; (2) $P(X>Y)$.  \n解:  \n1. 积分区域见图 3.1.3a 中的阴影部分,  \n$$\n\\begin{aligned}\nP(X<1, Y>1) & =\\int_{1}^{+\\infty} \\int_{0}^{1} 6 \\mathrm{e}^{-2 x-3 y} \\mathrm{~d} x \\mathrm{~d} y \\\\\n& =6 \\int_{0}^{1} \\mathrm{e}^{-2 x} \\mathrm{~d} x \\int_{1}^{+\\infty} \\mathrm{e}^{-3 x} \\mathrm{~d} y \\\\\n& =\\left(1-\\mathrm{e}^{-2}\\right) \\mathrm{e}^{-3}=0.0430 .\n\\end{aligned}\n$$  \n2. 积分区域见图 3.1.3b 中的阴影部分, 从而容易写出累次积分.  \n$$\n\\begin{aligned}\nP(X>Y) & =\\int_{0}^{+\\infty} \\int_{0}^{x} 6 \\mathrm{e}^{-2 x} \\mathrm{e}^{-3 y} \\mathrm{~d} y \\mathrm{~d} x=\\int_{0}^{+\\infty} 2 \\mathrm{e}^{-2 x}\\left(1-\\mathrm{e}^{-3 x}\\right) \\mathrm{d} x \\\\\n& =\\left[-\\mathrm{e}^{-2 x}+\\frac{1}{5} \\mathrm{e}^{-5 x}\\right]_{0}^{+\\infty}=1-\\frac{1}{5}=\\frac{4}{5} .\n\\end{aligned}\n$$  \n!  \n(a) $\\{x<1, y>1\\}$ 区域 $D_{1}$  \n!  \n(b) $\\{x>y\\}$ 区域 $D_{2}$  \n图 3.1.3: $p(x, y)$ 的非零区域与有关事件的交集部分",
        "metadata": {
            "Header 2": "3.1 .4 联合密度函数"
        },
        "type": "Document"
    },
    {
        "page_content": "下面介绍一些多维随机变量的常用分布.",
        "metadata": {
            "Header 2": "3.1 .4 联合密度函数",
            "Header 3": "3.1.5 常用多维分布"
        },
        "type": "Document"
    },
    {
        "page_content": "多项分布是重要的多维离散分布, 它是二项分布的推广.\n进行 $n$ 次独立重复试验, 如果每次试验有 $r$ 个可能结果: $A_{1}, A_{2}, \\cdots, A_{r}$, 且每次试验中 $A_{i}$ 发生的概率为 $p_{i}=P\\left(A_{i}\\right), i=1,2, \\ldots, r . p_{1}+p_{2}+\\cdots+p_{r}=1$. 记 $X_{i}$ 为 $n$ 次独立重复试验中 $A_{i}$出现的次数, $i=1,2, \\ldots, r$. 则 $\\left(X_{1}, X_{2}, \\ldots, X_{r}\\right)$ 取值 $\\left(n_{1}, n_{2}, \\ldots, n_{r}\\right)$ 的概率, 即 $A_{1}$ 出现 $n_{1}$ 次, $A_{2}$出现 $n_{2}$ 次 ....... $A_{r}$ 出现 $n_{r}$ 次的概率为  \n$$\n\\begin{equation*}\nP\\left(X_{1}=n_{1}, X_{2}=n_{2}, \\ldots, X_{r}=n_{r}\\right)=\\frac{n !}{n_{1} ! n_{2} ! \\cdots n_{r} !} p_{1}^{n_{1}} p_{2}^{n_{2}} \\ldots p_{r}^{n_{r}} \\tag{3.1.5}\n\\end{equation*}\n$$  \n其中 $n=n_{1}+n_{2}+\\cdots+n_{r}$.  \n这个联合分布列称为 $r$ 项分布, 又称多项分布, 记为 $M\\left(n, p_{1}, p_{2}, \\ldots, p_{r}\\right)$. 这个概率是多项式 $\\left(p_{1}+p_{2}+\\cdots+p_{r}\\right)^{n}$ 展开式中的一项, 故其和为 1 . 当 $r=2$ 时, 即为二项分布.  \n例 3.1.4: 一批产品共有 100 件, 其中一等品 60 件、二等品 30 件、三等品 10 件. 从这批产品中有放回地任取 3 件, 以 $X$ 和 $Y$ 分别表示取出的 3 件产品中一等品、二等品的件数, 求二维随机变量 $(X, Y)$ 的联合分布列.",
        "metadata": {
            "Header 2": "一、多项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n其中 $n=n_{1}+n_{2}+\\cdots+n_{r}$.  \n这个联合分布列称为 $r$ 项分布, 又称多项分布, 记为 $M\\left(n, p_{1}, p_{2}, \\ldots, p_{r}\\right)$. 这个概率是多项式 $\\left(p_{1}+p_{2}+\\cdots+p_{r}\\right)^{n}$ 展开式中的一项, 故其和为 1 . 当 $r=2$ 时, 即为二项分布.  \n例 3.1.4: 一批产品共有 100 件, 其中一等品 60 件、二等品 30 件、三等品 10 件. 从这批产品中有放回地任取 3 件, 以 $X$ 和 $Y$ 分别表示取出的 3 件产品中一等品、二等品的件数, 求二维随机变量 $(X, Y)$ 的联合分布列.  \n解: 因为 $X$ 和 $Y$ 的可能取值都是 $0,1,2,3$, 所以记 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | 2 | 3 |  |\n| 0 | $p_{00}$ | $p_{01}$ | $p_{02}$ | $p_{03}$ |  |\n| 1 | $p_{10}$ | $p_{11}$ | $p_{12}$ | $p_{13}$ |  |\n| 2 | $p_{20}$ | $p_{21}$ | $p_{22}$ | $p_{23}$ |  |\n| 3 | $p_{30}$ | $p_{31}$ | $p_{32}$ | $p_{33}$ |  |  \n当 $i+j>3$ 时, 有 $p_{i j}=0$, 即  \n$$\np_{13}=p_{22}=p_{23}=p_{31}=p_{32}=p_{33}=0\n$$  \n而当 $i+j \\leqslant 3$ 时, 事件 $\\{X=i, Y=j\\}$ 表示: 取出的 3 件产品中有 $i$ 件一等品、 $j$ 件二等品、 $3-i-j$ 件三等品的件数, 所以有放回地抽取时, 对 $i+j \\leqslant 3$, 有  \n$$",
        "metadata": {
            "Header 2": "一、多项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| $X$ | 0 | 1 | 2 | 3 |  |\n| 0 | $p_{00}$ | $p_{01}$ | $p_{02}$ | $p_{03}$ |  |\n| 1 | $p_{10}$ | $p_{11}$ | $p_{12}$ | $p_{13}$ |  |\n| 2 | $p_{20}$ | $p_{21}$ | $p_{22}$ | $p_{23}$ |  |\n| 3 | $p_{30}$ | $p_{31}$ | $p_{32}$ | $p_{33}$ |  |  \n当 $i+j>3$ 时, 有 $p_{i j}=0$, 即  \n$$\np_{13}=p_{22}=p_{23}=p_{31}=p_{32}=p_{33}=0\n$$  \n而当 $i+j \\leqslant 3$ 时, 事件 $\\{X=i, Y=j\\}$ 表示: 取出的 3 件产品中有 $i$ 件一等品、 $j$ 件二等品、 $3-i-j$ 件三等品的件数, 所以有放回地抽取时, 对 $i+j \\leqslant 3$, 有  \n$$\np_{i j}=\\frac{3 !}{i ! j !(3-i-j) !}\\left(\\frac{6}{10}\\right)^{i}\\left(\\frac{3}{10}\\right)^{j}\\left(\\frac{1}{10}\\right)^{3-i-j} .\n$$  \n由以上公式, 就可具体算出 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | 2 | 3 |\n| 0 | 0.001 | 0.009 | 0.027 | 0.027 |\n| 1 | 0.018 | 0.108 | 0.162 | 0 |\n| 2 | 0.108 | 0.324 | 0 | 0 |\n| 3 | 0.216 | 0 | 0 | 0 |  \n有此联合分布列, 就可计算有关事件的概率, 譬如  \n$$\n\\begin{gathered}\nP(X \\leqslant 1, Y \\leqslant 1)=0.001+0.009+0.018+0.108=0.136 . \\\\",
        "metadata": {
            "Header 2": "一、多项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "p_{i j}=\\frac{3 !}{i ! j !(3-i-j) !}\\left(\\frac{6}{10}\\right)^{i}\\left(\\frac{3}{10}\\right)^{j}\\left(\\frac{1}{10}\\right)^{3-i-j} .\n$$  \n由以上公式, 就可具体算出 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | 2 | 3 |\n| 0 | 0.001 | 0.009 | 0.027 | 0.027 |\n| 1 | 0.018 | 0.108 | 0.162 | 0 |\n| 2 | 0.108 | 0.324 | 0 | 0 |\n| 3 | 0.216 | 0 | 0 | 0 |  \n有此联合分布列, 就可计算有关事件的概率, 譬如  \n$$\n\\begin{gathered}\nP(X \\leqslant 1, Y \\leqslant 1)=0.001+0.009+0.018+0.108=0.136 . \\\\\nP(X=0)=\\sum_{j=0}^{3} P(X=0, Y=j)=0.001+0.009+0.027+0.027=0.064 .\n\\end{gathered}\n$$  \n此例是第二章 2.4 节中的二项分布的推广, 差别在于: 2.4 中讨论的是从” 合格品”、”不合格品” 两种情况中抽取, 而在此是从一等品、二等品和三等品三种情况中抽取. 这里我们称它为三项分布,它是一种特殊的多项分布.",
        "metadata": {
            "Header 2": "一、多项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "以下给出多维超几何分布的描述: 袋中有 $N$ 只球, 其中有 $N_{i}$ 只 $i$ 号球, $i=1,2, \\ldots, r$, 记 $N=$ $N_{1}+N_{2}+\\cdots+N_{r}$. 从中任意取出 $n$ 只, 若记 $X_{i}$ 为取出的 $n$ 只球中 $i$ 号球的个数, $i=1,2, \\ldots, r$,\n则  \n$$\nP\\left(X_{1}=n_{1}, X_{2}=n_{2}, \\ldots, X_{r}=n_{r}\\right)=\\frac{\\left(\\begin{array}{l}\nN_{1}  \\tag{3.1.6}\\\\\nn_{1}\n\\end{array}\\right)\\left(\\begin{array}{l}\nN_{2} \\\\\nn_{2}\n\\end{array}\\right) \\cdots\\left(\\begin{array}{l}\nN_{r} \\\\\nn_{r}\n\\end{array}\\right)}{\\left(\\begin{array}{l}\nN \\\\\nn\n\\end{array}\\right)}\n$$  \n其中 $n_{1}+n_{2}+\\cdots+n_{r}=n$.  \n例 3.1.5: 将例 3.1.4 改成不放回抽样, 即从这批产品中不放回地任取 3 件, 记 $x$ 和 $Y$ 分别表示 3 件产品中一等品和二等品的件数, 求二维随机变 $(X, Y)$ 的联合分布列.  \n解: 记 $i$ 与 $j$ 分别为 $X$ 与 $Y$ 的取值, 此时对 $i+j>3$, 有 $p_{i j}=0$, 即  \n$$\np_{13}=p_{22}=p_{23}=p_{31}=p_{32}=p_{33}=0 .\n$$  \n对于 $i+j \\leqslant 3$, 有  \n$$\np_{i j}=\\frac{\\left(\\begin{array}{c}\n60 \\\\\ni\n\\end{array}\\right)\\left(\\begin{array}{c}\n30 \\\\\nj\n\\end{array}\\right)\\left(\\begin{array}{c}\n10 \\\\\n3-i-j\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n100 \\\\\n3\n\\end{array}\\right)}",
        "metadata": {
            "Header 2": "二.多维超几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "例 3.1.5: 将例 3.1.4 改成不放回抽样, 即从这批产品中不放回地任取 3 件, 记 $x$ 和 $Y$ 分别表示 3 件产品中一等品和二等品的件数, 求二维随机变 $(X, Y)$ 的联合分布列.  \n解: 记 $i$ 与 $j$ 分别为 $X$ 与 $Y$ 的取值, 此时对 $i+j>3$, 有 $p_{i j}=0$, 即  \n$$\np_{13}=p_{22}=p_{23}=p_{31}=p_{32}=p_{33}=0 .\n$$  \n对于 $i+j \\leqslant 3$, 有  \n$$\np_{i j}=\\frac{\\left(\\begin{array}{c}\n60 \\\\\ni\n\\end{array}\\right)\\left(\\begin{array}{c}\n30 \\\\\nj\n\\end{array}\\right)\\left(\\begin{array}{c}\n10 \\\\\n3-i-j\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n100 \\\\\n3\n\\end{array}\\right)}\n$$  \n由此可得 $(X, Y)$ 的联合分布列, 譬如  \n$$\nP(X=1, Y=2)=\\frac{\\left(\\begin{array}{c}\n60 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n30 \\\\\n2\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n100 \\\\\n3\n\\end{array}\\right)}=\\frac{60 \\times 30 \\times 29 / 2}{100 \\times 99 \\times 98 / 6}=\\frac{89}{539}=0.1614\n$$  \n其他各概率都类似求出, 最后得如下联合分布列  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | 2 | 3 |\n| 0 | 0.0007 | 0.0083 | 0.0269 | 0.0251 |\n| 1 | 0.0167 | 0.1113 | 0.1614 | 0 |\n| 2 | 0.1095 | 0.3284 | 0 | 0 |",
        "metadata": {
            "Header 2": "二.多维超几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(X=1, Y=2)=\\frac{\\left(\\begin{array}{c}\n60 \\\\\n1\n\\end{array}\\right)\\left(\\begin{array}{c}\n30 \\\\\n2\n\\end{array}\\right)}{\\left(\\begin{array}{c}\n100 \\\\\n3\n\\end{array}\\right)}=\\frac{60 \\times 30 \\times 29 / 2}{100 \\times 99 \\times 98 / 6}=\\frac{89}{539}=0.1614\n$$  \n其他各概率都类似求出, 最后得如下联合分布列  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | 2 | 3 |\n| 0 | 0.0007 | 0.0083 | 0.0269 | 0.0251 |\n| 1 | 0.0167 | 0.1113 | 0.1614 | 0 |\n| 2 | 0.1095 | 0.3284 | 0 | 0 |\n| 3 | 0.2116 | 0 | 0 | 0 |  \n有此联合分布列, 就可计算有关事件的概率, 譬如  \n$$\n\\begin{gathered}\nP(X \\leqslant 1, Y \\leqslant 1)=0.0007+0.0167+0.0083+0.1113=0.1370 \\\\\nP(X=0)=\\sum_{j=0}^{3} P(X=0, Y=j)=0.0610\n\\end{gathered}\n$$  \n此例是超几何分布的推广, 差别在于: 2.4 中讨论的是从 “合格品”、“不合格品”两种情况中抽取, 而在此是从一等品、二等品和三等品三种情况中抽取. 这里我们称它为三维超几何分布, 它是一种特殊的多维超几何分布.",
        "metadata": {
            "Header 2": "二.多维超几何分布"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $D$ 为 $R^{n}$ 中的一个有界区域, 其度量 (平面上为面积, 空间为体积等 ) 为 $S_{D}$, 如果多维随机变量 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的联合密度函数为  \n$$\np\\left(x_{1}, x_{2}, \\cdots, x_{n}=\\left\\{\\begin{array}{ll}\n\\frac{1}{S_{D}}, & \\left(x_{1}, x_{2}, \\ldots, x_{n} \\in D\\right.  \\tag{3.1.7}\\\\\n0, & \\text { 其他 }\n\\end{array} .\\right.\\right.\n$$  \n则称 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 服从 $D$ 上的多维均匀分布, 记为 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right) \\sim U(D)$.  \n二维均匀分布所描述的随机现象就是向平面区域 $D$ 中随机投点, 如果该点坐标 $(X, Y)$ 落在 $D$ 的子区域 $G$ 中的概率只与 $G$ 的面积有关, 而与 $G$ 的位置无关, 则由第一章知这是几何概率. 现在由二维均匀分布来描述, 则  \n$$\nP((X, Y) \\in G)=\\iint_{G} p(x, y) \\mathrm{d} x \\mathrm{~d} y=\\operatorname{int}_{G} \\frac{1}{S_{D}} \\mathrm{~d} x \\mathrm{~d} y=\\frac{G \\text { 的面积 }}{D \\text { 的面积 }} .\n$$  \n这正是几何概率的计算公式.  \n例 3.1.6: 设 $D$ 为平面上以原点为圆心、以 $r$ 为半径的圆, $(X, Y)$ 服从 $D$ 上的二维均匀分布, 其密\n度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{\\pi r^{2}}, & x^{2}+y^{2} \\leqslant r^{2} \\\\ 0, & x^{2}+y^{2}>r^{2}\\end{cases}\n$$  \n试求概率 $P(X) \\leqslant r / 2$.",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP((X, Y) \\in G)=\\iint_{G} p(x, y) \\mathrm{d} x \\mathrm{~d} y=\\operatorname{int}_{G} \\frac{1}{S_{D}} \\mathrm{~d} x \\mathrm{~d} y=\\frac{G \\text { 的面积 }}{D \\text { 的面积 }} .\n$$  \n这正是几何概率的计算公式.  \n例 3.1.6: 设 $D$ 为平面上以原点为圆心、以 $r$ 为半径的圆, $(X, Y)$ 服从 $D$ 上的二维均匀分布, 其密\n度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{\\pi r^{2}}, & x^{2}+y^{2} \\leqslant r^{2} \\\\ 0, & x^{2}+y^{2}>r^{2}\\end{cases}\n$$  \n试求概率 $P(X) \\leqslant r / 2$.  \n解: $p(x, y)$ 的非零区域与事件 $\\{|X| \\leqslant r / 2\\}$ 的交集部分见图 3.1.4, 因此所求概率为  \n$$\n\\begin{aligned}\nP(|X| \\leqslant r / 2) & =\\int_{-r / 2}^{r / 2} \\int_{-\\sqrt{r^{2}-x^{2}}}^{\\sqrt{r^{2}-x^{2}}} \\frac{1}{\\pi r^{2}} \\mathrm{~d} y \\mathrm{~d} x=\\frac{1}{\\pi r^{2}} \\int_{-r / 2}^{r / 2} 2 \\sqrt{r^{2}-x^{2}} \\mathrm{~d} x \\\\\n& =\\left.\\frac{1}{\\pi r^{2}}\\left[x \\sqrt{r^{2}-x^{2}}+r^{2} \\arcsin \\frac{x}{r}\\right]\\right|_{-r / 2} ^{r / 2} \\\\\n& =\\frac{1}{\\pi r^{2}}\\left[r \\sqrt{r^{2}-\\frac{r^{2}}{4}}+2 r^{2} \\arcsin \\frac{1}{2}\\right] \\\\",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nP(|X| \\leqslant r / 2) & =\\int_{-r / 2}^{r / 2} \\int_{-\\sqrt{r^{2}-x^{2}}}^{\\sqrt{r^{2}-x^{2}}} \\frac{1}{\\pi r^{2}} \\mathrm{~d} y \\mathrm{~d} x=\\frac{1}{\\pi r^{2}} \\int_{-r / 2}^{r / 2} 2 \\sqrt{r^{2}-x^{2}} \\mathrm{~d} x \\\\\n& =\\left.\\frac{1}{\\pi r^{2}}\\left[x \\sqrt{r^{2}-x^{2}}+r^{2} \\arcsin \\frac{x}{r}\\right]\\right|_{-r / 2} ^{r / 2} \\\\\n& =\\frac{1}{\\pi r^{2}}\\left[r \\sqrt{r^{2}-\\frac{r^{2}}{4}}+2 r^{2} \\arcsin \\frac{1}{2}\\right] \\\\\n& =\\frac{1}{\\pi}\\left[\\frac{\\sqrt{3}}{2}+\\frac{\\pi}{3}\\right]=0.609\n\\end{aligned}\n$$  \n!  \n图 3.1.4: $p(x, y)$ 的非零区域与有关事件的交集部分  \n四、二元正态分布  \n如果二维随机变量 $(X, Y)$ 的联合密度函数 (见图 3.1.5) 为  \n$$\n\\begin{align*}\np(x, y) & =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}} \\exp \\left\\{-\\frac{1}{2\\left(1-\\rho^{2}\\right)}\\left[\\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}\\right.\\right.  \\tag{3.1.8}\\\\",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{1}{\\pi r^{2}}\\left[r \\sqrt{r^{2}-\\frac{r^{2}}{4}}+2 r^{2} \\arcsin \\frac{1}{2}\\right] \\\\\n& =\\frac{1}{\\pi}\\left[\\frac{\\sqrt{3}}{2}+\\frac{\\pi}{3}\\right]=0.609\n\\end{aligned}\n$$  \n!  \n图 3.1.4: $p(x, y)$ 的非零区域与有关事件的交集部分  \n四、二元正态分布  \n如果二维随机变量 $(X, Y)$ 的联合密度函数 (见图 3.1.5) 为  \n$$\n\\begin{align*}\np(x, y) & =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}} \\exp \\left\\{-\\frac{1}{2\\left(1-\\rho^{2}\\right)}\\left[\\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}\\right.\\right.  \\tag{3.1.8}\\\\\n& \\left.\\left.-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\\right\\}, \\quad-\\infty<x, y<+\\infty\n\\end{align*}\n$$  \n则称 $(X, Y)$ 服从二元正态分布, 记为 $(X, Y) \\sim N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$. 其中五个参数的取值范围分别是:  \n$$\n-\\infty<\\mu_{1}, \\mu_{2}<+\\infty ; \\quad \\sigma_{1}, \\sigma_{2}>0 ; \\quad-1 \\leqslant \\rho \\leqslant 1\n$$",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& \\left.\\left.-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\\right\\}, \\quad-\\infty<x, y<+\\infty\n\\end{align*}\n$$  \n则称 $(X, Y)$ 服从二元正态分布, 记为 $(X, Y) \\sim N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$. 其中五个参数的取值范围分别是:  \n$$\n-\\infty<\\mu_{1}, \\mu_{2}<+\\infty ; \\quad \\sigma_{1}, \\sigma_{2}>0 ; \\quad-1 \\leqslant \\rho \\leqslant 1\n$$  \n以后将指出: $\\mu_{1}, \\mu_{2}$ 分别是 $X$ 与 $Y$ 的均值, $\\sigma_{1}^{2}, \\sigma_{2}^{2}$ 分别是 $X$ 与 $Y$ 的方差, $\\rho$ 是 $X$ 与 $Y$ 的相关系数.  \n二元正态密度函数的图形很像一顶四周无限延伸的草帽, 其中心点在 $\\left(\\mu_{1}, \\mu_{2}\\right)$ 处, 其等高线是椭圆。  \n例 3.1.7: 设二维随机变量 $(X, Y) \\sim N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$, 求 $(x, Y)$ 落在区域  \n$$\nD=\\left\\{(x, y) ; \\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}} \\leqslant \\lambda^{2}\\right\\}",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "二元正态密度函数的图形很像一顶四周无限延伸的草帽, 其中心点在 $\\left(\\mu_{1}, \\mu_{2}\\right)$ 处, 其等高线是椭圆。  \n例 3.1.7: 设二维随机变量 $(X, Y) \\sim N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$, 求 $(x, Y)$ 落在区域  \n$$\nD=\\left\\{(x, y) ; \\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}} \\leqslant \\lambda^{2}\\right\\}\n$$  \n内的概率.  \n!  \n图 3.1.5: 二元正态密度函数  \n解: 所求的概率为  \n$$\n\\begin{aligned}\np(x, y) & =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}} \\iint_{D} \\exp \\left\\{-\\frac{1}{2\\left(1-\\rho^{2}\\right)}\\left[\\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}\\right.\\right. \\\\\n& \\left.\\left.-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\\right\\} \\mathrm{d} x \\mathrm{~d} y\n\\end{aligned}\n$$  \n作变换  \n$$\n\\left\\{\\begin{array}{l}",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n图 3.1.5: 二元正态密度函数  \n解: 所求的概率为  \n$$\n\\begin{aligned}\np(x, y) & =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}} \\iint_{D} \\exp \\left\\{-\\frac{1}{2\\left(1-\\rho^{2}\\right)}\\left[\\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}\\right.\\right. \\\\\n& \\left.\\left.-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\\right\\} \\mathrm{d} x \\mathrm{~d} y\n\\end{aligned}\n$$  \n作变换  \n$$\n\\left\\{\\begin{array}{l}\nu=\\frac{x-\\mu_{1}}{\\sigma_{1}}-\\rho \\frac{y-\\mu_{2}}{\\sigma_{2}} \\\\\nv=\\frac{y-\\mu_{2}}{\\sigma_{2}} \\sqrt{1-\\rho^{2}}\n\\end{array}\\right.\n$$  \n则可得  \n$$\n\\frac{\\partial(u, v)}{\\partial(x, y)}=\\left|\\begin{array}{cc}\n\\frac{1}{\\sigma_{1}} & 0 \\\\\n-\\frac{\\rho}{\\sigma_{2}} & \\frac{\\sqrt{1-\\rho^{2}}}{\\sigma_{2}}\n\\end{array}\\right|=\\frac{\\sqrt{1-\\rho^{2}}}{\\sigma_{1} \\sigma_{2}}, \\quad|J|=\\frac{\\sigma_{1} \\sigma_{2}}{\\sqrt{1-\\rho^{2}}},\n$$  \n由此得  \n$$",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n作变换  \n$$\n\\left\\{\\begin{array}{l}\nu=\\frac{x-\\mu_{1}}{\\sigma_{1}}-\\rho \\frac{y-\\mu_{2}}{\\sigma_{2}} \\\\\nv=\\frac{y-\\mu_{2}}{\\sigma_{2}} \\sqrt{1-\\rho^{2}}\n\\end{array}\\right.\n$$  \n则可得  \n$$\n\\frac{\\partial(u, v)}{\\partial(x, y)}=\\left|\\begin{array}{cc}\n\\frac{1}{\\sigma_{1}} & 0 \\\\\n-\\frac{\\rho}{\\sigma_{2}} & \\frac{\\sqrt{1-\\rho^{2}}}{\\sigma_{2}}\n\\end{array}\\right|=\\frac{\\sqrt{1-\\rho^{2}}}{\\sigma_{1} \\sigma_{2}}, \\quad|J|=\\frac{\\sigma_{1} \\sigma_{2}}{\\sqrt{1-\\rho^{2}}},\n$$  \n由此得  \n$$\np=\\frac{1}{2 \\pi\\left(1-\\rho^{2}\\right)} \\iint_{x^{2}+v^{2} \\leqslant \\lambda^{2}} \\exp \\left\\{-\\frac{u^{2}+v^{2}}{2\\left(1-\\rho^{2}\\right)}\\right\\} \\mathrm{d} u \\mathrm{~d} v\n$$  \n再作极坐标变换  \n$$\n\\left\\{\\begin{array}{l}\nu=r \\sin \\alpha \\\\\nv=r \\cos \\alpha\n\\end{array}\\right.\n$$  \n则可得  \n$$\nJ=\\frac{\\partial(u, v)}{\\partial(r, \\alpha)}=\\left|\\begin{array}{cc}\n\\sin \\alpha & \\cos \\alpha \\\\\nr \\cos \\alpha & -r \\sin \\alpha\n\\end{array}\\right|=-r\\left(\\sin ^{2} \\alpha+\\cos ^{2} \\alpha\\right)=-r \\text {, }\n$$",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n再作极坐标变换  \n$$\n\\left\\{\\begin{array}{l}\nu=r \\sin \\alpha \\\\\nv=r \\cos \\alpha\n\\end{array}\\right.\n$$  \n则可得  \n$$\nJ=\\frac{\\partial(u, v)}{\\partial(r, \\alpha)}=\\left|\\begin{array}{cc}\n\\sin \\alpha & \\cos \\alpha \\\\\nr \\cos \\alpha & -r \\sin \\alpha\n\\end{array}\\right|=-r\\left(\\sin ^{2} \\alpha+\\cos ^{2} \\alpha\\right)=-r \\text {, }\n$$  \n最后得  \n$$\n\\begin{aligned}\np & =\\frac{1}{2 \\pi\\left(1-\\rho^{2}\\right)} \\int_{0}^{2 \\pi} \\mathrm{d} \\alpha \\int_{0}^{\\lambda} r \\exp \\left\\{-\\frac{r^{2}}{2\\left(1-\\rho^{2}\\right)}\\right\\} \\mathrm{d} r \\\\\n& =\\int_{0}^{\\lambda} \\exp \\left\\{-\\frac{r^{2}}{2\\left(1-\\rho^{2}\\right)}\\right\\} \\mathrm{d}\\left(\\frac{r^{2}}{2\\left(1-\\rho^{2}\\right)}\\right) \\\\\n& =-\\left.\\exp \\left\\{-\\frac{r^{2}}{2\\left(1-\\rho^{2}\\right)}\\right\\}\\right|_{0} ^{\\lambda}=1-\\exp \\left\\{-\\frac{\\lambda^{2}}{2\\left(1-\\rho^{2}\\right)}\\right\\} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "三、多维均匀分布"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 一批产品中有一等品 $50 \\%$, 二等品 $30 \\%$, 三等品 $20 \\%$. 从中有放回地抽取 5 件, 以 $X 、 Y$ 分别表示取出的 5 件中一等品、二等品的件数, 求 $(X, Y)$ 的联合分布列.\n2. 100 件产品中有 50 件一等品, 30 件二等品, 20 件三等品. 从中不放回地抽取 5 件, 以 $X 、 Y$ 分别表示取出的 5 件中一等品、二等品的件数, 求 $(X, Y)$ 的联合分布列.\n3. 盘子里装有 3 只黑球、 2 只红球、 2 只白球, 从中任取 4 只, 以 $X$ 表示取到黑球的只数, 以 $Y$ 表示取到红球的只数, 试求 $P\\{X=Y\\}$.\n4. 设随机变量 $X_{i}, i=1,2$, 的分布列如下, 且满足 $P\\left(X_{1} X_{2}=0\\right)=1$, 试求 $P\\left(X_{1}=X_{2}\\right)$.  \n| $X_{t}$ | -1 | 0 | 1 |\n| :---: | :---: | :---: | :---: |\n| $P$ | 0.25 | 0.5 | 0.25 |  \n5. 设随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}k(6-x-y), & 0<x<2,2<y<4 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) 常数 $k$;  \n(2) $P\\{X<1, Y<3\\}$;  \n(3) $P\\{X<1.5\\}$;  \n(4) $P\\{X+Y \\leqslant 4\\}$.  \n6. 设随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}k \\mathrm{e}^{-(3 x+4 y)}, & x>0, y>0 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) 常数 $k$;  \n(2) $(X, Y)$ 的联合分布函数 $F(X, Y)$;  \n(3) $P\\{0<X \\leqslant 1,0<Y \\leqslant 2\\}$.  \n7. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$",
        "metadata": {
            "Header 2": "也习题 3.1"
        },
        "type": "Document"
    },
    {
        "page_content": "5. 设随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}k(6-x-y), & 0<x<2,2<y<4 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) 常数 $k$;  \n(2) $P\\{X<1, Y<3\\}$;  \n(3) $P\\{X<1.5\\}$;  \n(4) $P\\{X+Y \\leqslant 4\\}$.  \n6. 设随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}k \\mathrm{e}^{-(3 x+4 y)}, & x>0, y>0 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) 常数 $k$;  \n(2) $(X, Y)$ 的联合分布函数 $F(X, Y)$;  \n(3) $P\\{0<X \\leqslant 1,0<Y \\leqslant 2\\}$.  \n7. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}4 x y, & 0<x<1,0<y<1, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) $P(0<X<0.5,0.25<Y<1)$;  \n(2) $P(X+Y)$;  \n(3) $P(X<Y)$;  \n(4) $(X, Y)$ 的联合分布函数.  \n8. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n(1) 试求常数 $k$;  \n$$\np(x, y)= \\begin{cases}k, & 0<x^{2}<y<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n(2) 求 $P(X>0.5)$ 和 $P(Y<0.5)$.  \n9. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}6(1-y), & 0<x<y<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n(1) 求 $P(X>0.5, Y>0.5)$;  \n(2) 求 $P(X<0.5)$ 和 $P(Y<0.5)$;",
        "metadata": {
            "Header 2": "也习题 3.1"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试求  \n(1) $P(0<X<0.5,0.25<Y<1)$;  \n(2) $P(X+Y)$;  \n(3) $P(X<Y)$;  \n(4) $(X, Y)$ 的联合分布函数.  \n8. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n(1) 试求常数 $k$;  \n$$\np(x, y)= \\begin{cases}k, & 0<x^{2}<y<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n(2) 求 $P(X>0.5)$ 和 $P(Y<0.5)$.  \n9. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}6(1-y), & 0<x<y<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n(1) 求 $P(X>0.5, Y>0.5)$;  \n(2) 求 $P(X<0.5)$ 和 $P(Y<0.5)$;  \n(3) 求 $P(X+Y)<1$.  \n10. 设随机变量 $Y$ 服从参数为 $\\lambda=1$ 的指数分布, 定义随机变量 $X_{k}$ 如下  \n$$\nX_{k}=\\left\\{\\begin{array}{ll}\n0, & Y \\leqslant k, \\\\\n1, & Y>k,\n\\end{array} \\quad k=1,2 .\\right.\n$$  \n求 $X_{1}$ 和 $X_{2}$ 的联合分布列.  \n11. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}x^{2}+\\frac{x y}{3}, & 0<x<1,0<y<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $P(X+Y) \\geqslant 1$.  \n12. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\mathrm{e}^{-y}, & 0<x<y \\\\ 0 & \\text { 其他. }\\end{cases}\n$$  \n试求 $P(X, Y) \\leqslant 1$.  \n13. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$",
        "metadata": {
            "Header 2": "也习题 3.1"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nX_{k}=\\left\\{\\begin{array}{ll}\n0, & Y \\leqslant k, \\\\\n1, & Y>k,\n\\end{array} \\quad k=1,2 .\\right.\n$$  \n求 $X_{1}$ 和 $X_{2}$ 的联合分布列.  \n11. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}x^{2}+\\frac{x y}{3}, & 0<x<1,0<y<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $P(X+Y) \\geqslant 1$.  \n12. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\mathrm{e}^{-y}, & 0<x<y \\\\ 0 & \\text { 其他. }\\end{cases}\n$$  \n试求 $P(X, Y) \\leqslant 1$.  \n13. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}1 / 2, & 0<x<1,0<y<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $X$ 与 $Y$ 中至少一个小于 0.5 的概率.  \n14. 从 $(0,1)$ 中随机地取两个数, 求其积不小于 $3 / 16$, 且其和不大于 1 的概率.",
        "metadata": {
            "Header 2": "也习题 3.1"
        },
        "type": "Document"
    },
    {
        "page_content": "二维联合分布函数 (二维联合分布列、二维联合密度函数也一样) 含有丰富的信息, 主要有以下三方面信息：  \n。每个分量的分布 (每个分量的所有信息), 即边际分布.  \n- 两个分量之间的关联程度, 即协方差和相关系数.\n- 给定一个分量时, 另一个分量的分布, 即条件分布.  \n我们的目的时将这些信息从联合分布中挖掘出来, 本节先讨论边际分布.",
        "metadata": {
            "Header 2": "3.2 边际分布与随机变量的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "如果在二维随机变量 $(X, Y)$ 的联合分布函数 $F(X, Y)$ 中令 $y \\rightarrow+\\infty$, 由于 $|Y<+\\infty|$ 为必然事件, 故可得  \n$$\n\\lim _{y \\rightarrow+\\infty} F(x, y)=P(X \\leqslant x, Y<+\\infty)=P(X \\leqslant x)\n$$  \n这是一个分布函数, 被称为 $X$ 的边际分布, 记为  \n$$\n\\begin{equation*}\nF_{X}(x)=F(x,+\\infty) . \\tag{3.2.1}\n\\end{equation*}\n$$  \n类似地, 在 $F(x, y)$ 中令 $x \\rightarrow+\\infty$, 可得 $Y$ 的边际分布  \n$$\n\\begin{equation*}\nF_{Y}(y)=F(+\\infty, y) \\tag{3.2.2}\n\\end{equation*}\n$$  \n在三维随机变量 $(X, Y, Z)$ 的联合分布函数 $F(x, y, z)$ 中, 用类似的方法可得到更多的边际分布函数:  \n$$\n\\begin{aligned}\n& F_{X}(x)=F(x,+\\infty,+\\infty) \\\\\n& F_{Y}(y)=F(+\\infty, y,+\\infty)\n\\end{aligned}\n$$  \n$$\n\\begin{aligned}\n& F_{Z}(z)=F(+\\infty,+\\infty, z) \\\\\n& F_{X, Y}(x, y)=F(x, y,+\\infty) \\\\\n& F_{X, Z}(x, z)=F(x,+\\infty, z) \\\\\n& F_{Y, Z}(y, z)=F(+\\infty, y, z) .\n\\end{aligned}\n$$  \n在更高维的场合, 也可类似地从联合分布函数获得其低维的边际分布函数.  \n例 3.2.1: 设二维随机变量 $(X, Y)$ 的联合分布函数为  \n$$\nF(x, y)= \\begin{cases}1-\\mathrm{e}^{-x}-\\mathrm{e}^{-y}+\\mathrm{e}^{-x-y-\\lambda x y}, & x>0, y>0 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$",
        "metadata": {
            "Header 2": "3.2 边际分布与随机变量的独立性",
            "Header 3": "3.2.1 边际分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\begin{aligned}\n& F_{X}(x)=F(x,+\\infty,+\\infty) \\\\\n& F_{Y}(y)=F(+\\infty, y,+\\infty)\n\\end{aligned}\n$$  \n$$\n\\begin{aligned}\n& F_{Z}(z)=F(+\\infty,+\\infty, z) \\\\\n& F_{X, Y}(x, y)=F(x, y,+\\infty) \\\\\n& F_{X, Z}(x, z)=F(x,+\\infty, z) \\\\\n& F_{Y, Z}(y, z)=F(+\\infty, y, z) .\n\\end{aligned}\n$$  \n在更高维的场合, 也可类似地从联合分布函数获得其低维的边际分布函数.  \n例 3.2.1: 设二维随机变量 $(X, Y)$ 的联合分布函数为  \n$$\nF(x, y)= \\begin{cases}1-\\mathrm{e}^{-x}-\\mathrm{e}^{-y}+\\mathrm{e}^{-x-y-\\lambda x y}, & x>0, y>0 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n这个分布被称为二维指数分布, 其中参数 $\\lambda>0$.  \n由此联合分布函数 $F(x, y)$, 容易获得 $X$ 与 $Y$ 的边际分布函数为  \n$$\n\\begin{aligned}\n& F_{X}(x)=F(x,+\\infty)= \\begin{cases}1-\\mathrm{e}^{-x}, & x>0 ; \\\\\n0, & x \\leqslant 0\\end{cases} \\\\\n& F_{Y}(y)=F(+\\infty, y)= \\begin{cases}1-\\mathrm{e}^{-y}, & y>0 \\\\\n0, & y \\leqslant 0\\end{cases}\n\\end{aligned}\n$$  \n它们都是一维指数分布, 且与参数 $\\lambda>0$ 无关. 不同的 $\\lambda>0$ 对应不同的二维指数分布, 但它们的两个边际分布不变. 这说明: 二维联合分布不仅含有每个分量的概率分布, 而且还含有两个变量 $X$与 $Y$ 间关系的信息, 这正是人们要研究多维随机变量的原因.",
        "metadata": {
            "Header 2": "3.2 边际分布与随机变量的独立性",
            "Header 3": "3.2.1 边际分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "在二维离散随机变量 $(X, Y)$ 的联合分布列 $\\left\\{P\\left(X=x_{i}, Y=y_{i}\\right)\\right\\}$ 中, 对 $j$ 求和所得的分布列  \n$$\n\\begin{equation*}\n\\sum_{j=1}^{+\\infty} P\\left(X=x_{i}, Y=y_{j}\\right)=P\\left(X=x_{i}\\right), i=1,2, \\ldots \\tag{3.2.3}\n\\end{equation*}\n$$  \n被称为 $X$ 的边际分布列. 类似地, 对 $i$ 求和所得的分布列  \n$$\n\\begin{equation*}\n\\sum_{i=1}^{+\\infty} P\\left(X=x_{i}, Y=y_{j}\\right)=P\\left(Y=y_{j}\\right), j=1,2, \\ldots \\tag{3.2.4}\n\\end{equation*}\n$$  \n被称为 $Y$ 的边际分布列.  \n例 3.2.2: 设二维随机变量 $(X, Y)$ 有如下的联合分布列  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | 1 | 2 | 3 |\n| 0 | 0.09 | 0.21 | 0.24 |\n| 1 | 0.07 | 0.12 | 0.27 |  \n求 $X$ 与 $Y$ 的边际分布列.  \n解：在上述联合分布列中, 对每一行求和得 0.54 与 0.46 , 并把它们写在对应行得右侧, 这就是 $X$的边际分布列. 再对每一列求和, 得 $0.16,0.33$ 和 0.51 , 并把它们写在对应列的下侧, 这就是 $Y$ 得边际分布列.  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 1 | 2 | 3 | $P(X=i)$ |\n| 0 | 0.09 | 0.21 | 0.24 | 0.54 |\n| 1 | 0.07 | 0.12 | 0.27 | 0.46 |\n| $P(Y=j)$ | 0.16 | 0.33 | 0.51 | 1 |",
        "metadata": {
            "Header 2": "3.2 边际分布与随机变量的独立性",
            "Header 3": "3.2.2 边际分布列"
        },
        "type": "Document"
    },
    {
        "page_content": "如果二维连续随机变量 $(X, Y)$ 的联合密度函数为 $p(x, y)$, 因为  \n$$\n\\begin{aligned}\n& F_{X}(x)=F(x,+\\infty)=\\int_{-\\infty}^{x}\\left(\\int_{-\\infty}^{+\\infty} p(u, v) \\mathrm{d} v\\right) \\mathrm{d} u=\\int_{-\\infty}^{x} p_{X}(u) \\mathrm{d} u, \\\\\n& F_{Y}(y)=F(+\\infty, y)=\\int_{-\\infty}^{y}\\left(\\int_{-\\infty}^{+\\infty} p(u, v) \\mathrm{d} u\\right) \\mathrm{d} v=\\int_{-\\infty}^{y} p_{Y}(v) \\mathrm{d} v,\n\\end{aligned}\n$$  \n其中 $p_{X}(x)$ 和 $p_{Y}(y)$ 分别为  \n$$\n\\begin{align*}\n& p_{X}(x)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y .  \\tag{3.2.5}\\\\\n& p_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x . \\tag{3.2.6}\n\\end{align*}\n$$  \n它们恰好处于密度函数位置, 故称上式给出的 $p_{X}(x)$ 为 $X$ 的边际密度函数, $p_{Y}(y)$ 为 $Y$ 的边际密度函数.  \n由联合密度函数求边际密度函数时, 要注意积分区域的确定.  \n例 3.2.3: 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}1, & 0<x<1,|y|<x \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求:(1) 边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$;(2) $P(X<1 / 2)$ 及 $P(Y>1 / 2)$.  \n解: 首先识别 $p(x, y)$ 的非零区域, 它如图 3.2.1 所示.  \n!  \n图 3.2.1: $p(x, y)$ 的非零区域",
        "metadata": {
            "Header 2": "3.2 边际分布与随机变量的独立性",
            "Header 3": "3.2.3 边际密度函数"
        },
        "type": "Document"
    },
    {
        "page_content": "& p_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x . \\tag{3.2.6}\n\\end{align*}\n$$  \n它们恰好处于密度函数位置, 故称上式给出的 $p_{X}(x)$ 为 $X$ 的边际密度函数, $p_{Y}(y)$ 为 $Y$ 的边际密度函数.  \n由联合密度函数求边际密度函数时, 要注意积分区域的确定.  \n例 3.2.3: 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}1, & 0<x<1,|y|<x \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求:(1) 边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$;(2) $P(X<1 / 2)$ 及 $P(Y>1 / 2)$.  \n解: 首先识别 $p(x, y)$ 的非零区域, 它如图 3.2.1 所示.  \n!  \n图 3.2.1: $p(x, y)$ 的非零区域  \n(1) 求 $p_{X}(x)$ : 当 $x \\leqslant 0$ 或 $x \\geqslant 1$ 时, 有 $p_{X}(x)=0$. 而当 $0<x<1$ 时, 有  \n$$\np_{X}(x)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y=\\int_{-x}^{x} \\mathrm{~d} y=2 x .\n$$  \n所以 $X$ 的边际密度函数为 (见图 3.2.2)  \n$$\np_{X}(x)= \\begin{cases}2 x, & 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n再求 $p_{Y}(y)$ : 当 $y \\leqslant-1$ 或 $y \\geqslant 1$ 时, 有 $p_{Y}(y)=0$. 而当 $-1<y<0$ 时, 有  \n$$\np_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x=\\int_{-y}^{1} \\mathrm{~d} x=1+y,\n$$  \n当 $0<y<1$ 时, 有  \n$$",
        "metadata": {
            "Header 2": "3.2 边际分布与随机变量的独立性",
            "Header 3": "3.2.3 边际密度函数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np_{X}(x)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y=\\int_{-x}^{x} \\mathrm{~d} y=2 x .\n$$  \n所以 $X$ 的边际密度函数为 (见图 3.2.2)  \n$$\np_{X}(x)= \\begin{cases}2 x, & 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n再求 $p_{Y}(y)$ : 当 $y \\leqslant-1$ 或 $y \\geqslant 1$ 时, 有 $p_{Y}(y)=0$. 而当 $-1<y<0$ 时, 有  \n$$\np_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x=\\int_{-y}^{1} \\mathrm{~d} x=1+y,\n$$  \n当 $0<y<1$ 时, 有  \n$$\np_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x=\\int_{y}^{1} \\mathrm{~d} x=1-y .\n$$  \n!  \n图 3.2.2: $X$ 的边际密度函数  \n所以 $Y$ 的边际密度函数为 (见图 3.2.3)  \n$$\np_{Y}(y)= \\begin{cases}1+y, & -1<y<0, \\\\ 1-y, & 0<y<1, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n!  \n图 3.2.3: $Y$ 的边际密度函数  \n(2) 要求的概率分别为  \n$$\n\\begin{aligned}\n& P(X<1 / 2)=\\int_{-\\infty}^{1 / 2} p_{X}(x) \\mathrm{d} x=\\int_{0}^{1 / 2} 2 x \\mathrm{~d} x=\\frac{1}{4} . \\\\\n& P(Y>1 / 2)=\\int_{1 / 2}^{+\\infty} p_{Y}(y) \\mathrm{d} y=\\int_{1 / 2}^{1}(1-y) \\mathrm{d} y=\\frac{1}{8} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "3.2 边际分布与随机变量的独立性",
            "Header 3": "3.2.3 边际密度函数"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 下面只证三项分布的边际分布为二项分布. 设 $(X, Y)$ 服从三项分布 $M\\left(n, p_{1}, p_{2}, p_{3}\\right)$, 其联合分布列为  \n$$\nP(X=i, Y=j)=\\frac{n !}{i ! j !(n-i-j) !} p_{1}^{i} p_{2}^{j}\\left(1-p_{1}-p_{2}\\right)^{n-i-j}, i, j=1,2, \\ldots, n, i+j \\leqslant n\n$$  \n对上式分别乘以和除以 $\\left(1-p_{1}\\right)^{n-i} /(n-i)$ !, 再对 $j$ 从 0 到 $n-1$ 求和, 并记 $p_{2}^{\\prime}=p_{2} /\\left(1-p_{1}\\right)$, 则可得  \n$$\n\\begin{aligned}\n& \\sum_{j=0}^{n-i} P(X=i, Y=j)=\\frac{n !}{i !(n-i) !} p_{1}^{i}\\left(1-p_{1}\\right)^{n-i} . \\\\\n& \\sum_{j=0}^{n-i}\\left(\\begin{array}{c}\nn-i \\\\\nj\n\\end{array}\\right)\\left(\\frac{p_{2}}{1-p_{1}}\\right)^{j}\\left(1-\\frac{p_{2}}{1-p_{1}}\\right)^{n-i-j} \\\\\n& =\\frac{n !}{i !(n-i) !} p_{1}^{i}\\left(1-p_{1}\\right)^{n-i}\\left[p_{2}^{\\prime}+\\left(1-p_{2}^{\\prime}\\right)\\right]^{n-i} \\\\\n& =\\frac{n !}{i !(n-i) !} p_{1}^{i}\\left(1-p_{1}\\right)^{n-i} .\n\\end{aligned}\n$$  \n所以 $X \\sim b\\left(n, p_{1}\\right)$. 同理可证 $Y \\sim b\\left(n, p_{2}\\right)$.",
        "metadata": {
            "Header 2": "例 3.2.4: 多项分布的边际分布仍为多项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& \\sum_{j=0}^{n-i}\\left(\\begin{array}{c}\nn-i \\\\\nj\n\\end{array}\\right)\\left(\\frac{p_{2}}{1-p_{1}}\\right)^{j}\\left(1-\\frac{p_{2}}{1-p_{1}}\\right)^{n-i-j} \\\\\n& =\\frac{n !}{i !(n-i) !} p_{1}^{i}\\left(1-p_{1}\\right)^{n-i}\\left[p_{2}^{\\prime}+\\left(1-p_{2}^{\\prime}\\right)\\right]^{n-i} \\\\\n& =\\frac{n !}{i !(n-i) !} p_{1}^{i}\\left(1-p_{1}\\right)^{n-i} .\n\\end{aligned}\n$$  \n所以 $X \\sim b\\left(n, p_{1}\\right)$. 同理可证 $Y \\sim b\\left(n, p_{2}\\right)$.  \n用类似的方法可以证明: 若 $\\left(X, X_{2}, \\ldots, X_{r}\\right) \\sim M\\left(n, p_{1}, p_{2}, \\ldots, p_{r}\\right)$, 则 $X_{i} \\sim b\\left(n, p_{i}\\right), i=$ $1,2, \\ldots, r$.",
        "metadata": {
            "Header 2": "例 3.2.4: 多项分布的边际分布仍为多项分布"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 设 $(X, Y) \\sim N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$. 先把 (3.1.8) 式二维正态密度函数 $p(x, y)$ 的指数部分  \n改写成  \n$$\n-\\frac{1}{2\\left(1-\\rho^{2}\\right)}\\left[\\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\n$$  \n$$\n-\\frac{1}{2}\\left[\\rho \\frac{x-\\mu_{1}}{\\sigma_{1} \\sqrt{1-\\rho^{2}}}-\\frac{y-\\mu_{2}}{\\sigma_{2} \\sqrt{1-\\rho^{2}}}\\right]^{2}-\\frac{\\left(x-\\mu_{1}\\right)^{2}}{2 \\sigma_{1}^{2}} .\n$$  \n再对积分  \n$$\n\\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{1}{2}\\left[\\rho \\frac{x-\\mu_{1}}{\\sigma_{1} \\sqrt{1-\\rho^{2}}}-\\frac{y-\\mu_{2}}{\\sigma_{2} \\sqrt{1-\\rho^{2}}}\\right]^{2}\\right\\} \\mathrm{d} y\n$$  \n作变换 (注意把 $x$ 看作常量)  \n$$\nt=\\rho \\frac{x-\\mu_{1}}{\\sigma_{1} \\sqrt{1-\\rho^{2}}}-\\frac{y-\\mu_{2}}{\\sigma_{2} \\sqrt{1-\\rho^{2}}}\n$$  \n则  \n$$\n\\begin{aligned}\np_{X}(x) & =\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y \\\\",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n再对积分  \n$$\n\\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{1}{2}\\left[\\rho \\frac{x-\\mu_{1}}{\\sigma_{1} \\sqrt{1-\\rho^{2}}}-\\frac{y-\\mu_{2}}{\\sigma_{2} \\sqrt{1-\\rho^{2}}}\\right]^{2}\\right\\} \\mathrm{d} y\n$$  \n作变换 (注意把 $x$ 看作常量)  \n$$\nt=\\rho \\frac{x-\\mu_{1}}{\\sigma_{1} \\sqrt{1-\\rho^{2}}}-\\frac{y-\\mu_{2}}{\\sigma_{2} \\sqrt{1-\\rho^{2}}}\n$$  \n则  \n$$\n\\begin{aligned}\np_{X}(x) & =\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y \\\\\n& =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}} \\exp \\left\\{-\\frac{\\left(x-\\mu_{1}\\right)^{2}}{2 \\sigma_{1}^{2}}\\right\\} \\sigma_{2} \\sqrt{1-\\rho^{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{t^{2}}{2}\\right\\} \\mathrm{d} t .\n\\end{aligned}\n$$  \n注意到上式中的积分恰好等于 $\\sqrt{2 \\pi}$, 所以有  \n$$\np_{X}(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{1}} \\exp \\left\\{-\\frac{\\left(x-\\mu_{1}\\right)^{2}}{2 \\sigma_{1}^{2}}\\right\\} \\text {. }\n$$",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布"
        },
        "type": "Document"
    },
    {
        "page_content": "p_{X}(x) & =\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y \\\\\n& =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}} \\exp \\left\\{-\\frac{\\left(x-\\mu_{1}\\right)^{2}}{2 \\sigma_{1}^{2}}\\right\\} \\sigma_{2} \\sqrt{1-\\rho^{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{t^{2}}{2}\\right\\} \\mathrm{d} t .\n\\end{aligned}\n$$  \n注意到上式中的积分恰好等于 $\\sqrt{2 \\pi}$, 所以有  \n$$\np_{X}(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{1}} \\exp \\left\\{-\\frac{\\left(x-\\mu_{1}\\right)^{2}}{2 \\sigma_{1}^{2}}\\right\\} \\text {. }\n$$  \n这正是一维正态分布 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 的密度函数, 即 $X \\sim N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$. 同理可证 $Y \\sim N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$. 由此可见  \n-二维正态分布的边际分布中不含参数 $\\rho$.  \n- 这说明二维正态分布 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, 0.1\\right)$ 与 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, 0.2\\right)$ 的边际分布是相同的.\n- 具有相同边际分布的多维联合分布可以是不同的.",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布"
        },
        "type": "Document"
    },
    {
        "page_content": "在多维随机变量中, 各分量的取值有时会相互影响, 但有时毫无影响. 譬如一个人的身高 $X$ 和体重 $Y$ 就会相互影响, 但与收人 $Z$ 一般无影响. 当两个随机变量取值的规律互不影响时, 就称它们是相互独立的.  \n定义 3.2.1. 设 $n$ 维随机变量 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的联合分布函数为 $F\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right), F_{i}\\left(x_{i}\\right)$ 为 $X_{i}$的边际分布函数. 如果对任意 $n$ 个实数 $x_{1}, x_{2}, \\ldots, x_{n}$, 有  \n$$\n\\begin{equation*}\nF\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} F_{i}\\left(x_{i}\\right) \\tag{3.2.7}\n\\end{equation*}\n$$  \n则称 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立.  \n在离散随机变量场合, 如果对其任意 $n$ 个取值 $x_{1}, x_{2}, \\ldots, x_{n}$, 有  \n$$\n\\begin{equation*}\nP\\left(X_{1}=x_{1}, X_{2}=x_{2}, \\ldots, X_{n}=x_{n}\\right)=\\prod_{i=1}^{n} P\\left(X_{i}=x_{i}\\right) \\tag{3.2.8}\n\\end{equation*}\n$$  \n则称 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立.  \n在连续随机变量场合, 如果对任意 $n$ 个实数 $x_{1}, x_{2}, \\ldots, x_{n}$, 有  \n$$\n\\begin{equation*}\np\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} p_{i}\\left(x_{i}\\right) \\tag{3.2.9}\n\\end{equation*}\n$$  \n则称 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立.",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "在离散随机变量场合, 如果对其任意 $n$ 个取值 $x_{1}, x_{2}, \\ldots, x_{n}$, 有  \n$$\n\\begin{equation*}\nP\\left(X_{1}=x_{1}, X_{2}=x_{2}, \\ldots, X_{n}=x_{n}\\right)=\\prod_{i=1}^{n} P\\left(X_{i}=x_{i}\\right) \\tag{3.2.8}\n\\end{equation*}\n$$  \n则称 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立.  \n在连续随机变量场合, 如果对任意 $n$ 个实数 $x_{1}, x_{2}, \\ldots, x_{n}$, 有  \n$$\n\\begin{equation*}\np\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} p_{i}\\left(x_{i}\\right) \\tag{3.2.9}\n\\end{equation*}\n$$  \n则称 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立.  \n例 3.2.6: 设 $(X, Y)$ 是二维离散随机变量, $X$ 和 $Y$ 的边际分布列分别如下所示: 如果 $P\\{X Y=0\\}=$  \n| $X$ | -1 | 0 | 1 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $1 / 4$ | $1 / 2$ | $1 / 4$ |  \n| $Y$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1 / 2$ | $1 / 2$ |  \n1 , 试求  \n(1) $(X, Y)$ 的联合分布列;  \n(2) $X$ 与 $Y$ 是否独立?  \n解:  \n(1) 记 $(X, Y)$ 得联合分布列如下, 其中 $p_{i j}=P(X=i, Y=j)$, 在联合分布列的右侧是 $X$ 的边际分布列, 下侧是 $Y$ 的边际分布列.  \n|  | $Y$ |  |  |\n| :--- | :--- | :--- | :--- |\n| $X$ | 0 | 1 | $P(X=i)$ |\n| -1 | $p_{11}$ | $p_{12}$ | $1 / 4$ |",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "| $X$ | -1 | 0 | 1 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $1 / 4$ | $1 / 2$ | $1 / 4$ |  \n| $Y$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1 / 2$ | $1 / 2$ |  \n1 , 试求  \n(1) $(X, Y)$ 的联合分布列;  \n(2) $X$ 与 $Y$ 是否独立?  \n解:  \n(1) 记 $(X, Y)$ 得联合分布列如下, 其中 $p_{i j}=P(X=i, Y=j)$, 在联合分布列的右侧是 $X$ 的边际分布列, 下侧是 $Y$ 的边际分布列.  \n|  | $Y$ |  |  |\n| :--- | :--- | :--- | :--- |\n| $X$ | 0 | 1 | $P(X=i)$ |\n| -1 | $p_{11}$ | $p_{12}$ | $1 / 4$ |\n| 0 | $p_{21}$ | $p_{22}$ | $1 / 2$ |\n| 1 | $p_{31}$ | $p_{32}$ | $1 / 4$ |\n| $P(Y=j)$ | $1 / 2$ | $1 / 2$ | 1 |  \n由 $P(X Y=0)=1$, 知 $P(X Y \\neq 0)=0$, 即  \n$$\np_{12}=P(X=-1, Y=1)=0, \\quad p_{32}=P(X=1, Y=1)=0\n$$  \n其余四个概率可由下面等式分别确定.  \n从表中第一行看, 由 $p_{11}+p_{12}=1 / 4$, 得 $p_{11}=1 / 4$.  \n从表中第三行看, 由 $p_{31}+p_{32}=1 / 4$, 得 $p_{31}=1 / 4$.  \n从表中第一列看, 由 $p_{11}+p_{21}+p_{31}=1 / 2=1 / 4+p_{21}+1 / 4$, 得 $p_{21}=0$.  \n从表中第二列看, 由 $p_{12}+p_{22}+p_{32}=1 / 2=0+p_{22}+0$, 得 $p_{22}=1 / 2$.  \n于是得 $(X, Y)$ 的联合分布列如下:  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "| $P(Y=j)$ | $1 / 2$ | $1 / 2$ | 1 |  \n由 $P(X Y=0)=1$, 知 $P(X Y \\neq 0)=0$, 即  \n$$\np_{12}=P(X=-1, Y=1)=0, \\quad p_{32}=P(X=1, Y=1)=0\n$$  \n其余四个概率可由下面等式分别确定.  \n从表中第一行看, 由 $p_{11}+p_{12}=1 / 4$, 得 $p_{11}=1 / 4$.  \n从表中第三行看, 由 $p_{31}+p_{32}=1 / 4$, 得 $p_{31}=1 / 4$.  \n从表中第一列看, 由 $p_{11}+p_{21}+p_{31}=1 / 2=1 / 4+p_{21}+1 / 4$, 得 $p_{21}=0$.  \n从表中第二列看, 由 $p_{12}+p_{22}+p_{32}=1 / 2=0+p_{22}+0$, 得 $p_{22}=1 / 2$.  \n于是得 $(X, Y)$ 的联合分布列如下:  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | $p_{i}$. |\n| -1 | $1 / 4$ | 0 | $1 / 4$ |\n| 0 | 0 | $1 / 2$ | $1 / 2$ |\n| 1 | $1 / 4$ | 0 | $1 / 4$ |\n| $p_{\\cdot j}$ | $1 / 2$ | $1 / 2$ | 1 |  \n(2) 因为 $P(X=0, Y=0)=p_{21}=0$, 而 $P(X=0) P(Y=0)=1 / 4$, 所以 $X$ 与 $Y$ 不独立.  \n例 3.2.7: 若 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}8 x y, & 0 \\leqslant x \\leqslant y \\leqslant 1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n问 $X$ 与 $Y$ 是否相互独立?",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "于是得 $(X, Y)$ 的联合分布列如下:  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | $p_{i}$. |\n| -1 | $1 / 4$ | 0 | $1 / 4$ |\n| 0 | 0 | $1 / 2$ | $1 / 2$ |\n| 1 | $1 / 4$ | 0 | $1 / 4$ |\n| $p_{\\cdot j}$ | $1 / 2$ | $1 / 2$ | 1 |  \n(2) 因为 $P(X=0, Y=0)=p_{21}=0$, 而 $P(X=0) P(Y=0)=1 / 4$, 所以 $X$ 与 $Y$ 不独立.  \n例 3.2.7: 若 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}8 x y, & 0 \\leqslant x \\leqslant y \\leqslant 1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n问 $X$ 与 $Y$ 是否相互独立?  \n解: 为判断 $X$ 与 $Y$ 是否独立, 只需看边际密度函数的乘积是否等于联合密度函数. 为此先求边际密度函数. 当 $x<0$ 或 $x>1$ 时, $p_{X}(x)=0$. 而当 $0 \\leqslant x \\leqslant 1$ 时, 有  \n因此  \n$$\np_{X}(x)=\\int_{x}^{1} 8 x y \\mathrm{~d} y=8 x\\left(\\frac{1}{2}-\\frac{x^{2}}{2}\\right)=4 x\\left(1-x^{2}\\right) .\n$$  \n$$\np_{X}(x)= \\begin{cases}4 x\\left(1-x^{2}\\right), & 0 \\leqslant x \\leqslant 1, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n同样, 当 $y<0$ 或 $y>1$ 时, $p_{Y}(y)=0$. 而当 $0 \\leqslant y \\leqslant 1$ 时, 有  \n$$\np_{Y}(y)=\\int_{0}^{x} 8 x y \\mathrm{~d} x=4 y^{3} .\n$$  \n因此  \n$$",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "因此  \n$$\np_{X}(x)=\\int_{x}^{1} 8 x y \\mathrm{~d} y=8 x\\left(\\frac{1}{2}-\\frac{x^{2}}{2}\\right)=4 x\\left(1-x^{2}\\right) .\n$$  \n$$\np_{X}(x)= \\begin{cases}4 x\\left(1-x^{2}\\right), & 0 \\leqslant x \\leqslant 1, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n同样, 当 $y<0$ 或 $y>1$ 时, $p_{Y}(y)=0$. 而当 $0 \\leqslant y \\leqslant 1$ 时, 有  \n$$\np_{Y}(y)=\\int_{0}^{x} 8 x y \\mathrm{~d} x=4 y^{3} .\n$$  \n因此  \n$$\np_{Y}(y)= \\begin{cases}4 y^{3}, & 0 \\leqslant y \\leqslant 1 ; \\\\ 0, & \\text { 其他 } .\\end{cases}\n$$  \n由此得 $p(x, y) \\neq p_{X}(x) p_{Y}(y)$, 所以 $X$ 与 $Y$ 不独立.  \n例 3.2.8: 从 $(0,1)$ 中任取两个数, 求下列事件的概率.  \n(1) 两数之和小于 1.2 ;  \n(2) 两数之积小于 $1 / 4$.  \n解: 分别记这两个数为 $X$ 和 $Y$, 则 $X$ 和 $Y$ 独立, 且都服从 $(0,1)$ 上的均匀分布, $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)=p_{X}(x) p_{Y}(y)= \\begin{cases}1, & 0<x<1,0<y<1 \\\\ 0, & \\text { 其他 }\\end{cases}\n$$  \n(1) 从图 3.2.4a可知  \n$$\n\\begin{array}{r}\nP(X+Y<1.2)=\\int_{0}^{0.2} \\int_{0}^{1} \\mathrm{~d} y \\mathrm{~d} x+\\int_{0.2}^{1} \\int_{0}^{1.2-x} \\mathrm{~d} y \\mathrm{~d} x \\\\",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由此得 $p(x, y) \\neq p_{X}(x) p_{Y}(y)$, 所以 $X$ 与 $Y$ 不独立.  \n例 3.2.8: 从 $(0,1)$ 中任取两个数, 求下列事件的概率.  \n(1) 两数之和小于 1.2 ;  \n(2) 两数之积小于 $1 / 4$.  \n解: 分别记这两个数为 $X$ 和 $Y$, 则 $X$ 和 $Y$ 独立, 且都服从 $(0,1)$ 上的均匀分布, $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)=p_{X}(x) p_{Y}(y)= \\begin{cases}1, & 0<x<1,0<y<1 \\\\ 0, & \\text { 其他 }\\end{cases}\n$$  \n(1) 从图 3.2.4a可知  \n$$\n\\begin{array}{r}\nP(X+Y<1.2)=\\int_{0}^{0.2} \\int_{0}^{1} \\mathrm{~d} y \\mathrm{~d} x+\\int_{0.2}^{1} \\int_{0}^{1.2-x} \\mathrm{~d} y \\mathrm{~d} x \\\\\n=0.2+\\int_{0.2}^{1}(1.2-x) \\mathrm{d} x=0.2+0.48=0.68 .\n\\end{array}\n$$  \n!  \n(a) $\\{x+y<1.2,0<x, y<1\\}$  \n!  \n(b) $\\{x y<1 / 4,0<x, y<1\\}$  \n图 3.2.4: $p(x, y)$ 的非零区域与有关事件的交集部分  \n(2) 从图 3.2.4b可知  \n$$\n\\begin{gathered}\nP(X Y<1 / 4)=\\int_{0}^{1 / 4} \\int_{0}^{1} \\mathrm{~d} y \\mathrm{~d} x+\\int_{1 / 4}^{1} \\int_{0}^{1 /(4 x)} \\mathrm{d} y \\mathrm{~d} x \\\\\n=\\frac{1}{4}+\\int_{1 / 4}^{1} \\frac{1}{4 x} \\mathrm{~d} x=\\frac{1}{4}+\\frac{1}{4} \\ln 4=0.5966 . \\\\\n\\text { 如 题 } 3.2\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "=0.2+\\int_{0.2}^{1}(1.2-x) \\mathrm{d} x=0.2+0.48=0.68 .\n\\end{array}\n$$  \n!  \n(a) $\\{x+y<1.2,0<x, y<1\\}$  \n!  \n(b) $\\{x y<1 / 4,0<x, y<1\\}$  \n图 3.2.4: $p(x, y)$ 的非零区域与有关事件的交集部分  \n(2) 从图 3.2.4b可知  \n$$\n\\begin{gathered}\nP(X Y<1 / 4)=\\int_{0}^{1 / 4} \\int_{0}^{1} \\mathrm{~d} y \\mathrm{~d} x+\\int_{1 / 4}^{1} \\int_{0}^{1 /(4 x)} \\mathrm{d} y \\mathrm{~d} x \\\\\n=\\frac{1}{4}+\\int_{1 / 4}^{1} \\frac{1}{4 x} \\mathrm{~d} x=\\frac{1}{4}+\\frac{1}{4} \\ln 4=0.5966 . \\\\\n\\text { 如 题 } 3.2\n\\end{gathered}\n$$  \n1. 设二维离散随机变量 $(X, Y)$ 的可能值为  \n$$\n(0,0),(-1,1),(-1,2),(1,0) \\text {. }\n$$  \n且取这些值的概率依次为 $1 / 6,1 / 3,1 / 12,5 / 12$, 试求 $X$ 与 $Y$ 各自的边际分布列.  \n2. 设二维随机变量 $(X, Y)$ 的联合分布函数为  \n$$\nF(x, y)= \\begin{cases}1-\\mathrm{e}^{-\\lambda_{1} x}-\\mathrm{e}^{-\\lambda_{2} y}+\\mathrm{e}^{-\\lambda_{1} x-\\lambda_{2} y-\\lambda_{12} \\max \\{x, y\\}}, & x>0, y>0 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $X$ 和 $Y$ 各自的边际分布函数.  \n3. 试求以下二维均匀分布的边际分布:  \n$$",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "\\text { 如 题 } 3.2\n\\end{gathered}\n$$  \n1. 设二维离散随机变量 $(X, Y)$ 的可能值为  \n$$\n(0,0),(-1,1),(-1,2),(1,0) \\text {. }\n$$  \n且取这些值的概率依次为 $1 / 6,1 / 3,1 / 12,5 / 12$, 试求 $X$ 与 $Y$ 各自的边际分布列.  \n2. 设二维随机变量 $(X, Y)$ 的联合分布函数为  \n$$\nF(x, y)= \\begin{cases}1-\\mathrm{e}^{-\\lambda_{1} x}-\\mathrm{e}^{-\\lambda_{2} y}+\\mathrm{e}^{-\\lambda_{1} x-\\lambda_{2} y-\\lambda_{12} \\max \\{x, y\\}}, & x>0, y>0 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $X$ 和 $Y$ 各自的边际分布函数.  \n3. 试求以下二维均匀分布的边际分布:  \n$$\np(x, y)= \\begin{cases}\\frac{1}{\\pi}, & x^{2}+y^{2} \\leqslant 1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n4. 设平面区域 $D$ 由曲线 $y=1 / x$ 及直线 $y=0, x=1, x=\\mathrm{e}^{2}$ 所围成, 二维随机变量 $(X, Y)$ 在区域 $D$ 上服从均匀分布, 试求 $X$ 的边际密度函数.\n5. 求以下给出的 $(X, Y)$ 的联合密度函数的边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$.  \n$$\n\\begin{aligned}\n& p_{1}(x, y)= \\begin{cases}\\mathrm{e}^{-y}, & 0<x<y ; \\\\\n0, & \\text { 其他. }\\end{cases} \\\\\n& p_{2}(x, y)= \\begin{cases}\\frac{5}{4}\\left(x^{2}+y\\right), & 0<y<1-x^{2} ; \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n4. 设平面区域 $D$ 由曲线 $y=1 / x$ 及直线 $y=0, x=1, x=\\mathrm{e}^{2}$ 所围成, 二维随机变量 $(X, Y)$ 在区域 $D$ 上服从均匀分布, 试求 $X$ 的边际密度函数.\n5. 求以下给出的 $(X, Y)$ 的联合密度函数的边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$.  \n$$\n\\begin{aligned}\n& p_{1}(x, y)= \\begin{cases}\\mathrm{e}^{-y}, & 0<x<y ; \\\\\n0, & \\text { 其他. }\\end{cases} \\\\\n& p_{2}(x, y)= \\begin{cases}\\frac{5}{4}\\left(x^{2}+y\\right), & 0<y<1-x^{2} ; \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$  \n6. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}6, & 0<x^{2}<y<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$.  \n7. 试验证: 以下给出的两个不同的联合密度函数, 它们有相同的边际密度函数.  \n$$\n\\begin{aligned}\n& p(x, y)= \\begin{cases}x+y, & 0 \\leqslant x \\leqslant 1,0 \\leqslant y \\leqslant 1 ; \\\\\n0, & \\text { 其他. }\\end{cases} \\\\\n& g(x, y)= \\begin{cases}(0.5+x)(0.5+y), & 0 \\leqslant x \\leqslant 1,0 \\leqslant y \\leqslant 1 ; \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$  \n8. 设随机变量 $X$ 和 $Y$ 独立同分布, 且  \n$$\nP(X=-1)=P(Y=-1)=P(X=1)=P(Y=1)=\\frac{1}{2}\n$$  \n试求 $P\\{X=Y\\}$.",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试求边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$.  \n7. 试验证: 以下给出的两个不同的联合密度函数, 它们有相同的边际密度函数.  \n$$\n\\begin{aligned}\n& p(x, y)= \\begin{cases}x+y, & 0 \\leqslant x \\leqslant 1,0 \\leqslant y \\leqslant 1 ; \\\\\n0, & \\text { 其他. }\\end{cases} \\\\\n& g(x, y)= \\begin{cases}(0.5+x)(0.5+y), & 0 \\leqslant x \\leqslant 1,0 \\leqslant y \\leqslant 1 ; \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$  \n8. 设随机变量 $X$ 和 $Y$ 独立同分布, 且  \n$$\nP(X=-1)=P(Y=-1)=P(X=1)=P(Y=1)=\\frac{1}{2}\n$$  \n试求 $P\\{X=Y\\}$.  \n9. 甲、乙两人独立地各进行两次射击, 假设甲的命中率为 0.2 , 乙的命中率为 0.5 , 以 $X$ 和 $Y$ 分别表示甲和乙的命中次数, 试求 $P(X \\leqslant Y)$.\n10. 设随机变量 $X$ 和 $Y$ 相互独立, 其联合分布列为  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | $y_{1}$ | $y_{2}$ | $y_{3}$ |\n| $x_{1}$ | $a$ | $1 / 9$ | $c$ |\n| $x_{2}$ | $1 / 9$ | $b$ | $1 / 3$ |  \n试求联合分布列中的 $a, b, c$.  \n11. 设 $k_{1}, k_{2}$ 分别是掷一枚骰子两次先后出现的点数. 试求方程 $x^{2}+k_{1} x+k_{2}=0$ 有实根的概率 $p$ 和有重根的概率 $q$.\n12. 设 $X$ 与 $Y$ 是两个相互独立的随机变量, $X \\sim U(0,1), Y \\sim \\operatorname{Exp}(1)$. 试求  \n(1) $X$ 与 $Y$ 的联合密度函数;",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "10. 设随机变量 $X$ 和 $Y$ 相互独立, 其联合分布列为  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | $y_{1}$ | $y_{2}$ | $y_{3}$ |\n| $x_{1}$ | $a$ | $1 / 9$ | $c$ |\n| $x_{2}$ | $1 / 9$ | $b$ | $1 / 3$ |  \n试求联合分布列中的 $a, b, c$.  \n11. 设 $k_{1}, k_{2}$ 分别是掷一枚骰子两次先后出现的点数. 试求方程 $x^{2}+k_{1} x+k_{2}=0$ 有实根的概率 $p$ 和有重根的概率 $q$.\n12. 设 $X$ 与 $Y$ 是两个相互独立的随机变量, $X \\sim U(0,1), Y \\sim \\operatorname{Exp}(1)$. 试求  \n(1) $X$ 与 $Y$ 的联合密度函数;  \n(2) $P(Y \\leqslant X)$;  \n(3) $P(X+Y \\leqslant 1)$.  \n13. 设随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}3 x, & 0<x<1,0<y<x \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) 边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$;  \n(2) $X$ 与 $Y$ 是否独立?  \n14. 设随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}1, & |x|<y, 0<y<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) 边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$;  \n(2) $X$ 与 $Y$ 是否独立?  \n15. 在长为 $a$ 的线段的中点的两边随机地各选取一点, 求两点间的距离小于 $a / 3$ 的概率.",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) $X$ 与 $Y$ 的联合密度函数;  \n(2) $P(Y \\leqslant X)$;  \n(3) $P(X+Y \\leqslant 1)$.  \n13. 设随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}3 x, & 0<x<1,0<y<x \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) 边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$;  \n(2) $X$ 与 $Y$ 是否独立?  \n14. 设随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}1, & |x|<y, 0<y<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求  \n(1) 边际密度函数 $p_{X}(x)$ 和 $p_{Y}(y)$;  \n(2) $X$ 与 $Y$ 是否独立?  \n15. 在长为 $a$ 的线段的中点的两边随机地各选取一点, 求两点间的距离小于 $a / 3$ 的概率.\n16. 设二维随机变量 $(X, Y)$ 的联合密度函数为 $p(x, y)$. 证明: $X$ 与 $Y$ 相互独立的充要条件是 $p(x, y)$ 可分离变量, 即 $p(x, y)=h(x) g(y)$. 又问 $h(x), g(y)$ 与边际密度函数有什么关系?",
        "metadata": {
            "Header 2": "例 3.2.5: 二维正态分布的边际分布为一维正态分布",
            "Header 3": "3.2.4 随机变量间的独立性"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 为 $n$ 维随机变量, 则 $Y=g\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 是 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的函数, $Y$是一维随机变量. 现在的问题是如何由 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的分布, 求出 $Y$ 的分布. 这是一类技巧性很强的工作, 不仅对离散场合和连续场合有不同的方法, 而且对不同形式的函数 $g\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$要采用不同的方法, 甚至有些方法只对特殊形式的 $g(\\cdot)$ 适用. 下面将以例子形式讲述这些方法.",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 为 $n$ 维离散随机变量, 则某一函数 $Y=g\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 是一维离散随机变量. 当 $\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 所有可能取值较少时, 可将 $Y$ 的取值一一列出, 然后再合并整理就可得出结果, 见下例.  \n例 3.3.1: 设 $(X, Y)$ 的联合分布列如下所示:  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | -1 | 1 | 2 |\n| -1 | $5 / 20$ | $2 / 20$ | $6 / 20$ |\n| 2 | $3 / 20$ | $3 / 20$ | $1 / 20$ |  \n试求:  \n(1) $Z_{1}=X+Y$ 的分布列;  \n(2) $Z_{2}=X-Y$ 的分布列;  \n(3) $Z_{3}=\\max \\{X, Y\\}$ 的分布列.  \n解: 将 $(X, Y)$ 及各个函数的取值对应列于同一表中:  \n| $P$ | $5 / 20$ | $2 / 20$ | $6 / 20$ | $3 / 20$ | $3 / 20$ | $1 / 20$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $(X, Y)$ | $(-1,-1)$ | $(-1,1)$ | $(-1,2)$ | $(2,-1)$ | $(2,1)$ | $(2,2)$ |\n| $Z_{1}=X+Y$ | -2 | 0 | 1 | 1 | 3 | 4 |\n| $Z_{2}=X-Y$ | 0 | -2 | -3 | 3 | 1 | 0 |\n| $Z_{3}=\\max \\{X, Y\\}$ | -1 | 1 | 2 | 2 | 2 | 2 |  \n然后经过合并整理就可得最后结果:  \n| $Z_{1}=X+Y$ | -2 | 0 | 1 | 3 | 4 |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 将 $(X, Y)$ 及各个函数的取值对应列于同一表中:  \n| $P$ | $5 / 20$ | $2 / 20$ | $6 / 20$ | $3 / 20$ | $3 / 20$ | $1 / 20$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $(X, Y)$ | $(-1,-1)$ | $(-1,1)$ | $(-1,2)$ | $(2,-1)$ | $(2,1)$ | $(2,2)$ |\n| $Z_{1}=X+Y$ | -2 | 0 | 1 | 1 | 3 | 4 |\n| $Z_{2}=X-Y$ | 0 | -2 | -3 | 3 | 1 | 0 |\n| $Z_{3}=\\max \\{X, Y\\}$ | -1 | 1 | 2 | 2 | 2 | 2 |  \n然后经过合并整理就可得最后结果:  \n| $Z_{1}=X+Y$ | -2 | 0 | 1 | 3 | 4 |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P$ | $5 / 20$ | $2 / 20$ | $9 / 20$ | $3 / 20$ | $1 / 20$ |  |\n|  |  |  |  |  |  |  |\n| $Z_{2}=X-Y$ | -3 | -2 | 0 | 1 | 3 |  |\n| $P$ | $6 / 20$ | $2 / 20$ | $6 / 20$ | $3 / 20$ | $3 / 20$ |  |  \n| $Z_{3}=\\max \\{X, Y\\}$ | -1 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $5 / 20$ | $2 / 20$ | $13 / 20$ |  \n例 3.3.2(泊松分布的可加性): 设 $X \\sim P\\left(\\lambda_{1}\\right), Y \\sim P\\left(\\lambda_{2}\\right)$, 且 $X$ 与 $Y$ 独立, 证明 $Z=X+Y \\sim$ $P\\left(\\lambda_{1}+\\lambda_{2}\\right)$.",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| $P$ | $5 / 20$ | $2 / 20$ | $9 / 20$ | $3 / 20$ | $1 / 20$ |  |\n|  |  |  |  |  |  |  |\n| $Z_{2}=X-Y$ | -3 | -2 | 0 | 1 | 3 |  |\n| $P$ | $6 / 20$ | $2 / 20$ | $6 / 20$ | $3 / 20$ | $3 / 20$ |  |  \n| $Z_{3}=\\max \\{X, Y\\}$ | -1 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $5 / 20$ | $2 / 20$ | $13 / 20$ |  \n例 3.3.2(泊松分布的可加性): 设 $X \\sim P\\left(\\lambda_{1}\\right), Y \\sim P\\left(\\lambda_{2}\\right)$, 且 $X$ 与 $Y$ 独立, 证明 $Z=X+Y \\sim$ $P\\left(\\lambda_{1}+\\lambda_{2}\\right)$.  \n证明: 首先指出, $Z=X+Y$ 可取 $0,1,2, \\ldots$ 所有非负整数. 面事件 $\\{Z=k\\}$ 是诸互不相容事件  \n$$\n\\{X=i, Y=k-i\\}, \\quad i=0,1, \\ldots, k\n$$  \n的并, 再考虑到独立性, 则对任意非负整数 $k$, 有  \n$$\n\\begin{equation*}\nP(Z=k)=\\sum_{i=0}^{k} P(X=i) P(Y=k-i) \\tag{3.3.1}\n\\end{equation*}\n$$  \n这个概率等式被称为离散场合下的卷积公式. 利用此公式可得  \n$$\n\\begin{aligned}\nP(Z=k) & =\\sum_{i=1}^{k}\\left(\\frac{\\lambda_{1}^{i}}{i !} \\mathrm{e}^{-\\lambda_{1}}\\right)\\left(\\frac{\\lambda_{2}^{k-i}}{(k-i) !} \\mathrm{e}^{-\\lambda_{2}}\\right) \\\\",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "证明: 首先指出, $Z=X+Y$ 可取 $0,1,2, \\ldots$ 所有非负整数. 面事件 $\\{Z=k\\}$ 是诸互不相容事件  \n$$\n\\{X=i, Y=k-i\\}, \\quad i=0,1, \\ldots, k\n$$  \n的并, 再考虑到独立性, 则对任意非负整数 $k$, 有  \n$$\n\\begin{equation*}\nP(Z=k)=\\sum_{i=0}^{k} P(X=i) P(Y=k-i) \\tag{3.3.1}\n\\end{equation*}\n$$  \n这个概率等式被称为离散场合下的卷积公式. 利用此公式可得  \n$$\n\\begin{aligned}\nP(Z=k) & =\\sum_{i=1}^{k}\\left(\\frac{\\lambda_{1}^{i}}{i !} \\mathrm{e}^{-\\lambda_{1}}\\right)\\left(\\frac{\\lambda_{2}^{k-i}}{(k-i) !} \\mathrm{e}^{-\\lambda_{2}}\\right) \\\\\n& =\\frac{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{k}}{k !} \\mathrm{e}^{\\left(\\lambda_{1}+\\lambda_{2}\\right)} \\sum_{i=0}^{k} \\frac{k !}{i !(k-i) !}\\left(\\frac{\\lambda_{1}}{\\lambda_{1}+\\lambda_{2}}\\right)^{i}\\left(\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}\\right)^{k-i} \\\\\n& =\\frac{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{k}}{k !} \\mathrm{e}^{\\left(\\lambda_{1}+\\lambda_{2}\\right)}\\left(\\frac{\\lambda_{1}}{\\lambda_{1}+\\lambda_{2}}+\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}\\right)^{k} \\\\",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{k}}{k !} \\mathrm{e}^{\\left(\\lambda_{1}+\\lambda_{2}\\right)} \\sum_{i=0}^{k} \\frac{k !}{i !(k-i) !}\\left(\\frac{\\lambda_{1}}{\\lambda_{1}+\\lambda_{2}}\\right)^{i}\\left(\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}\\right)^{k-i} \\\\\n& =\\frac{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{k}}{k !} \\mathrm{e}^{\\left(\\lambda_{1}+\\lambda_{2}\\right)}\\left(\\frac{\\lambda_{1}}{\\lambda_{1}+\\lambda_{2}}+\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}\\right)^{k} \\\\\n& =\\frac{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{k}}{k !} \\mathrm{e}^{-\\left(\\lambda_{1}+\\lambda_{2}\\right)}, \\quad k=0,1, \\ldots\n\\end{aligned}\n$$  \n这表明 $X+Y \\sim P\\left(\\lambda_{1}+\\lambda_{2}\\right)$, 结论得证. 注意 $X-Y$ 不服从泊松分布.  \n泊松分布的这个性质可以叙述为: 泊松分布的卷积仍是泊松分布, 并记为  \n$$\n\\begin{equation*}\nP\\left(\\lambda_{1}\\right) * P\\left(\\lambda_{2}\\right)=P\\left(\\lambda_{1}+\\lambda_{2}\\right) \\text {. } \\tag{3.3.2}\n\\end{equation*}\n$$  \n这里卷积是指 “寻求两个独立随机变量和的分布运算”. 显然这个性质可以推广到有限个独立泊松变量之和的分布上去, 即  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n这表明 $X+Y \\sim P\\left(\\lambda_{1}+\\lambda_{2}\\right)$, 结论得证. 注意 $X-Y$ 不服从泊松分布.  \n泊松分布的这个性质可以叙述为: 泊松分布的卷积仍是泊松分布, 并记为  \n$$\n\\begin{equation*}\nP\\left(\\lambda_{1}\\right) * P\\left(\\lambda_{2}\\right)=P\\left(\\lambda_{1}+\\lambda_{2}\\right) \\text {. } \\tag{3.3.2}\n\\end{equation*}\n$$  \n这里卷积是指 “寻求两个独立随机变量和的分布运算”. 显然这个性质可以推广到有限个独立泊松变量之和的分布上去, 即  \n$$\n\\begin{equation*}\nP\\left(\\lambda_{1}\\right) * P\\left(\\lambda_{2}\\right) * \\cdots * P\\left(\\lambda_{n}\\right)=P\\left(\\lambda_{1}+\\lambda_{2}+\\cdots+\\lambda_{n}\\right) \\tag{3.3.3}\n\\end{equation*}\n$$  \n特别, 当 $\\lambda_{1}=\\lambda_{2}=\\cdots=\\lambda_{n}=\\lambda$ 时, 有  \n$$\n\\begin{equation*}\nP(\\lambda) * P(\\lambda) * \\cdots * P(\\lambda)=P(n \\lambda) \\tag{3.3.4}\n\\end{equation*}\n$$  \n这些结论在理论上和应用上都是重要的.  \n以后我们称性质 “同一类分布的独立随机变量和的分布仍属于此类分布” 为此类分布具有可加性. 上例说明泊松分布具有可加性, 下例又说明二项分布具有可加性.  \n例 3.3.3二项分布的可加性: 设 $X \\sim b(n, p), Y \\sim b(m, p)$, 且 $X$ 与 $Y$ 独立, 证明 $Z=X+Y \\sim$ $b(n+m, p)$.",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n特别, 当 $\\lambda_{1}=\\lambda_{2}=\\cdots=\\lambda_{n}=\\lambda$ 时, 有  \n$$\n\\begin{equation*}\nP(\\lambda) * P(\\lambda) * \\cdots * P(\\lambda)=P(n \\lambda) \\tag{3.3.4}\n\\end{equation*}\n$$  \n这些结论在理论上和应用上都是重要的.  \n以后我们称性质 “同一类分布的独立随机变量和的分布仍属于此类分布” 为此类分布具有可加性. 上例说明泊松分布具有可加性, 下例又说明二项分布具有可加性.  \n例 3.3.3二项分布的可加性: 设 $X \\sim b(n, p), Y \\sim b(m, p)$, 且 $X$ 与 $Y$ 独立, 证明 $Z=X+Y \\sim$ $b(n+m, p)$.  \n证明：首先指出, $Z=X+Y$ 可取 $0,1,2, \\ldots, n+m$ 等 $n+m+1$ 个不同的值, 利用离散场合的卷积公式 (3.3.1), 可把事件 $\\{Z=k\\}$ 的概率表示为  \n$$\nP(Z=k)=\\sum_{i=0}^{k} P(X=i) P(Y=k-i)\n$$  \n在二项分布场合, 上式中有些事件是不可能事件:  \n- 当 $i>n$ 时, $\\{X=i\\}$ 是不可能事件, 所以只须考虑 $i \\leqslant n$;\n- 当 $k-i>m$ 时, $\\{Y=k-i\\}$ 是不可能事件, 所以只须考虑 $i \\geqslant k-m$.  \n因此记  \n$$\na=\\max \\{0, k-m\\}, \\quad b=\\min \\{n, k\\},\n$$  \n则  \n$$\n\\begin{aligned}\nP(Z=k) & =\\sum_{i=a}^{b} P(X=i) P(Y=k-i) \\\\\n& =\\sum_{i=a}^{b}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right) p^{i}(1-p)^{n-i} \\cdot\\left(\\begin{array}{c}\nm \\\\\nk-i\n\\end{array}\\right) p^{k-i}(1-p)^{m-(k-i)} \\\\",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(Z=k)=\\sum_{i=0}^{k} P(X=i) P(Y=k-i)\n$$  \n在二项分布场合, 上式中有些事件是不可能事件:  \n- 当 $i>n$ 时, $\\{X=i\\}$ 是不可能事件, 所以只须考虑 $i \\leqslant n$;\n- 当 $k-i>m$ 时, $\\{Y=k-i\\}$ 是不可能事件, 所以只须考虑 $i \\geqslant k-m$.  \n因此记  \n$$\na=\\max \\{0, k-m\\}, \\quad b=\\min \\{n, k\\},\n$$  \n则  \n$$\n\\begin{aligned}\nP(Z=k) & =\\sum_{i=a}^{b} P(X=i) P(Y=k-i) \\\\\n& =\\sum_{i=a}^{b}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right) p^{i}(1-p)^{n-i} \\cdot\\left(\\begin{array}{c}\nm \\\\\nk-i\n\\end{array}\\right) p^{k-i}(1-p)^{m-(k-i)} \\\\\n& =p^{k}(1-p)^{n+m-k} \\sum_{i=a}^{b}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right)\\left(\\begin{array}{c}\nm \\\\\nk-i\n\\end{array}\\right) .\n\\end{aligned}\n$$  \n利用超几何分布可证明上式组合乘积的和满足:  \n$$\n\\sum_{i=a}^{b} \\frac{\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right)\\left(\\begin{array}{c}\nm \\\\\nk-i\n\\end{array}\\right)}{\\left(\\begin{array}{c}\nn+m \\\\\nk\n\\end{array}\\right)}=1 \\quad \\text { 或 } \\quad \\sum_{i=a}^{b}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right)\\left(\\begin{array}{c}\nm \\\\\nk-i\n\\end{array}\\right)=\\left(\\begin{array}{c}",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "n \\\\\ni\n\\end{array}\\right)\\left(\\begin{array}{c}\nm \\\\\nk-i\n\\end{array}\\right) .\n\\end{aligned}\n$$  \n利用超几何分布可证明上式组合乘积的和满足:  \n$$\n\\sum_{i=a}^{b} \\frac{\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right)\\left(\\begin{array}{c}\nm \\\\\nk-i\n\\end{array}\\right)}{\\left(\\begin{array}{c}\nn+m \\\\\nk\n\\end{array}\\right)}=1 \\quad \\text { 或 } \\quad \\sum_{i=a}^{b}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right)\\left(\\begin{array}{c}\nm \\\\\nk-i\n\\end{array}\\right)=\\left(\\begin{array}{c}\nn+m \\\\\nk\n\\end{array}\\right)\n$$  \n代回原式, 可得  \n$$\nP(Z=k)=\\left(\\begin{array}{c}\nn+m \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n+m-k}, \\quad k=0,1, \\ldots, n+m\n$$  \n这表明 $Z=X+Y \\sim b(n+m, p)$, 即在参数 $p$ 相同情况下, 二项分布的卷积仍是二项分布 $b(n, p) * b(m, p)=$ $b(n+m, p)$. 这个性质可以推广到有限个场合, 即  \n$$\n\\begin{equation*}\nb\\left(n_{1}, p\\right) * b\\left(n_{2}, p\\right) * \\cdots * b\\left(n_{k}, p\\right)=b\\left(n_{1}+n_{2}+\\cdots+n_{k}, p\\right) \\tag{3.3.5}\n\\end{equation*}\n$$  \n特别当 $n_{1}=n_{2}=\\cdots=n_{k}=1$ 时, 有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "k\n\\end{array}\\right)\n$$  \n代回原式, 可得  \n$$\nP(Z=k)=\\left(\\begin{array}{c}\nn+m \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{n+m-k}, \\quad k=0,1, \\ldots, n+m\n$$  \n这表明 $Z=X+Y \\sim b(n+m, p)$, 即在参数 $p$ 相同情况下, 二项分布的卷积仍是二项分布 $b(n, p) * b(m, p)=$ $b(n+m, p)$. 这个性质可以推广到有限个场合, 即  \n$$\n\\begin{equation*}\nb\\left(n_{1}, p\\right) * b\\left(n_{2}, p\\right) * \\cdots * b\\left(n_{k}, p\\right)=b\\left(n_{1}+n_{2}+\\cdots+n_{k}, p\\right) \\tag{3.3.5}\n\\end{equation*}\n$$  \n特别当 $n_{1}=n_{2}=\\cdots=n_{k}=1$ 时, 有  \n$$\n\\begin{equation*}\nb(1, p) * b(1, p) * \\cdots * b(1, p)=b(n, p) . \\tag{3.3.6}\n\\end{equation*}\n$$  \n这表明: 如果 $X_{1}, X_{2}, \\ldots, X_{n}$ 独立同分布, 都服从 $b(1, p)$ 分布, 即其和 $\\sum_{i=1}^{n} X_{i} \\sim b(n, p)$. 或者说, 服从二项分布 $b(n, p)$ 的随机变量可以分解成 $n$ 个相互独立的 $0-1$ 分布的随机变量之和.",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.1 多维离散随机变量函数的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "例 3.3.4 最大值分布: 设 $X_{1}, X_{2}, \\ldots, X_{n}$ 是相互独立的 $n$ 个随机变量, 若 $Y=\\max \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ . 试在以下情况下求 $Y$ 的分布:  \n(1) $X_{i} \\sim F_{i}(x), i=1,2, \\ldots, n$;  \n(2) $X_{i}$ 同分布, 即 $X_{i} \\sim F(x), i=1,2, \\ldots, n$;  \n(3) $X_{i}$ 为连续随机变量, 且 $X_{i}$ 同分布, 即 $X_{i}$ 的密度函数为 $p(x), i=1,2, \\ldots, n$;  \n(4) $X_{i} \\sim \\operatorname{Exp}(\\lambda), i=1,2, \\ldots, n$.  \n解:  \n(1) $Y=\\max \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的分布函数为  \n$$\n\\begin{align*}\nF_{Y}(y) & =P\\left(\\max \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right) \\leqslant y\\right)=P\\left(X_{1} \\leqslant y, X_{2} \\leqslant y, \\ldots, X_{n} \\leqslant y\\right) \\\\\n& =P\\left(X_{1} \\leqslant y\\right) P\\left(X_{2} \\leqslant y\\right) \\cdots P\\left(X_{n} \\leqslant y\\right)=\\prod_{i=1}^{n} F_{i}(y) . \\tag{3.3.7}\n\\end{align*}\n$$  \n(2) 将 $X_{i}$ 的共同分布函数 $F(x)$ 代人上式得  \n$$\n\\begin{equation*}\nF_{Y}(y)=[F(y)]^{n} . \\tag{3.3.8}\n\\end{equation*}\n$$  \n(3) $Y$ 的分布函数仍为上式, 密度函数可对上式关于 $y$ 求导得  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.2 最大值与最小值的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =P\\left(X_{1} \\leqslant y\\right) P\\left(X_{2} \\leqslant y\\right) \\cdots P\\left(X_{n} \\leqslant y\\right)=\\prod_{i=1}^{n} F_{i}(y) . \\tag{3.3.7}\n\\end{align*}\n$$  \n(2) 将 $X_{i}$ 的共同分布函数 $F(x)$ 代人上式得  \n$$\n\\begin{equation*}\nF_{Y}(y)=[F(y)]^{n} . \\tag{3.3.8}\n\\end{equation*}\n$$  \n(3) $Y$ 的分布函数仍为上式, 密度函数可对上式关于 $y$ 求导得  \n$$\n\\begin{equation*}\np_{Y}(y)=F_{Y}^{\\prime}(y)=n[F(y)]^{n-1} p(y) . \\tag{3.3.9}\n\\end{equation*}\n$$  \n(4) 将 $\\operatorname{Exp}(\\lambda)$ 的分布函数和密度函数代人 ( (3.3.8)) 和 ( (3.3.9)) 式得  \n$$\n\\begin{aligned}\n& F_{Y}(y)= \\begin{cases}0, & y<0 \\\\\n{\\left[1-\\mathrm{e}^{-\\lambda y}\\right]^{n},} & y \\geqslant 0\\end{cases} \\\\\n& p_{Y}(y)= \\begin{cases}0, & y<0 \\\\\nn\\left[1-\\mathrm{e}^{-\\lambda y}\\right]^{n-1} \\lambda \\mathrm{e}^{-\\lambda y}, & y \\geqslant 0\\end{cases}\n\\end{aligned}\n$$  \n例 3.3.5 最小值分布: 设 $X_{1}, X_{2}, \\ldots, X_{n}$ 是相互独立得 $n$ 个随机变量, 若 $Y=\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ . 试在以下情况下求 $Y$ 得分布:  \n(1) $X_{i} \\sim F_{i}(x), i=1,2, \\ldots, n$;",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.2 最大值与最小值的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n& F_{Y}(y)= \\begin{cases}0, & y<0 \\\\\n{\\left[1-\\mathrm{e}^{-\\lambda y}\\right]^{n},} & y \\geqslant 0\\end{cases} \\\\\n& p_{Y}(y)= \\begin{cases}0, & y<0 \\\\\nn\\left[1-\\mathrm{e}^{-\\lambda y}\\right]^{n-1} \\lambda \\mathrm{e}^{-\\lambda y}, & y \\geqslant 0\\end{cases}\n\\end{aligned}\n$$  \n例 3.3.5 最小值分布: 设 $X_{1}, X_{2}, \\ldots, X_{n}$ 是相互独立得 $n$ 个随机变量, 若 $Y=\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ . 试在以下情况下求 $Y$ 得分布:  \n(1) $X_{i} \\sim F_{i}(x), i=1,2, \\ldots, n$;  \n(2) $X_{i}$ 同分布, 即 $X_{i} \\sim F(x), i=1,2, \\ldots, n$;  \n(3) $X_{i}$ 为连续随机变量, 且 $X_{i}$ 同分布, 即 $X_{i}$ 的密度函数为 $p(x), i=1,2, \\ldots, n$;  \n(4) $X_{i} \\sim \\operatorname{Exp}(\\lambda), i=1,2, \\ldots, n$.  \n解:  \n(1) $Y=\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的分布函数为  \n$$\n\\begin{align*}\nF_{Y}(y) & =P\\left(\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right) \\leqslant y\\right) \\\\\n& =1-P\\left(\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)>y\\right) \\\\\n& =1-P\\left(X_{1}>y, X_{2}>y, \\ldots, X_{n}>y\\right) \\\\",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.2 最大值与最小值的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "(3) $X_{i}$ 为连续随机变量, 且 $X_{i}$ 同分布, 即 $X_{i}$ 的密度函数为 $p(x), i=1,2, \\ldots, n$;  \n(4) $X_{i} \\sim \\operatorname{Exp}(\\lambda), i=1,2, \\ldots, n$.  \n解:  \n(1) $Y=\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的分布函数为  \n$$\n\\begin{align*}\nF_{Y}(y) & =P\\left(\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right) \\leqslant y\\right) \\\\\n& =1-P\\left(\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)>y\\right) \\\\\n& =1-P\\left(X_{1}>y, X_{2}>y, \\ldots, X_{n}>y\\right) \\\\\n& =1-P\\left(X_{1}>y\\right) P\\left(X_{2}>y\\right) \\cdots P\\left(X_{n}>y\\right) \\\\\n& =1-\\prod_{i=1}^{n}\\left[1-F_{i}(y)\\right] . \\tag{3.3.10}\n\\end{align*}\n$$  \n(2) 将 $X_{i}$ 的共同分布函数 $F(x)$ 代人上式得  \n$$\n\\begin{equation*}\nF_{Y}(y)=1-[1-F(y)]^{n} . \\tag{3.3.11}\n\\end{equation*}\n$$  \n(3) $Y$ 的分布函数仍为上式, 密度函数可对上式关于 $y$ 求导得  \n$$\n\\begin{equation*}\np_{Y}(y)=F_{Y}^{\\prime}(y)=n[1-F(y)]^{n-1} p(y) . \\tag{3.3.12}\n\\end{equation*}\n$$  \n(4) 将 $\\operatorname{Exp}(\\lambda)$ 的分布函数和密度函数代人 ((3.3.11)) 和 ((3.3.12)) 式得  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.2 最大值与最小值的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =1-\\prod_{i=1}^{n}\\left[1-F_{i}(y)\\right] . \\tag{3.3.10}\n\\end{align*}\n$$  \n(2) 将 $X_{i}$ 的共同分布函数 $F(x)$ 代人上式得  \n$$\n\\begin{equation*}\nF_{Y}(y)=1-[1-F(y)]^{n} . \\tag{3.3.11}\n\\end{equation*}\n$$  \n(3) $Y$ 的分布函数仍为上式, 密度函数可对上式关于 $y$ 求导得  \n$$\n\\begin{equation*}\np_{Y}(y)=F_{Y}^{\\prime}(y)=n[1-F(y)]^{n-1} p(y) . \\tag{3.3.12}\n\\end{equation*}\n$$  \n(4) 将 $\\operatorname{Exp}(\\lambda)$ 的分布函数和密度函数代人 ((3.3.11)) 和 ((3.3.12)) 式得  \n$$\n\\begin{aligned}\n& F_{Y}(y)= \\begin{cases}0, & y<0 ; \\\\\n1-\\mathrm{e}^{-n \\lambda y}, & y \\geqslant 0 .\\end{cases} \\\\\n& p_{Y}(y)= \\begin{cases}0, & y<0 ; \\\\\nn \\lambda \\mathrm{e}^{-n \\lambda y}, & y \\geqslant 0 .\\end{cases}\n\\end{aligned}\n$$  \n由上面例 3.3.4 和 3.3.5 可以看出: 若 $X_{1}, X_{2}, \\ldots, X_{n}$ 独立同分布, $X_{i}$ 服从参数为 $\\lambda$ 的指数分布, 则 $\\max \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 不服从指数分布, 而 $\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 仍服从指数分布, 参数为 $n \\lambda$.",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.2 最大值与最小值的分布"
        },
        "type": "Document"
    },
    {
        "page_content": "定理 3.3.1. 设 $X$ 与 $Y$ 是两个相互独立的连续随机变量, 其密度函数分别为 $p_{X}(x)$ 和 $p_{Y}(y)$, 则其和 $Z=X+Y$ 的密度函数为  \n$$\n\\begin{equation*}\np_{Z}(z)=\\int_{-\\infty}^{+\\infty} p_{X}(z-y) p_{Y}(y) \\mathrm{d} y \\tag{3.3.13}\n\\end{equation*}\n$$  \n证明: $Z=X+Y$ 的分布函数为  \n$$\n\\begin{aligned}\nF_{Z}(z) & =P(X+Y \\leqslant z)=\\iint_{x+y \\leqslant z} p_{X}(x) p_{Y}(y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\int_{-\\infty}^{+\\infty}\\left\\{\\int_{-\\infty}^{z-y} p_{X}(x) \\mathrm{d} x\\right\\} p_{Y}(y) \\mathrm{d} y \\\\\n& =\\int_{-\\infty}^{+\\infty} F_{X}(z-y) p_{Y}(y) \\mathrm{d} y .\n\\end{aligned}\n$$  \n其中 $F_{X}(x)$ 为 $X$ 的分布函数, 对上式两端求导, 可得 $Z$ 的密度函数为  \n$$\np_{Z}(z)=\\int_{-\\infty}^{+\\infty} p_{X}(z-y) p_{Y}(y) \\mathrm{d} y\n$$  \n这就是连续场合下的卷积公式.  \n下面对正态分布和伽玛分布分别使用上述卷积公式.  \n例 3.3.6(正态分布的可加性): 设 $X \\sim N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right), Y \\sim N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$, 且 $X$ 与 $Y$ 独立, 证明 $Z+X+Y \\sim$ $N\\left(\\mu_{1}+\\mu_{2}, \\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)$.  \n证明: 首先指出 $Z=X+Y$ 在 $(-\\infty,+\\infty)$ 上取值, 利用卷积公式 ( (3.3.13)) 可得",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n其中 $F_{X}(x)$ 为 $X$ 的分布函数, 对上式两端求导, 可得 $Z$ 的密度函数为  \n$$\np_{Z}(z)=\\int_{-\\infty}^{+\\infty} p_{X}(z-y) p_{Y}(y) \\mathrm{d} y\n$$  \n这就是连续场合下的卷积公式.  \n下面对正态分布和伽玛分布分别使用上述卷积公式.  \n例 3.3.6(正态分布的可加性): 设 $X \\sim N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right), Y \\sim N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$, 且 $X$ 与 $Y$ 独立, 证明 $Z+X+Y \\sim$ $N\\left(\\mu_{1}+\\mu_{2}, \\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)$.  \n证明: 首先指出 $Z=X+Y$ 在 $(-\\infty,+\\infty)$ 上取值, 利用卷积公式 ( (3.3.13)) 可得  \n$$\np_{Z}(z)=\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{1}{2}\\left[\\frac{\\left(z-y-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\\right\\} \\mathrm{d} y\n$$  \n对上式被积函数中的指数部分按 $y$ 的幂次展开, 再合并同类项, 不难得到  \n$$\n\\frac{\\left(z-y-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}=A\\left(y-\\frac{B}{A}\\right)^{2}+\\frac{\\left(y-\\mu_{1}-\\mu_{2}\\right)^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}},\n$$  \n其中  \n代回原式, 可得  \n$$",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n对上式被积函数中的指数部分按 $y$ 的幂次展开, 再合并同类项, 不难得到  \n$$\n\\frac{\\left(z-y-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}=A\\left(y-\\frac{B}{A}\\right)^{2}+\\frac{\\left(y-\\mu_{1}-\\mu_{2}\\right)^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}},\n$$  \n其中  \n代回原式, 可得  \n$$\nA=\\frac{1}{\\sigma_{1}^{2}}+\\frac{1}{\\sigma_{2}^{2}}, \\quad B=\\frac{z-\\mu_{1}}{\\sigma_{1}^{2}}+\\frac{\\mu_{2}}{\\sigma_{2}^{2}}\n$$  \n$$\np_{Z}(z)=\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\exp \\left\\{-\\frac{1}{2} \\frac{\\left(z-\\mu_{1}-\\mu_{2}\\right)^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}\\right\\} \\cdot \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{A}{2}\\left(y-\\frac{B}{A}\\right)^{2}\\right\\} \\mathrm{d} y\n$$  \n利用正态密度函数的正则性, 上式中的积分应为 $\\sqrt{2 \\pi} / \\sqrt{A}$, 于是  \n$$\np_{Z}(z)=\\frac{1}{\\sqrt{2 \\pi\\left(\\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)}} \\exp \\left\\{\\frac{1}{2} \\frac{\\left(z-\\mu_{1}-\\mu_{2}\\right)^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}\\right\\}\n$$  \n这正是均值为 $\\mu_{1}+\\mu_{2}$, 方差是 $\\sigma_{1}^{2}+\\sigma_{2}^{2}$ 的正态密度函数.",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n利用正态密度函数的正则性, 上式中的积分应为 $\\sqrt{2 \\pi} / \\sqrt{A}$, 于是  \n$$\np_{Z}(z)=\\frac{1}{\\sqrt{2 \\pi\\left(\\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)}} \\exp \\left\\{\\frac{1}{2} \\frac{\\left(z-\\mu_{1}-\\mu_{2}\\right)^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}\\right\\}\n$$  \n这正是均值为 $\\mu_{1}+\\mu_{2}$, 方差是 $\\sigma_{1}^{2}+\\sigma_{2}^{2}$ 的正态密度函数.  \n上述结论表明: 两个独立的正态变量之和仍为正态变量, 其分布中的两个参数分别对应相加,即  \n$$\n\\begin{equation*}\nN\\left(\\mu_{1}, \\sigma_{1}^{2}\\right) * N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)=N\\left(\\mu_{1}+\\mu_{2}, \\sigma_{1}^{2}+\\sigma_{2}^{2}\\right) \\tag{3.3.14}\n\\end{equation*}\n$$  \n显然, 这个结论可以推广到有限个独立正态变量之和的场合.  \n另外我们知道, 若 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 则对任意非零实数 $a$ 有 $a X \\sim N\\left(a \\mu, a^{2} \\sigma\\right)$. 由此我们可得另一个重要结论: 任意 $n$ 个相互独立的正态变量的线性组合仍是正态变量, 即  \n$$\n\\begin{equation*}\na_{1} X_{1}+a_{2} X_{2}+\\cdots+a_{n} X_{n} \\sim N\\left(\\mu_{0}, \\sigma_{0}^{2}\\right) \\tag{3.3.15}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n显然, 这个结论可以推广到有限个独立正态变量之和的场合.  \n另外我们知道, 若 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 则对任意非零实数 $a$ 有 $a X \\sim N\\left(a \\mu, a^{2} \\sigma\\right)$. 由此我们可得另一个重要结论: 任意 $n$ 个相互独立的正态变量的线性组合仍是正态变量, 即  \n$$\n\\begin{equation*}\na_{1} X_{1}+a_{2} X_{2}+\\cdots+a_{n} X_{n} \\sim N\\left(\\mu_{0}, \\sigma_{0}^{2}\\right) \\tag{3.3.15}\n\\end{equation*}\n$$  \n若记 $X_{i} \\sim N\\left(\\mu_{i}, \\sigma_{i}^{2}\\right), i=1,2, \\ldots, n$, 则参数 $\\mu_{0}$ 与 $\\sigma_{0}^{2}$ 分别为  \n$$\n\\mu_{0}=\\sum_{i=1}^{n} a_{i} \\mu_{i}, \\quad \\sigma_{0}^{2}=\\sum_{i=1}^{n} a_{i}^{2} \\sigma_{i}^{2}\n$$  \n譬如, 已知 $X \\sim N(-3,1), Y \\sim N(2,1)$, 且 $X$ 与 $Y$ 独立, 则  \n$$\nZ=X-2 Y+7 \\sim N(0,5) \\text {. }\n$$  \n例 3.3.7(伽玛分布的可加性): 设 $X \\sim G a\\left(\\alpha_{1}, \\lambda\\right), Y \\sim G a\\left(\\alpha_{2}, \\lambda\\right)$, 且 $X$ 与 $Y$ 独立, 证明 $Z=$ $X+Y \\sim G a\\left(\\alpha_{1}+\\alpha_{2}, \\lambda\\right)$.  \n证明：首先指出 $Z=X+Y$ 在 $(0,+\\infty)$ 上取值, 所以当 $z \\leqslant 0$ 时, $p_{Z}(z)=0$. 而当 $z>0$ 时, 可用卷积公",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\mu_{0}=\\sum_{i=1}^{n} a_{i} \\mu_{i}, \\quad \\sigma_{0}^{2}=\\sum_{i=1}^{n} a_{i}^{2} \\sigma_{i}^{2}\n$$  \n譬如, 已知 $X \\sim N(-3,1), Y \\sim N(2,1)$, 且 $X$ 与 $Y$ 独立, 则  \n$$\nZ=X-2 Y+7 \\sim N(0,5) \\text {. }\n$$  \n例 3.3.7(伽玛分布的可加性): 设 $X \\sim G a\\left(\\alpha_{1}, \\lambda\\right), Y \\sim G a\\left(\\alpha_{2}, \\lambda\\right)$, 且 $X$ 与 $Y$ 独立, 证明 $Z=$ $X+Y \\sim G a\\left(\\alpha_{1}+\\alpha_{2}, \\lambda\\right)$.  \n证明：首先指出 $Z=X+Y$ 在 $(0,+\\infty)$ 上取值, 所以当 $z \\leqslant 0$ 时, $p_{Z}(z)=0$. 而当 $z>0$ 时, 可用卷积公\n式 (3.3.13), 此时使被积函数 $p_{X}(z-y) p_{Y}(y)>0$ 的积分限为 $0<y<z$, 故  \n$$\n\\begin{aligned}\np_{Z}(z) & =\\frac{\\lambda^{\\alpha_{1}+\\alpha_{2}}}{\\Gamma\\left(\\alpha_{1}\\right) \\Gamma\\left(\\alpha_{2}\\right)} \\int_{0}^{z}(z-y)^{\\alpha_{1}-1} \\mathrm{e}^{-\\lambda(z-y)} \\cdot y^{\\alpha_{2}-1} \\mathrm{e}^{-\\lambda y} \\mathrm{~d} y \\\\",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "证明：首先指出 $Z=X+Y$ 在 $(0,+\\infty)$ 上取值, 所以当 $z \\leqslant 0$ 时, $p_{Z}(z)=0$. 而当 $z>0$ 时, 可用卷积公\n式 (3.3.13), 此时使被积函数 $p_{X}(z-y) p_{Y}(y)>0$ 的积分限为 $0<y<z$, 故  \n$$\n\\begin{aligned}\np_{Z}(z) & =\\frac{\\lambda^{\\alpha_{1}+\\alpha_{2}}}{\\Gamma\\left(\\alpha_{1}\\right) \\Gamma\\left(\\alpha_{2}\\right)} \\int_{0}^{z}(z-y)^{\\alpha_{1}-1} \\mathrm{e}^{-\\lambda(z-y)} \\cdot y^{\\alpha_{2}-1} \\mathrm{e}^{-\\lambda y} \\mathrm{~d} y \\\\\n& =\\frac{\\lambda^{\\alpha_{1}+\\alpha_{2}} \\mathrm{e}^{-\\lambda z}}{\\Gamma\\left(\\alpha_{1}\\right) \\Gamma\\left(\\alpha_{2}\\right)} \\int_{0}^{z}(z-y)^{\\alpha_{1}-1} y^{\\alpha_{2}-1} \\mathrm{~d} y \\\\\n& =\\frac{\\lambda^{\\alpha_{1}+\\alpha_{2}} \\mathrm{e}^{-\\lambda z}}{\\Gamma\\left(\\alpha_{1}\\right) \\Gamma\\left(\\alpha_{2}\\right)} z^{\\alpha_{1}+\\alpha_{2}-1} \\int_{0}^{1}(1-t)^{\\alpha_{1}-1} t^{\\alpha_{2}-1} \\mathrm{~d} t\n\\end{aligned}\n$$  \n最后的积分是贝塔函数, 它等于 $\\Gamma\\left(\\alpha_{1}\\right) \\Gamma\\left(\\alpha_{2}\\right) / \\Gamma\\left(\\alpha_{1}+\\alpha_{2}\\right)$. 代人上式得  \n$$",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{\\lambda^{\\alpha_{1}+\\alpha_{2}} \\mathrm{e}^{-\\lambda z}}{\\Gamma\\left(\\alpha_{1}\\right) \\Gamma\\left(\\alpha_{2}\\right)} z^{\\alpha_{1}+\\alpha_{2}-1} \\int_{0}^{1}(1-t)^{\\alpha_{1}-1} t^{\\alpha_{2}-1} \\mathrm{~d} t\n\\end{aligned}\n$$  \n最后的积分是贝塔函数, 它等于 $\\Gamma\\left(\\alpha_{1}\\right) \\Gamma\\left(\\alpha_{2}\\right) / \\Gamma\\left(\\alpha_{1}+\\alpha_{2}\\right)$. 代人上式得  \n$$\np_{Z}(z)=\\frac{\\lambda^{\\alpha_{1}+\\alpha_{2}}}{\\Gamma\\left(\\alpha_{1}+\\alpha_{2}\\right)} z^{\\alpha_{1}+\\alpha_{2}-1} \\mathrm{e}^{-\\lambda z}\n$$  \n这正是形状参数为 $\\alpha_{1}+\\alpha_{2}$, 尺度参数仍为 $\\lambda$ 的伽马分布.  \n这个结论表明: 两个尺度参数相同的独立的伽马变量之和仍为伽马变量, 其尺度参数不变, 而形状参数相加, 即  \n$$\n\\begin{equation*}\nG a\\left(\\alpha_{1}, \\lambda\\right) * G a\\left(\\alpha_{2}, \\lambda\\right)=G a\\left(\\alpha_{1}+\\alpha_{2}, \\lambda\\right) \\tag{3.3.16}\n\\end{equation*}\n$$  \n显然这个结论可推广到有限个尺度参数相同的独立伽马变量之和上.  \n另外由第二章中我们知道, 伽马分布有两个常用的特例: 指数分布和卡方分布, 即  \n$$\n\\operatorname{Exp}(\\lambda)=G a(1, \\lambda), \\quad \\chi^{2}(n)=G a\\left(\\frac{n}{2}, \\frac{1}{2}\\right),\n$$",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n这正是形状参数为 $\\alpha_{1}+\\alpha_{2}$, 尺度参数仍为 $\\lambda$ 的伽马分布.  \n这个结论表明: 两个尺度参数相同的独立的伽马变量之和仍为伽马变量, 其尺度参数不变, 而形状参数相加, 即  \n$$\n\\begin{equation*}\nG a\\left(\\alpha_{1}, \\lambda\\right) * G a\\left(\\alpha_{2}, \\lambda\\right)=G a\\left(\\alpha_{1}+\\alpha_{2}, \\lambda\\right) \\tag{3.3.16}\n\\end{equation*}\n$$  \n显然这个结论可推广到有限个尺度参数相同的独立伽马变量之和上.  \n另外由第二章中我们知道, 伽马分布有两个常用的特例: 指数分布和卡方分布, 即  \n$$\n\\operatorname{Exp}(\\lambda)=G a(1, \\lambda), \\quad \\chi^{2}(n)=G a\\left(\\frac{n}{2}, \\frac{1}{2}\\right),\n$$  \n由此又可以得到另两个结论:  \n(1) $m$ 个独立同分布的指数变量之和为伽马变量, 即  \n$$\n\\begin{equation*}\n\\underbrace{\\operatorname{Exp}(\\lambda) * \\operatorname{Exp}(\\lambda) * \\cdots * \\operatorname{Exp}(\\lambda)}_{m \\uparrow}=G a(m, \\lambda) \\tag{3.3.17}\n\\end{equation*}\n$$  \n(2) $m$ 个独立的 $\\chi^{2}$ 变量之和为 $\\chi^{2}$ 变量 ( $\\chi^{2}$ 分布的可加性), 即  \n$$\n\\begin{equation*}\n\\chi^{2}\\left(n_{1}\\right) * \\chi^{2}\\left(n_{2}\\right) * \\cdots * \\chi^{2}\\left(n_{m}\\right)=\\chi^{2}\\left(n_{1}+n_{2}+\\cdots+n_{m}\\right) . \\tag{3.3.18}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) $m$ 个独立同分布的指数变量之和为伽马变量, 即  \n$$\n\\begin{equation*}\n\\underbrace{\\operatorname{Exp}(\\lambda) * \\operatorname{Exp}(\\lambda) * \\cdots * \\operatorname{Exp}(\\lambda)}_{m \\uparrow}=G a(m, \\lambda) \\tag{3.3.17}\n\\end{equation*}\n$$  \n(2) $m$ 个独立的 $\\chi^{2}$ 变量之和为 $\\chi^{2}$ 变量 ( $\\chi^{2}$ 分布的可加性), 即  \n$$\n\\begin{equation*}\n\\chi^{2}\\left(n_{1}\\right) * \\chi^{2}\\left(n_{2}\\right) * \\cdots * \\chi^{2}\\left(n_{m}\\right)=\\chi^{2}\\left(n_{1}+n_{2}+\\cdots+n_{m}\\right) . \\tag{3.3.18}\n\\end{equation*}\n$$  \n例 3.3.8: 设 $X_{1}, X_{2}, \\ldots, X_{n}$ 是 $n$ 个相互独立同分布的标准正态变量, 证明其平方和 $Y=X_{1}^{2}+$ $X_{2}^{2}+\\cdots+X_{n}^{2}$ 服从自由度为 $n$ 的 $\\chi^{2}$ 分布.  \n证明: 由上一章例 ??, 我们已经证得: 当 $X_{i} \\sim N(0,1)$, 有 $X_{i}^{2} \\sim \\chi^{2}(1)$. 所以再由 $\\chi^{2}$ 分布的可加性即可得结论.  \n由此可见, $\\chi^{2}(n)$ 分布中的参数 $n$ 就体现在: $n$ 是独立的标准正态变量的个数, 因此人们称这个参数 $n$ 为自由度.",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.3 连续场合的卷积公式"
        },
        "type": "Document"
    },
    {
        "page_content": "在此我们仅介绍二维随机变量函数的分布, 而对于 $n$ 维随机变量函数的分布, 方法是类似的.",
        "metadata": {
            "Header 2": "3.3 多维随机变量函数的分布",
            "Header 3": "3.3.4 变量变换法"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $(X, Y)$ 的联合密度函数为 $p(x, y)$, 如果函数  \n有连续偏导数, 且存在唯一的反函数  \n$$\n\\left\\{\\begin{array}{l}\nu=g_{1}(x, y) \\\\\nv=g_{2}(x, y)\n\\end{array}\\right.\n$$  \n$$\n\\left\\{\\begin{array}{l}\nx=x(u, v) \\\\\ny=y(u, v)\n\\end{array}\\right.\n$$  \n其变换的雅可比行列式  \n$$\nJ=\\frac{\\partial(x, y)}{\\partial(u, v)}=\\left|\\begin{array}{ll}\n\\frac{\\partial x}{\\partial u} & \\frac{\\partial y}{\\partial u}  \\tag{3.3.19}\\\\\n\\frac{\\partial x}{\\partial v} & \\frac{\\partial y}{\\partial v}\n\\end{array}\\right|=\\left(\\frac{\\partial(u, v)}{\\partial(x, y)}\\right)^{-1}=\\left(\\left|\\begin{array}{ll}\n\\frac{\\partial u}{\\partial x} & \\frac{\\partial u}{\\partial y} \\\\\n\\frac{\\partial v}{\\partial x} & \\frac{\\partial v}{\\partial y}\n\\end{array}\\right|\\right)^{-1} \\neq 0\n$$  \n若  \n$$\n\\left\\{\\begin{array}{l}\nU=g_{1}(X, Y) \\\\\nV=g_{2}(X, Y)\n\\end{array}\\right.\n$$  \n则 $(U, V)$ 的联合密度函数为  \n$$\n\\begin{equation*}\np(u, v)=p(x(u, v), y(u, v))|J| . \\tag{3.3.20}\n\\end{equation*}\n$$  \n这个方法实际上就是二重积分的变量变换法, 其证明可参阅数学分析教科书.",
        "metadata": {
            "Header 2": "一、变量变换法"
        },
        "type": "Document"
    },
    {
        "page_content": "\\frac{\\partial u}{\\partial x} & \\frac{\\partial u}{\\partial y} \\\\\n\\frac{\\partial v}{\\partial x} & \\frac{\\partial v}{\\partial y}\n\\end{array}\\right|\\right)^{-1} \\neq 0\n$$  \n若  \n$$\n\\left\\{\\begin{array}{l}\nU=g_{1}(X, Y) \\\\\nV=g_{2}(X, Y)\n\\end{array}\\right.\n$$  \n则 $(U, V)$ 的联合密度函数为  \n$$\n\\begin{equation*}\np(u, v)=p(x(u, v), y(u, v))|J| . \\tag{3.3.20}\n\\end{equation*}\n$$  \n这个方法实际上就是二重积分的变量变换法, 其证明可参阅数学分析教科书.  \n例 3.3.9：设 $X$ 与 $Y$ 独立同分布, 都服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$. 记  \n$$\n\\left\\{\\begin{array}{l}\nU=X+Y \\\\\nV=X-Y\n\\end{array}\\right.\n$$  \n试求 $(U, V)$ 的联合密度函数, 问 $U$ 与 $V$ 是否独立?  \n解: 因为  \n$$\n\\left\\{\\begin{array}{l}\nu=x+y \\\\\nv=x-y\n\\end{array}\\right.\n$$  \n的反函数为  \n$$\n\\left\\{\\begin{array}{l}\nx=(u+v) / 2 \\\\\ny=(u-v) / 2\n\\end{array}\\right.\n$$  \n则  \n$$\nJ=\\left|\\begin{array}{ll}\n\\frac{\\partial x}{\\partial u} & \\frac{\\partial y}{\\partial u} \\\\\n\\frac{\\partial x}{\\partial v} & \\frac{\\partial y}{\\partial v}\n\\end{array}\\right|=\\left|\\begin{array}{cc}\n1 / 2 & 1 / 2 \\\\\n1 / 2 & -1 / 2",
        "metadata": {
            "Header 2": "一、变量变换法"
        },
        "type": "Document"
    },
    {
        "page_content": "\\left\\{\\begin{array}{l}\nU=X+Y \\\\\nV=X-Y\n\\end{array}\\right.\n$$  \n试求 $(U, V)$ 的联合密度函数, 问 $U$ 与 $V$ 是否独立?  \n解: 因为  \n$$\n\\left\\{\\begin{array}{l}\nu=x+y \\\\\nv=x-y\n\\end{array}\\right.\n$$  \n的反函数为  \n$$\n\\left\\{\\begin{array}{l}\nx=(u+v) / 2 \\\\\ny=(u-v) / 2\n\\end{array}\\right.\n$$  \n则  \n$$\nJ=\\left|\\begin{array}{ll}\n\\frac{\\partial x}{\\partial u} & \\frac{\\partial y}{\\partial u} \\\\\n\\frac{\\partial x}{\\partial v} & \\frac{\\partial y}{\\partial v}\n\\end{array}\\right|=\\left|\\begin{array}{cc}\n1 / 2 & 1 / 2 \\\\\n1 / 2 & -1 / 2\n\\end{array}\\right|=-\\frac{1}{2}\n$$  \n所以得 $(U, V)$ 的联合密度函数为  \n$$\n\\begin{aligned}\np(u, v) & =p(x(u, v), y(u, v))|J|=p_{X}((u+v) / 2) p_{Y}((u-v) / 2)\\left|-\\frac{1}{2}\\right| \\\\\n& =\\frac{1}{2 \\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{[(u+v) / 2-\\mu]^{2}}{2 \\sigma^{2}}\\right\\} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{[(u-v) / 2-\\mu]^{2}}{2 \\sigma^{2}}\\right\\} \\\\\n& =\\frac{1}{4 \\pi \\sigma^{2}} \\exp \\left\\{-\\frac{(u-2 \\mu)^{2}+v^{2}}{4 \\sigma^{2}}\\right\\} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "一、变量变换法"
        },
        "type": "Document"
    },
    {
        "page_content": "1 / 2 & -1 / 2\n\\end{array}\\right|=-\\frac{1}{2}\n$$  \n所以得 $(U, V)$ 的联合密度函数为  \n$$\n\\begin{aligned}\np(u, v) & =p(x(u, v), y(u, v))|J|=p_{X}((u+v) / 2) p_{Y}((u-v) / 2)\\left|-\\frac{1}{2}\\right| \\\\\n& =\\frac{1}{2 \\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{[(u+v) / 2-\\mu]^{2}}{2 \\sigma^{2}}\\right\\} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{[(u-v) / 2-\\mu]^{2}}{2 \\sigma^{2}}\\right\\} \\\\\n& =\\frac{1}{4 \\pi \\sigma^{2}} \\exp \\left\\{-\\frac{(u-2 \\mu)^{2}+v^{2}}{4 \\sigma^{2}}\\right\\} .\n\\end{aligned}\n$$  \n这正是二元正态分布 $N\\left(2 \\mu, 0,2 \\sigma^{2}, 2 \\sigma^{2}, 0\\right)$ 的密度函数, 其边际分布为 $U \\sim N\\left(2 \\mu, 2 \\sigma^{2}\\right), V \\sim$ $N\\left(0,2 \\sigma^{2}\\right)$, 所以由 $p(u, v)=p_{U}(u) p_{V}(v)$ 知 $U$ 与 $V$ 相互独立.",
        "metadata": {
            "Header 2": "一、变量变换法"
        },
        "type": "Document"
    },
    {
        "page_content": "增补变量法实质上是变换法的一种应用: 为了求出二维连续随机变量 $(X, Y)$ 的函数 $U=$ $g(X, Y)$ 的密度函数, 增补一个新的随机变量 $V=h(X, Y)$,一般令 $V=X$ 或 $V=Y$. 先用变换法求出 $(U, V)$ 的联合密度函数 $p(u, v)$, 再对 $p(u, v)$ 关于 $v$ 积分, 从而得出关于 $U$ 的边际密度函数.  \n下面我们以例子形式, 给出两个随机变量的积与商的公式.  \n例 3.3.10(积的公式): 设 $X$ 与 $Y$ 相互独立, 其密度函数分别为 $p_{X}(x)$ 和 $p_{Y}(y)$. 则 $U=X Y$ 的密度函数为  \n$$\n\\begin{equation*}\np_{U}(u)=\\int_{-\\infty}^{+\\infty} p_{X}(u / v) p_{Y}(v) \\frac{1}{|v|} \\mathrm{d} v . \\tag{3.3.21}\n\\end{equation*}\n$$  \n解: 记 $V=Y$, 则 $\\left\\{\\begin{array}{l}y=x y, \\\\ v=y\\end{array}\\right.$ 的反函数为 $\\left\\{\\begin{array}{l}x=u / v, \\\\ y=v,\\end{array}\\right.$ 雅可比行列式为  \n$$\nJ=\\left|\\begin{array}{cc}\n1 / v & -u / v^{2} \\\\\n0 & 1\n\\end{array}\\right|=\\frac{1}{v}\n$$  \n所以 $(U, V)$ 的联合密度函数为  \n$$\np(u, v)=p_{X}(u / v) \\cdot p_{Y}(v)|J|=p_{X}(u / v) p_{Y}(v) \\frac{1}{|v|}\n$$  \n对 $p(u, v)$ 关于 $v$ 积分, 就可得 $U=X Y$ 的密度函数为 (3.3.21) 式.  \n例 3.3.11(商的公式): 设 $X$ 与 $Y$ 相互独立, 其密度函数分别为 $p_{X}(x)$ 和 $p_{Y}(y)$. 则 $U=X / Y$ 的密度函数为  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "二、增补变量法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nJ=\\left|\\begin{array}{cc}\n1 / v & -u / v^{2} \\\\\n0 & 1\n\\end{array}\\right|=\\frac{1}{v}\n$$  \n所以 $(U, V)$ 的联合密度函数为  \n$$\np(u, v)=p_{X}(u / v) \\cdot p_{Y}(v)|J|=p_{X}(u / v) p_{Y}(v) \\frac{1}{|v|}\n$$  \n对 $p(u, v)$ 关于 $v$ 积分, 就可得 $U=X Y$ 的密度函数为 (3.3.21) 式.  \n例 3.3.11(商的公式): 设 $X$ 与 $Y$ 相互独立, 其密度函数分别为 $p_{X}(x)$ 和 $p_{Y}(y)$. 则 $U=X / Y$ 的密度函数为  \n$$\n\\begin{equation*}\np_{U}(u)=\\int_{-\\infty}^{+\\infty} p_{X}(u v) p_{Y}(v)|v| \\mathrm{d} v \\tag{3.3.22}\n\\end{equation*}\n$$  \n解: 记 $V=Y$, 则 $\\left\\{\\begin{array}{l}u=x / y, \\\\ v=y\\end{array}\\right.$ 的反函数为 $\\left\\{\\begin{array}{l}x=u v, \\\\ y=v,\\end{array}\\right.$ 雅可比行列式为  \n$$\nJ=\\left|\\begin{array}{ll}\nv & u \\\\\n0 & 1\n\\end{array}\\right|=v\n$$  \n所以 $(U, V)$ 的联合密度函数为  \n$$\np(u, v)=p_{X}(u v) \\cdot p_{Y}(v)|J|=p(u v, v)|v| .\n$$  \n对 $p(u, v)$ 关于 $v$ 积分, 就可得 $U=X / Y$ 的密度函数为 (3.3.22) 式.",
        "metadata": {
            "Header 2": "二、增补变量法"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设二维随机变量 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | 1 | 2 | 3 |\n| 0 | 0.05 | 0.15 | 0.20 |\n| 1 | 0.07 | 0.11 | 0.22 |\n| 2 | 0.04 | 0.07 | 0.09 |  \n试分别求 $U=\\max (X, Y)$ 和 $V=\\min (X, Y)$ 的分布列.  \n2. 设 $X$ 和 $Y$ 是相互独立的随机变量, 且 $X \\sim \\operatorname{Exp}(\\lambda), Y \\sim \\operatorname{Exp}(\\mu)$. 如果定义随机变量 $Z$ 如下  \n$$\nZ= \\begin{cases}1, & \\text { 当 } X \\leqslant Y ; \\\\ 0, & \\text { 当 } X>Y .\\end{cases}\n$$  \n求 $Z$ 的分布列.  \n3. 设随机变量 $X$ 和 $Y$ 的分布列分别为  \n| $X$ | -1 | 0 | 1 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $1 / 4$ | $1 / 2$ | $1 / 4$ |  \n| $Y$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1 / 2$ | $1 / 2$ |  \n已知 $P(X Y=0)=1$, 试求 $Z=\\max \\{X, Y\\}$ 的分布列  \n4. 设随机变量 $X, Y$ 独立同分布, 在以下情况下求随机变量 $Z=\\max \\{X, Y\\}$ 的分布列.  \n(1) $X$ 服从 $p=0.5$ 的 $(0-1)$ 分布;  \n(2) $X$ 服从几何分布, 即 $P(X=k)=(1-p)^{k-1} p, k=1,2, \\ldots$.  \n5. 设 $X$ 和 $Y$ 为两个随机变量, 且  \n$$\nP\\{X \\geqslant 0, Y \\geqslant 0\\}=\\frac{3}{7}, \\quad P\\{X \\geqslant 0\\}=P\\{Y \\geqslant 0\\}=\\frac{4}{7} .\n$$",
        "metadata": {
            "Header 2": "如 题 3.3"
        },
        "type": "Document"
    },
    {
        "page_content": "| :---: | :---: | :---: | :---: |\n| $P$ | $1 / 4$ | $1 / 2$ | $1 / 4$ |  \n| $Y$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1 / 2$ | $1 / 2$ |  \n已知 $P(X Y=0)=1$, 试求 $Z=\\max \\{X, Y\\}$ 的分布列  \n4. 设随机变量 $X, Y$ 独立同分布, 在以下情况下求随机变量 $Z=\\max \\{X, Y\\}$ 的分布列.  \n(1) $X$ 服从 $p=0.5$ 的 $(0-1)$ 分布;  \n(2) $X$ 服从几何分布, 即 $P(X=k)=(1-p)^{k-1} p, k=1,2, \\ldots$.  \n5. 设 $X$ 和 $Y$ 为两个随机变量, 且  \n$$\nP\\{X \\geqslant 0, Y \\geqslant 0\\}=\\frac{3}{7}, \\quad P\\{X \\geqslant 0\\}=P\\{Y \\geqslant 0\\}=\\frac{4}{7} .\n$$  \n试求 $P\\{\\max (X, Y) \\geqslant 0\\}$.  \n6. 设 $X$ 与 $Y$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\mathrm{e}^{-(x+y)}, & x>0, y>0 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求以下随机变量的密度函数  \n(1) $Z=(X+Y) / 2$;  \n(2) $Z=Y-X$.  \n7. 设 $X$ 与 $Y$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}3 x, & 0<x<1,0<y<x ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $Z=X-Y$ 的密度函数.  \n8. 某种商品一周的需要量是一个随机变量, 其密度函数为  \n$$\np_{1}(t)= \\begin{cases}t \\mathrm{e}^{-t}, & t>0 \\\\ 0, & t \\leqslant 0\\end{cases}\n$$  \n设各周的需要量是相互独立的, 试求  \n(1) 两周需要量的密度函数 $p_{2}(x)$;",
        "metadata": {
            "Header 2": "如 题 3.3"
        },
        "type": "Document"
    },
    {
        "page_content": "6. 设 $X$ 与 $Y$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\mathrm{e}^{-(x+y)}, & x>0, y>0 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求以下随机变量的密度函数  \n(1) $Z=(X+Y) / 2$;  \n(2) $Z=Y-X$.  \n7. 设 $X$ 与 $Y$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}3 x, & 0<x<1,0<y<x ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $Z=X-Y$ 的密度函数.  \n8. 某种商品一周的需要量是一个随机变量, 其密度函数为  \n$$\np_{1}(t)= \\begin{cases}t \\mathrm{e}^{-t}, & t>0 \\\\ 0, & t \\leqslant 0\\end{cases}\n$$  \n设各周的需要量是相互独立的, 试求  \n(1) 两周需要量的密度函数 $p_{2}(x)$;  \n(2) 三周需要量的密度函数 $p_{3}(x)$.  \n9. 设随机变量 $X$ 与 $Y$ 相互独立, 试在以下情况下求 $Z=X+Y$ 的密度函数:  \n(1) $X \\sim U(0,1), Y \\sim U(0,1)$;  \n(2) $X \\sim U(0,1), Y \\sim \\operatorname{Exp}(1)$.  \n10. 设二维随机变量 $(X, Y)$ 在矩形  \n$$\nG=\\{(x, y) \\mid 0 \\leqslant x \\leqslant 2,0 \\leqslant y \\leqslant 1\\}\n$$  \n上服从均匀分布, 试求边长分别为 $X$ 和 $Y$ 的矩形面积 $Z$ 的密度函数.  \n11. 设随机变量 $X_{1}, X_{2}, X_{3}, X_{4}$ 相互独立同分布, $P\\left\\{X_{i}=0\\right\\}=0.6, P\\left\\{X_{i}=1\\right\\}=0.4, i=1,2,3,4$,求行列式 $X=\\left|\\begin{array}{ll}X_{1} & X_{2} \\\\ X_{3} & X_{4}\\end{array}\\right|$ 的分布列.",
        "metadata": {
            "Header 2": "如 题 3.3"
        },
        "type": "Document"
    },
    {
        "page_content": "9. 设随机变量 $X$ 与 $Y$ 相互独立, 试在以下情况下求 $Z=X+Y$ 的密度函数:  \n(1) $X \\sim U(0,1), Y \\sim U(0,1)$;  \n(2) $X \\sim U(0,1), Y \\sim \\operatorname{Exp}(1)$.  \n10. 设二维随机变量 $(X, Y)$ 在矩形  \n$$\nG=\\{(x, y) \\mid 0 \\leqslant x \\leqslant 2,0 \\leqslant y \\leqslant 1\\}\n$$  \n上服从均匀分布, 试求边长分别为 $X$ 和 $Y$ 的矩形面积 $Z$ 的密度函数.  \n11. 设随机变量 $X_{1}, X_{2}, X_{3}, X_{4}$ 相互独立同分布, $P\\left\\{X_{i}=0\\right\\}=0.6, P\\left\\{X_{i}=1\\right\\}=0.4, i=1,2,3,4$,求行列式 $X=\\left|\\begin{array}{ll}X_{1} & X_{2} \\\\ X_{3} & X_{4}\\end{array}\\right|$ 的分布列.\n12. 设某一设备装有 3 个同类的电器元件, 元件工作相互独立, 且工作时间都服从参数为 $\\lambda$ 的指数分布. 当 3 个元件都正常工作时, 设备才正常工作. 试求设备正常工作时间 $T$ 的概率分布.\n13. 设 $X, Y$ 独立同分布, 且都服从标准正态分布 $N(0,1)$, 试求 $Z=\\sqrt{X^{2}+Y^{2}}$ 的分布.\n14. 设 $X, Y$ 独立同分布, 且都服从标准正态分布 $N(0,1)$, 试证明: $Z=X / Y$ 服从柯西分布.\n15. 设随机变量 $X$ 与 $Y$ 相互独立, 都服从 $(\\theta-1 / 2, \\theta+1 / 2)$ 上的均匀分布, 试证 $X-Y$ 的分布与 $\\theta$ 无关.\n16. 设随机变量 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立, 且 $X_{i} \\sim \\operatorname{Exp}(\\lambda)$, 试证:  \n$$",
        "metadata": {
            "Header 2": "如 题 3.3"
        },
        "type": "Document"
    },
    {
        "page_content": "12. 设某一设备装有 3 个同类的电器元件, 元件工作相互独立, 且工作时间都服从参数为 $\\lambda$ 的指数分布. 当 3 个元件都正常工作时, 设备才正常工作. 试求设备正常工作时间 $T$ 的概率分布.\n13. 设 $X, Y$ 独立同分布, 且都服从标准正态分布 $N(0,1)$, 试求 $Z=\\sqrt{X^{2}+Y^{2}}$ 的分布.\n14. 设 $X, Y$ 独立同分布, 且都服从标准正态分布 $N(0,1)$, 试证明: $Z=X / Y$ 服从柯西分布.\n15. 设随机变量 $X$ 与 $Y$ 相互独立, 都服从 $(\\theta-1 / 2, \\theta+1 / 2)$ 上的均匀分布, 试证 $X-Y$ 的分布与 $\\theta$ 无关.\n16. 设随机变量 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立, 且 $X_{i} \\sim \\operatorname{Exp}(\\lambda)$, 试证:  \n$$\nP\\left\\{X_{i}=\\min \\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)\\right\\}=\\frac{\\lambda_{i}}{\\lambda_{1}+\\lambda_{2}+\\cdots+\\lambda_{n}}\n$$  \n17. 设连续随机变量 $X_{1}, X_{2}, \\ldots, X_{n}$ 独立同分布, 试证:\n18. 设随机变量 $X$ 与 $Y$ 独立同分布, 其密度函数为  \n$$\nP\\left\\{X_{n}>\\max \\left(X_{1}, X_{2}, \\ldots, X_{n-1}\\right)\\right\\}=\\frac{1}{n} .\n$$  \n$$\np(x)= \\begin{cases}\\mathrm{e}^{-x}, & x>0 \\\\ 0, & x \\leqslant 0\\end{cases}\n$$  \n(1) 求 $U=X+Y$ 与 $V=X /(X+Y)$ 的联合密度函数 $p_{U, V}(u, v)$;  \n(2) 以上的 $U$ 与 $V$ 独立吗?",
        "metadata": {
            "Header 2": "如 题 3.3"
        },
        "type": "Document"
    },
    {
        "page_content": "类似于一维随机变量的特征数, 多维随机变量也有特征数, 除了各个分量的期望、方差、标准差以外, 还有两个随机变量间的关联程度, 即协方差与相关系数, 这是一种反映两个随机变量相依关系的特征数, 要特别注意.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数"
        },
        "type": "Document"
    },
    {
        "page_content": "在第二章中, 在求一维随机变量函数 $Y=g(X)$ 的数学期望中, 定理 ?? 发挥了重要的作用. 现在要求多维随机变量函数 $Z=g\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的数学期望 $E(Z)$, 下面的定理 3.4.1 也起着很重要的作用. 利用此定理, 可以省略求随机变量函数 $Z=g\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的分布. 此定理的证明涉及更多的工具, 在此省略了. 为简单起见, 我们用二维随机变量叙述此定理, 而对 $n$ 维随机变量结论是类似的.  \n定理 3.4.1. 若二维随机变量 $(X, Y)$ 的分布用联合分布列 $P\\left(X=x_{i}, Y=y_{j}\\right)$ 或用联合密度函数 $p(x, y)$ 表示, 则 $Z=g(X, Y)$ 的数学期望为  \n$$\nE(Z)= \\begin{cases}\\sum_{i} \\sum_{j} g\\left(x_{i}, y_{j}\\right) P\\left(X=x_{i}, Y=y_{j}\\right), & \\text { 在离散场合, }  \\tag{3.4.1}\\\\ \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} g(x, y) p(x, y) \\mathrm{d} x \\mathrm{~d} y, & \\text { 在连续场合. }\\end{cases}\n$$  \n这里所涉及的数学期望都假设存在.  \n还要指出, 在连续场合 (离散场合也类似) 有:  \n- 当 $g(X, Y)=X$ 时, 可得 $X$ 的数学期望为  \n$$\nE(X)=\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} x p(x, y) \\mathrm{d} x \\mathrm{~d} y=\\int_{-\\infty}^{+\\infty} x p_{X}(x) \\mathrm{d} x .\n$$  \n- 当 $g(X, Y)=(X-E(X))^{2}$ 时, 可得 $X$ 的方差为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.1 多维随机变量函数的数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n这里所涉及的数学期望都假设存在.  \n还要指出, 在连续场合 (离散场合也类似) 有:  \n- 当 $g(X, Y)=X$ 时, 可得 $X$ 的数学期望为  \n$$\nE(X)=\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} x p(x, y) \\mathrm{d} x \\mathrm{~d} y=\\int_{-\\infty}^{+\\infty} x p_{X}(x) \\mathrm{d} x .\n$$  \n- 当 $g(X, Y)=(X-E(X))^{2}$ 时, 可得 $X$ 的方差为  \n$$\n\\begin{aligned}\n\\operatorname{Var}(X) & =E(X-E(X))^{2}=\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty}(x-E(X))^{2} p(x, y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\int_{-\\infty}^{+\\infty}(x-E(X))^{2} p_{X}(x) \\mathrm{d} x\n\\end{aligned}\n$$  \n类似地可给出 $Y$ 的数学期望与方差的公式.  \n例 3.4.1: 在长为 $a$ 的线段上任取两个点 $X$ 与 $Y$, 求此两点间的平均长度.  \n解: 因为 $X$ 与 $Y$ 都服从 $(0, a)$ 上的均匀分布, 且 $X$ 与 $Y$ 相互独立, 所以 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{a^{2}}, & 0<x<a, 0<y<a ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n利用定理 3.4.1, 得两点间的平均长度为  \n$$\n\\begin{aligned}\nE(|X-Y|) & =\\int_{0}^{a} \\int_{0}^{a}|x-y| \\frac{1}{a^{2}} \\mathrm{~d} x \\mathrm{~d} y \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.1 多维随机变量函数的数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\int_{-\\infty}^{+\\infty}(x-E(X))^{2} p_{X}(x) \\mathrm{d} x\n\\end{aligned}\n$$  \n类似地可给出 $Y$ 的数学期望与方差的公式.  \n例 3.4.1: 在长为 $a$ 的线段上任取两个点 $X$ 与 $Y$, 求此两点间的平均长度.  \n解: 因为 $X$ 与 $Y$ 都服从 $(0, a)$ 上的均匀分布, 且 $X$ 与 $Y$ 相互独立, 所以 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{a^{2}}, & 0<x<a, 0<y<a ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n利用定理 3.4.1, 得两点间的平均长度为  \n$$\n\\begin{aligned}\nE(|X-Y|) & =\\int_{0}^{a} \\int_{0}^{a}|x-y| \\frac{1}{a^{2}} \\mathrm{~d} x \\mathrm{~d} y \\\\\n& =\\frac{1}{a^{2}}\\left\\{\\int_{0}^{a} \\int_{0}^{x}(x-y) \\mathrm{d} y \\mathrm{~d} x+\\int_{0}^{a} \\int_{x}^{a}(y-x) \\mathrm{d} y \\mathrm{~d} x\\right\\} \\\\\n& =\\frac{1}{a^{2}}\\left\\{\\int_{0}^{a}\\left(x^{2}-a x+\\frac{a^{2}}{2}\\right) \\mathrm{d} x\\right\\}=\\frac{a}{3} .\n\\end{aligned}\n$$  \n注意, 利用定理 3.4.1, 虽然可以省略求随机变量函数的分布, 但在某些场合所涉及的求和或求积难以计算, 此时只能分两步进行: 先求随机变量函数 $Z=g\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的分布, 然后再由 $Z$ 的分布去求 $E(Z)$, 见下例.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.1 多维随机变量函数的数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{1}{a^{2}}\\left\\{\\int_{0}^{a} \\int_{0}^{x}(x-y) \\mathrm{d} y \\mathrm{~d} x+\\int_{0}^{a} \\int_{x}^{a}(y-x) \\mathrm{d} y \\mathrm{~d} x\\right\\} \\\\\n& =\\frac{1}{a^{2}}\\left\\{\\int_{0}^{a}\\left(x^{2}-a x+\\frac{a^{2}}{2}\\right) \\mathrm{d} x\\right\\}=\\frac{a}{3} .\n\\end{aligned}\n$$  \n注意, 利用定理 3.4.1, 虽然可以省略求随机变量函数的分布, 但在某些场合所涉及的求和或求积难以计算, 此时只能分两步进行: 先求随机变量函数 $Z=g\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)$ 的分布, 然后再由 $Z$ 的分布去求 $E(Z)$, 见下例.  \n例 3.4.2: 设 $X_{1}$ 和 $X_{2}$ 是独立同分布的随机变量, 其共同分布为指数分布 $\\operatorname{Exp}(\\lambda)$. 试求 $Y=$ $\\max \\left(X_{1}, X_{2}\\right)$ 的数学期望.\n解: 在前面例 3.3.4 中已求得 $Y=\\max \\left(X_{1}, X_{2}\\right)$ 的密度函数为  \n$$\np_{Y}(y)=2\\left[1-\\mathrm{e}^{-\\lambda y}\\right] \\lambda \\mathrm{e}^{-\\lambda y}, y>0 .\n$$  \n这时 $Y=\\max \\left(X_{1}, X_{2}\\right)$ 的数学期望为  \n$$\n\\begin{aligned}\nE\\left[\\max \\left(X_{1}, X_{2}\\right)\\right] & =\\int_{0}^{+\\infty} 2 \\lambda y\\left[1-\\mathrm{e}^{-\\lambda y}\\right] \\mathrm{e}^{-\\lambda y} \\mathrm{~d} y \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.1 多维随机变量函数的数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 在前面例 3.3.4 中已求得 $Y=\\max \\left(X_{1}, X_{2}\\right)$ 的密度函数为  \n$$\np_{Y}(y)=2\\left[1-\\mathrm{e}^{-\\lambda y}\\right] \\lambda \\mathrm{e}^{-\\lambda y}, y>0 .\n$$  \n这时 $Y=\\max \\left(X_{1}, X_{2}\\right)$ 的数学期望为  \n$$\n\\begin{aligned}\nE\\left[\\max \\left(X_{1}, X_{2}\\right)\\right] & =\\int_{0}^{+\\infty} 2 \\lambda y\\left[1-\\mathrm{e}^{-\\lambda y}\\right] \\mathrm{e}^{-\\lambda y} \\mathrm{~d} y \\\\\n& =2 \\int_{0}^{+\\infty} y \\mathrm{e}^{-\\lambda y} \\mathrm{~d}(\\lambda y)-\\int_{0}^{+\\infty} y \\mathrm{e}^{-2 \\lambda y} \\mathrm{~d}(2 \\lambda y) \\\\\n& =\\frac{2}{\\lambda} \\int_{0}^{+\\infty} u \\mathrm{e}^{-u} \\mathrm{~d} u-\\frac{1}{2 \\lambda} \\int_{0}^{+\\infty} v \\mathrm{e}^{-v} \\mathrm{~d} v \\\\\n& =\\frac{2}{\\lambda} \\Gamma(2)-\\frac{1}{2 \\lambda} \\Gamma(2)=\\frac{3}{2 \\lambda} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.1 多维随机变量函数的数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "在第二章中曾给出了数学期望与方差的一些简单性质, 在此利用以上定理 3.4.1, 我们就可以给出数学期望和方差的一些运算性质, 以下均假定有关的期望和方差存在.  \n性质 3.4.1: 设 $(X, Y)$ 是二维随机变量, 则有  \n$$\n\\begin{equation*}\nE(X+Y)=E(X)+E(Y) \\tag{3.4.2}\n\\end{equation*}\n$$  \n证明: 不妨设 ( $X, Y)$ 为连续随机变量 (对离散随机变量可类似证明), 其联合密度函数为 $p(x, y)$, 若令 $g(X, Y)=X+Y$, 则由定理 3.4.1 可得  \n$$\n\\begin{aligned}\nE(X+Y) & =\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty}(x+y) p(x, y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\int_{-\\infty}^{+\\infty} x\\left\\{\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y\\right\\} \\mathrm{d} x+\\int_{-\\infty}^{+\\infty} y\\left\\{\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x\\right\\} \\mathrm{d} y \\\\\n& =\\int_{-\\infty}^{+\\infty} x p_{X}(x) \\mathrm{d} x+\\int_{-\\infty}^{+\\infty} y p_{Y}(y) \\mathrm{d} y \\\\\n& =E(X)+E(Y) .\n\\end{aligned}\n$$  \n这个性质可简单叙述为 “和的期望等于期望的和”. 这个性质还可推广到 $n$ 维随机变量场合,即  \n$$\n\\begin{equation*}\nE\\left(X_{1}+X_{2}+\\cdots+X_{n}\\right)=E\\left(X_{1}\\right)+E\\left(X_{2}\\right)+\\cdots+E\\left(X_{n}\\right) . \\tag{3.4.3}\n\\end{equation*}\n$$  \n性质 3.4.2: 若随机变量 $X$ 与 $Y$ 相互独立, 则有",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\int_{-\\infty}^{+\\infty} x p_{X}(x) \\mathrm{d} x+\\int_{-\\infty}^{+\\infty} y p_{Y}(y) \\mathrm{d} y \\\\\n& =E(X)+E(Y) .\n\\end{aligned}\n$$  \n这个性质可简单叙述为 “和的期望等于期望的和”. 这个性质还可推广到 $n$ 维随机变量场合,即  \n$$\n\\begin{equation*}\nE\\left(X_{1}+X_{2}+\\cdots+X_{n}\\right)=E\\left(X_{1}\\right)+E\\left(X_{2}\\right)+\\cdots+E\\left(X_{n}\\right) . \\tag{3.4.3}\n\\end{equation*}\n$$  \n性质 3.4.2: 若随机变量 $X$ 与 $Y$ 相互独立, 则有  \n$$\n\\begin{equation*}\nE(X Y)=E(X) E(Y) \\tag{3.4.4}\n\\end{equation*}\n$$  \n证明: 不妨设 $(X, Y)$ 为连续随机变量 (对离散随机变量可类似证明), 其联合密度函数为 $p(x, y)$, 由 $X$ 与 $Y$独立可知 $p(x, y)=p_{X}(x) p_{Y}(y)$. 若令 $g(X, Y)=X Y$, 则由定理 3.4.1可得  \n$$\n\\begin{aligned}\nE(X Y) & =\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} x y p_{X}(x) p_{Y}(y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\int_{-\\infty}^{+\\infty} x p_{X}(x) \\mathrm{d} x \\int_{-\\infty}^{+\\infty} y p_{Y}(y) \\mathrm{d} y \\\\\n& =E(X) E(Y)\n\\end{aligned}\n$$  \n这个性质可推广到 $n$ 维随机变量场合, 即若 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立, 则有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n证明: 不妨设 $(X, Y)$ 为连续随机变量 (对离散随机变量可类似证明), 其联合密度函数为 $p(x, y)$, 由 $X$ 与 $Y$独立可知 $p(x, y)=p_{X}(x) p_{Y}(y)$. 若令 $g(X, Y)=X Y$, 则由定理 3.4.1可得  \n$$\n\\begin{aligned}\nE(X Y) & =\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} x y p_{X}(x) p_{Y}(y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\int_{-\\infty}^{+\\infty} x p_{X}(x) \\mathrm{d} x \\int_{-\\infty}^{+\\infty} y p_{Y}(y) \\mathrm{d} y \\\\\n& =E(X) E(Y)\n\\end{aligned}\n$$  \n这个性质可推广到 $n$ 维随机变量场合, 即若 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立, 则有  \n$$\n\\begin{equation*}\nE\\left(X_{1} X_{2} \\cdots X_{n}\\right)=E\\left(X_{1}\\right) E\\left(X_{2}\\right) \\cdots E\\left(X_{n}\\right) \\tag{3.4.5}\n\\end{equation*}\n$$  \n性质 3.4.3: 若随机变量 $X$ 与 $Y$ 相互独立, 则有  \n$$\n\\operatorname{Var}(X \\pm Y)=\\operatorname{Var}(X) \\pm \\operatorname{Var}(Y)\n$$  \n证明: 由性质 3.4.2和 3.4.2可得  \n$$\n\\begin{aligned}\n\\operatorname{Var}(X+Y) & =E(X+Y-E(X+Y))^{2} \\\\\n& =E((X-E(X))+(Y-E(Y)))^{2} \\\\\n& =\\operatorname{Var}(X)+\\operatorname{Var}(Y)+2 E(X-E(X))(Y-E(Y))\n\\end{aligned}\n$$  \n最后一项为零, 故证得性质 3.4.2.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "E\\left(X_{1} X_{2} \\cdots X_{n}\\right)=E\\left(X_{1}\\right) E\\left(X_{2}\\right) \\cdots E\\left(X_{n}\\right) \\tag{3.4.5}\n\\end{equation*}\n$$  \n性质 3.4.3: 若随机变量 $X$ 与 $Y$ 相互独立, 则有  \n$$\n\\operatorname{Var}(X \\pm Y)=\\operatorname{Var}(X) \\pm \\operatorname{Var}(Y)\n$$  \n证明: 由性质 3.4.2和 3.4.2可得  \n$$\n\\begin{aligned}\n\\operatorname{Var}(X+Y) & =E(X+Y-E(X+Y))^{2} \\\\\n& =E((X-E(X))+(Y-E(Y)))^{2} \\\\\n& =\\operatorname{Var}(X)+\\operatorname{Var}(Y)+2 E(X-E(X))(Y-E(Y))\n\\end{aligned}\n$$  \n最后一项为零, 故证得性质 3.4.2.  \n这个性质可推广到 $n$ 维随机变量场合, 即若 $X_{1}, X_{2}, \\cdots, X_{n}$ 相互独立, 则有  \n$$\n\\begin{equation*}\n\\operatorname{Var}\\left(X_{1} \\pm X_{2} \\pm \\cdots \\pm X_{n}\\right)=\\operatorname{Var}\\left(X_{1}\\right)+\\operatorname{Var}\\left(X_{2}\\right)+\\cdots+\\operatorname{Var}\\left(X_{n}\\right) \\tag{3.4.6}\n\\end{equation*}\n$$  \n这表明: 对独立随机变量来说, 它们之间无论是相加或相减, 其方差总是逐个累积起来, 不可能有所减少.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "& =E((X-E(X))+(Y-E(Y)))^{2} \\\\\n& =\\operatorname{Var}(X)+\\operatorname{Var}(Y)+2 E(X-E(X))(Y-E(Y))\n\\end{aligned}\n$$  \n最后一项为零, 故证得性质 3.4.2.  \n这个性质可推广到 $n$ 维随机变量场合, 即若 $X_{1}, X_{2}, \\cdots, X_{n}$ 相互独立, 则有  \n$$\n\\begin{equation*}\n\\operatorname{Var}\\left(X_{1} \\pm X_{2} \\pm \\cdots \\pm X_{n}\\right)=\\operatorname{Var}\\left(X_{1}\\right)+\\operatorname{Var}\\left(X_{2}\\right)+\\cdots+\\operatorname{Var}\\left(X_{n}\\right) \\tag{3.4.6}\n\\end{equation*}\n$$  \n这表明: 对独立随机变量来说, 它们之间无论是相加或相减, 其方差总是逐个累积起来, 不可能有所减少.  \n例 3.4.3: 已知随机变量 $X_{1}, X_{2}, X_{3}$ 相互独立, 且 $X_{1} \\sim U(0,6), X_{2} \\sim N(1,3), X_{3} \\sim \\operatorname{Exp}(3)$. 求 $Y=X_{1}-2 X_{2}+3 X_{3}$ 的数学期望、方差和标准差.  \n解: 由数学期望和方差的运算性质得  \n$$\n\\begin{aligned}\n& E\\left(X_{1}-2 X_{2}+3 X_{3}\\right)=3-2 \\times 1+3 \\times \\frac{1}{3}=2 . \\\\\n& \\operatorname{Var}\\left(X_{1}-2 X_{2}+3 X_{3}\\right)=\\frac{6^{2}}{12}+4 \\times 3+9 \\times \\frac{1}{9}=16 . \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n这表明: 对独立随机变量来说, 它们之间无论是相加或相减, 其方差总是逐个累积起来, 不可能有所减少.  \n例 3.4.3: 已知随机变量 $X_{1}, X_{2}, X_{3}$ 相互独立, 且 $X_{1} \\sim U(0,6), X_{2} \\sim N(1,3), X_{3} \\sim \\operatorname{Exp}(3)$. 求 $Y=X_{1}-2 X_{2}+3 X_{3}$ 的数学期望、方差和标准差.  \n解: 由数学期望和方差的运算性质得  \n$$\n\\begin{aligned}\n& E\\left(X_{1}-2 X_{2}+3 X_{3}\\right)=3-2 \\times 1+3 \\times \\frac{1}{3}=2 . \\\\\n& \\operatorname{Var}\\left(X_{1}-2 X_{2}+3 X_{3}\\right)=\\frac{6^{2}}{12}+4 \\times 3+9 \\times \\frac{1}{9}=16 . \\\\\n& \\sigma\\left(X_{1}-2 X_{2}+3 X_{3}\\right)=\\sqrt{\\operatorname{Var}\\left(X_{1}-2 X_{2}+3 X_{3}\\right)}=\\sqrt{16}=4 .\n\\end{aligned}\n$$  \n将一个随机变量写成几个随机变量的和, 然后再利用数学期望的性质去进行计算, 可以使复杂的计算变得简单,下例说明了这一点.  \n例 3.4.4: 设一袋中装有 $m$ 只颜色各不相同的球, 每次从中任取一只, 有放回地摸取 $n$ 次, 以 $X$ 表示在 $n$ 次摸球中摸到球的不同颜色的数目, 求 $E(X)$.  \n解: 直接写出 $X$ 的分布列较为困难, 其原因在于: 若第 $i$ 种颜色的球被取到过, 则此种颜色的球又可被取到过一次、二次 $\\cdots n$ 次, 情况较多, 而其对立事件 “第 $i$ 种颜色的球没被取到过” 的概率容易写出为  \n$$\nP(\\text { 第 } i \\text { 种颜色的球在 } n \\text { 次摸球中一次也没被摸到 })=\\left(1-\\frac{1}{m}\\right)^{n} \\text {. }\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n将一个随机变量写成几个随机变量的和, 然后再利用数学期望的性质去进行计算, 可以使复杂的计算变得简单,下例说明了这一点.  \n例 3.4.4: 设一袋中装有 $m$ 只颜色各不相同的球, 每次从中任取一只, 有放回地摸取 $n$ 次, 以 $X$ 表示在 $n$ 次摸球中摸到球的不同颜色的数目, 求 $E(X)$.  \n解: 直接写出 $X$ 的分布列较为困难, 其原因在于: 若第 $i$ 种颜色的球被取到过, 则此种颜色的球又可被取到过一次、二次 $\\cdots n$ 次, 情况较多, 而其对立事件 “第 $i$ 种颜色的球没被取到过” 的概率容易写出为  \n$$\nP(\\text { 第 } i \\text { 种颜色的球在 } n \\text { 次摸球中一次也没被摸到 })=\\left(1-\\frac{1}{m}\\right)^{n} \\text {. }\n$$  \n为此令  \n$$\nX_{i}=\\left\\{\\begin{array}{l}\n1, \\text { 第 } i \\text { 种颜色的球在 } n \\text { 次摸球中至少被摸到一次; } \\quad i=1,2, \\ldots, m . \\\\\n0, \\text { 第 } i \\text { 种颜色的球在 } n \\text { 次摸球中一次也没被摸到. }\n\\end{array}\\right.\n$$  \n这些 $X_{i}$ 相当于是计数器, 分别记录下第 $i$ 种颜色的球是否被取到过, 而 $X$ 是取到过的不同颜色总数, 所以 $X=\\sum_{i=1}^{m} X_{i}$. 由  \n$$\nP\\left(X_{i}=0\\right)=\\left(1-\\frac{1}{m}\\right)^{n}\n$$  \n可得  \n$$\nE\\left(X_{i}\\right)=P\\left(X_{i}=1\\right)=1-P\\left(X_{i}=0\\right)=1-\\left(1-\\frac{1}{m}\\right)^{n}\n$$  \n所以  \n$$\nE(X)=m E\\left(X_{i}\\right)=m\\left[1-\\left(1-\\frac{1}{m}\\right)^{n}\\right]\n$$  \n譬如, 在 $m=n=6$ 时,  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "0, \\text { 第 } i \\text { 种颜色的球在 } n \\text { 次摸球中一次也没被摸到. }\n\\end{array}\\right.\n$$  \n这些 $X_{i}$ 相当于是计数器, 分别记录下第 $i$ 种颜色的球是否被取到过, 而 $X$ 是取到过的不同颜色总数, 所以 $X=\\sum_{i=1}^{m} X_{i}$. 由  \n$$\nP\\left(X_{i}=0\\right)=\\left(1-\\frac{1}{m}\\right)^{n}\n$$  \n可得  \n$$\nE\\left(X_{i}\\right)=P\\left(X_{i}=1\\right)=1-P\\left(X_{i}=0\\right)=1-\\left(1-\\frac{1}{m}\\right)^{n}\n$$  \n所以  \n$$\nE(X)=m E\\left(X_{i}\\right)=m\\left[1-\\left(1-\\frac{1}{m}\\right)^{n}\\right]\n$$  \n譬如, 在 $m=n=6$ 时,  \n$$\nE(X)=6\\left(1-\\left(\\frac{5}{6}\\right)^{6}\\right)=3.99 \\approx 4\n$$  \n这表明袋中有 6 只不同颜色的球, 从中有放回地摸取 6 次, 平均只能摸到 4 种颜色的球.  \n例 3.4.5: 设 $X \\sim b(n, p)$, 试求 $X$ 的数学期望和方差.\n解: 二项分布的数学期望和方差在第二章中已经求得, 但其计算过程较为复杂. 在此用另一种简便的方法求之. 令 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立, $X_{i}$ 都服从二点分布 $b(1, p)$, 则  \n$$\nE\\left(X_{i}\\right)=p, \\quad \\operatorname{Var}\\left(X_{i}\\right)=p(1-p)\n$$  \n且 $X=X_{1}+X_{2}+\\cdots+X_{n} \\sim b(n, p)$, 由此得  \n$$\n\\begin{gathered}\nE(X)=E\\left(\\sum_{i=1}^{n} X_{i}\\right)=\\sum_{i=1}^{n} E\\left(X_{i}\\right)=n p \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n这表明袋中有 6 只不同颜色的球, 从中有放回地摸取 6 次, 平均只能摸到 4 种颜色的球.  \n例 3.4.5: 设 $X \\sim b(n, p)$, 试求 $X$ 的数学期望和方差.\n解: 二项分布的数学期望和方差在第二章中已经求得, 但其计算过程较为复杂. 在此用另一种简便的方法求之. 令 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立, $X_{i}$ 都服从二点分布 $b(1, p)$, 则  \n$$\nE\\left(X_{i}\\right)=p, \\quad \\operatorname{Var}\\left(X_{i}\\right)=p(1-p)\n$$  \n且 $X=X_{1}+X_{2}+\\cdots+X_{n} \\sim b(n, p)$, 由此得  \n$$\n\\begin{gathered}\nE(X)=E\\left(\\sum_{i=1}^{n} X_{i}\\right)=\\sum_{i=1}^{n} E\\left(X_{i}\\right)=n p \\\\\n\\operatorname{Var}(X)=\\operatorname{Var}\\left(\\sum_{i=1}^{n} X_{i}\\right)=\\sum_{i=1}^{n} \\operatorname{Var}\\left(X_{i}\\right)=\\sum_{i=1}^{n} p(1-p)=n p(1-p)\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.2 数学期望与方差的运算性质"
        },
        "type": "Document"
    },
    {
        "page_content": "二维联合分布中除含有各分量的边际分布外, 还含有两个分最间相互关联的信息. 描述这种相互关联程度的一个特征数就是协方差, 它的定义如下:  \n定义 3.4.1. 设 $(X, Y)$ 是一个二维随机变量, 若 $E[(X-E(X))(Y-E(Y))]$ 存在, 则称此数学期望为 $X$ 与 $Y$ 的协方差, 或称为 $X$ 与 $Y$ 的相关 (中心) 矩, 并记为  \n$$\n\\begin{equation*}\n\\operatorname{Cov}(X, Y)=E[(X-E(X))(Y-E(Y))] . \\tag{3.4.7}\n\\end{equation*}\n$$  \n特别有 $\\operatorname{Cov}(X, X)=\\operatorname{Var}(X)$.  \n从协方差的定义可以看出, 它是 $X$ 的偏差 “ $X-E(X)$ ” 与 $Y$ 的偏差 “ $Y-E(Y)$ ”乘积的数学期望. 由于偏差可正可负, 故协方差也可正可负, 也可为零, 其具体表现如下:  \n- 当 $\\operatorname{Cov}(X, Y)>0$ 时, 称 $X$ 与 $Y$ 正相关, 这时两个偏差 $(X-E(X))$ 与 $(Y-E(Y))$ 同时增加或同时减少. 由于 $E(X)$ 与 $E(Y)$ 都是常数, 故等价于 $X$ 与 $Y$ 同时增加或同时减少, 这就是正相关的含义.\n- 当 $\\operatorname{Cov}(X, Y)<0$ 时, 称 $X$ 与 $Y$ 负相关, 这时 $X$ 增加而 $Y$ 减少, 或 $Y$ 增加而 $X$ 减少, 这就是负相关的含义.\n- 当 $\\operatorname{Cov}(X, Y)=0$ 时, 称 $X$ 与 $Y$ 不相关.  \n协方差的计算要用到联合分布, 常用如下的等价形式来完成.  \n性质 3.4.4: $\\operatorname{Cov}(X, Y)=E(X Y)-E(X) E(Y)$  \n证明: 由协方差的定义和数学期望的性质可知  \n$$\n\\begin{aligned}\n\\operatorname{Cov}(X, Y) & =E\\{X Y-X E(Y)-Y E(X)+E(X) E(Y)\\} \\\\\n& =E(X Y)-E(X) E(Y)\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "- 当 $\\operatorname{Cov}(X, Y)<0$ 时, 称 $X$ 与 $Y$ 负相关, 这时 $X$ 增加而 $Y$ 减少, 或 $Y$ 增加而 $X$ 减少, 这就是负相关的含义.\n- 当 $\\operatorname{Cov}(X, Y)=0$ 时, 称 $X$ 与 $Y$ 不相关.  \n协方差的计算要用到联合分布, 常用如下的等价形式来完成.  \n性质 3.4.4: $\\operatorname{Cov}(X, Y)=E(X Y)-E(X) E(Y)$  \n证明: 由协方差的定义和数学期望的性质可知  \n$$\n\\begin{aligned}\n\\operatorname{Cov}(X, Y) & =E\\{X Y-X E(Y)-Y E(X)+E(X) E(Y)\\} \\\\\n& =E(X Y)-E(X) E(Y)\n\\end{aligned}\n$$  \n下面的性质表明: “不相关”是比“独立”更弱的一个新概念.  \n性质 3.4.5: 若 $X$ 与 $Y$ 相互独立, 则 $\\operatorname{Cov}(X, Y)=0$, 反之不然.  \n证明: 这是因为在独立场合有 $E(X Y)=E(X) E(Y)$, 再由以上性质 3.4.3 即可得协方差为零. “反之不然”可见下面的反例.  \n例 3.4.6: 设随机变量 $X \\sim N\\left(0, \\sigma^{2}\\right)$, 且令 $Y=X^{2}$, 则 $X$ 与 $Y$ 不独立. 此时 $X$ 与 $Y$ 的协方差为  \n$$\n\\operatorname{Cov}(X, Y)=\\operatorname{Cov}\\left(X, X^{2}\\right)=E\\left(X \\cdot X^{2}\\right)-E(X) E\\left(X^{2}\\right)=0\n$$  \n最后的等式是因为正态分布 $N\\left(0, \\sigma^{2}\\right)$ 的奇数阶原点矩均为零, 即 $E(X)=E\\left(X^{3}\\right)=0$.  \n这个例子表明, “独立”必导致“不相关”, 而“不相关”不一定导致 “独立” (见图 3.4.1). 独立要求严, 不相关要求宽. 因为独立性是用分布定义的, 而不相关只是用矩定义的. 二者之间的差别一定要认识到.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "例 3.4.6: 设随机变量 $X \\sim N\\left(0, \\sigma^{2}\\right)$, 且令 $Y=X^{2}$, 则 $X$ 与 $Y$ 不独立. 此时 $X$ 与 $Y$ 的协方差为  \n$$\n\\operatorname{Cov}(X, Y)=\\operatorname{Cov}\\left(X, X^{2}\\right)=E\\left(X \\cdot X^{2}\\right)-E(X) E\\left(X^{2}\\right)=0\n$$  \n最后的等式是因为正态分布 $N\\left(0, \\sigma^{2}\\right)$ 的奇数阶原点矩均为零, 即 $E(X)=E\\left(X^{3}\\right)=0$.  \n这个例子表明, “独立”必导致“不相关”, 而“不相关”不一定导致 “独立” (见图 3.4.1). 独立要求严, 不相关要求宽. 因为独立性是用分布定义的, 而不相关只是用矩定义的. 二者之间的差别一定要认识到.  \n另外可以看出, 前而有关数学期望的性质 3.4.2: 若 $X$ 与 $Y$ 相互独立, 则 $E(X Y)=E(X) E(Y)$, 现可以将条件“独立”降弱为“不相关”。  \n协方差概念的引人可以完善随机变量和的方差计算, 请看下面性质.  \n!  \n图 3.4.1: 不相关与独立的逻辑关系  \n性质 3.4.6: 对任意二维随机变量 $(X, Y)$, 有  \n$$\n\\begin{equation*}\n\\operatorname{Var}(X \\pm Y)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)+2 \\operatorname{Cov}(X, Y) \\tag{3.4.8}\n\\end{equation*}\n$$  \n证明: 由方差的定义知  \n$$\n\\begin{aligned}\n\\operatorname{Var}(X \\pm Y) & =E\\{(X \\pm Y)-E(X \\pm Y)\\}^{2} \\\\\n& =E\\{(X-E(X)) \\pm(Y-E(Y))\\}^{2} \\\\\n& =E\\left\\{(X-E(X))^{2}+(Y-E(Y))^{2} \\pm 2(X-E(X))(Y-E(Y))\\right\\} \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "协方差概念的引人可以完善随机变量和的方差计算, 请看下面性质.  \n!  \n图 3.4.1: 不相关与独立的逻辑关系  \n性质 3.4.6: 对任意二维随机变量 $(X, Y)$, 有  \n$$\n\\begin{equation*}\n\\operatorname{Var}(X \\pm Y)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)+2 \\operatorname{Cov}(X, Y) \\tag{3.4.8}\n\\end{equation*}\n$$  \n证明: 由方差的定义知  \n$$\n\\begin{aligned}\n\\operatorname{Var}(X \\pm Y) & =E\\{(X \\pm Y)-E(X \\pm Y)\\}^{2} \\\\\n& =E\\{(X-E(X)) \\pm(Y-E(Y))\\}^{2} \\\\\n& =E\\left\\{(X-E(X))^{2}+(Y-E(Y))^{2} \\pm 2(X-E(X))(Y-E(Y))\\right\\} \\\\\n& =\\operatorname{Var}(X)+\\operatorname{Var}(Y) \\pm 2 \\operatorname{Cov}(X, Y)\n\\end{aligned}\n$$  \n这个性质表明: 在 $X$ 与 $Y$ 相关的场合, 和的方差不等于方差的和. 或换句话说, 在 $X$ 与 $Y$ 不相关的场合, 和的方差等于方差的和. 这又可将前面有关方差的性质 3.4.2：  \n$$\n\\text { 若 } X \\text { 与 } Y \\text { 相互独立, 则 } \\operatorname{Var}(X \\pm Y)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)\n$$  \n中的条件“独立”降弱为“不相关”.  \n以上性质 3.4.3 还可以推广到更多个随机变量场合, 即对任意 $n$ 个随机变量 $X_{1}, X_{2}, \\ldots, X_{n}$,有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\operatorname{Var}(X)+\\operatorname{Var}(Y) \\pm 2 \\operatorname{Cov}(X, Y)\n\\end{aligned}\n$$  \n这个性质表明: 在 $X$ 与 $Y$ 相关的场合, 和的方差不等于方差的和. 或换句话说, 在 $X$ 与 $Y$ 不相关的场合, 和的方差等于方差的和. 这又可将前面有关方差的性质 3.4.2：  \n$$\n\\text { 若 } X \\text { 与 } Y \\text { 相互独立, 则 } \\operatorname{Var}(X \\pm Y)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)\n$$  \n中的条件“独立”降弱为“不相关”.  \n以上性质 3.4.3 还可以推广到更多个随机变量场合, 即对任意 $n$ 个随机变量 $X_{1}, X_{2}, \\ldots, X_{n}$,有  \n$$\n\\begin{equation*}\n\\operatorname{Var}\\left(\\sum_{i=1}^{n} X_{i}\\right)=\\sum_{i=1}^{n} \\operatorname{Var}\\left(X_{i}\\right)+2 \\sum_{i=1}^{n} \\sum_{j=1}^{i-1} \\operatorname{Cov}\\left(X_{i}, X_{j}\\right) \\tag{3.4.9}\n\\end{equation*}\n$$  \n关于协方差的计算, 还有下面四条有用的性质.  \n性质 3.4.7: 协方差 $\\operatorname{Cov}(X, Y)$ 的计算与 $X, Y$ 的次序无关, 即  \n$$\n\\operatorname{Cov}(X, Y)=\\operatorname{Cov}(Y, X)\n$$  \n证明: 这由协方差的定义就可看出.  \n性质 3.4.8: 任意随机变量 $X$ 与常数 $a$ 的协方差为零, 即  \n$$\n\\operatorname{Cov}(X, a)=0 \\text {. }\n$$  \n证明: 这只要用协方差的定义计算一下即可得知.  \n性质 3.4.9：对任意常数 $a, b$, 有  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n关于协方差的计算, 还有下面四条有用的性质.  \n性质 3.4.7: 协方差 $\\operatorname{Cov}(X, Y)$ 的计算与 $X, Y$ 的次序无关, 即  \n$$\n\\operatorname{Cov}(X, Y)=\\operatorname{Cov}(Y, X)\n$$  \n证明: 这由协方差的定义就可看出.  \n性质 3.4.8: 任意随机变量 $X$ 与常数 $a$ 的协方差为零, 即  \n$$\n\\operatorname{Cov}(X, a)=0 \\text {. }\n$$  \n证明: 这只要用协方差的定义计算一下即可得知.  \n性质 3.4.9：对任意常数 $a, b$, 有  \n$$\n\\operatorname{Cov}(a X, b Y)=a b \\operatorname{Cov}(X, Y) .\n$$  \n证明: 由协方差的定义知  \n$$\n\\operatorname{Cov}(a X, b Y)=E\\{(a X-E(a X))(b Y-E(b Y))\\}\n$$  \n把公因子 $a$ 与 $b$ 提出, 即得 $a b \\operatorname{Cov}(X, Y)$.  \n性质 3.4.10: 设 $X, Y, Z$ 是任意三个随机变量, 则  \n$$\n\\operatorname{Cov}(X+Y, Z)=\\operatorname{Cov}(X, Z)+\\operatorname{Cov}(Y, Z)\n$$  \n证明: 由协方差的性质 3.4.3 得  \n$$\n\\begin{aligned}\n\\operatorname{Cov}(X+Y, Z) & =E[(X+Y) Z]-E(X+Y) E(Z) \\\\\n& =E(X Z)+E(Y Z)-E(X) E(Z)-E(Y) E(Z) \\\\\n& =[E(X Z)-E(X) E(Z)]+[E(Y Z)-E(Y) E(Z)] \\\\\n& =\\operatorname{Cov}(X, Z)+\\operatorname{Cov}(Y, Z)\n\\end{aligned}\n$$  \n例 3.4.7: 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n把公因子 $a$ 与 $b$ 提出, 即得 $a b \\operatorname{Cov}(X, Y)$.  \n性质 3.4.10: 设 $X, Y, Z$ 是任意三个随机变量, 则  \n$$\n\\operatorname{Cov}(X+Y, Z)=\\operatorname{Cov}(X, Z)+\\operatorname{Cov}(Y, Z)\n$$  \n证明: 由协方差的性质 3.4.3 得  \n$$\n\\begin{aligned}\n\\operatorname{Cov}(X+Y, Z) & =E[(X+Y) Z]-E(X+Y) E(Z) \\\\\n& =E(X Z)+E(Y Z)-E(X) E(Z)-E(Y) E(Z) \\\\\n& =[E(X Z)-E(X) E(Z)]+[E(Y Z)-E(Y) E(Z)] \\\\\n& =\\operatorname{Cov}(X, Z)+\\operatorname{Cov}(Y, Z)\n\\end{aligned}\n$$  \n例 3.4.7: 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}3 x, & 0<y<x<1, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $\\operatorname{Cov}(X, Y)$.  \n证明: 利用协方差的计算公式, 我们需要先计算 $E(X), E(Y), E(X Y)$ 的值, 它们可直接用 $p(x, y)$ 导出, 但要注意积分限的确定, 具体如下.  \n$$\n\\begin{aligned}\n& E(X)=\\int_{0}^{1} \\int_{0}^{x} x \\cdot 3 x \\mathrm{~d} y \\mathrm{~d} x=\\int_{0}^{1} 3 x^{3} \\mathrm{~d} x=\\frac{3}{4} \\\\\n& E(Y)=\\int_{0}^{1} \\int_{0}^{x} y \\cdot 3 x \\mathrm{~d} y \\mathrm{~d} x=\\int_{0}^{1} \\frac{3 x^{3}}{2} \\mathrm{~d} x=\\frac{3}{8} \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np(x, y)= \\begin{cases}3 x, & 0<y<x<1, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $\\operatorname{Cov}(X, Y)$.  \n证明: 利用协方差的计算公式, 我们需要先计算 $E(X), E(Y), E(X Y)$ 的值, 它们可直接用 $p(x, y)$ 导出, 但要注意积分限的确定, 具体如下.  \n$$\n\\begin{aligned}\n& E(X)=\\int_{0}^{1} \\int_{0}^{x} x \\cdot 3 x \\mathrm{~d} y \\mathrm{~d} x=\\int_{0}^{1} 3 x^{3} \\mathrm{~d} x=\\frac{3}{4} \\\\\n& E(Y)=\\int_{0}^{1} \\int_{0}^{x} y \\cdot 3 x \\mathrm{~d} y \\mathrm{~d} x=\\int_{0}^{1} \\frac{3 x^{3}}{2} \\mathrm{~d} x=\\frac{3}{8} \\\\\n& E(X Y)=\\int_{0}^{1} \\int_{0}^{x} x y \\cdot 3 x \\mathrm{~d} y \\mathrm{~d} x=\\int_{0}^{1} \\frac{3 x^{4}}{2} \\mathrm{~d} x=\\frac{3}{10} .\n\\end{aligned}\n$$  \n因此我们得  \n$$\n\\operatorname{Cov}(X, Y)=\\frac{3}{10}-\\frac{3}{4} \\times \\frac{3}{8}=\\frac{3}{160}>0\n$$  \n由此我们还可以得结论: $X$ 与 $Y$ 不相互独立.  \n例 3.4.8: 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{3}(x+y), & 0<x<1,0<y<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $\\operatorname{Var}(2 X-3 Y+8)$.  \n解: 因为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "& E(X Y)=\\int_{0}^{1} \\int_{0}^{x} x y \\cdot 3 x \\mathrm{~d} y \\mathrm{~d} x=\\int_{0}^{1} \\frac{3 x^{4}}{2} \\mathrm{~d} x=\\frac{3}{10} .\n\\end{aligned}\n$$  \n因此我们得  \n$$\n\\operatorname{Cov}(X, Y)=\\frac{3}{10}-\\frac{3}{4} \\times \\frac{3}{8}=\\frac{3}{160}>0\n$$  \n由此我们还可以得结论: $X$ 与 $Y$ 不相互独立.  \n例 3.4.8: 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{3}(x+y), & 0<x<1,0<y<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $\\operatorname{Var}(2 X-3 Y+8)$.  \n解: 因为  \n$$\n\\begin{aligned}\n\\operatorname{Var}(2 X-3 Y+8) & =\\operatorname{Var}(2 X)+\\operatorname{Var}(3 Y)-2 \\operatorname{Cov}(2 X, 3 Y) \\\\\n& =4 \\operatorname{Var}(X)+9 \\operatorname{Var}(Y)-12 \\operatorname{Cov}(X, Y) .\n\\end{aligned}\n$$  \n所以我们先分别计算 $E(X), E(Y), E\\left(X^{2}\\right), E\\left(Y^{2}\\right), E(X Y)$. 为此先计算两个边际密度函数.  \n$$\n\\begin{aligned}\n& p_{X}(x)=\\int_{0}^{2} \\frac{1}{3}(x+y) \\mathrm{d} y=\\frac{2}{3}(x+1), 0<x<1 \\\\\n& p_{Y}(y)=\\int_{0}^{1} \\frac{1}{3}(x+y) \\mathrm{d} x=\\frac{1}{3}\\left(\\frac{1}{2}+y\\right), 0<y<2",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "& =4 \\operatorname{Var}(X)+9 \\operatorname{Var}(Y)-12 \\operatorname{Cov}(X, Y) .\n\\end{aligned}\n$$  \n所以我们先分别计算 $E(X), E(Y), E\\left(X^{2}\\right), E\\left(Y^{2}\\right), E(X Y)$. 为此先计算两个边际密度函数.  \n$$\n\\begin{aligned}\n& p_{X}(x)=\\int_{0}^{2} \\frac{1}{3}(x+y) \\mathrm{d} y=\\frac{2}{3}(x+1), 0<x<1 \\\\\n& p_{Y}(y)=\\int_{0}^{1} \\frac{1}{3}(x+y) \\mathrm{d} x=\\frac{1}{3}\\left(\\frac{1}{2}+y\\right), 0<y<2\n\\end{aligned}\n$$  \n然后再计算一、二阶矩,  \n$$\n\\begin{aligned}\n& E(X)=\\int_{0}^{1} \\frac{2}{3} x(x+1) \\mathrm{d} x=\\frac{5}{9} . \\\\\n& E\\left(X^{2}\\right)=\\int_{0}^{1} \\frac{2}{3} x^{2}(x+1) \\mathrm{d} x=\\frac{7}{8} . \\\\\n& E(Y)=\\int_{0}^{2} \\frac{1}{3} y\\left(\\frac{1}{2}+y\\right) \\mathrm{d} y=\\frac{11}{9} . \\\\\n& E\\left(Y^{2}\\right)=\\int_{0}^{2} \\frac{1}{3} y^{2}\\left(\\frac{1}{2}+y\\right) \\mathrm{d} y=\\frac{16}{9} .\n\\end{aligned}\n$$  \n由此可得  \n$$\n\\operatorname{Var}(X)=\\frac{7}{8}-\\left(\\frac{5}{9}\\right)^{2}=\\frac{13}{162}, \\quad \\operatorname{Var}(Y)=\\frac{16}{9}-\\left(\\frac{11}{9}\\right)^{2}=\\frac{23}{81} .\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "& E\\left(X^{2}\\right)=\\int_{0}^{1} \\frac{2}{3} x^{2}(x+1) \\mathrm{d} x=\\frac{7}{8} . \\\\\n& E(Y)=\\int_{0}^{2} \\frac{1}{3} y\\left(\\frac{1}{2}+y\\right) \\mathrm{d} y=\\frac{11}{9} . \\\\\n& E\\left(Y^{2}\\right)=\\int_{0}^{2} \\frac{1}{3} y^{2}\\left(\\frac{1}{2}+y\\right) \\mathrm{d} y=\\frac{16}{9} .\n\\end{aligned}\n$$  \n由此可得  \n$$\n\\operatorname{Var}(X)=\\frac{7}{8}-\\left(\\frac{5}{9}\\right)^{2}=\\frac{13}{162}, \\quad \\operatorname{Var}(Y)=\\frac{16}{9}-\\left(\\frac{11}{9}\\right)^{2}=\\frac{23}{81} .\n$$  \n最后还需要计算 $E(X Y)$, 它只能从联合密度函数导出.  \n$$\nE(X Y)=\\frac{1}{3} \\int_{0}^{1} \\int_{0}^{2} x y(x+y) \\mathrm{d} y \\mathrm{~d} x=\\frac{1}{3} \\int_{0}^{1}\\left(2 x^{2}+\\frac{8}{3} x\\right) \\mathrm{d} x=\\frac{2}{3} .\n$$  \n于是得协方差为  \n$$\n\\operatorname{Cov}(X, Y)=\\frac{2}{3}-\\frac{5}{9} \\times \\frac{11}{9}=-\\frac{1}{81}\n$$  \n代回原式得  \n$$\n\\operatorname{Var}(2 X-3 Y+8)=4 \\times \\frac{13}{162}+9 \\times \\frac{23}{81}-12 \\times\\left(-\\frac{1}{81}\\right)=\\frac{245}{81}\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.3 协方差"
        },
        "type": "Document"
    },
    {
        "page_content": "协方差 $\\operatorname{Cov}(X, Y)$ 是有量纲的量, 譬如 $X$ 表示人的身高, 单位是米 $(\\mathrm{m}), Y$ 表示人的体重, 单位是公斤 $(\\mathrm{kg})$, 则 $\\operatorname{Cov}(X, Y)$ 带有量纲 $(\\mathrm{m} \\cdot \\mathrm{kg})$. 为了消除量纲的影响, 现对协方差除以相同量纲的量, 就得到一个新的概念一一相关系数, 它的定义如下.  \n定义 3.4.2. 设 $(X, Y)$ 是一个二维随机变量, 且 $\\operatorname{Var}(X)>0, \\operatorname{Var}(Y)>0$. 则称  \n$$\n\\begin{equation*}\n\\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sqrt{\\operatorname{Var}(X)} \\sqrt{\\operatorname{Var}(Y)}}=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{X} \\sigma_{Y}} \\tag{3.4.10}\n\\end{equation*}\n$$  \n为 $X$ 与 $Y$ 的 (线性) 相关系数.  \n从以上定义中可看出: 相关系数 $\\operatorname{Corr}(X, Y)$ 与协方差 $\\operatorname{Cov}(X, Y)$ 是同符号的, 即同为正, 或同为负, 或同为零. 这说明, 从相关系数的取值也可反映出 $X$ 与 $Y$ 的正相关、负相关和不相关.  \n相关系数的另一个解释是: 它是相应标准化变量的协方差. 若记 $X$ 与 $Y$ 的数学期望分别为 $\\mu_{X}, \\mu_{Y}$, 其标准化变量为  \n$$\nX^{*}=\\frac{X-\\mu_{X}}{\\sigma_{X}}, \\quad Y^{*}=\\frac{Y-\\mu_{Y}}{\\sigma_{Y}}\n$$  \n则有  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n为 $X$ 与 $Y$ 的 (线性) 相关系数.  \n从以上定义中可看出: 相关系数 $\\operatorname{Corr}(X, Y)$ 与协方差 $\\operatorname{Cov}(X, Y)$ 是同符号的, 即同为正, 或同为负, 或同为零. 这说明, 从相关系数的取值也可反映出 $X$ 与 $Y$ 的正相关、负相关和不相关.  \n相关系数的另一个解释是: 它是相应标准化变量的协方差. 若记 $X$ 与 $Y$ 的数学期望分别为 $\\mu_{X}, \\mu_{Y}$, 其标准化变量为  \n$$\nX^{*}=\\frac{X-\\mu_{X}}{\\sigma_{X}}, \\quad Y^{*}=\\frac{Y-\\mu_{Y}}{\\sigma_{Y}}\n$$  \n则有  \n$$\n\\operatorname{Cov}\\left(X^{*}, Y^{*}\\right)=\\operatorname{Cov}\\left(\\frac{X-\\mu_{X}}{\\sigma_{X}}, \\frac{Y-\\mu_{Y}}{\\sigma_{Y}}\\right)=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{X} \\sigma_{Y}}=\\operatorname{Corr}(X, Y)\n$$  \n例 3.4.9: 二维正态分布 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$ 的相关系数就是 $\\rho$.  \n解: 下面先求 $\\operatorname{Cov}(X, Y)$.  \n$$\n\\begin{aligned}\n\\operatorname{Cov}(X, Y)= & E[(X-E(X))(Y-E(Y))] \\\\\n= & \\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}} \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty}\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right) . \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n例 3.4.9: 二维正态分布 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$ 的相关系数就是 $\\rho$.  \n解: 下面先求 $\\operatorname{Cov}(X, Y)$.  \n$$\n\\begin{aligned}\n\\operatorname{Cov}(X, Y)= & E[(X-E(X))(Y-E(Y))] \\\\\n= & \\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}} \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty}\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right) . \\\\\n& \\exp \\left\\{-\\frac{1}{2\\left(1-\\rho^{2}\\right)}\\left[\\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\\right\\} \\mathrm{d} x \\mathrm{~d} y .\n\\end{aligned}\n$$  \n先将上式中方括号化成  \n$$\n\\left(\\frac{\\left(x-\\mu_{1}\\right)}{\\sigma_{1}}-\\rho \\frac{y-\\mu_{2}}{\\sigma_{2}}\\right)^{2}+\\left(\\sqrt{1-\\rho^{2}} \\frac{y-\\mu_{2}}{\\sigma_{2}}\\right)^{2},\n$$  \n再作变量变换  \n$$\n\\left\\{\\begin{array}{l}\nu=\\frac{1}{\\sqrt{1-\\rho^{2}}}\\left(\\frac{x-\\mu_{1}}{\\sigma_{1}}-\\rho \\frac{y-\\mu_{2}}{\\sigma_{2}}\\right) \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n先将上式中方括号化成  \n$$\n\\left(\\frac{\\left(x-\\mu_{1}\\right)}{\\sigma_{1}}-\\rho \\frac{y-\\mu_{2}}{\\sigma_{2}}\\right)^{2}+\\left(\\sqrt{1-\\rho^{2}} \\frac{y-\\mu_{2}}{\\sigma_{2}}\\right)^{2},\n$$  \n再作变量变换  \n$$\n\\left\\{\\begin{array}{l}\nu=\\frac{1}{\\sqrt{1-\\rho^{2}}}\\left(\\frac{x-\\mu_{1}}{\\sigma_{1}}-\\rho \\frac{y-\\mu_{2}}{\\sigma_{2}}\\right) \\\\\nv=\\frac{y-\\mu_{2}}{\\sigma_{2}}\n\\end{array}\\right.\n$$  \n则  \n$$\n\\begin{aligned}\n& \\left\\{\\begin{array}{l}\nx-\\mu_{1}=\\sigma_{1}\\left[u \\sqrt{1-\\rho^{2}}+\\rho v\\right], \\\\\ny-\\mu_{2}=\\sigma_{2} v\n\\end{array}\\right. \\\\\n& \\mathrm{d} x \\mathrm{~d} y=\\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}} \\mathrm{~d} u \\mathrm{~d} v .\n\\end{aligned}\n$$  \n由此得  \n$$\n\\operatorname{Cov}(X, Y)=\\frac{\\sigma_{1} \\sigma_{2}}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty}\\left[u v \\sqrt{1-\\rho^{2}}+\\rho v^{2}\\right] \\exp \\left\\{-\\frac{1}{2}\\left(u^{2}+v^{2}\\right)\\right\\} \\mathrm{d} u \\mathrm{~d} v\n$$  \n上式右端积分可以分为两个积分, 其中  \n从而  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "y-\\mu_{2}=\\sigma_{2} v\n\\end{array}\\right. \\\\\n& \\mathrm{d} x \\mathrm{~d} y=\\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}} \\mathrm{~d} u \\mathrm{~d} v .\n\\end{aligned}\n$$  \n由此得  \n$$\n\\operatorname{Cov}(X, Y)=\\frac{\\sigma_{1} \\sigma_{2}}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty}\\left[u v \\sqrt{1-\\rho^{2}}+\\rho v^{2}\\right] \\exp \\left\\{-\\frac{1}{2}\\left(u^{2}+v^{2}\\right)\\right\\} \\mathrm{d} u \\mathrm{~d} v\n$$  \n上式右端积分可以分为两个积分, 其中  \n从而  \n$$\n\\begin{aligned}\n& \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} u v \\exp \\left\\{-\\frac{1}{2}\\left(u^{2}+v^{2}\\right)\\right\\} \\mathrm{d} u \\mathrm{~d} v=0 \\\\\n& \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} v^{2} \\exp \\left\\{-\\frac{1}{2}\\left(u^{2}+v^{2}\\right)\\right\\} \\mathrm{d} u \\mathrm{~d} v=2 \\pi\n\\end{aligned}\n$$  \n$$\n\\begin{gathered}\n\\operatorname{Cov}(X, Y)=\\frac{\\sigma_{1} \\sigma_{2}}{2 \\pi} \\cdot \\rho \\cdot 2 \\pi=\\rho \\sigma_{1} \\sigma_{2} \\\\\n\\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{1} \\sigma_{2}}=\\rho .",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "& \\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} v^{2} \\exp \\left\\{-\\frac{1}{2}\\left(u^{2}+v^{2}\\right)\\right\\} \\mathrm{d} u \\mathrm{~d} v=2 \\pi\n\\end{aligned}\n$$  \n$$\n\\begin{gathered}\n\\operatorname{Cov}(X, Y)=\\frac{\\sigma_{1} \\sigma_{2}}{2 \\pi} \\cdot \\rho \\cdot 2 \\pi=\\rho \\sigma_{1} \\sigma_{2} \\\\\n\\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{1} \\sigma_{2}}=\\rho .\n\\end{gathered}\n$$  \n为了研究相关系数的性质, 需要如下引理.  \n引理 3.4.1 (施瓦茨不等式)。对任意二维随机变量 $(X, Y)$, 若 $X$ 与 $Y$ 的方差都存在, 且记 $\\sigma_{X}^{2}=$ $\\operatorname{Var}(X), \\sigma_{Y}^{2}=\\operatorname{Var}(Y)$, 则有  \n$$\n\\begin{equation*}\n[\\operatorname{Cov}(X, Y)]^{2} \\leqslant \\sigma_{X}^{2} \\sigma_{Y}^{2} \\tag{3.4.11}\n\\end{equation*}\n$$  \n证明: 不妨设 $\\sigma_{X}^{2}>0$, 因为当 $\\sigma_{X}^{2}=0$ 时, 则 $X$ 几乎处处为常数, 因而其与 $Y$ 的协方差亦为零, 从而 (3.4.11) 式两端皆为零, 结论成立. 在 $\\sigma_{X}^{2}>0$ 成立下, 考虑 $t$ 的如下二次函数:  \n$$\ng(t)=E[t(X-E(X))+(Y-E(Y))]^{2}=t^{2} \\sigma_{X}^{2}+2 t \\cdot \\operatorname{Cov}(X, Y)+\\sigma_{Y}^{2}\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n[\\operatorname{Cov}(X, Y)]^{2} \\leqslant \\sigma_{X}^{2} \\sigma_{Y}^{2} \\tag{3.4.11}\n\\end{equation*}\n$$  \n证明: 不妨设 $\\sigma_{X}^{2}>0$, 因为当 $\\sigma_{X}^{2}=0$ 时, 则 $X$ 几乎处处为常数, 因而其与 $Y$ 的协方差亦为零, 从而 (3.4.11) 式两端皆为零, 结论成立. 在 $\\sigma_{X}^{2}>0$ 成立下, 考虑 $t$ 的如下二次函数:  \n$$\ng(t)=E[t(X-E(X))+(Y-E(Y))]^{2}=t^{2} \\sigma_{X}^{2}+2 t \\cdot \\operatorname{Cov}(X, Y)+\\sigma_{Y}^{2}\n$$  \n由于上述的二次三项式非负, 平方项系数 $\\sigma_{X}^{2}$ 为正, 所以其判别式小于或等于零, 即  \n$$\n[2 \\operatorname{Cov}(X, Y)]^{2}-4 \\sigma_{X}^{2} \\sigma_{Y}^{2} \\leqslant 0\n$$  \n移项后即得施瓦茨不等式.  \n利用施瓦茨不等式立即可得相关系数的一个重要性质.  \n性质 3.4.11: $-1 \\leqslant \\operatorname{Corr}(X, Y) \\leqslant 1$.  \n这个性质表明: 相关系数介于 -1 与 1 之间. 对相关系数为 $\\pm 1$ 时, 有另一重要性质.  \n性质 3.4.12: $\\operatorname{Corr}(X, Y)= \\pm 1$ 的充要条件是 $X$ 与 $Y$ 间几乎处处有线性关系, 即存在 $a(\\neq 0)$ 与 $b$,使得  \n$$\nP(Y=a X+b)=1\n$$  \n其中当 $\\operatorname{Corr}(X, Y)=1$ 时, 有 $a>0$; 当 $\\operatorname{Corr}(X, Y)=-1$ 时, 有 $a<0$.  \n证明: 充分性. 若 $Y=a X+b(X=c Y+d$ 也一样 $)$, 则将  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n移项后即得施瓦茨不等式.  \n利用施瓦茨不等式立即可得相关系数的一个重要性质.  \n性质 3.4.11: $-1 \\leqslant \\operatorname{Corr}(X, Y) \\leqslant 1$.  \n这个性质表明: 相关系数介于 -1 与 1 之间. 对相关系数为 $\\pm 1$ 时, 有另一重要性质.  \n性质 3.4.12: $\\operatorname{Corr}(X, Y)= \\pm 1$ 的充要条件是 $X$ 与 $Y$ 间几乎处处有线性关系, 即存在 $a(\\neq 0)$ 与 $b$,使得  \n$$\nP(Y=a X+b)=1\n$$  \n其中当 $\\operatorname{Corr}(X, Y)=1$ 时, 有 $a>0$; 当 $\\operatorname{Corr}(X, Y)=-1$ 时, 有 $a<0$.  \n证明: 充分性. 若 $Y=a X+b(X=c Y+d$ 也一样 $)$, 则将  \n$$\n\\operatorname{Var}(Y)=a^{2} \\operatorname{Var}(X), \\operatorname{Cov}(X, Y)=a \\operatorname{Cov}(X, X)=a \\operatorname{Var}(X)\n$$  \n代人相关系数的定义中得  \n$$\n\\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{X} \\sigma_{Y}}=\\frac{a \\operatorname{Var}(X)}{|a| \\operatorname{Var}(X)}= \\begin{cases}1, & a>0 \\\\ -1, & a<0\\end{cases}\n$$  \n必要性. 因为  \n$$\n\\begin{equation*}\n\\operatorname{Var}\\left(\\frac{X}{\\sigma_{X}} \\pm \\frac{Y}{\\sigma_{Y}}\\right)=2[1 \\pm \\operatorname{Corr}(X, Y)] \\tag{3.4.12}\n\\end{equation*}\n$$  \n所以当 $\\operatorname{Corr}(X, Y)=1$ 时, 有  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n代人相关系数的定义中得  \n$$\n\\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{X} \\sigma_{Y}}=\\frac{a \\operatorname{Var}(X)}{|a| \\operatorname{Var}(X)}= \\begin{cases}1, & a>0 \\\\ -1, & a<0\\end{cases}\n$$  \n必要性. 因为  \n$$\n\\begin{equation*}\n\\operatorname{Var}\\left(\\frac{X}{\\sigma_{X}} \\pm \\frac{Y}{\\sigma_{Y}}\\right)=2[1 \\pm \\operatorname{Corr}(X, Y)] \\tag{3.4.12}\n\\end{equation*}\n$$  \n所以当 $\\operatorname{Corr}(X, Y)=1$ 时, 有  \n$$\n\\operatorname{Var}\\left(\\frac{X}{\\sigma_{X}}-\\frac{Y}{\\sigma_{Y}}\\right)=0\n$$  \n由此得  \n$$\nP\\left(\\frac{X}{\\sigma_{X}}-\\frac{Y}{\\sigma_{Y}}=c\\right)=1,\n$$  \n或  \n$$\nP\\left(Y=\\frac{\\sigma_{Y}}{\\sigma_{X}} X-c \\sigma_{Y}\\right)=1 .\n$$  \n这就证明了: 当 $\\operatorname{Corr}(X, Y)=1$ 时, $Y$ 与 $X$ 几乎处处线性正相关.  \n当 $\\operatorname{Corr}(X, Y)=-1$ 时, 由 (3.4.12) 得  \n$$\n\\operatorname{Var}\\left(\\frac{X}{\\sigma_{X}}+\\frac{Y}{\\sigma_{Y}}\\right)=0\n$$  \n由此得  \n$$\nP\\left(\\frac{X}{\\sigma_{X}}+\\frac{Y}{\\sigma_{Y}}=c\\right)=1\n$$  \n或  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由此得  \n$$\nP\\left(\\frac{X}{\\sigma_{X}}-\\frac{Y}{\\sigma_{Y}}=c\\right)=1,\n$$  \n或  \n$$\nP\\left(Y=\\frac{\\sigma_{Y}}{\\sigma_{X}} X-c \\sigma_{Y}\\right)=1 .\n$$  \n这就证明了: 当 $\\operatorname{Corr}(X, Y)=1$ 时, $Y$ 与 $X$ 几乎处处线性正相关.  \n当 $\\operatorname{Corr}(X, Y)=-1$ 时, 由 (3.4.12) 得  \n$$\n\\operatorname{Var}\\left(\\frac{X}{\\sigma_{X}}+\\frac{Y}{\\sigma_{Y}}\\right)=0\n$$  \n由此得  \n$$\nP\\left(\\frac{X}{\\sigma_{X}}+\\frac{Y}{\\sigma_{Y}}=c\\right)=1\n$$  \n或  \n$$\nP\\left(Y=-\\frac{\\sigma_{Y}}{\\sigma_{X}} X+c \\sigma_{Y}\\right)=1\n$$  \n这也证明了: 当 $\\operatorname{Corr}(X, Y)=-1$ 时, $Y$ 与 $X$ 几乎处处线性负相关.  \n对于这个性质可作以下几点说明:  \n- 相关系数 $\\operatorname{Corr}(X, Y)$ 刻画了 $X$ 与 $Y$ 之间的线性关系, 因此也常称其为 “线性相关系数”.\n- 若 $\\operatorname{Corr}(X, Y)=0$, 则称 $X$ 与 $Y$ 不相关. 不相关是指 $X$ 与 $Y$ 之间没有线性关系, 但 $X$ 与 $Y$之间可能有其他的函数关系, 譬如平方关系、对数关系等.\n- 若 $\\operatorname{Corr}(X, Y)=1$, 则称 $X$ 与 $Y$ 完全正相关; 若 $\\operatorname{Corr}(X, Y)=-1$, 则称 $X$ 与 $Y$ 完全负相关.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n或  \n$$\nP\\left(Y=-\\frac{\\sigma_{Y}}{\\sigma_{X}} X+c \\sigma_{Y}\\right)=1\n$$  \n这也证明了: 当 $\\operatorname{Corr}(X, Y)=-1$ 时, $Y$ 与 $X$ 几乎处处线性负相关.  \n对于这个性质可作以下几点说明:  \n- 相关系数 $\\operatorname{Corr}(X, Y)$ 刻画了 $X$ 与 $Y$ 之间的线性关系, 因此也常称其为 “线性相关系数”.\n- 若 $\\operatorname{Corr}(X, Y)=0$, 则称 $X$ 与 $Y$ 不相关. 不相关是指 $X$ 与 $Y$ 之间没有线性关系, 但 $X$ 与 $Y$之间可能有其他的函数关系, 譬如平方关系、对数关系等.\n- 若 $\\operatorname{Corr}(X, Y)=1$, 则称 $X$ 与 $Y$ 完全正相关; 若 $\\operatorname{Corr}(X, Y)=-1$, 则称 $X$ 与 $Y$ 完全负相关.\n- 若 $0<|\\operatorname{Corr}(X, Y)|<1$, 则称 $X$ 与 $Y$ 有 “一定程度” 的线性关系. $|\\operatorname{Corr}(X, Y)|$ 越接近于 1 ,则线性相关程度越高; $|\\operatorname{Corr}(X, Y)|$ 越接近于 0 , 则线性相关程度越低. 而协方差看不出这一点. 若协方差很小, 而其两个标准差 $\\sigma_{X}$ 和 $\\sigma_{Y}$ 也很小, 则其比值就不一定很小, 这可从下面例 3.4.10 看出.  \n例 3.4.10: 已知随机向量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{8}{3}, & 0<x-y<0.5,0<x, y<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $X, Y$ 的相关系数 $\\operatorname{Corr}(X, Y)$.  \n解: 先计算两个边际密度函数.  \n当 $0<x<0.5$ 时,  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "- 若 $0<|\\operatorname{Corr}(X, Y)|<1$, 则称 $X$ 与 $Y$ 有 “一定程度” 的线性关系. $|\\operatorname{Corr}(X, Y)|$ 越接近于 1 ,则线性相关程度越高; $|\\operatorname{Corr}(X, Y)|$ 越接近于 0 , 则线性相关程度越低. 而协方差看不出这一点. 若协方差很小, 而其两个标准差 $\\sigma_{X}$ 和 $\\sigma_{Y}$ 也很小, 则其比值就不一定很小, 这可从下面例 3.4.10 看出.  \n例 3.4.10: 已知随机向量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{8}{3}, & 0<x-y<0.5,0<x, y<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $X, Y$ 的相关系数 $\\operatorname{Corr}(X, Y)$.  \n解: 先计算两个边际密度函数.  \n当 $0<x<0.5$ 时,  \n$$\np_{X}(x)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y=\\int_{0}^{x} \\frac{8}{3} \\mathrm{~d} y=\\frac{8}{3} x\n$$  \n当 $0.5<x<1$ 时,  \n$$\np_{X}(x)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y=\\int_{x-0.5}^{x} \\frac{8}{3} \\mathrm{~d} y=\\frac{4}{3},\n$$  \n所以得 $X$ 的边际密度函数为  \n$$\np_{X}(x)= \\begin{cases}\\frac{8}{3} x, & 0<x<0.5 ; \\\\ \\frac{4}{3}, & 0.5<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n!  \n图 3.4.2: 例 3.4.10 中 $p(x, y)$ 的非零区域  \n当 $0<y<0.5$ 时,  \n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 先计算两个边际密度函数.  \n当 $0<x<0.5$ 时,  \n$$\np_{X}(x)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y=\\int_{0}^{x} \\frac{8}{3} \\mathrm{~d} y=\\frac{8}{3} x\n$$  \n当 $0.5<x<1$ 时,  \n$$\np_{X}(x)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} y=\\int_{x-0.5}^{x} \\frac{8}{3} \\mathrm{~d} y=\\frac{4}{3},\n$$  \n所以得 $X$ 的边际密度函数为  \n$$\np_{X}(x)= \\begin{cases}\\frac{8}{3} x, & 0<x<0.5 ; \\\\ \\frac{4}{3}, & 0.5<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n!  \n图 3.4.2: 例 3.4.10 中 $p(x, y)$ 的非零区域  \n当 $0<y<0.5$ 时,  \n$$\np_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x=\\int_{y}^{y+0.5} \\frac{8}{3} \\mathrm{~d} x=\\frac{4}{3}\n$$  \n当 $0.5<y<1$ 时,  \n$$\np_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x=\\int_{y}^{1} \\frac{8}{3} \\mathrm{~d} x=\\frac{8}{3}(1-y) .\n$$  \n所以得 $Y$ 的边际密度函数为  \n$$\np_{Y}(y)= \\begin{cases}\\frac{4}{3}, & 0<x<0.5 \\\\ \\frac{8}{3}(1-y), & 0.5<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n然后分别计算 $X$ 与 $Y$ 的一、二阶矩  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n图 3.4.2: 例 3.4.10 中 $p(x, y)$ 的非零区域  \n当 $0<y<0.5$ 时,  \n$$\np_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x=\\int_{y}^{y+0.5} \\frac{8}{3} \\mathrm{~d} x=\\frac{4}{3}\n$$  \n当 $0.5<y<1$ 时,  \n$$\np_{Y}(y)=\\int_{-\\infty}^{+\\infty} p(x, y) \\mathrm{d} x=\\int_{y}^{1} \\frac{8}{3} \\mathrm{~d} x=\\frac{8}{3}(1-y) .\n$$  \n所以得 $Y$ 的边际密度函数为  \n$$\np_{Y}(y)= \\begin{cases}\\frac{4}{3}, & 0<x<0.5 \\\\ \\frac{8}{3}(1-y), & 0.5<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n然后分别计算 $X$ 与 $Y$ 的一、二阶矩  \n$$\n\\begin{aligned}\n& E(X)=\\int_{0}^{0.5} \\frac{8}{3} x^{2} \\mathrm{~d} x+\\int_{0.5}^{1} \\frac{4}{3} x \\mathrm{~d} x=\\frac{11}{18}, \\\\\n& E(Y)=\\int_{0}^{0.5} \\frac{4}{3} y \\mathrm{~d} y+\\int_{0.5}^{1} \\frac{8}{3} y(1-y) \\mathrm{d} y=\\frac{7}{18}, \\\\\n& E\\left(X^{2}\\right)=\\int_{0}^{0.5} \\frac{8}{3} x^{3} \\mathrm{~d} x+\\int_{0.5}^{1} \\frac{4}{3} x^{2} \\mathrm{~d} x=\\frac{31}{72}, \\\\\n& E\\left(Y^{2}\\right)=\\int_{0}^{0.5} \\frac{4}{3} y^{2} \\mathrm{~d} y+\\int_{0.5}^{1} \\frac{8}{3} y^{2}(1-y) \\mathrm{d} y=\\frac{15}{72} .",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "& E(X)=\\int_{0}^{0.5} \\frac{8}{3} x^{2} \\mathrm{~d} x+\\int_{0.5}^{1} \\frac{4}{3} x \\mathrm{~d} x=\\frac{11}{18}, \\\\\n& E(Y)=\\int_{0}^{0.5} \\frac{4}{3} y \\mathrm{~d} y+\\int_{0.5}^{1} \\frac{8}{3} y(1-y) \\mathrm{d} y=\\frac{7}{18}, \\\\\n& E\\left(X^{2}\\right)=\\int_{0}^{0.5} \\frac{8}{3} x^{3} \\mathrm{~d} x+\\int_{0.5}^{1} \\frac{4}{3} x^{2} \\mathrm{~d} x=\\frac{31}{72}, \\\\\n& E\\left(Y^{2}\\right)=\\int_{0}^{0.5} \\frac{4}{3} y^{2} \\mathrm{~d} y+\\int_{0.5}^{1} \\frac{8}{3} y^{2}(1-y) \\mathrm{d} y=\\frac{15}{72} .\n\\end{aligned}\n$$  \n由此可得 $X$ 与 $Y$ 各自的方差  \n$$\n\\begin{aligned}\n& \\operatorname{Var}(X)=\\frac{31}{72}-\\left(\\frac{11}{18}\\right)=\\frac{37}{648} \\\\\n& \\operatorname{Var}(Y)=\\frac{15}{72}-\\left(\\frac{7}{18}\\right)^{2}=\\frac{37}{648}\n\\end{aligned}\n$$  \n最后还需要计算 $E(X Y)$, 它只能从联合密度函数导出.  \n$$\n\\begin{aligned}\nE(X Y) & =\\int_{0}^{0.5} \\int_{0}^{x} \\frac{8}{3} x y \\mathrm{~d} y \\mathrm{~d} x+\\int_{0.5}^{1} \\int_{x-0.5}^{x} \\frac{8}{3} x y \\mathrm{~d} y \\mathrm{~d} x \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n由此可得 $X$ 与 $Y$ 各自的方差  \n$$\n\\begin{aligned}\n& \\operatorname{Var}(X)=\\frac{31}{72}-\\left(\\frac{11}{18}\\right)=\\frac{37}{648} \\\\\n& \\operatorname{Var}(Y)=\\frac{15}{72}-\\left(\\frac{7}{18}\\right)^{2}=\\frac{37}{648}\n\\end{aligned}\n$$  \n最后还需要计算 $E(X Y)$, 它只能从联合密度函数导出.  \n$$\n\\begin{aligned}\nE(X Y) & =\\int_{0}^{0.5} \\int_{0}^{x} \\frac{8}{3} x y \\mathrm{~d} y \\mathrm{~d} x+\\int_{0.5}^{1} \\int_{x-0.5}^{x} \\frac{8}{3} x y \\mathrm{~d} y \\mathrm{~d} x \\\\\n& =\\int_{0}^{0.5} \\frac{4}{3} x^{3} \\mathrm{~d} x+\\int_{0.5}^{1} \\frac{4}{3} x\\left(x-\\frac{1}{4}\\right) \\mathrm{d} x=\\frac{1}{48}+\\frac{7}{18}-\\frac{1}{8}=\\frac{41}{144}\n\\end{aligned}\n$$  \n最后得协方差和相关系数为  \n$$\n\\begin{aligned}\n& \\operatorname{Cov}(X, Y)=\\frac{41}{144}-\\frac{11}{18} \\times \\frac{7}{18}=\\frac{61}{1296}=0.0471 . \\\\\n& \\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{X} \\sigma_{Y}}=\\frac{61}{1296} \\times \\frac{648}{37}=\\frac{61}{74}=0.8243 .\n\\end{aligned}\n$$  \n这个协方差很小, 但其相关系数并不小.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n最后得协方差和相关系数为  \n$$\n\\begin{aligned}\n& \\operatorname{Cov}(X, Y)=\\frac{41}{144}-\\frac{11}{18} \\times \\frac{7}{18}=\\frac{61}{1296}=0.0471 . \\\\\n& \\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma_{X} \\sigma_{Y}}=\\frac{61}{1296} \\times \\frac{648}{37}=\\frac{61}{74}=0.8243 .\n\\end{aligned}\n$$  \n这个协方差很小, 但其相关系数并不小.  \n上例中, 从相关系数 $\\operatorname{Corr}(X, Y)=0.8243$ 看, $X$ 与 $Y$ 有相当程度的正相关; 但从相应的协方差 $\\operatorname{Cov}(X, Y)=0.0471$ 看, $X$ 与 $Y$ 的相关性很微弱, 几乎可以忽略不计. 造成这种错觉的原因在于没有考虑标准差, 若两个标准差都很小, 即使协方差小一些, 相关系数也能显示一定程度的相关性.\n由此可见, 在协方差的基础上加工形成的相关系数是更为重要的相关性的特征数.  \n在一般场合, 独立必导致不相关, 但不相关推不出独立. 但也有例外, 下面的性质指出了这个例外.  \n性质 3.4.13: 在二维正态分布 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$ 的相关系数是 $\\rho$, 因此我们只需证 $\\rho=0$ 与独立是等价的. 因为二维正态分布 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$ 的两个边际分布为 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 和 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$, 所以记其联合密度函数为 $p(x, y)$, 边际密度函数为 $p_{X}(x)$ 与 $p_{Y}(y)$.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "由此可见, 在协方差的基础上加工形成的相关系数是更为重要的相关性的特征数.  \n在一般场合, 独立必导致不相关, 但不相关推不出独立. 但也有例外, 下面的性质指出了这个例外.  \n性质 3.4.13: 在二维正态分布 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$ 的相关系数是 $\\rho$, 因此我们只需证 $\\rho=0$ 与独立是等价的. 因为二维正态分布 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$ 的两个边际分布为 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 和 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$, 所以记其联合密度函数为 $p(x, y)$, 边际密度函数为 $p_{X}(x)$ 与 $p_{Y}(y)$.  \n当 $\\rho=0$ 时, 可从正态密度函数的表达式中看出  \n$$\np(x, y)=p_{X}(x) p_{Y}(y)\n$$  \n即 $X$ 与 $Y$ 相互独立.  \n反之, 若 $X$ 与 $Y$ 相互独立, 即对一切 $x$ 与 $y$ 有 $p(x, y)=p_{X}(x) p_{Y}(y)$, 若令 $x=\\mu_{1}, y=\\mu_{2}$ , 则可得  \n$$\n\\frac{1}{\\sqrt{1-\\rho^{2}}}=1\n$$  \n从而有 $\\rho=0$. 结论得证.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "当 $\\rho=0$ 时, 可从正态密度函数的表达式中看出  \n$$\np(x, y)=p_{X}(x) p_{Y}(y)\n$$  \n即 $X$ 与 $Y$ 相互独立.  \n反之, 若 $X$ 与 $Y$ 相互独立, 即对一切 $x$ 与 $y$ 有 $p(x, y)=p_{X}(x) p_{Y}(y)$, 若令 $x=\\mu_{1}, y=\\mu_{2}$ , 则可得  \n$$\n\\frac{1}{\\sqrt{1-\\rho^{2}}}=1\n$$  \n从而有 $\\rho=0$. 结论得证.  \n例 3.4.11(投资风险组合)：设有一笔资金, 总量记为 1 (可以是 1 万元, 也可以是 100 万元等), 如今要投资甲、乙两种证券. 若将资金 $x_{1}$ 投资于甲证券, 将余下的资金 $1-x_{1}=x_{2}$ 投资于乙证券, 于是 $\\left(x_{1}, x_{2}\\right)$ 就形成了一个投资组合. 记 $X$ 为投资甲证券的收益率, $Y$ 为投资乙证券的收益率, 它们都是随机变量. 如果已知 $X$ 和 $Y$ 的均值 (代表平均收益) 分别为 $\\mu_{1}$ 和 $\\mu_{2}$, 方差 (代表风险) 分别为 $\\sigma_{1}^{2}$ 和 $\\sigma_{2}^{2}, X$ 和 $Y$ 间的相关系数为 $\\rho$. 试求该投资组合的平均收益与风险 (方差), 并求使投资风险最小的 $x_{1}$ 是多少?  \n解: 因为组合收益为  \n$$\nZ=x_{1} X+x_{2} Y=x_{1} X+\\left(1-x_{1}\\right) Y\n$$  \n所以该组合的平均收益为  \n$$\nE(Z)=x_{1} E(X)+\\left(1-x_{1}\\right) E(Y)=x_{1} \\mu_{1}+\\left(1-x_{1}\\right) \\mu_{2} .\n$$  \n而该组合的风险 (方差) 为  \n$$\n\\begin{aligned}\n\\operatorname{Var}(Z) & =\\operatorname{Var}\\left\\{x_{1} X+\\left(1-x_{1}\\right) Y\\right\\} \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 因为组合收益为  \n$$\nZ=x_{1} X+x_{2} Y=x_{1} X+\\left(1-x_{1}\\right) Y\n$$  \n所以该组合的平均收益为  \n$$\nE(Z)=x_{1} E(X)+\\left(1-x_{1}\\right) E(Y)=x_{1} \\mu_{1}+\\left(1-x_{1}\\right) \\mu_{2} .\n$$  \n而该组合的风险 (方差) 为  \n$$\n\\begin{aligned}\n\\operatorname{Var}(Z) & =\\operatorname{Var}\\left\\{x_{1} X+\\left(1-x_{1}\\right) Y\\right\\} \\\\\n& =x_{1}^{2} \\operatorname{Var}(X)+\\left(1-x_{1}\\right)^{2} \\operatorname{Var}(Y)+2 x_{1}\\left(1-x_{1}\\right) \\operatorname{Cov}(X, Y) \\\\\n& =x_{1}^{2} \\sigma_{1}^{2}+\\left(1-x_{1}\\right)^{2} \\sigma_{2}^{2}+2 x_{1}\\left(1-x_{1}\\right) \\rho \\sigma_{1} \\sigma_{2}\n\\end{aligned}\n$$  \n求最小组合风险, 即求 $\\operatorname{Var}(Z)$ 关于 $x_{1}$ 的极小点, 为此令  \n$$\n\\frac{\\mathrm{d}(\\operatorname{Var}(Z))}{\\mathrm{d} x_{1}}=2 x_{1} \\sigma_{1}^{2}-2\\left(1-x_{1}\\right) \\sigma_{2}^{2}+2 \\rho \\sigma_{1} \\sigma_{2}-4 x_{1} \\rho \\sigma_{1} \\sigma_{2}=0\n$$  \n从中解得  \n$$\nx_{1}^{*}=\\frac{\\sigma_{2}^{2}-\\rho \\sigma_{1} \\sigma_{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2 \\rho \\sigma_{1} \\sigma_{2}}\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n求最小组合风险, 即求 $\\operatorname{Var}(Z)$ 关于 $x_{1}$ 的极小点, 为此令  \n$$\n\\frac{\\mathrm{d}(\\operatorname{Var}(Z))}{\\mathrm{d} x_{1}}=2 x_{1} \\sigma_{1}^{2}-2\\left(1-x_{1}\\right) \\sigma_{2}^{2}+2 \\rho \\sigma_{1} \\sigma_{2}-4 x_{1} \\rho \\sigma_{1} \\sigma_{2}=0\n$$  \n从中解得  \n$$\nx_{1}^{*}=\\frac{\\sigma_{2}^{2}-\\rho \\sigma_{1} \\sigma_{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2 \\rho \\sigma_{1} \\sigma_{2}}\n$$  \n它与 $\\mu_{1}, \\mu_{2}$ 无关. 又因为 $\\operatorname{Var}(Z)$ 中 $x_{1}^{2}$ 的系数为正, 所以以上的 $x_{1}^{*}$ 可使组合风险达到最小.  \n譬如, $\\sigma_{1}^{2}=0.3, \\sigma_{2}^{2}=0.5, \\rho=0.4$, 则  \n$$\nx_{1}^{*}=\\frac{0.5-0.4 \\sqrt{0.3 \\times 0.5}}{0.3+0.5-2 \\times 0.4 \\sqrt{0.3 \\times 0.5}}=0.704\n$$  \n这说明应把全部资金的 $70 \\%$ 投资于甲证券, 而把余下的 30\\% 资金投向乙证券, 这样的投资组合风险最小.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.4 相关系数"
        },
        "type": "Document"
    },
    {
        "page_content": "以下我们用矩阵形式给出 $n$ 维随机变量的数学期望与方差.  \n定义 3.4.3. 记 $n$ 维随机向量为 $\\boldsymbol{X}=\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)^{\\prime}$, 若其每个分量的数学期望都存在, 则称  \n$$\nE(\\boldsymbol{X})=\\left(E\\left(X_{1}\\right), E\\left(X_{2}\\right), \\ldots, E\\left(X_{n}\\right)\\right)^{\\prime}\n$$  \n为 $n$ 维随机向量 $X$ 的数学期望向量, 简称为 $X$ 的数学期望, 而称  \n$$\n\\begin{aligned}\n& E\\left[(\\boldsymbol{X}-E(\\boldsymbol{X}))(\\boldsymbol{X}-E(\\boldsymbol{X}))^{\\prime}\\right] \\\\\n& =\\left(\\begin{array}{cccc}\n\\operatorname{Var}\\left(X_{1}\\right) & \\operatorname{Cov}\\left(X_{1}, X_{2}\\right) & \\cdots & \\operatorname{Cov}\\left(X_{1}, X_{n}\\right) \\\\\n\\operatorname{Cov}\\left(X_{2}, X_{1}\\right) & \\operatorname{Var}\\left(X_{2}\\right) & \\cdots & \\operatorname{Cov}\\left(X_{2}, X_{n}\\right) \\\\\n\\vdots & \\vdots & & \\vdots \\\\\n\\operatorname{Cov}\\left(X_{n}, X_{1}\\right) & \\operatorname{Cov}\\left(X_{n}, X_{2}\\right) & \\cdots & \\operatorname{Var}\\left(X_{n}\\right)\n\\end{array}\\right)\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.5 随机向量的数学期望与协方差阵"
        },
        "type": "Document"
    },
    {
        "page_content": "\\operatorname{Var}\\left(X_{1}\\right) & \\operatorname{Cov}\\left(X_{1}, X_{2}\\right) & \\cdots & \\operatorname{Cov}\\left(X_{1}, X_{n}\\right) \\\\\n\\operatorname{Cov}\\left(X_{2}, X_{1}\\right) & \\operatorname{Var}\\left(X_{2}\\right) & \\cdots & \\operatorname{Cov}\\left(X_{2}, X_{n}\\right) \\\\\n\\vdots & \\vdots & & \\vdots \\\\\n\\operatorname{Cov}\\left(X_{n}, X_{1}\\right) & \\operatorname{Cov}\\left(X_{n}, X_{2}\\right) & \\cdots & \\operatorname{Var}\\left(X_{n}\\right)\n\\end{array}\\right)\n\\end{aligned}\n$$  \n为该随机向量的方差一协方差阵, 简称协方差阵, 记为 $\\operatorname{Cov}(\\boldsymbol{X})$.  \n至此我们可以看出, $n$ 维随机向量的数学期望是各分量的数学期望组成的向量. 而其方差就是由各分量的方差与协方差组成的矩阵, 其对角线上的元素就是方差, 非对角线元素为协方差.  \n以下给出的协方差阵的一个重要性质.  \n定理 3.4.2. $n$ 维随机向量的协方差阵 $\\operatorname{Cov}(\\boldsymbol{X})=\\left(\\operatorname{Cov}\\left(X_{i}, X_{j}\\right)\\right)_{n \\times n}$ 是一个对称的非负定矩阵.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.5 随机向量的数学期望与协方差阵"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array}\\right)\n\\end{aligned}\n$$  \n为该随机向量的方差一协方差阵, 简称协方差阵, 记为 $\\operatorname{Cov}(\\boldsymbol{X})$.  \n至此我们可以看出, $n$ 维随机向量的数学期望是各分量的数学期望组成的向量. 而其方差就是由各分量的方差与协方差组成的矩阵, 其对角线上的元素就是方差, 非对角线元素为协方差.  \n以下给出的协方差阵的一个重要性质.  \n定理 3.4.2. $n$ 维随机向量的协方差阵 $\\operatorname{Cov}(\\boldsymbol{X})=\\left(\\operatorname{Cov}\\left(X_{i}, X_{j}\\right)\\right)_{n \\times n}$ 是一个对称的非负定矩阵.  \n证明: 因为 $\\operatorname{Cov}\\left(X_{i}, X_{j}\\right)=\\operatorname{Cov}\\left(X_{j}, X_{i}\\right)$, 所以对称性是显然的. 下证非负定性. 因为对任意的 $n$ 维实向量 $c=\\left(c_{1}, c_{2}, \\ldots, c_{n}\\right)^{\\prime}$, 有  \n$$\n\\begin{aligned}\n\\boldsymbol{c}^{\\prime} \\operatorname{Cov}(\\boldsymbol{X}) \\boldsymbol{c} & =\\left(c_{1}, c_{2}, \\ldots, c_{n}\\right)\\left(\\begin{array}{ccc}\n\\operatorname{Var}\\left(X_{1}\\right) & \\cdots & \\operatorname{Cov}\\left(X_{1}, X_{n}\\right) \\\\\n\\operatorname{Cov}\\left(X_{2}, X_{1}\\right) & \\cdots & \\operatorname{Cov}\\left(X_{2}, X_{n}\\right) \\\\\n\\vdots & & \\vdots \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.5 随机向量的数学期望与协方差阵"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n\\boldsymbol{c}^{\\prime} \\operatorname{Cov}(\\boldsymbol{X}) \\boldsymbol{c} & =\\left(c_{1}, c_{2}, \\ldots, c_{n}\\right)\\left(\\begin{array}{ccc}\n\\operatorname{Var}\\left(X_{1}\\right) & \\cdots & \\operatorname{Cov}\\left(X_{1}, X_{n}\\right) \\\\\n\\operatorname{Cov}\\left(X_{2}, X_{1}\\right) & \\cdots & \\operatorname{Cov}\\left(X_{2}, X_{n}\\right) \\\\\n\\vdots & & \\vdots \\\\\n\\operatorname{Cov}\\left(X_{n}, X_{1}\\right) & \\cdots & \\operatorname{Var}\\left(X_{n}\\right)\n\\end{array}\\right)\\left(\\begin{array}{c}\nc_{1} \\\\\nc_{2} \\\\\n\\vdots \\\\\nc_{n}\n\\end{array}\\right) \\\\\n& =\\sum_{i=1}^{n} \\sum_{j=1}^{n} c_{i} c_{j} \\operatorname{Cov}\\left(X_{i}, X_{j}\\right) \\\\\n& =\\sum_{i=1}^{n} \\sum_{j=1}^{n} E\\left\\{\\left[c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]\\left[c_{j}\\left(X_{j}-E\\left(X_{j}\\right)\\right)\\right]\\right\\} \\\\\n& =E\\left\\{\\sum_{i=1}^{n} \\sum_{j=1}^{n}\\left[c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]\\left[c_{j}\\left(X_{j}-E\\left(X_{j}\\right)\\right)\\right]\\right\\} \\\\",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.5 随机向量的数学期望与协方差阵"
        },
        "type": "Document"
    },
    {
        "page_content": "c_{1} \\\\\nc_{2} \\\\\n\\vdots \\\\\nc_{n}\n\\end{array}\\right) \\\\\n& =\\sum_{i=1}^{n} \\sum_{j=1}^{n} c_{i} c_{j} \\operatorname{Cov}\\left(X_{i}, X_{j}\\right) \\\\\n& =\\sum_{i=1}^{n} \\sum_{j=1}^{n} E\\left\\{\\left[c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]\\left[c_{j}\\left(X_{j}-E\\left(X_{j}\\right)\\right)\\right]\\right\\} \\\\\n& =E\\left\\{\\sum_{i=1}^{n} \\sum_{j=1}^{n}\\left[c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]\\left[c_{j}\\left(X_{j}-E\\left(X_{j}\\right)\\right)\\right]\\right\\} \\\\\n& =E\\left\\{\\left[\\sum_{i=1}^{n} c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]\\left[\\sum_{j=1}^{n} c_{j}\\left(X_{j}-E\\left(X_{j}\\right)\\right)\\right]\\right\\} \\\\\n& =E\\left[\\sum_{i=1}^{n} c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]^{2} \\geqslant 0\n\\end{aligned}\n$$  \n所以矩阵 $\\operatorname{Cov}(\\boldsymbol{X})$ 是非负定的, 定理得证.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.5 随机向量的数学期望与协方差阵"
        },
        "type": "Document"
    },
    {
        "page_content": "& =E\\left\\{\\sum_{i=1}^{n} \\sum_{j=1}^{n}\\left[c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]\\left[c_{j}\\left(X_{j}-E\\left(X_{j}\\right)\\right)\\right]\\right\\} \\\\\n& =E\\left\\{\\left[\\sum_{i=1}^{n} c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]\\left[\\sum_{j=1}^{n} c_{j}\\left(X_{j}-E\\left(X_{j}\\right)\\right)\\right]\\right\\} \\\\\n& =E\\left[\\sum_{i=1}^{n} c_{i}\\left(X_{i}-E\\left(X_{i}\\right)\\right)\\right]^{2} \\geqslant 0\n\\end{aligned}\n$$  \n所以矩阵 $\\operatorname{Cov}(\\boldsymbol{X})$ 是非负定的, 定理得证.  \n例 3.4.12 ( $n$ 元正态分布 $)$ : 设 $n$ 维随机变量 $\\boldsymbol{X}=\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)^{\\prime}$ 的协方阵为 $\\boldsymbol{B}=\\operatorname{Cov}(\\boldsymbol{X})$, 数学期望向量为 $\\boldsymbol{a}=\\left(a_{1}, a_{2}, \\ldots, a_{n}\\right)^{\\prime}$. 又记 $\\boldsymbol{x}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)^{\\prime}$, 则由密度函数  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.5 随机向量的数学期望与协方差阵"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n所以矩阵 $\\operatorname{Cov}(\\boldsymbol{X})$ 是非负定的, 定理得证.  \n例 3.4.12 ( $n$ 元正态分布 $)$ : 设 $n$ 维随机变量 $\\boldsymbol{X}=\\left(X_{1}, X_{2}, \\ldots, X_{n}\\right)^{\\prime}$ 的协方阵为 $\\boldsymbol{B}=\\operatorname{Cov}(\\boldsymbol{X})$, 数学期望向量为 $\\boldsymbol{a}=\\left(a_{1}, a_{2}, \\ldots, a_{n}\\right)^{\\prime}$. 又记 $\\boldsymbol{x}=\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)^{\\prime}$, 则由密度函数  \n$$\n\\begin{equation*}\np\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=p(\\boldsymbol{x})=\\frac{1}{(2 \\pi)^{\\frac{n}{2}}|\\boldsymbol{B}|^{\\frac{1}{2}}} \\exp \\left\\{-\\frac{1}{2}(\\boldsymbol{x}-\\boldsymbol{a})^{\\prime} \\boldsymbol{B}^{-1}(\\boldsymbol{x}-\\boldsymbol{a})\\right\\} \\tag{3.4.13}\n\\end{equation*}\n$$  \n定义的分布称为 $n$ 元正态分布, 记为 $\\boldsymbol{X} \\sim N(\\boldsymbol{a}, \\boldsymbol{B})$. 其中 $|\\boldsymbol{B}|$ 表示 $\\boldsymbol{B}$ 的行列式, $\\boldsymbol{B}^{-1}$ 表示 $\\boldsymbol{B}$ 的逆阵, $(x-a)^{\\prime}$ 表示向量 $(x-a)$ 的转置.  \n若记 $\\boldsymbol{B}^{-1}=\\left(r_{i j}\\right)$, 则 (3.4.13) 式可写成  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.5 随机向量的数学期望与协方差阵"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n定义的分布称为 $n$ 元正态分布, 记为 $\\boldsymbol{X} \\sim N(\\boldsymbol{a}, \\boldsymbol{B})$. 其中 $|\\boldsymbol{B}|$ 表示 $\\boldsymbol{B}$ 的行列式, $\\boldsymbol{B}^{-1}$ 表示 $\\boldsymbol{B}$ 的逆阵, $(x-a)^{\\prime}$ 表示向量 $(x-a)$ 的转置.  \n若记 $\\boldsymbol{B}^{-1}=\\left(r_{i j}\\right)$, 则 (3.4.13) 式可写成  \n$$\n\\begin{equation*}\np\\left(x_{1}, x_{2}, \\ldots, x_{n}\\right)=\\frac{1}{(2 \\pi)^{\\frac{n}{2}}|\\boldsymbol{B}|^{\\frac{1}{2}}} \\exp \\left\\{-\\frac{1}{2} \\sum_{i, j=1}^{n} r_{i j}\\left(x_{i}-a_{i}\\right)\\left(x_{j}-a_{j}\\right)\\right\\} . \\tag{3.4.14}\n\\end{equation*}\n$$  \n若取数学期望向量和协方差矩阵分别为  \n$$\n\\boldsymbol{a}=\\left(\\begin{array}{l}\n\\mu_{1} \\\\\n\\mu_{2}\n\\end{array}\\right), \\quad \\boldsymbol{B}=\\left(\\begin{array}{cc}\n\\sigma_{1}^{2} & \\sigma_{1} \\sigma_{2} \\rho \\\\\n\\sigma_{1} \\sigma_{2} \\rho & \\sigma_{2}^{2}\n\\end{array}\\right),\n$$  \n代人 (3.4.13) 式, 则可得到 (3.1.8) 式给出的二元正态密度函数.  \n$n$ 元正态分布是一种最重要的多维分布, 它在概率论、数理统计和随机过程中都占有重要地位.",
        "metadata": {
            "Header 2": "3.4 多维随机变量的特征数",
            "Header 3": "3.4.5 随机向量的数学期望与协方差阵"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 掷一颗均匀的骰子 2 次, 其最小点数记为 $X$, 求 $E(X)$.\n2. 求掷 $n$ 颗骰子出现点数之和的数学期望与方差.\n3. 从数字 $0,1, \\ldots, n$ 中任取两个不同的数字, 求这两个数字之差的绝对值的数学期望.\n4. 设在区间 $(0,1)$ 上随机地取 $n$ 个点, 求相距最远的两点间的距离的数学期望.\n5. 盘中有 $n$ 个不同的球, 其上分别写有数字 $1,2, \\ldots, n$. 每次随机抽出一个, 记下其号码, 放回去再抽. 直到抽到有两个不同的数字为止. 求平均抽球次数.\n6. 设随机变量 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |\n| :---: | :---: | :---: |\n| $X$ | 0 | 1 |\n| 0 | 0.1 | 0.15 |\n| 1 | 0.25 | 0.2 |\n| 2 | 0.15 | 0.15 |  \n试求 $Z=\\sin \\left[\\frac{\\pi}{2}(X+Y)\\right]$ 的数学期望.  \n7. 随机变量 $(X, Y)$ 服从以点 $(0,1),(1,0),(1,1)$ 为顶点的三角形区域上的均匀分布, 试求 $E(X+$ $Y)$ 和 $\\operatorname{Var}(X+Y)$.\n8. 设随机变量 $(X, Y)$ 的联合密度函数为  \n试求 $E(Y / X)$.  \n$$\np(x, y)= \\begin{cases}x\\left(1+3 y^{2}\\right) / 4, & 0<x<2,0<y<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n9. 设 $X_{1}, X_{2}, \\ldots, X_{5}$ 是独立同分布的随机变量, 其共同密度函数为  \n$$\np(x)= \\begin{cases}2 x, & 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $Y=\\max \\left(X_{1}, X_{2}, \\ldots, X_{5}\\right)$ 的密度函数、数学期望和方差.",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "7. 随机变量 $(X, Y)$ 服从以点 $(0,1),(1,0),(1,1)$ 为顶点的三角形区域上的均匀分布, 试求 $E(X+$ $Y)$ 和 $\\operatorname{Var}(X+Y)$.\n8. 设随机变量 $(X, Y)$ 的联合密度函数为  \n试求 $E(Y / X)$.  \n$$\np(x, y)= \\begin{cases}x\\left(1+3 y^{2}\\right) / 4, & 0<x<2,0<y<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n9. 设 $X_{1}, X_{2}, \\ldots, X_{5}$ 是独立同分布的随机变量, 其共同密度函数为  \n$$\np(x)= \\begin{cases}2 x, & 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $Y=\\max \\left(X_{1}, X_{2}, \\ldots, X_{5}\\right)$ 的密度函数、数学期望和方差.  \n10. 系统由 $n$ 个部件组成. 记 $X_{i}$ 为第 $i$ 个部件能持续工作的时间, 如果 $X_{1}, \\ldots, X_{n}$ 独立同分布, 且 $X_{i} \\sim \\operatorname{Exp}(\\lambda)$, 试在以下情况下求系统持续工作的平均时间:  \n(1) 如果有一个部件停止工作, 系统就不工作了;  \n(2) 如果至少有一个部件在工作, 系统就工作.  \n11. 邮局里有 $A 、 B 、 C$ 三个顾客, 假定邮局对每个顾客的服务时间服从参数为 $\\lambda$ 的指数分布. 对 $A$和 $B$ 立即开始服务, 在对 $A$ 或 $B$ 结束服务后开始对 $C$ 服务, 对 $A 、 B$ 两人服务所需的时间是独立的. 求 $C$ 在邮局中  \n(1) 等待时间的数学期望;  \n(2) 逗留时间的数学期望.  \n12. 设 $X, Y$ 独立同分布, 都服从标准正态分布 $N(0,1)$, 求 $E[\\max (X, Y)]$.\n13. 设随机变量 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立, 且都服从 $(0, \\theta)$ 上的均匀分布, 记  \n$$",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 如果有一个部件停止工作, 系统就不工作了;  \n(2) 如果至少有一个部件在工作, 系统就工作.  \n11. 邮局里有 $A 、 B 、 C$ 三个顾客, 假定邮局对每个顾客的服务时间服从参数为 $\\lambda$ 的指数分布. 对 $A$和 $B$ 立即开始服务, 在对 $A$ 或 $B$ 结束服务后开始对 $C$ 服务, 对 $A 、 B$ 两人服务所需的时间是独立的. 求 $C$ 在邮局中  \n(1) 等待时间的数学期望;  \n(2) 逗留时间的数学期望.  \n12. 设 $X, Y$ 独立同分布, 都服从标准正态分布 $N(0,1)$, 求 $E[\\max (X, Y)]$.\n13. 设随机变量 $X_{1}, X_{2}, \\ldots, X_{n}$ 相互独立, 且都服从 $(0, \\theta)$ 上的均匀分布, 记  \n$$\nY=\\max \\left\\{X_{1}, X_{2}, \\ldots, X_{n}\\right\\}, \\quad Z=\\min \\left\\{X_{1}, X_{2}, \\ldots, X_{n}\\right\\}\n$$  \n试求 $E(Y)$ 和 $E(Z)$.  \n14. 设随机变量 $U$ 服从 $(-2,2)$ 上的均匀分布, 定义 $X$ 和 $Y$ 如下:  \n试求 $\\operatorname{Var}(X+Y)$.  \n$$\nX=\\left\\{\\begin{array}{ll}\n-1, & \\text { 若 } U<-1 ; \\\\\n1, & \\text { 若 } U \\geqslant-1 .\n\\end{array} \\quad Y= \\begin{cases}-1, & \\text { 若 } U<1 ; \\\\\n1, & \\text { 若 } U \\geqslant 1 .\\end{cases}\\right.\n$$  \n15. 一商店经销某种商品, 每周进货量 $X$ 与顾客对该种商品的需求量 $Y$ 是相互独立的随机变量, 且都跟从区间 $(10,20)$ 上的均匀分布. 商店每售出一单位商品可得利润 1000 元; 若需求量超过了进货量, 则可从其他商店调剂供应, 这时每单位商品获利润为 500 元. 试求此商店经销该种商品每局的平均利润.",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试求 $E(Y)$ 和 $E(Z)$.  \n14. 设随机变量 $U$ 服从 $(-2,2)$ 上的均匀分布, 定义 $X$ 和 $Y$ 如下:  \n试求 $\\operatorname{Var}(X+Y)$.  \n$$\nX=\\left\\{\\begin{array}{ll}\n-1, & \\text { 若 } U<-1 ; \\\\\n1, & \\text { 若 } U \\geqslant-1 .\n\\end{array} \\quad Y= \\begin{cases}-1, & \\text { 若 } U<1 ; \\\\\n1, & \\text { 若 } U \\geqslant 1 .\\end{cases}\\right.\n$$  \n15. 一商店经销某种商品, 每周进货量 $X$ 与顾客对该种商品的需求量 $Y$ 是相互独立的随机变量, 且都跟从区间 $(10,20)$ 上的均匀分布. 商店每售出一单位商品可得利润 1000 元; 若需求量超过了进货量, 则可从其他商店调剂供应, 这时每单位商品获利润为 500 元. 试求此商店经销该种商品每局的平均利润.\n16. 设随机变量 $X$ 与 $Y$ 独立, 都服从正态分布 $N\\left(a, \\sigma^{2}\\right)$, 试证  \n$$\nE[\\max (X, Y)]=a+\\frac{\\sigma}{\\sqrt{\\pi}}\n$$  \n17. 设二维随机变量 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | -1 | 0 | 1 |\n| 0 | 0.07 | 0.18 | 0.15 |\n| 1 | 0.08 | 0.32 | 0.20 |  \n试求 $X^{2}$ 与 $Y^{2}$ 的协方差.  \n18. 把一个骰子独立地郑 $n$ 次, 求 1 点出现的次数与 6 点出现次数的协方差及相关系数.\n19. 某箱装 100 件产品, 其中一、二和三等品分别为 80,10 和 10 件. 现从中随机取一件, 定义三个随机变量 $X_{1}, X_{2}, X_{3}$ 如下  \n$$",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "16. 设随机变量 $X$ 与 $Y$ 独立, 都服从正态分布 $N\\left(a, \\sigma^{2}\\right)$, 试证  \n$$\nE[\\max (X, Y)]=a+\\frac{\\sigma}{\\sqrt{\\pi}}\n$$  \n17. 设二维随机变量 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |\n| :---: | :---: | :---: | :---: |\n| $X$ | -1 | 0 | 1 |\n| 0 | 0.07 | 0.18 | 0.15 |\n| 1 | 0.08 | 0.32 | 0.20 |  \n试求 $X^{2}$ 与 $Y^{2}$ 的协方差.  \n18. 把一个骰子独立地郑 $n$ 次, 求 1 点出现的次数与 6 点出现次数的协方差及相关系数.\n19. 某箱装 100 件产品, 其中一、二和三等品分别为 80,10 和 10 件. 现从中随机取一件, 定义三个随机变量 $X_{1}, X_{2}, X_{3}$ 如下  \n$$\nX_{i}= \\begin{cases}1, & \\text { 若抽到 } i \\text { 等品; } \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求随机变量 $X_{1}$ 和 $X_{2}$ 的相关系数 $\\operatorname{Corr}\\left(X_{1}, X_{2}\\right)$.  \n20. 将一枚硬币重复郑 $n$ 次, 以 $X$ 和 $Y$ 分别表示正面向上和反面向上的次数, 试求 $X$ 和 $Y$ 的协方差及相关系数.\n21. 设随机变量 $X$ 和 $Y$ 独立同服从参数为 $\\lambda$ 的泊松分布, 令  \n$$\nU=2 X+Y, \\quad V=2 X-Y\n$$  \n求 $U$ 和 $V$ 的相关系数 $\\operatorname{Corr}(U, V)$.  \n22. 在一个有 $n$ 个人参加的晚会上, 每个人带了一件礼物, 且假定各人带的礼物都不相同. 晚会期间各人从放在一起的 $n$ 件礼物中随机抽取一件, 试求选中自己礼品的人数 $X$ 的均值和方差.",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nX_{i}= \\begin{cases}1, & \\text { 若抽到 } i \\text { 等品; } \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求随机变量 $X_{1}$ 和 $X_{2}$ 的相关系数 $\\operatorname{Corr}\\left(X_{1}, X_{2}\\right)$.  \n20. 将一枚硬币重复郑 $n$ 次, 以 $X$ 和 $Y$ 分别表示正面向上和反面向上的次数, 试求 $X$ 和 $Y$ 的协方差及相关系数.\n21. 设随机变量 $X$ 和 $Y$ 独立同服从参数为 $\\lambda$ 的泊松分布, 令  \n$$\nU=2 X+Y, \\quad V=2 X-Y\n$$  \n求 $U$ 和 $V$ 的相关系数 $\\operatorname{Corr}(U, V)$.  \n22. 在一个有 $n$ 个人参加的晚会上, 每个人带了一件礼物, 且假定各人带的礼物都不相同. 晚会期间各人从放在一起的 $n$ 件礼物中随机抽取一件, 试求选中自己礼品的人数 $X$ 的均值和方差.\n23. 设随机变量 $X$ 和 $Y$ 的数学期望分别为 -2 和 2 , 方差分别为 1 和 4 , 而它们的相关系数为 -0.5 . 试根据车比晓夫不等式, 估计 $P(|X+Y| \\geqslant 6)$ 的上限.\n24. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}1, & |y|<x, 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $E(X), E(Y), \\operatorname{Cov}(X, Y)$.  \n25. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}3 x, & 0<y<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $X$ 与 $Y$ 的相关系数.  \n26. 已知随机变量 $X$ 与 $Y$ 的相关系数为 $\\rho$, 求 $X_{1}=a X+b$ 与 $Y_{1}=c Y+d$ 的相关系数, 其中 $a, b, c, d$ 均为常数.",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "23. 设随机变量 $X$ 和 $Y$ 的数学期望分别为 -2 和 2 , 方差分别为 1 和 4 , 而它们的相关系数为 -0.5 . 试根据车比晓夫不等式, 估计 $P(|X+Y| \\geqslant 6)$ 的上限.\n24. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}1, & |y|<x, 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $E(X), E(Y), \\operatorname{Cov}(X, Y)$.  \n25. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}3 x, & 0<y<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $X$ 与 $Y$ 的相关系数.  \n26. 已知随机变量 $X$ 与 $Y$ 的相关系数为 $\\rho$, 求 $X_{1}=a X+b$ 与 $Y_{1}=c Y+d$ 的相关系数, 其中 $a, b, c, d$ 均为常数.\n27. 设 $X_{1}$ 与 $X_{2}$ 独立同分布, 其共同分布为 $\\operatorname{Exp}(\\lambda)$. 试求 $Y_{1}=4 X_{1}-3 X_{2}$ 与 $Y_{2}=3 X_{1}+X_{2}$ 的相关系数.\n28. 设 $X_{1}$ 与 $X_{2}$ 独立同分布, 其共同分布为 $N\\left(\\mu, \\sigma^{2}\\right)$. 试求 $Y=a X_{1}+b X_{2}$ 与 $Z=a X_{1}-b X_{2}$ 的相关系数, 其中 $a$ 与 $b$ 为常数.\n29. 设二维随机变量 $(X, Y)$ 服从二维正态分布 $N(0,0,1,1, \\rho)$,  \n(1) 求 $E[\\max (X, Y)]$;  \n(2) 求 $X-Y$ 与 $X Y$ 的协方差及相关系数.  \n30. 设二维随机变量 $(X, Y)$ 服从区域 $D=\\{(x, y) \\mid 0<x<1,0<x<y<1\\}$ 上的均匀分布, 求 $X$与 $Y$ 的协方差及相关系数.\n31. 设二维随机变量 $(X, Y)$ 的联合密度函数为",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "28. 设 $X_{1}$ 与 $X_{2}$ 独立同分布, 其共同分布为 $N\\left(\\mu, \\sigma^{2}\\right)$. 试求 $Y=a X_{1}+b X_{2}$ 与 $Z=a X_{1}-b X_{2}$ 的相关系数, 其中 $a$ 与 $b$ 为常数.\n29. 设二维随机变量 $(X, Y)$ 服从二维正态分布 $N(0,0,1,1, \\rho)$,  \n(1) 求 $E[\\max (X, Y)]$;  \n(2) 求 $X-Y$ 与 $X Y$ 的协方差及相关系数.  \n30. 设二维随机变量 $(X, Y)$ 服从区域 $D=\\{(x, y) \\mid 0<x<1,0<x<y<1\\}$ 上的均匀分布, 求 $X$与 $Y$ 的协方差及相关系数.\n31. 设二维随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{6}{7}\\left(x^{2}+\\frac{x y}{2}\\right), & 0<x<1,0<y<2 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求 $X$ 与 $Y$ 的协方差及相关系数.  \n32. 设二维随机变量 $(X, Y)$ 在矩形  \n$$\nG=\\{(x, y) \\mid 0 \\leqslant x \\leqslant 2,0 \\leqslant y \\leqslant 1\\}\n$$  \n上服从均匀分布, 记  \n$$\nU=\\left\\{\\begin{array}{ll}\n1, & X>Y ; \\\\\n0, & X \\leqslant Y\n\\end{array} \\quad V= \\begin{cases}1, & X>2 Y \\\\\n0, & X \\leqslant 2 Y\\end{cases}\\right.\n$$  \n求 $U$ 和 $V$ 的相关系数.  \n33. 设二维随机变量 $(X, Y)$ 的联合密度函数如下, 试求 $(X, Y)$ 的协方差矩阵.  \n$$\np(x, y)= \\begin{cases}6 x y^{2}, & 0<x<1,0<y<1,  \\tag{1}\\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n$$",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n求 $X$ 与 $Y$ 的协方差及相关系数.  \n32. 设二维随机变量 $(X, Y)$ 在矩形  \n$$\nG=\\{(x, y) \\mid 0 \\leqslant x \\leqslant 2,0 \\leqslant y \\leqslant 1\\}\n$$  \n上服从均匀分布, 记  \n$$\nU=\\left\\{\\begin{array}{ll}\n1, & X>Y ; \\\\\n0, & X \\leqslant Y\n\\end{array} \\quad V= \\begin{cases}1, & X>2 Y \\\\\n0, & X \\leqslant 2 Y\\end{cases}\\right.\n$$  \n求 $U$ 和 $V$ 的相关系数.  \n33. 设二维随机变量 $(X, Y)$ 的联合密度函数如下, 试求 $(X, Y)$ 的协方差矩阵.  \n$$\np(x, y)= \\begin{cases}6 x y^{2}, & 0<x<1,0<y<1,  \\tag{1}\\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n$$\np(x, y)= \\begin{cases}\\frac{x+y}{8}, & 0<x<2,0<y<2  \\tag{2}\\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n34. 设 $a$ 为区间 $(0,1)$ 上的一个定点, 随机变量 $X$ 服从区间 $(0,1)$ 上的均匀分布, 以 $Y$ 表示点 $X$ 到 $a$ 的距离. 问 $a$ 为何值时 $X$ 与 $Y$ 不相关.\n35. 设随机向量 $\\left(X_{1}, X_{2}, X_{3}\\right)$ 满足条件  \n$$\n\\begin{aligned}\n& a X_{1}+b X_{2}+c X_{3}=0, \\\\\n& E\\left(X_{1}\\right)=E\\left(X_{2}\\right)=E\\left(X_{3}\\right)=d, \\\\\n& \\operatorname{Var}\\left(X_{1}\\right)=\\operatorname{Var}\\left(X_{2}\\right)=\\operatorname{Var}\\left(X_{3}\\right)=\\sigma^{2}\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n34. 设 $a$ 为区间 $(0,1)$ 上的一个定点, 随机变量 $X$ 服从区间 $(0,1)$ 上的均匀分布, 以 $Y$ 表示点 $X$ 到 $a$ 的距离. 问 $a$ 为何值时 $X$ 与 $Y$ 不相关.\n35. 设随机向量 $\\left(X_{1}, X_{2}, X_{3}\\right)$ 满足条件  \n$$\n\\begin{aligned}\n& a X_{1}+b X_{2}+c X_{3}=0, \\\\\n& E\\left(X_{1}\\right)=E\\left(X_{2}\\right)=E\\left(X_{3}\\right)=d, \\\\\n& \\operatorname{Var}\\left(X_{1}\\right)=\\operatorname{Var}\\left(X_{2}\\right)=\\operatorname{Var}\\left(X_{3}\\right)=\\sigma^{2}\n\\end{aligned}\n$$  \n其中 $a, b, c, d, \\sigma^{2}$ 均为常数, 求相关系数 $\\rho_{12}, \\rho_{23}, \\rho_{31}$.  \n36. 设随机向量 $X$ 与 $Y$ 都只能取两个值, 试证: $X$ 与 $Y$ 的独立性与不相关性是等价的.\n37. 设随机变量 $X$ 跟从区间 $(-0.5,0.5)$ 上的均匀分布, $Y=\\cos x$, 则 $X$ 与 $Y$ 有函数关系. 试证 $X$与 $Y$ 不相关, 即 $X$ 与 $Y$ 无线性关系.\n38. 设二维随机变量 $(X, Y)$ 服从单位圆内的均匀分布, 其联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{\\pi}, & x^{2}+y^{2}<1 \\\\ 0, & x^{2}+y^{2} \\geqslant 1\\end{cases}\n$$  \n试证 $X$ 与 $Y$ 不独立且 $X$ 与 $Y$ 不相关.  \n39. 设随机向量 $\\left(X_{1}, X_{2}, X_{3}\\right)$ 的相关系数为 $\\rho_{12}, \\rho_{23}, \\rho_{31}$, 证明  \n$$",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "36. 设随机向量 $X$ 与 $Y$ 都只能取两个值, 试证: $X$ 与 $Y$ 的独立性与不相关性是等价的.\n37. 设随机变量 $X$ 跟从区间 $(-0.5,0.5)$ 上的均匀分布, $Y=\\cos x$, 则 $X$ 与 $Y$ 有函数关系. 试证 $X$与 $Y$ 不相关, 即 $X$ 与 $Y$ 无线性关系.\n38. 设二维随机变量 $(X, Y)$ 服从单位圆内的均匀分布, 其联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{\\pi}, & x^{2}+y^{2}<1 \\\\ 0, & x^{2}+y^{2} \\geqslant 1\\end{cases}\n$$  \n试证 $X$ 与 $Y$ 不独立且 $X$ 与 $Y$ 不相关.  \n39. 设随机向量 $\\left(X_{1}, X_{2}, X_{3}\\right)$ 的相关系数为 $\\rho_{12}, \\rho_{23}, \\rho_{31}$, 证明  \n$$\n\\rho_{12}^{2}+\\rho_{23}^{2}+p_{31}^{2} \\leqslant 1+2 \\rho_{12} \\rho_{23} \\rho_{31} \\text {. }\n$$  \n40. 设随机向量 $\\left(X_{1}, X_{2}, X_{3}\\right)$ 的相关系数为 $\\rho_{12}, \\rho_{23}, \\rho_{31}$, 且  \n$$\nE\\left(X_{1}\\right)=E\\left(X_{2}\\right)=E\\left(X_{3}\\right)=0, \\quad \\operatorname{Var}\\left(X_{1}\\right)=\\operatorname{Var}\\left(X_{2}\\right)=\\operatorname{Var}\\left(X_{3}\\right)=\\sigma^{2}\n$$  \n令  \n$$\nY_{1}=X_{1}+X_{2}, \\quad Y_{2}=X_{2}+X_{3}, \\quad Y_{3}=X_{3}+X_{1}\n$$  \n证明: $Y_{1}, Y_{2}, Y_{3}$ 两两不相关的充要条件为 $\\rho_{12}+\\rho_{23}+\\rho_{31}=-1$.",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n40. 设随机向量 $\\left(X_{1}, X_{2}, X_{3}\\right)$ 的相关系数为 $\\rho_{12}, \\rho_{23}, \\rho_{31}$, 且  \n$$\nE\\left(X_{1}\\right)=E\\left(X_{2}\\right)=E\\left(X_{3}\\right)=0, \\quad \\operatorname{Var}\\left(X_{1}\\right)=\\operatorname{Var}\\left(X_{2}\\right)=\\operatorname{Var}\\left(X_{3}\\right)=\\sigma^{2}\n$$  \n令  \n$$\nY_{1}=X_{1}+X_{2}, \\quad Y_{2}=X_{2}+X_{3}, \\quad Y_{3}=X_{3}+X_{1}\n$$  \n证明: $Y_{1}, Y_{2}, Y_{3}$ 两两不相关的充要条件为 $\\rho_{12}+\\rho_{23}+\\rho_{31}=-1$.  \n41. 设 $X \\sim N(0,1), Y$ 各以 0.5 的概率取值 $\\pm 1$, 且假定 $X$ 与 $Y$ 相互独立. 令 $Z=X \\cdot Y$, 证明:  \n(1) $Z \\sim N(0,1)$;  \n(2) $X$ 与 $Z$ 不相关, 但不独立.  \n42. 设随机变量 $X$ 有密度函数 $p(x)$, 且密度函数 $p(x)$ 是偶函数, 假定 $E|X|^{3}<+\\infty$. 证明 $X$ 与 $Y=X^{2}$ 不相关, 但不独立.\n43. 设二维随机向量 $(X, Y)$ 服从二维正态分布, 且  \n$$\nE(X)=E(Y)=0, \\quad E(X Y)<0\n$$  \n证明: 对任意正常数 $a, b$ 有  \n$$\nP(X \\geqslant a, Y \\geqslant b) \\leqslant P(X \\geqslant a) P(Y \\geqslant b) .\n$$  \n44. 设随机向量 $(X, Y)$ 满足  \n$$\nE(X)=E(Y)=0, \\quad \\operatorname{Var}(X)=\\operatorname{Var}(Y)=1, \\quad \\operatorname{Cov}(X, Y)=\\rho",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) $Z \\sim N(0,1)$;  \n(2) $X$ 与 $Z$ 不相关, 但不独立.  \n42. 设随机变量 $X$ 有密度函数 $p(x)$, 且密度函数 $p(x)$ 是偶函数, 假定 $E|X|^{3}<+\\infty$. 证明 $X$ 与 $Y=X^{2}$ 不相关, 但不独立.\n43. 设二维随机向量 $(X, Y)$ 服从二维正态分布, 且  \n$$\nE(X)=E(Y)=0, \\quad E(X Y)<0\n$$  \n证明: 对任意正常数 $a, b$ 有  \n$$\nP(X \\geqslant a, Y \\geqslant b) \\leqslant P(X \\geqslant a) P(Y \\geqslant b) .\n$$  \n44. 设随机向量 $(X, Y)$ 满足  \n$$\nE(X)=E(Y)=0, \\quad \\operatorname{Var}(X)=\\operatorname{Var}(Y)=1, \\quad \\operatorname{Cov}(X, Y)=\\rho\n$$  \n证明: $E\\left[\\max \\left(X^{2}, Y^{2}\\right)\\right] \\leqslant 1+\\sqrt{1-\\rho^{2}}$.  \n45. 设随机变量 $X_{1}, X_{2}, \\ldots, X_{n}$ 中任意两个的相关系数都是 $\\rho$, 试证: $\\rho \\geqslant-1 /(n-1)$.",
        "metadata": {
            "Header 2": "习题 3.4"
        },
        "type": "Document"
    },
    {
        "page_content": "二维随机变量 $(X, Y)$ 之间主要表现为独立与相依两类关系. 由于在许多问题中有关的随机变量取值往往是彼此有影响的, 这就使得条件分布成为研究变量之间的相依关系的一个有力工具.",
        "metadata": {
            "Header 2": "3.5 条件分布和条件期望"
        },
        "type": "Document"
    },
    {
        "page_content": "对二维随机变量 $(X, Y)$ 而言, 所谓随机变量 $X$ 的条件分布, 就是在给定 $Y$ 取某个值的条件下 $X$ 的分布. 臂如, 记 $X$ 为人的体重, $Y$ 为人的身高, 则 $X$ 与 $Y$ 之间一般有相依关系, 现在如果限定 $Y=1.7(\\mathrm{~m})$, 在这个条件下体重 $X$ 的分布显然与 $X$ 的无条件分布 (无此限制下体重的分布) 会有很大的不同, 本节将给出条件分布的定义, 以便进一步在条件分布的基础上给出条件期望的概念.",
        "metadata": {
            "Header 2": "3.5 .1 条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "设二维离散随机变量 $(X, Y)$ 的联合分布列为  \n$$\np_{i j}=P\\left(X=x_{i}, Y=y_{j}\\right), \\quad i=1,2, \\ldots, \\quad j=1,2, \\ldots\n$$  \n仿照条件概率的定义, 我们很容易地如下给出离散随机变量的条件分布列.  \n定义 3.5.1. 对一切使 $P\\left(Y=y_{j}\\right)=p_{\\cdot j}=\\sum_{i=1}^{+\\infty} p_{i j}>0$ 的 $y_{j}$, 称  \n$$\n\\begin{equation*}\np_{i \\mid j}=P\\left(X=x_{i} \\mid Y=y_{j}\\right)=\\frac{P\\left(X=x_{i}, Y=y_{j}\\right)}{P\\left(Y=y_{j}\\right)}=\\frac{p_{i j}}{p_{\\cdot j}}, \\quad i=1,2, \\ldots \\tag{3.5.1}\n\\end{equation*}\n$$  \n为给定 $Y=y_{j}$ 条件下 $X$ 的条件分布列.\n同理, 对一切使 $P\\left(X=x_{i}\\right)=p_{i}=\\sum_{i=1}^{+\\infty} p_{i j}>$ 的 $x_{i}$, 称  \n$$\n\\begin{equation*}\np_{j \\mid i}=P\\left(Y=y_{j} \\mid X=x_{i}\\right)=\\frac{P\\left(X=x_{i}, Y=y_{i}\\right)}{P\\left(X=x_{i}\\right)}=\\frac{p_{i j}}{p_{i}}, \\quad j=1,2, \\ldots \\tag{3.5.2}\n\\end{equation*}\n$$  \n为给定 $X=x_{i}$ 条件下 $Y$ 的条件分布列.  \n有了条件分布列, 我们就可以给出离散随机变量的条件分布函数.  \n定义 3.5.2. 给定 $Y=y_{j}$ 条件下 $X$ 的条件分布函数为  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "一、离散随机变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n为给定 $Y=y_{j}$ 条件下 $X$ 的条件分布列.\n同理, 对一切使 $P\\left(X=x_{i}\\right)=p_{i}=\\sum_{i=1}^{+\\infty} p_{i j}>$ 的 $x_{i}$, 称  \n$$\n\\begin{equation*}\np_{j \\mid i}=P\\left(Y=y_{j} \\mid X=x_{i}\\right)=\\frac{P\\left(X=x_{i}, Y=y_{i}\\right)}{P\\left(X=x_{i}\\right)}=\\frac{p_{i j}}{p_{i}}, \\quad j=1,2, \\ldots \\tag{3.5.2}\n\\end{equation*}\n$$  \n为给定 $X=x_{i}$ 条件下 $Y$ 的条件分布列.  \n有了条件分布列, 我们就可以给出离散随机变量的条件分布函数.  \n定义 3.5.2. 给定 $Y=y_{j}$ 条件下 $X$ 的条件分布函数为  \n$$\n\\begin{equation*}\nF\\left(x \\mid y_{j}\\right)=\\sum_{x_{i} \\leqslant x} P\\left(X=x_{i} \\mid Y=y_{j}\\right)=\\sum_{x_{i} \\in x} p_{i \\mid j} \\tag{3.5.3}\n\\end{equation*}\n$$  \n给定 $X=x_{i}$ 条件下 $Y$ 的条件分布函数为  \n$$\n\\begin{equation*}\nF\\left(y \\mid x_{i}\\right)=\\sum_{y_{j} \\leqslant y} P\\left(Y=y_{j} \\mid X=x_{i}\\right)=\\sum_{y_{j} \\leqslant y} p_{j \\mid i} \\tag{3.5.4}\n\\end{equation*}\n$$  \n例 3.5.1: 设二维离散随机变量 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 1 | 2 | 3 | $p_{i}$ |\n| 1 | 0.1 | 0.3 | 0.2 | 0.6 |",
        "metadata": {
            "Header 2": "一、离散随机变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n给定 $X=x_{i}$ 条件下 $Y$ 的条件分布函数为  \n$$\n\\begin{equation*}\nF\\left(y \\mid x_{i}\\right)=\\sum_{y_{j} \\leqslant y} P\\left(Y=y_{j} \\mid X=x_{i}\\right)=\\sum_{y_{j} \\leqslant y} p_{j \\mid i} \\tag{3.5.4}\n\\end{equation*}\n$$  \n例 3.5.1: 设二维离散随机变量 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 1 | 2 | 3 | $p_{i}$ |\n| 1 | 0.1 | 0.3 | 0.2 | 0.6 |\n| 2 | 0.2 | 0.05 | 0.15 | 0.4 |\n| $p \\cdot j$ | 0.3 | 0.35 | 0.35 | 1.0 |  \n因为 $P(X=1)=p_{1}=0.6$ 所以用第一行各元素分别除以 0.6 , 就可得给定 $X=1$ 下, $Y$ 的条件分布列为  \n| $Y \\mid X=1$ | 1 | 2 | 3 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $1 / 6$ | $1 / 2$ | $1 / 3$ |  \n用第二行各元素分别除以 0.4 , 就可得给定 $X=2$ 下, $Y$ 的条件分布列为  \n| $Y \\mid X=2$ | 1 | 2 | 3 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $1 / 2$ | $1 / 8$ | $3 / 8$ |  \n用第一列各元素分别除以 0.3 , 就可得给定 $Y=1$ 下, $X$ 的条件分布列为  \n| $X \\mid Y=1$ | 1 | 2 |\n| :---: | :---: | :---: |\n| $P$ | $1 / 3$ | $2 / 3$ |  \n用第二列各元素分别除以 0.35 , 就可得给定 $Y=2$ 下, $X$ 的条件分布列为  \n| $X \\mid Y=2$ | 1 | 2 |",
        "metadata": {
            "Header 2": "一、离散随机变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| $Y \\mid X=1$ | 1 | 2 | 3 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $1 / 6$ | $1 / 2$ | $1 / 3$ |  \n用第二行各元素分别除以 0.4 , 就可得给定 $X=2$ 下, $Y$ 的条件分布列为  \n| $Y \\mid X=2$ | 1 | 2 | 3 |\n| :---: | :---: | :---: | :---: |\n| $P$ | $1 / 2$ | $1 / 8$ | $3 / 8$ |  \n用第一列各元素分别除以 0.3 , 就可得给定 $Y=1$ 下, $X$ 的条件分布列为  \n| $X \\mid Y=1$ | 1 | 2 |\n| :---: | :---: | :---: |\n| $P$ | $1 / 3$ | $2 / 3$ |  \n用第二列各元素分别除以 0.35 , 就可得给定 $Y=2$ 下, $X$ 的条件分布列为  \n| $X \\mid Y=2$ | 1 | 2 |\n| :---: | :---: | :---: |\n| $P$ | $6 / 7$ | $1 / 7$ |  \n用第三列各元素分别除以 0.35 , 就可得给定 $Y=3$ 下, $X$ 的条件分布列为  \n| $X \\mid Y=3$ | 1 | 2 |\n| :---: | :---: | :---: |\n| $P$ | $4 / 7$ | $3 / 7$ |  \n从这个例子看出, 二维联合分布列只有一个, 而条件分布列有 5 个. 若 $X$ 与 $Y$ 的取值更多, 则条件分布也更多, 每个条件分布都从一个侧面描述了一种状态下的特定分布. 可见条件分布的内容丰富, 其应用也更广。  \n例 3.5.2: 设随机变量 $X$ 与 $Y$ 相互独立, 且 $X \\sim P\\left(\\lambda_{1}\\right), Y \\sim P\\left(\\lambda_{2}\\right)$. 在已知 $X+Y=n$ 的条件下,求 $X$ 的条件分布.  \n解: 因为独立泊松变量的和仍为泊松变量, 即 $X+Y \\sim P\\left(\\lambda_{1}+\\lambda_{2}\\right)$, 所以  \n$$",
        "metadata": {
            "Header 2": "一、离散随机变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| $P$ | $6 / 7$ | $1 / 7$ |  \n用第三列各元素分别除以 0.35 , 就可得给定 $Y=3$ 下, $X$ 的条件分布列为  \n| $X \\mid Y=3$ | 1 | 2 |\n| :---: | :---: | :---: |\n| $P$ | $4 / 7$ | $3 / 7$ |  \n从这个例子看出, 二维联合分布列只有一个, 而条件分布列有 5 个. 若 $X$ 与 $Y$ 的取值更多, 则条件分布也更多, 每个条件分布都从一个侧面描述了一种状态下的特定分布. 可见条件分布的内容丰富, 其应用也更广。  \n例 3.5.2: 设随机变量 $X$ 与 $Y$ 相互独立, 且 $X \\sim P\\left(\\lambda_{1}\\right), Y \\sim P\\left(\\lambda_{2}\\right)$. 在已知 $X+Y=n$ 的条件下,求 $X$ 的条件分布.  \n解: 因为独立泊松变量的和仍为泊松变量, 即 $X+Y \\sim P\\left(\\lambda_{1}+\\lambda_{2}\\right)$, 所以  \n$$\nP(X=k \\mid X+Y=n)=\\frac{P(X=k, X+Y=n)}{P(X+Y=n)}\n$$  \n$$\n\\begin{aligned}\n& =\\frac{P(X=k) P(Y=n-k)}{P(X+Y=n)} \\\\\n& =\\frac{\\frac{\\lambda_{1}^{k}}{k !} \\mathrm{e}^{-\\lambda_{1}} \\cdot \\frac{\\lambda_{2}^{n-k}}{(n-k) !} \\mathrm{e}^{-\\lambda_{2}}}{\\frac{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{n}}{n !} \\mathrm{e}^{-\\left(\\lambda_{1}+\\lambda_{2}\\right)}} \\\\\n& =\\frac{n !}{k !(n-k) !} \\frac{\\lambda_{1}^{k} \\lambda_{2}^{n-k}}{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{n}} \\\\\n& =\\left(\\begin{array}{l}\nn \\\\\nk",
        "metadata": {
            "Header 2": "一、离散随机变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP(X=k \\mid X+Y=n)=\\frac{P(X=k, X+Y=n)}{P(X+Y=n)}\n$$  \n$$\n\\begin{aligned}\n& =\\frac{P(X=k) P(Y=n-k)}{P(X+Y=n)} \\\\\n& =\\frac{\\frac{\\lambda_{1}^{k}}{k !} \\mathrm{e}^{-\\lambda_{1}} \\cdot \\frac{\\lambda_{2}^{n-k}}{(n-k) !} \\mathrm{e}^{-\\lambda_{2}}}{\\frac{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{n}}{n !} \\mathrm{e}^{-\\left(\\lambda_{1}+\\lambda_{2}\\right)}} \\\\\n& =\\frac{n !}{k !(n-k) !} \\frac{\\lambda_{1}^{k} \\lambda_{2}^{n-k}}{\\left(\\lambda_{1}+\\lambda_{2}\\right)^{n}} \\\\\n& =\\left(\\begin{array}{l}\nn \\\\\nk\n\\end{array}\\right)\\left(\\frac{\\lambda_{1}}{\\lambda_{1}+\\lambda_{2}}\\right)^{k}\\left(\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}\\right)^{n-k}, \\quad k=0,1, \\cdots, n .\n\\end{aligned}\n$$  \n即在 $X+Y=n$ 的条件下, $X$ 服从二项分布 $b(n, p)$, 其中 $p=\\lambda_{1} /\\left(\\lambda_{1}+\\lambda_{2}\\right)$.  \n例 3.5.3: 设在一段时间内进人某一商店的顾客人数 $X$ 服从泊松分布 $P(\\lambda)$, 每个顾客购买某种物品的概率为 $p$, 并且各个顾客是否购买该种物品相互独立, 求进人商店的顾客购买这种物品的人数 $Y$ 的分布列.  \n解: 由题意知  \n$$\nP\\{X=m\\}=\\frac{\\lambda^{m}}{m !} \\mathrm{e}^{-\\lambda}, \\quad m=0,1,2, \\ldots",
        "metadata": {
            "Header 2": "一、离散随机变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array}\\right)\\left(\\frac{\\lambda_{1}}{\\lambda_{1}+\\lambda_{2}}\\right)^{k}\\left(\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}\\right)^{n-k}, \\quad k=0,1, \\cdots, n .\n\\end{aligned}\n$$  \n即在 $X+Y=n$ 的条件下, $X$ 服从二项分布 $b(n, p)$, 其中 $p=\\lambda_{1} /\\left(\\lambda_{1}+\\lambda_{2}\\right)$.  \n例 3.5.3: 设在一段时间内进人某一商店的顾客人数 $X$ 服从泊松分布 $P(\\lambda)$, 每个顾客购买某种物品的概率为 $p$, 并且各个顾客是否购买该种物品相互独立, 求进人商店的顾客购买这种物品的人数 $Y$ 的分布列.  \n解: 由题意知  \n$$\nP\\{X=m\\}=\\frac{\\lambda^{m}}{m !} \\mathrm{e}^{-\\lambda}, \\quad m=0,1,2, \\ldots\n$$  \n在进人商店的人数 $X=m$ 的条件下, 购买某种物品的人数 $Y$ 的条件分布为二项分布 $b(m, p)$, 即  \n$$\nP\\{Y=k \\mid X=m\\}=\\left(\\begin{array}{c}\nm \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{m-k}, \\quad k=0,1,2, \\cdots, m .\n$$  \n由全概率公式有  \n$$\n\\begin{aligned}\nP\\{Y=k\\} & =\\sum_{m=k}^{+\\infty} P\\{X=m\\} P\\{Y=k \\mid X=m\\} \\\\\n& =\\sum_{m=k}^{+\\infty} \\frac{\\lambda^{m}}{m !} \\mathrm{e}^{-\\lambda} \\cdot \\frac{m !}{k !(m-k) !} p^{k}(1-p)^{m-k} \\\\\n& =\\mathrm{e}^{-\\lambda} \\sum_{m=k}^{+\\infty} \\frac{\\lambda^{m}}{k !(m-k) !} p^{k}(1-p)^{m-k} \\\\",
        "metadata": {
            "Header 2": "一、离散随机变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n在进人商店的人数 $X=m$ 的条件下, 购买某种物品的人数 $Y$ 的条件分布为二项分布 $b(m, p)$, 即  \n$$\nP\\{Y=k \\mid X=m\\}=\\left(\\begin{array}{c}\nm \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{m-k}, \\quad k=0,1,2, \\cdots, m .\n$$  \n由全概率公式有  \n$$\n\\begin{aligned}\nP\\{Y=k\\} & =\\sum_{m=k}^{+\\infty} P\\{X=m\\} P\\{Y=k \\mid X=m\\} \\\\\n& =\\sum_{m=k}^{+\\infty} \\frac{\\lambda^{m}}{m !} \\mathrm{e}^{-\\lambda} \\cdot \\frac{m !}{k !(m-k) !} p^{k}(1-p)^{m-k} \\\\\n& =\\mathrm{e}^{-\\lambda} \\sum_{m=k}^{+\\infty} \\frac{\\lambda^{m}}{k !(m-k) !} p^{k}(1-p)^{m-k} \\\\\n& =\\mathrm{e}^{-\\lambda} \\frac{(\\lambda p)^{k}}{k !} \\sum_{m=k}^{+\\infty} \\frac{[(1-p) \\lambda]^{m-k}}{(m-k) !} \\\\\n& =\\frac{(\\lambda p)^{k}}{k !} \\mathrm{e}^{-\\lambda} \\mathrm{e}^{\\lambda(1-p)} \\\\\n& =\\frac{(\\lambda p)^{k}}{k !} \\mathrm{e}^{-\\lambda p}, \\quad k=0,1,2, \\ldots\n\\end{aligned}\n$$  \n即 $Y$ 服从参数为 $\\lambda p$ 的泊松分布.  \n这个例子告诉我们: 在直接寻求 $Y$ 的分布有困难时, 有时借助条件分布可把困难克服了.",
        "metadata": {
            "Header 2": "一、离散随机变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "设二维连续随机变量 $(X, Y)$ 的联合密度函数为 $p(x, y)$, 边际密度函数为 $p_{X}(x), p_{Y}(y)$.  \n在离散随机变量场合, 其条件分布函数为 $P(X \\leqslant x \\mid Y=y)$. 但是, 因为连续随机变量取某个值的概率为零, 即 $P(Y=y)=0$, 所以无法用条件概率直接计算 $P(X \\leqslant x \\mid Y=y)$, 一个很自然的想法是: 将 $P(X \\leqslant x \\mid Y=y)$ 看成是 $h \\rightarrow 0$ 时 $P(X \\leqslant x \\mid y \\leqslant Y \\leqslant y+h)$ 的极限, 即  \n$$\n\\begin{aligned}\nP(X \\leqslant x \\mid Y=y) & =\\lim _{h \\rightarrow 0} P(X \\leqslant x \\mid y \\leqslant Y \\leqslant y+h) \\\\\n& =\\lim _{h \\rightarrow 0} \\frac{P(X \\leqslant x, y \\leqslant Y \\leqslant y+h)}{P(y \\leqslant Y \\leqslant y+h)} \\\\\n& =\\lim _{h \\rightarrow 0} \\frac{\\int_{-\\infty}^{x} \\int_{y}^{y+h} p(u, v) \\mathrm{d} v \\mathrm{~d} u}{\\int_{y}^{y+h} p_{Y}(v) \\mathrm{d} v}\n\\end{aligned}\n$$  \n$$\n=\\lim _{h \\rightarrow 0} \\frac{\\int_{-\\infty}^{x}\\left\\{\\frac{1}{h} \\int_{y}^{y+h} p(u, v) \\mathrm{d} v\\right\\} \\mathrm{d} u}{\\frac{1}{h} \\int_{y}^{y+h} p_{Y}(v) \\mathrm{d} v}\n$$  \n当 $p_{Y}(y), p(x, y)$ 在 $y$ 处连续时, 由积分中值定理可得  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "二、连续变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\lim _{h \\rightarrow 0} \\frac{\\int_{-\\infty}^{x} \\int_{y}^{y+h} p(u, v) \\mathrm{d} v \\mathrm{~d} u}{\\int_{y}^{y+h} p_{Y}(v) \\mathrm{d} v}\n\\end{aligned}\n$$  \n$$\n=\\lim _{h \\rightarrow 0} \\frac{\\int_{-\\infty}^{x}\\left\\{\\frac{1}{h} \\int_{y}^{y+h} p(u, v) \\mathrm{d} v\\right\\} \\mathrm{d} u}{\\frac{1}{h} \\int_{y}^{y+h} p_{Y}(v) \\mathrm{d} v}\n$$  \n当 $p_{Y}(y), p(x, y)$ 在 $y$ 处连续时, 由积分中值定理可得  \n$$\n\\begin{aligned}\n& \\lim _{h \\rightarrow 0} \\frac{1}{h} \\int_{y}^{y+h} p_{Y}(v) \\mathrm{d} v=p_{Y}(y), \\\\\n& \\lim _{h \\rightarrow 0} \\frac{1}{h} \\int_{y}^{y+h} p(u, v) \\mathrm{d} v=p(u, y) .\n\\end{aligned}\n$$  \n所以  \n$$\nP(X \\leqslant x \\mid Y=y)=\\int_{-\\infty}^{x} \\frac{p(u, y)}{p_{Y}(y)} \\mathrm{d} u .\n$$  \n至此, 我们可以定义连续随机变量的条件分布如下.  \n定义 3.5.3. 对一切使 $p_{Y}(y)>0$ 的 $y$, 给定 $Y=y$ 条件下 $X$ 的条件分布函数和条件密度函数分别为  \n$$\n\\begin{align*}\n& F(x \\mid y)=\\int_{-\\infty}^{x} \\frac{p(u, y)}{p_{Y}(y)} \\mathrm{d} u,  \\tag{3.5.5}\\\\\n& p(x \\mid y)=\\frac{p(x, y)}{p_{Y}(y)} . \\tag{3.5.6}\n\\end{align*}\n$$",
        "metadata": {
            "Header 2": "二、连续变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& \\lim _{h \\rightarrow 0} \\frac{1}{h} \\int_{y}^{y+h} p(u, v) \\mathrm{d} v=p(u, y) .\n\\end{aligned}\n$$  \n所以  \n$$\nP(X \\leqslant x \\mid Y=y)=\\int_{-\\infty}^{x} \\frac{p(u, y)}{p_{Y}(y)} \\mathrm{d} u .\n$$  \n至此, 我们可以定义连续随机变量的条件分布如下.  \n定义 3.5.3. 对一切使 $p_{Y}(y)>0$ 的 $y$, 给定 $Y=y$ 条件下 $X$ 的条件分布函数和条件密度函数分别为  \n$$\n\\begin{align*}\n& F(x \\mid y)=\\int_{-\\infty}^{x} \\frac{p(u, y)}{p_{Y}(y)} \\mathrm{d} u,  \\tag{3.5.5}\\\\\n& p(x \\mid y)=\\frac{p(x, y)}{p_{Y}(y)} . \\tag{3.5.6}\n\\end{align*}\n$$  \n同理对一切使 $p_{Y}(y)>0$ 的 $x$, 给定 $X=x$ 条件下 $Y$ 的条件分布函数和条件密度函数分别为  \n$$\n\\begin{align*}\n& F(y \\mid x)=\\int_{-\\infty}^{y} \\frac{p(x, v)}{p_{X}(x)} \\mathrm{d} v  \\tag{3.5.7}\\\\\n& p(y \\mid x)=\\frac{p(x, y)}{p_{X}(x)} \\tag{3.5.8}\n\\end{align*}\n$$  \n例 3.5.4: 设 $(X, Y)$ 服从二维正态分布 $N\\left(u_{1}, u_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$ 由边际分布知 $X$ 服从正态分布 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$, $Y$ 服从正态分布 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$. 现在来求条件分布. 根据式 (3.5.6) 得  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "二、连续变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n同理对一切使 $p_{Y}(y)>0$ 的 $x$, 给定 $X=x$ 条件下 $Y$ 的条件分布函数和条件密度函数分别为  \n$$\n\\begin{align*}\n& F(y \\mid x)=\\int_{-\\infty}^{y} \\frac{p(x, v)}{p_{X}(x)} \\mathrm{d} v  \\tag{3.5.7}\\\\\n& p(y \\mid x)=\\frac{p(x, y)}{p_{X}(x)} \\tag{3.5.8}\n\\end{align*}\n$$  \n例 3.5.4: 设 $(X, Y)$ 服从二维正态分布 $N\\left(u_{1}, u_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$ 由边际分布知 $X$ 服从正态分布 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$, $Y$ 服从正态分布 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$. 现在来求条件分布. 根据式 (3.5.6) 得  \n$$\n\\begin{aligned}\np(x \\mid y) & =\\frac{p(x, y)}{p_{Y}(y)} \\\\\n& =\\frac{\\exp \\left\\{-1 /\\left\\{2\\left(1-\\rho^{2}\\right)\\left[\\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\\right\\}\\right\\} /\\left(2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}\\right)}{\\exp \\left\\{-\\left(y-\\mu_{2}\\right)^{2} /\\left(2 \\sigma_{2}^{2}\\right)\\right\\} / \\sqrt{2 \\pi}} \\\\",
        "metadata": {
            "Header 2": "二、连续变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\np(x \\mid y) & =\\frac{p(x, y)}{p_{Y}(y)} \\\\\n& =\\frac{\\exp \\left\\{-1 /\\left\\{2\\left(1-\\rho^{2}\\right)\\left[\\frac{\\left(x-\\mu_{1}\\right)^{2}}{\\sigma_{1}^{2}}-2 \\rho \\frac{\\left(x-\\mu_{1}\\right)\\left(y-\\mu_{2}\\right)}{\\sigma_{1} \\sigma_{2}}+\\frac{\\left(y-\\mu_{2}\\right)^{2}}{\\sigma_{2}^{2}}\\right]\\right\\}\\right\\} /\\left(2 \\pi \\sigma_{1} \\sigma_{2} \\sqrt{1-\\rho^{2}}\\right)}{\\exp \\left\\{-\\left(y-\\mu_{2}\\right)^{2} /\\left(2 \\sigma_{2}^{2}\\right)\\right\\} / \\sqrt{2 \\pi}} \\\\\n& =\\exp \\left\\{-\\left[x-\\left(\\mu_{1}+\\rho \\frac{\\partial_{1}}{\\sigma_{2}}\\left(y-\\mu_{2}\\right)\\right)\\right]^{2} / 2 \\sigma_{1}^{2}\\left(1-p^{2}\\right)\\right\\} /\\left(\\sqrt{2 \\pi} \\sigma_{1} \\sqrt{1-\\rho^{2}}\\right)\n\\end{aligned}\n$$  \n这正是正态密度函数, 其均值 $\\mu_{3}$ 和方差 $\\sigma_{3}^{2}$ 分别为  \n$$\n\\mu_{3}=\\mu_{1}+\\rho \\frac{\\sigma_{1}}{\\sigma_{2}}\\left(y-\\mu_{2}\\right) ; \\quad \\sigma_{3}^{2}=\\sigma_{1}^{2}\\left(1-\\rho^{2}\\right)\n$$",
        "metadata": {
            "Header 2": "二、连续变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\exp \\left\\{-\\left[x-\\left(\\mu_{1}+\\rho \\frac{\\partial_{1}}{\\sigma_{2}}\\left(y-\\mu_{2}\\right)\\right)\\right]^{2} / 2 \\sigma_{1}^{2}\\left(1-p^{2}\\right)\\right\\} /\\left(\\sqrt{2 \\pi} \\sigma_{1} \\sqrt{1-\\rho^{2}}\\right)\n\\end{aligned}\n$$  \n这正是正态密度函数, 其均值 $\\mu_{3}$ 和方差 $\\sigma_{3}^{2}$ 分别为  \n$$\n\\mu_{3}=\\mu_{1}+\\rho \\frac{\\sigma_{1}}{\\sigma_{2}}\\left(y-\\mu_{2}\\right) ; \\quad \\sigma_{3}^{2}=\\sigma_{1}^{2}\\left(1-\\rho^{2}\\right)\n$$  \n类似可得, 在给定 $X=x$ 的条件下, $Y$ 的条件分布仍为正态分布 $N\\left(\\mu_{4}, \\sigma_{4}^{2}\\right)$, 其均值和方差分别为  \n$$\n\\mu_{4}=\\mu_{2}+\\rho \\frac{\\sigma_{2}}{\\sigma_{1}}\\left(x-\\mu_{1}\\right) ; \\quad \\sigma_{4}^{2}=\\sigma_{2}^{2}\\left(1-\\rho^{2}\\right)\n$$  \n由此也可以看出: 二维正态分布的边际分布和条件分布都是一维正态分布, 这是正态分布的一个重要性质.  \n例 3.5.5: 设 $(X, Y)$ 服从 $G=\\left\\{(x, y) ; x^{2}+y^{2} \\leqslant 1\\right\\}$ 上的均匀分布, 试求给定 $Y=y$ 条件下 $X$ 的条件密度函数 $p(x \\mid y)$.  \n解: 因为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{\\pi}, & x^{2}+y^{2} \\leqslant 1 \\\\ 0 & \\text { 其他. }\\end{cases}\n$$  \n由此得 $Y$ 的边际密度函数为  \n$$",
        "metadata": {
            "Header 2": "二、连续变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\mu_{4}=\\mu_{2}+\\rho \\frac{\\sigma_{2}}{\\sigma_{1}}\\left(x-\\mu_{1}\\right) ; \\quad \\sigma_{4}^{2}=\\sigma_{2}^{2}\\left(1-\\rho^{2}\\right)\n$$  \n由此也可以看出: 二维正态分布的边际分布和条件分布都是一维正态分布, 这是正态分布的一个重要性质.  \n例 3.5.5: 设 $(X, Y)$ 服从 $G=\\left\\{(x, y) ; x^{2}+y^{2} \\leqslant 1\\right\\}$ 上的均匀分布, 试求给定 $Y=y$ 条件下 $X$ 的条件密度函数 $p(x \\mid y)$.  \n解: 因为  \n$$\np(x, y)= \\begin{cases}\\frac{1}{\\pi}, & x^{2}+y^{2} \\leqslant 1 \\\\ 0 & \\text { 其他. }\\end{cases}\n$$  \n由此得 $Y$ 的边际密度函数为  \n$$\np_{Y}(y)= \\begin{cases}\\frac{2}{\\pi} \\sqrt{1-y^{2}}, & -1 \\leqslant y \\leqslant 1 \\\\ 0 & \\text { 其他. }\\end{cases}\n$$  \n所以当 $-1<y<1$ 时, 有  \n$$\n\\begin{aligned}\np(x \\mid y) & =\\frac{p(x, y)}{p_{y}(y)} \\\\\n& = \\begin{cases}\\frac{1 / \\pi}{(2 / \\pi) \\sqrt{1-y^{2}}}=\\frac{1}{2 \\sqrt{1-y^{2}}}, & -\\sqrt{1-y^{2}} \\leqslant x \\leqslant \\sqrt{1-y^{2}} ; \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$  \n将 $y=0$ 和 $y=0.5$ 分别代人上式可得 (两个均匀分布)  \n$$\n\\begin{gathered}\np(x \\mid y=0)= \\begin{cases}\\frac{1}{2}, & -1 \\leqslant x \\leqslant 1 \\\\",
        "metadata": {
            "Header 2": "二、连续变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n所以当 $-1<y<1$ 时, 有  \n$$\n\\begin{aligned}\np(x \\mid y) & =\\frac{p(x, y)}{p_{y}(y)} \\\\\n& = \\begin{cases}\\frac{1 / \\pi}{(2 / \\pi) \\sqrt{1-y^{2}}}=\\frac{1}{2 \\sqrt{1-y^{2}}}, & -\\sqrt{1-y^{2}} \\leqslant x \\leqslant \\sqrt{1-y^{2}} ; \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$  \n将 $y=0$ 和 $y=0.5$ 分别代人上式可得 (两个均匀分布)  \n$$\n\\begin{gathered}\np(x \\mid y=0)= \\begin{cases}\\frac{1}{2}, & -1 \\leqslant x \\leqslant 1 \\\\\n0, & \\text { 其他. }\\end{cases} \\\\\np(x \\mid y=0.5)= \\begin{cases}\\frac{1}{\\sqrt{3}}, & -\\frac{\\sqrt{3}}{2} \\leqslant x \\leqslant \\frac{\\sqrt{3}}{2} \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{gathered}\n$$  \n进一步有: 当 $-1<y<1$ 时, 给定 $Y=y$ 条件下, $X$ 服从 $\\left(-\\sqrt{1-y^{2}}, \\sqrt{1-y^{2}}\\right)$ 上的均匀分布.同理有: 当 $-1<x<1$ 时, 给定 $X=x$ 条件下, $Y$ 服从 $\\left(-\\sqrt{1-x^{2}}, \\sqrt{1-x^{2}}\\right)$ 上的均匀分布.",
        "metadata": {
            "Header 2": "二、连续变量的条件分布"
        },
        "type": "Document"
    },
    {
        "page_content": "有了条件分布密度函数的概念, 我们可以顺便给出连续随机变量场合的全概率公式和贝叶斯公式. 将式 (3.5.6) 和式 (3.5.8) 改写为  \n$$\n\\begin{align*}\n& p(x, y)=p_{X}(x) p(y \\mid x),  \\tag{3.5.9}\\\\\n& p(x, y)=p_{Y}(y) p(x \\mid y) . \\tag{3.5.10}\n\\end{align*}\n$$  \n再对 $p(x, y)$ 求边际密度函数, 就得全概率公式的密度函数形式:  \n$$\n\\begin{align*}\n& p_{Y}(y)=\\int_{-\\infty}^{+\\infty} p_{X}(x) p(y \\mid x) \\mathrm{d} x  \\tag{3.5.11}\\\\\n& p_{X}(x)=\\int_{-\\infty}^{+\\infty} p_{Y}(y) p(x \\mid y) \\mathrm{d} y \\tag{3.5.12}\n\\end{align*}\n$$  \n将式 (3.5.9) 代人式 (3.5.6) 式的分子, 式 (3.5.11) 代人式 (3.5.6) 式的分母, 就得贝叶斯公式的密度函数形式:  \n$$\n\\begin{equation*}\np(x \\mid y)=\\frac{p_{X}(x) p(y \\mid x)}{\\int_{-\\infty}^{+\\infty} p_{X}(x) p(y \\mid x) \\mathrm{d} x} \\tag{3.5.13}\n\\end{equation*}\n$$  \n或  \n$$\n\\begin{equation*}\np(y \\mid x)=\\frac{p_{Y}(y) p(x \\mid y)}{\\int_{-\\infty}^{+\\infty} p_{y}(y) p(x \\mid y) \\mathrm{d} y} \\tag{3.5.14}\n\\end{equation*}\n$$  \n注意, 虽然由边际分布无法得到联合分布, 但式 (3.5.9) 和式 (3.5.10) 式说明, 由边际分布和条件分布就可以得到联合分布.",
        "metadata": {
            "Header 2": "三、连续场合的全概率公式和贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{align*}\n$$  \n将式 (3.5.9) 代人式 (3.5.6) 式的分子, 式 (3.5.11) 代人式 (3.5.6) 式的分母, 就得贝叶斯公式的密度函数形式:  \n$$\n\\begin{equation*}\np(x \\mid y)=\\frac{p_{X}(x) p(y \\mid x)}{\\int_{-\\infty}^{+\\infty} p_{X}(x) p(y \\mid x) \\mathrm{d} x} \\tag{3.5.13}\n\\end{equation*}\n$$  \n或  \n$$\n\\begin{equation*}\np(y \\mid x)=\\frac{p_{Y}(y) p(x \\mid y)}{\\int_{-\\infty}^{+\\infty} p_{y}(y) p(x \\mid y) \\mathrm{d} y} \\tag{3.5.14}\n\\end{equation*}\n$$  \n注意, 虽然由边际分布无法得到联合分布, 但式 (3.5.9) 和式 (3.5.10) 式说明, 由边际分布和条件分布就可以得到联合分布.  \n例 3.5.6: 设 $X \\sim N\\left(\\mu, \\sigma_{1}^{2}\\right)$, 在 $X=x$ 的条件下 $Y \\mid X=x \\sim N\\left(x, \\sigma_{2}^{2}\\right)$. 试求 $Y$ 的 (无条件) 密度函数 $p_{Y}(y)$.  \n解: 由题意知  \n$$\n\\begin{aligned}\n& p_{X}(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{1}} \\exp \\left\\{-\\frac{(x-\\mu)^{2}}{2 \\sigma_{1}^{2}}\\right\\} \\\\\n& p(y \\mid x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{2}} \\exp \\left\\{-\\frac{(y-x)^{2}}{2 \\sigma_{2}^{2}}\\right\\} .\n\\end{aligned}\n$$  \n所以由式 (3.5.11) 得  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "三、连续场合的全概率公式和贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "例 3.5.6: 设 $X \\sim N\\left(\\mu, \\sigma_{1}^{2}\\right)$, 在 $X=x$ 的条件下 $Y \\mid X=x \\sim N\\left(x, \\sigma_{2}^{2}\\right)$. 试求 $Y$ 的 (无条件) 密度函数 $p_{Y}(y)$.  \n解: 由题意知  \n$$\n\\begin{aligned}\n& p_{X}(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{1}} \\exp \\left\\{-\\frac{(x-\\mu)^{2}}{2 \\sigma_{1}^{2}}\\right\\} \\\\\n& p(y \\mid x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma_{2}} \\exp \\left\\{-\\frac{(y-x)^{2}}{2 \\sigma_{2}^{2}}\\right\\} .\n\\end{aligned}\n$$  \n所以由式 (3.5.11) 得  \n$$\n\\begin{aligned}\np_{Y}(y) & =\\int_{-\\infty}^{+\\infty} p_{X}(x) p(y \\mid x) \\mathrm{d} x \\\\\n& =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{(x-\\mu)^{2}}{2 \\sigma_{1}^{2}}-\\frac{(y-x)^{2}}{2 \\sigma_{2}^{2}}\\right\\} \\mathrm{d} x \\\\\n& =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{1}{2}\\left[\\left(\\frac{1}{\\sigma_{1}^{2}}+\\frac{1}{\\sigma_{2}^{2}}\\right) x^{2}-2\\left(\\frac{y}{\\sigma_{2}^{2}}+\\frac{\\mu}{\\sigma_{1}^{2}}\\right) x+\\frac{y^{2}}{\\sigma_{2}^{2}}\\right]\\right\\} \\mathrm{d} x",
        "metadata": {
            "Header 2": "三、连续场合的全概率公式和贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{(x-\\mu)^{2}}{2 \\sigma_{1}^{2}}-\\frac{(y-x)^{2}}{2 \\sigma_{2}^{2}}\\right\\} \\mathrm{d} x \\\\\n& =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{1}{2}\\left[\\left(\\frac{1}{\\sigma_{1}^{2}}+\\frac{1}{\\sigma_{2}^{2}}\\right) x^{2}-2\\left(\\frac{y}{\\sigma_{2}^{2}}+\\frac{\\mu}{\\sigma_{1}^{2}}\\right) x+\\frac{y^{2}}{\\sigma_{2}^{2}}\\right]\\right\\} \\mathrm{d} x\n\\end{aligned}\n$$  \n记 $c=\\frac{\\sigma_{1}^{2} \\sigma_{2}^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}$, 则上式化成  \n$$\n\\begin{aligned}\np_{Y}(y) & =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{1}{2} c^{-1}\\left[x-c\\left(\\frac{\\mu}{\\sigma_{1}^{2}}+\\frac{y}{\\sigma_{2}^{2}}\\right)\\right]^{2}-\\frac{1}{2} \\frac{(y-\\mu)^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}\\right\\} \\mathrm{d} x \\\\",
        "metadata": {
            "Header 2": "三、连续场合的全概率公式和贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n记 $c=\\frac{\\sigma_{1}^{2} \\sigma_{2}^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}$, 则上式化成  \n$$\n\\begin{aligned}\np_{Y}(y) & =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\int_{-\\infty}^{+\\infty} \\exp \\left\\{-\\frac{1}{2} c^{-1}\\left[x-c\\left(\\frac{\\mu}{\\sigma_{1}^{2}}+\\frac{y}{\\sigma_{2}^{2}}\\right)\\right]^{2}-\\frac{1}{2} \\frac{(y-\\mu)^{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}}\\right\\} \\mathrm{d} x \\\\\n& =\\frac{1}{2 \\pi \\sigma_{1} \\sigma_{2}} \\sqrt{2 \\pi c} \\exp \\left\\{-\\frac{(y-\\mu)^{2}}{2\\left(\\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)}\\right\\} \\\\\n& =\\frac{1}{\\sqrt{2 \\pi} \\sqrt{\\sigma_{1}^{2}+\\sigma_{2}^{2}}} \\exp \\left\\{-\\frac{(y-\\mu)^{2}}{2\\left(\\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)}\\right\\} .\n\\end{aligned}\n$$  \n这表明 $Y$ 仍服从正态分布 $N\\left(\\mu, \\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)$.",
        "metadata": {
            "Header 2": "三、连续场合的全概率公式和贝叶斯公式"
        },
        "type": "Document"
    },
    {
        "page_content": "条件分布的数学期望称为条件数学期望, 它的定义如下  \n定义 3.5.4. 条件分布的数学期望 (若存在) 称为条件期望, 其定义如下:  \n$$\n\\begin{align*}\n& E(X \\mid Y=y)= \\begin{cases}\\sum_{i} x_{i} P\\left(X=x_{i} \\mid Y=y\\right), & (X, Y) \\text { 为二维离散随机变量; } \\\\\n\\int_{-\\infty}^{+\\infty} x p(x \\mid y) \\mathrm{d} x, & (X, Y) \\text { 为二维离散随机变量. }\\end{cases}  \\tag{3.5.15}\\\\\n& E(Y \\mid X=x)= \\begin{cases}\\sum_{j} y_{j} P\\left(Y=y_{j} \\mid X=x\\right), & (X, Y) \\text { 为二维离散随机变量; } \\\\\n\\int_{-\\infty}^{+\\infty} y p(y \\mid x) \\mathrm{d} y, & (X, Y) \\text { 为二维离散随机变量. }\\end{cases} \\tag{3.5.16}\n\\end{align*}\n$$  \n注意条件期望 $E(X \\mid Y=y)$ 是 $y$ 的函数, 它与无条件期望 $E(X)$ 的区别, 不仅在于计算公式上, 而且在于其含义上, 譬如, $X$ 表示中国成年人的身高, 则 $E(X)$ 表示中国成年人的平均身高. 若用 $Y$ 表示中国成年人的足长 (脚趾到脚跟的长度), 则 $E(X \\mid y=y)$ 表示足长为 $y$ 的中国成年人的平均身高, 我国公安部门研究获得  \n$$\nE(X \\mid Y=y)=6.876 y\n$$  \n这个公式对公安部门破案起着重要的作用, 例如, 测得案犯留下的足印长为 $25.3 \\mathrm{~cm}$, 则由此公式可推算出此案犯身高约 $174 \\mathrm{~cm}$.",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "\\int_{-\\infty}^{+\\infty} y p(y \\mid x) \\mathrm{d} y, & (X, Y) \\text { 为二维离散随机变量. }\\end{cases} \\tag{3.5.16}\n\\end{align*}\n$$  \n注意条件期望 $E(X \\mid Y=y)$ 是 $y$ 的函数, 它与无条件期望 $E(X)$ 的区别, 不仅在于计算公式上, 而且在于其含义上, 譬如, $X$ 表示中国成年人的身高, 则 $E(X)$ 表示中国成年人的平均身高. 若用 $Y$ 表示中国成年人的足长 (脚趾到脚跟的长度), 则 $E(X \\mid y=y)$ 表示足长为 $y$ 的中国成年人的平均身高, 我国公安部门研究获得  \n$$\nE(X \\mid Y=y)=6.876 y\n$$  \n这个公式对公安部门破案起着重要的作用, 例如, 测得案犯留下的足印长为 $25.3 \\mathrm{~cm}$, 则由此公式可推算出此案犯身高约 $174 \\mathrm{~cm}$.  \n其实以上公式的得出并不复杂, 一般认为人的身高和足长 $(X, Y)$ 可以当作一个二维正态变量来处理, 即 $(X, Y)$ 服从二维正态分布 $N\\left(\\mu_{1}, \\mu_{2}, \\sigma_{1}^{2}, \\sigma_{2}^{2}, \\rho\\right)$. 由例 3.5.4 知, 在给定 $Y=y$ 的条件下, $X$ 服从一维正态分布  \n$$\nN\\left(\\mu_{1}+\\rho \\frac{\\sigma_{1}}{\\sigma_{2}}\\left(y-\\mu_{2}\\right), \\sigma_{1}^{2}\\left(1-\\rho^{2}\\right)\\right) .\n$$  \n由此得  \n$$\nE(X \\mid Y=y)=\\mu_{1}+\\rho \\frac{\\sigma_{1}}{\\sigma_{2}}\\left(y-\\mu_{2}\\right) .\n$$  \n这是 $y$ 的线性函数. 再用统计的方法 (后面第六章的内容), 从大量实际数据中得出 $\\mu_{1}, \\mu_{2}, \\sigma_{1}, \\sigma_{2}, \\rho$,的估计后, 就可得以上公式.",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nN\\left(\\mu_{1}+\\rho \\frac{\\sigma_{1}}{\\sigma_{2}}\\left(y-\\mu_{2}\\right), \\sigma_{1}^{2}\\left(1-\\rho^{2}\\right)\\right) .\n$$  \n由此得  \n$$\nE(X \\mid Y=y)=\\mu_{1}+\\rho \\frac{\\sigma_{1}}{\\sigma_{2}}\\left(y-\\mu_{2}\\right) .\n$$  \n这是 $y$ 的线性函数. 再用统计的方法 (后面第六章的内容), 从大量实际数据中得出 $\\mu_{1}, \\mu_{2}, \\sigma_{1}, \\sigma_{2}, \\rho$,的估计后, 就可得以上公式.  \n因为条件期望是条件分布的数学期望, 所以它具有数学期望的一切性质, 例如  \n$$\nE\\left(a_{1} X_{1}+a_{2} X_{2} \\mid Y=y\\right)=a_{1} E\\left(X_{1} \\mid Y=y\\right)+a_{2} E\\left(X_{2} \\mid Y=y\\right)\n$$  \n其他性质在此不一一列举, 读者可以自行写出.  \n我们特别要强调的是: $E(X \\mid Y=y)$ 是 $y$ 的函数, 对 $y$ 的不同取值, 条件期望 $E(X \\mid Y=y)$ 的取值也在变化. 为此我们可以记  \n$$\ng(y)=E(X \\mid Y=y) .\n$$  \n进一步还可以将条件期望看成是随机变量 $Y$ 的函数, 记为 $E(X \\mid Y)=g(Y)$, 而将 $E(X \\mid Y=y)$ 看成是 $Y=y$ 时 $E(X \\mid Y)$ 的一个取值, 由此看出: $E(X \\mid Y)$ 本身也是一个随机变量.  \n引进 $E(X \\mid Y)$ 不仅使我们前面所定义的 $E(X \\mid Y=y)$ 得到了统一的处理, 而且可以得到更深刻的结果.  \n定理 3.5.1 (重期望公式). 设 $(X, Y)$ 是二维随机变量, 且 $E(X)$ 存在, 则  \n$$\n\\begin{equation*}\nE(X)=E(E(X \\mid Y)) \\text {. } \\tag{3.5.17}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其他性质在此不一一列举, 读者可以自行写出.  \n我们特别要强调的是: $E(X \\mid Y=y)$ 是 $y$ 的函数, 对 $y$ 的不同取值, 条件期望 $E(X \\mid Y=y)$ 的取值也在变化. 为此我们可以记  \n$$\ng(y)=E(X \\mid Y=y) .\n$$  \n进一步还可以将条件期望看成是随机变量 $Y$ 的函数, 记为 $E(X \\mid Y)=g(Y)$, 而将 $E(X \\mid Y=y)$ 看成是 $Y=y$ 时 $E(X \\mid Y)$ 的一个取值, 由此看出: $E(X \\mid Y)$ 本身也是一个随机变量.  \n引进 $E(X \\mid Y)$ 不仅使我们前面所定义的 $E(X \\mid Y=y)$ 得到了统一的处理, 而且可以得到更深刻的结果.  \n定理 3.5.1 (重期望公式). 设 $(X, Y)$ 是二维随机变量, 且 $E(X)$ 存在, 则  \n$$\n\\begin{equation*}\nE(X)=E(E(X \\mid Y)) \\text {. } \\tag{3.5.17}\n\\end{equation*}\n$$  \n证明: 证在此仅对连续场合进行证明, 而离散场合可类似证明. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为 $\\mathrm{p}(\\mathrm{x}, \\mathrm{y})$. 记 $g(y)=E(X \\mid Y=y)$, 则 $g(Y)=E(X \\mid Y)$. 由此利用 $p(x, y)=p(x \\mid y) p_{Y}(y)$, 可得  \n$$\n\\begin{aligned}\nE(X) & =\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} x p(x, y) \\mathrm{d} x \\mathrm{~d} y=\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} x p(x \\mid y) p_{Y}(y) \\mathrm{d} x \\mathrm{~d} y \\\\",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nE(X)=E(E(X \\mid Y)) \\text {. } \\tag{3.5.17}\n\\end{equation*}\n$$  \n证明: 证在此仅对连续场合进行证明, 而离散场合可类似证明. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为 $\\mathrm{p}(\\mathrm{x}, \\mathrm{y})$. 记 $g(y)=E(X \\mid Y=y)$, 则 $g(Y)=E(X \\mid Y)$. 由此利用 $p(x, y)=p(x \\mid y) p_{Y}(y)$, 可得  \n$$\n\\begin{aligned}\nE(X) & =\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} x p(x, y) \\mathrm{d} x \\mathrm{~d} y=\\int_{-\\infty}^{+\\infty} \\int_{-\\infty}^{+\\infty} x p(x \\mid y) p_{Y}(y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\int_{-\\infty}^{+\\infty}\\left\\{\\int_{-\\infty}^{+\\infty} x p(x \\mid y) \\mathrm{d} x\\right\\} p_{Y}(y) \\mathrm{d} y .\n\\end{aligned}\n$$  \n其中括号中的积分不是别的, 正是条件期望 $E(X \\mid Y=y)$, 所以  \n$$\n\\begin{aligned}\nE(X) & =\\int_{-\\infty}^{+\\infty} E(X \\mid Y=y) p_{Y}(y) \\mathrm{d} y \\\\\n& =\\int_{-\\infty}^{+\\infty} g(y) p_{Y}(y) \\mathrm{d} y \\\\\n& =E(g(Y))=E(E(X \\mid Y)) .\n\\end{aligned}\n$$  \n这就证明了式 (3.5.17).",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\int_{-\\infty}^{+\\infty}\\left\\{\\int_{-\\infty}^{+\\infty} x p(x \\mid y) \\mathrm{d} x\\right\\} p_{Y}(y) \\mathrm{d} y .\n\\end{aligned}\n$$  \n其中括号中的积分不是别的, 正是条件期望 $E(X \\mid Y=y)$, 所以  \n$$\n\\begin{aligned}\nE(X) & =\\int_{-\\infty}^{+\\infty} E(X \\mid Y=y) p_{Y}(y) \\mathrm{d} y \\\\\n& =\\int_{-\\infty}^{+\\infty} g(y) p_{Y}(y) \\mathrm{d} y \\\\\n& =E(g(Y))=E(E(X \\mid Y)) .\n\\end{aligned}\n$$  \n这就证明了式 (3.5.17).  \n重期望公式是概率论中较为深刻的一个结论, 它在实际中很有用. 譬如, 要求在一个取值于很大范围上的指标 $x$ 的均值 $E(X)$, 这时会遇到计算上的各种困难. 为此, 我们换一种思维方式, 去找一个与 $X$ 有关的量 $Y$, 用 $Y$ 的不同取值把大范围划分成若干个小区域, 先在小区域上求 $X$ 的平均, 再对此类平均求加权平均, 即可得大范围上 $X$ 的平均 $E(X)$. 如要求全校学生的平均身高, 可先求出每个班级学生的平均身高, 然后再对各班级的平均身高作加权平均, 其权重就是班级人数在全校学生中所占的比例.  \n重期望公式的具体使用如下:  \n1. 如果 $Y$ 是一个离散随机变量, 则式 (3.5.17) 成为  \n$$\n\\begin{equation*}\nE(X)=\\sum_{j} E\\left(X \\mid Y=y_{j}\\right) P\\left(Y=y_{j}\\right) \\tag{3.5.18}\n\\end{equation*}\n$$  \n2. 如果 $Y$ 是一个连续随机变量, 则式 (3.5.17) 成为  \n$$\n\\begin{equation*}\nE(X)=\\int_{-\\infty}^{+\\infty} E(X \\mid Y=y) p_{Y}(y) \\mathrm{d} y . \\tag{3.5.19}\n\\end{equation*}",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "重期望公式的具体使用如下:  \n1. 如果 $Y$ 是一个离散随机变量, 则式 (3.5.17) 成为  \n$$\n\\begin{equation*}\nE(X)=\\sum_{j} E\\left(X \\mid Y=y_{j}\\right) P\\left(Y=y_{j}\\right) \\tag{3.5.18}\n\\end{equation*}\n$$  \n2. 如果 $Y$ 是一个连续随机变量, 则式 (3.5.17) 成为  \n$$\n\\begin{equation*}\nE(X)=\\int_{-\\infty}^{+\\infty} E(X \\mid Y=y) p_{Y}(y) \\mathrm{d} y . \\tag{3.5.19}\n\\end{equation*}\n$$  \n例 3.5.7: 一矿工被困在有三个门的矿井里. 第一个门通一坑道, 沿此坑道走 3 小时可到达安全区;第二个门通一坑道, 沿此坑道走 5 小时又回到原处; 第三个门通一坑道, 沿此坑道走 7 小时也回到原处. 假定此矿工总是等可能地在三个门中选择一个, 试求他平均要用多少时间才能到达安全区.解: 设该矿工需要 $X$ 小时到达安全区, 则 $X$ 的可能取值为  \n$$\n3, \\quad 5+3, \\quad 7+3, \\quad 5+5+3, \\quad 5+7+3, \\quad 7+7+3, \\ldots\n$$  \n要写出 $X$ 的分布列是困难的, 所以无法直接求 $E(X)$. 为此记 $Y$ 表示第一次所选的门, $\\{Y=i\\}$ 就\n是选择第 $i$ 个门, 由题设知  \n$$\nP(Y=1)=P(Y=2)=P(Y=3)=\\frac{1}{3}\n$$  \n因为选第一个门后 3 小时可到达安全区, 所以 $E(X \\mid Y=1)=3$.  \n又因为选第二个门后 5 小时回到原处, 所以 $E(X \\mid Y=2)=5+E(X)$.  \n又因为选第三个门后 7 小时也回到原处, 所以 $E(X \\mid Y=3)=7+E(X)$.  \n综上所述, 由式 (3.5.18) 得  \n$$\nE(X)=\\frac{1}{3}\\{3+5+E(X)+7+E(X)\\}=5+\\frac{2}{3} E(X)\n$$  \n解得 $E(X)=15$, 即该矿工平均要 15 小时才能到达安全区.",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n3, \\quad 5+3, \\quad 7+3, \\quad 5+5+3, \\quad 5+7+3, \\quad 7+7+3, \\ldots\n$$  \n要写出 $X$ 的分布列是困难的, 所以无法直接求 $E(X)$. 为此记 $Y$ 表示第一次所选的门, $\\{Y=i\\}$ 就\n是选择第 $i$ 个门, 由题设知  \n$$\nP(Y=1)=P(Y=2)=P(Y=3)=\\frac{1}{3}\n$$  \n因为选第一个门后 3 小时可到达安全区, 所以 $E(X \\mid Y=1)=3$.  \n又因为选第二个门后 5 小时回到原处, 所以 $E(X \\mid Y=2)=5+E(X)$.  \n又因为选第三个门后 7 小时也回到原处, 所以 $E(X \\mid Y=3)=7+E(X)$.  \n综上所述, 由式 (3.5.18) 得  \n$$\nE(X)=\\frac{1}{3}\\{3+5+E(X)+7+E(X)\\}=5+\\frac{2}{3} E(X)\n$$  \n解得 $E(X)=15$, 即该矿工平均要 15 小时才能到达安全区.  \n上例的解题方法带有某种普遍性, 请读者从下例中再体会一下这种方法.  \n例 3.5.8: 口袋中有编号为 $1,2, \\ldots, n$ 的 $n$ 个球, 从中任取 1 球. 若取到 1 号球, 则得 1 分, 且停止摸球; 若取到 $i$ 号球 $(i \\geqslant 2)$, 则得 $i$ 分, 且将此球放回, 重新摸球. 如此下去, 试求得到的平均总分数.  \n解: 记 $X$ 为得到的总分数, $Y$ 为第一次取到的球的号码. 则  \n$$\nP(Y=1)=P(Y=2)=\\cdots=P(Y=n)=\\frac{1}{n}\n$$  \n又因为 $E(X \\mid Y=1)=1$, 而当 $i \\geqslant 2$ 时, $E(X \\mid Y=i)=i+E(X)$. 所以  \n$$\nE(X)=\\sum_{i=1}^{n} E(X \\mid Y=i) P(Y=i)=\\frac{1}{n}\\{1+2+\\cdots+n+(n-1) E(X)\\}\n$$  \n由此解得  \n$$\nE(X)=\\frac{n(n+1)}{2}\n$$",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "上例的解题方法带有某种普遍性, 请读者从下例中再体会一下这种方法.  \n例 3.5.8: 口袋中有编号为 $1,2, \\ldots, n$ 的 $n$ 个球, 从中任取 1 球. 若取到 1 号球, 则得 1 分, 且停止摸球; 若取到 $i$ 号球 $(i \\geqslant 2)$, 则得 $i$ 分, 且将此球放回, 重新摸球. 如此下去, 试求得到的平均总分数.  \n解: 记 $X$ 为得到的总分数, $Y$ 为第一次取到的球的号码. 则  \n$$\nP(Y=1)=P(Y=2)=\\cdots=P(Y=n)=\\frac{1}{n}\n$$  \n又因为 $E(X \\mid Y=1)=1$, 而当 $i \\geqslant 2$ 时, $E(X \\mid Y=i)=i+E(X)$. 所以  \n$$\nE(X)=\\sum_{i=1}^{n} E(X \\mid Y=i) P(Y=i)=\\frac{1}{n}\\{1+2+\\cdots+n+(n-1) E(X)\\}\n$$  \n由此解得  \n$$\nE(X)=\\frac{n(n+1)}{2}\n$$  \n例 3.5.9: 设电力公司每月可以供应某工厂的电力 $X$ 服从 $(10,30)$ (单位: $10^{4} \\mathrm{~kW}$ ) 上的均匀分布,而该工厂每月实际需要的电力 $Y$ 服从 $(10,20)$ (单位: $10^{4} \\mathrm{~kW}$ ) 上的均匀分布. 如果工厂能从电力公司得到足够的电力, 则每 $10^{4} \\mathrm{~kW}$ 电可以创造 30 万元的利润, 若工厂从电力公司得不到足够的电力, 则不足部分由工厂通过其他途径解决, 由其他途径得到的电力每 $10^{4} \\mathrm{~kW}$ 电只有 10 万元的利润. 试求该厂每个月的平均利润.  \n解: 从题意知, 每月供应电力 $X \\sim U(10,30)$, 而工厂实际需要电力 $Y \\sim U(10,20)$. 若设工厂每个月的利润为 $Z$ 万元, 则按题意可得  \n$$\nZ= \\begin{cases}30 Y, & \\text { 当 } Y \\leqslant X ; \\\\ 30 X+10(Y-X), & \\text { 当 } Y>X\\end{cases}\n$$",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 从题意知, 每月供应电力 $X \\sim U(10,30)$, 而工厂实际需要电力 $Y \\sim U(10,20)$. 若设工厂每个月的利润为 $Z$ 万元, 则按题意可得  \n$$\nZ= \\begin{cases}30 Y, & \\text { 当 } Y \\leqslant X ; \\\\ 30 X+10(Y-X), & \\text { 当 } Y>X\\end{cases}\n$$  \n在 $X=x$ 给定时, $Z$ 仅是 $Y$ 的函数, 于是当 $10 \\leqslant x<20$ 时, $Z$ 的条件期望为  \n$$\n\\begin{aligned}\nE(Z \\mid X=x) & =\\int_{10}^{x} 30 y p_{Y}(y) \\mathrm{d} y+\\int_{x}^{20}(10 y+20 x) p_{Y}(y) \\mathrm{d} y \\\\\n& =\\int_{10}^{x} 30 y \\frac{1}{10} \\mathrm{~d} y+\\int_{x}^{20}(10 y+20 x) \\frac{1}{10} \\mathrm{~d} y \\\\\n& =\\frac{3}{2}\\left(x^{2}-100\\right)+\\frac{1}{2}\\left(20^{2}-x^{2}\\right)+2 x(20-x) \\\\\n& =50+40 x-x^{2} .\n\\end{aligned}\n$$  \n当 $20 \\leqslant x \\leqslant 30$ 时, $Z$ 的条件期望为  \n$$\nE(Z \\mid X=x)=\\int_{10}^{20} 30 y p_{Y}(y) \\mathrm{d} y=\\int_{10}^{20} 30 y \\frac{1}{10} \\mathrm{~d} y=450\n$$  \n然后用 $X$ 的分布对条件期望 $E(Z \\mid X=x)$ 再作一次平均, 即得  \n$$\nE(Z)=E(E(Z \\mid X))=\\int_{10}^{\\infty} E(Z \\mid X=x) p_{X}(x) \\mathrm{d} x+\\int_{\\infty}^{\\infty} E(Z \\mid X=x) p_{X}(x) \\mathrm{d} x\n$$  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{3}{2}\\left(x^{2}-100\\right)+\\frac{1}{2}\\left(20^{2}-x^{2}\\right)+2 x(20-x) \\\\\n& =50+40 x-x^{2} .\n\\end{aligned}\n$$  \n当 $20 \\leqslant x \\leqslant 30$ 时, $Z$ 的条件期望为  \n$$\nE(Z \\mid X=x)=\\int_{10}^{20} 30 y p_{Y}(y) \\mathrm{d} y=\\int_{10}^{20} 30 y \\frac{1}{10} \\mathrm{~d} y=450\n$$  \n然后用 $X$ 的分布对条件期望 $E(Z \\mid X=x)$ 再作一次平均, 即得  \n$$\nE(Z)=E(E(Z \\mid X))=\\int_{10}^{\\infty} E(Z \\mid X=x) p_{X}(x) \\mathrm{d} x+\\int_{\\infty}^{\\infty} E(Z \\mid X=x) p_{X}(x) \\mathrm{d} x\n$$  \n$$\n\\begin{aligned}\n& =\\frac{1}{20} \\int_{10}^{20}\\left(50+40 x-x^{2}\\right) d x+\\frac{1}{20} \\int_{20}^{30} 450 \\mathrm{~d} x \\\\\n& =25+300-\\frac{700}{6}+225 \\approx 433 .\n\\end{aligned}\n$$  \n所以该厂每月的平均利润为 433 万元.  \n例 3.5.10: 随机个随机变量和的数学期望 设 $X_{1}, X_{2}, \\ldots$, 为一列独立同分布的随机变量, 随机变  \n量 $N$ 只取正整数值, 且 $N$ 与 $\\left\\{X_{n}\\right\\}$ 独立, 证明  \n$$\nE\\left(\\sum_{i=1}^{N} X_{i}\\right)=E\\left(X_{1}\\right) E(N)\n$$  \n证明: 由定理 3.5.1 知  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n$$\n\\begin{aligned}\n& =\\frac{1}{20} \\int_{10}^{20}\\left(50+40 x-x^{2}\\right) d x+\\frac{1}{20} \\int_{20}^{30} 450 \\mathrm{~d} x \\\\\n& =25+300-\\frac{700}{6}+225 \\approx 433 .\n\\end{aligned}\n$$  \n所以该厂每月的平均利润为 433 万元.  \n例 3.5.10: 随机个随机变量和的数学期望 设 $X_{1}, X_{2}, \\ldots$, 为一列独立同分布的随机变量, 随机变  \n量 $N$ 只取正整数值, 且 $N$ 与 $\\left\\{X_{n}\\right\\}$ 独立, 证明  \n$$\nE\\left(\\sum_{i=1}^{N} X_{i}\\right)=E\\left(X_{1}\\right) E(N)\n$$  \n证明: 由定理 3.5.1 知  \n$$\n\\begin{aligned}\nE\\left(\\sum_{i=1}^{N} X_{i}\\right) & =E\\left[E\\left(\\sum_{i=1}^{N} X_{i} \\mid N\\right)\\right] \\\\\n& =\\sum_{n=1}^{+\\infty} E\\left(\\sum_{i=1}^{N} X_{i} \\mid N=n\\right) P(N=n) \\\\\n& =\\sum_{n=1}^{+\\infty} E\\left(\\sum_{i=1}^{n} X_{i}\\right) P(N=n) \\\\\n& =\\sum_{n=1}^{+\\infty} n E\\left(X_{1}\\right) P(N=n) \\\\\n& =E\\left(X_{1}\\right) \\sum_{n=1}^{+\\infty} n P(N=n)=E\\left(X_{1}\\right) E(N) .\n\\end{aligned}\n$$  \n得证.  \n利用此题的结论, 我们可以解很多实际问题, 下面列举几个:",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n证明: 由定理 3.5.1 知  \n$$\n\\begin{aligned}\nE\\left(\\sum_{i=1}^{N} X_{i}\\right) & =E\\left[E\\left(\\sum_{i=1}^{N} X_{i} \\mid N\\right)\\right] \\\\\n& =\\sum_{n=1}^{+\\infty} E\\left(\\sum_{i=1}^{N} X_{i} \\mid N=n\\right) P(N=n) \\\\\n& =\\sum_{n=1}^{+\\infty} E\\left(\\sum_{i=1}^{n} X_{i}\\right) P(N=n) \\\\\n& =\\sum_{n=1}^{+\\infty} n E\\left(X_{1}\\right) P(N=n) \\\\\n& =E\\left(X_{1}\\right) \\sum_{n=1}^{+\\infty} n P(N=n)=E\\left(X_{1}\\right) E(N) .\n\\end{aligned}\n$$  \n得证.  \n利用此题的结论, 我们可以解很多实际问题, 下面列举几个:  \n1. 设一天内到达某商场的顾客数 $N$ 是仅取非负整数值的随机变量, 且 $E(N)=35000$. 又设进人此商场的第 $i$ 个顾客的购物金额为 $X_{i}$, 可以认为诸 $X_{i}$ 是独立同分布的随机变量, 且 $E\\left(X_{i}\\right)=82$ (元). 假设 $N$ 与 $X_{i}$ 相互独立是合理的, 则此商场一天的平均营业额为  \n$$\nE\\left(\\sum_{i=0}^{N} X_{i}\\right)=E\\left(X_{1}\\right) E(N)=82 \\times 35000=287(\\text { 万元 }) .\n$$  \n其中 $X_{0}=0$.  \n2. 一只昆虫一次产卵数 $N$ 服从参数为 $\\lambda$ 的泊松分布, 每个卵能成活的概率是 $p$, 可设 $X_{i}$ 服从 $0-1$ 分布, 而 $\\left\\{X_{i}=1\\right\\}$ 表示第 $i$ 个卵成活, 则一只昆虫一次产卵后的平均成活卵数为  \n$$",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n得证.  \n利用此题的结论, 我们可以解很多实际问题, 下面列举几个:  \n1. 设一天内到达某商场的顾客数 $N$ 是仅取非负整数值的随机变量, 且 $E(N)=35000$. 又设进人此商场的第 $i$ 个顾客的购物金额为 $X_{i}$, 可以认为诸 $X_{i}$ 是独立同分布的随机变量, 且 $E\\left(X_{i}\\right)=82$ (元). 假设 $N$ 与 $X_{i}$ 相互独立是合理的, 则此商场一天的平均营业额为  \n$$\nE\\left(\\sum_{i=0}^{N} X_{i}\\right)=E\\left(X_{1}\\right) E(N)=82 \\times 35000=287(\\text { 万元 }) .\n$$  \n其中 $X_{0}=0$.  \n2. 一只昆虫一次产卵数 $N$ 服从参数为 $\\lambda$ 的泊松分布, 每个卵能成活的概率是 $p$, 可设 $X_{i}$ 服从 $0-1$ 分布, 而 $\\left\\{X_{i}=1\\right\\}$ 表示第 $i$ 个卵成活, 则一只昆虫一次产卵后的平均成活卵数为  \n$$\nE\\left(\\sum_{i=1}^{N} X_{i}\\right)=E\\left(X_{1}\\right) E(N)=\\lambda p\n$$",
        "metadata": {
            "Header 2": "3.5 .2 条件数学期望"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 以 $X$ 记某医院一天内诞生婴儿的个数, 以 $Y$ 记其中男婴的个数. 设 $X$ 与 $Y$ 的联合分布列为  \n$$\nP(X=n, Y=m)=\\frac{\\mathrm{e}^{-14}(7.14)^{m}(6.86)^{n-m}}{m !(n-m) !}, \\quad m=0,1, \\ldots, n, \\quad n=0,1,2, \\ldots\n$$  \n试求条件分布列 $P(Y=m \\mid X=n)$.  \n2. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}3 x, & 0<x<1,0<y<x ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求条件密度函数 $p(y \\mid x)$.  \n3. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}1, & |y|<x, 0<x<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求条件密度函数 $p(x \\mid y)$.  \n4. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{21}{4} x^{2} y, & x^{2} \\leqslant y \\leqslant 1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求条件概率 $P\\{Y \\geqslant 0.75 \\mid X=0.5\\}$.  \n5. 已知随机变景 $Y$ 的密度函数为  \n$$\np_{Y}(y)= \\begin{cases}5 y^{4}, & 0<y<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n在给定 $Y=y$ 条件下, 随机变量 $X$ 的条件密度函数为  \n$$\np(x \\mid y)= \\begin{cases}\\frac{3 x^{2}}{y^{3}}, & 0<x<y<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求概率 $P(X>0.5)$.",
        "metadata": {
            "Header 2": "如题 3.5"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n求条件密度函数 $p(x \\mid y)$.  \n4. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}\\frac{21}{4} x^{2} y, & x^{2} \\leqslant y \\leqslant 1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求条件概率 $P\\{Y \\geqslant 0.75 \\mid X=0.5\\}$.  \n5. 已知随机变景 $Y$ 的密度函数为  \n$$\np_{Y}(y)= \\begin{cases}5 y^{4}, & 0<y<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n在给定 $Y=y$ 条件下, 随机变量 $X$ 的条件密度函数为  \n$$\np(x \\mid y)= \\begin{cases}\\frac{3 x^{2}}{y^{3}}, & 0<x<y<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n求概率 $P(X>0.5)$.  \n6. 设随机变量 $X$ 服从 $(1,2)$ 上的均匀分布, 在 $X=x$ 的条件下, 随机变量 $Y$ 的条件分布是参数为 $x$ 的指数分布, 证明: $X Y$ 服从参数为 1 的指数分布.\n7. 设二维离散随机变量 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | 2 | 3 |\n| 0 | 0 | 0.01 | 0.01 | 0.01 |\n| 1 | 0.01 | 0.02 | 0.03 | 0.02 |\n| 2 | 0.03 | 0.04 | 0.05 | 0.04 |\n| 3 | 0.05 | 0.05 | 0.05 | 0.06 |\n| 4 | 0.07 | 0.06 | 0.05 | 0.06 |\n| 5 | 0.09 | 0.08 | 0.06 | 0.05 |  \n试求 $E(X \\mid Y=2)$ 和 $E(X \\mid Y=0)$.",
        "metadata": {
            "Header 2": "如题 3.5"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n求概率 $P(X>0.5)$.  \n6. 设随机变量 $X$ 服从 $(1,2)$ 上的均匀分布, 在 $X=x$ 的条件下, 随机变量 $Y$ 的条件分布是参数为 $x$ 的指数分布, 证明: $X Y$ 服从参数为 1 的指数分布.\n7. 设二维离散随机变量 $(X, Y)$ 的联合分布列为  \n|  | $Y$ |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $X$ | 0 | 1 | 2 | 3 |\n| 0 | 0 | 0.01 | 0.01 | 0.01 |\n| 1 | 0.01 | 0.02 | 0.03 | 0.02 |\n| 2 | 0.03 | 0.04 | 0.05 | 0.04 |\n| 3 | 0.05 | 0.05 | 0.05 | 0.06 |\n| 4 | 0.07 | 0.06 | 0.05 | 0.06 |\n| 5 | 0.09 | 0.08 | 0.06 | 0.05 |  \n试求 $E(X \\mid Y=2)$ 和 $E(X \\mid Y=0)$.  \n8. 设 $X$ 与 $Y$ 相互独立, 分别服从参数为 $\\lambda_{1}$ 和 $\\lambda_{2}$ 的泊松分布, 试求 $E\\left(X_{1} \\mid X_{1}+X_{2}=n\\right)$.\n9. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}x+y, & 0<x, y<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $E(X \\mid Y=0.5)$.  \n10. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}24(1-x) y, & 0<y<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求在 $0<y<1$ 时, 求 $E(X \\mid Y=y)$.  \n11. 设 $E(Y), E(h(Y))$ 存在, 试证 $E(h(Y) \\mid Y)=h(Y)$.\n12. 设随机变量 $X$ 与 $Y$ 独立同分布, 都服从参数为 $\\lambda$ 的指数分布, 令  \n$$",
        "metadata": {
            "Header 2": "如题 3.5"
        },
        "type": "Document"
    },
    {
        "page_content": "9. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}x+y, & 0<x, y<1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求 $E(X \\mid Y=0.5)$.  \n10. 设二维连续随机变量 $(X, Y)$ 的联合密度函数为  \n$$\np(x, y)= \\begin{cases}24(1-x) y, & 0<y<x<1 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n试求在 $0<y<1$ 时, 求 $E(X \\mid Y=y)$.  \n11. 设 $E(Y), E(h(Y))$ 存在, 试证 $E(h(Y) \\mid Y)=h(Y)$.\n12. 设随机变量 $X$ 与 $Y$ 独立同分布, 都服从参数为 $\\lambda$ 的指数分布, 令  \n$$\nZ= \\begin{cases}3 X+1, & X \\geqslant Y \\\\ 6 Y, & X<Y\\end{cases}\n$$  \n求 $E(Z)$.  \n13. 设 $X_{1}, X_{2}, \\ldots$, 为独立同分布的随机变量序列, 且方差存在. 随机变量 $N$ 只取正整数值, $\\operatorname{Var}(N)$\n存在, 且 $N$ 与 $\\left\\{X_{n}\\right\\}$ 独立. 证明  \n$$\n\\operatorname{Var}\\left(\\sum_{i=1}^{N} X_{t}\\right)=\\operatorname{Var}(N)\\left[E\\left(X_{1}\\right)\\right]^{2}+E(N) \\operatorname{Var}\\left(X_{1}\\right)\n$$",
        "metadata": {
            "Header 2": "如题 3.5"
        },
        "type": "Document"
    },
    {
        "page_content": "大数定律与中心极限定理",
        "metadata": {
            "Header 2": "第 4 章 大数定律与中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $p(x)$ 是随机变量 $X$ 的密度函数,则 $p(x)$ 的傅里叶变换是  \n$$\n\\varphi(t)=\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x\n$$  \n其中 $i=\\sqrt{-1}$ 是虚数单位. 由数学期望的概念知, $\\varphi(t)$ 恰好是 $E\\left(\\mathrm{e}^{i t x}\\right)$. 这就是本节要讨论的特征函数, 它是处理许多概率论问题的有力工具, 它能把寻求独立随机变量和的分布的卷积运算 (积分运算) 转换成乘法运算, 还能把求分布的各阶原点矩 (积分运算) 转换成微分运算. 特别它能把寻求随机变量序列的极限分布转换成一般的函数极限问题, 下面从特征函数的定义开始介绍它们.",
        "metadata": {
            "Header 2": "4.1 特征函数"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 4.1.1. 设 $X$ 是一个随机变量, 称  \n$$\n\\begin{equation*}\n\\varphi(t)=E\\left(\\mathrm{e}^{i t x}\\right),-\\infty \\leqslant t \\leqslant+\\infty, \\tag{4.1.1}\n\\end{equation*}\n$$  \n为 $X$ 的特征函数.  \n因为 $\\left|\\mathrm{e}^{i t x}\\right| \\leqslant 1$, 所以 $E\\left(\\mathrm{e}^{i t X}\\right)$ 总是存在的, 即任一随机变量的特征函数总是存在的.  \n当离散随机变量 $X$ 的分布列为 $p_{k}=P\\left(X=x_{k}\\right), k=1,2, \\cdots$, 则 $X$ 的特征函数为  \n$$\n\\begin{equation*}\n\\varphi(t)=\\sum_{k=1}^{+\\infty} \\mathrm{e}^{i t x_{k}} p_{k},-\\infty \\leqslant t \\leqslant+\\infty . \\tag{4.1.2}\n\\end{equation*}\n$$  \n当连续随机变量 $X$ 的密度函数为 $p(x)$, 则 $X$ 的特征函数为  \n$$\n\\begin{equation*}\n\\varphi(t)=\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x,-\\infty \\leqslant t \\leqslant+\\infty . \\tag{4.1.3}\n\\end{equation*}\n$$  \n与随机变量的数学期望、方差及各阶矩一样, 特征函数只依赖于随机变量的分布, 分布相同则特征函数也相同, 所以我们也常称为某分布的特征函数.  \n例 4.1.1: 常用分布的特征函数  \n1. 单点分布: $P(X=a)=1$, 其特征函数为  \n$$\n\\varphi(t)=\\mathrm{e}^{i t z} .\n$$  \n2. 0-1 分布: $P(X=x)=p^{x}(1-p)^{1-x}, x=0,1$, 其特征函数为  \n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.1 特征函数的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n当连续随机变量 $X$ 的密度函数为 $p(x)$, 则 $X$ 的特征函数为  \n$$\n\\begin{equation*}\n\\varphi(t)=\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x,-\\infty \\leqslant t \\leqslant+\\infty . \\tag{4.1.3}\n\\end{equation*}\n$$  \n与随机变量的数学期望、方差及各阶矩一样, 特征函数只依赖于随机变量的分布, 分布相同则特征函数也相同, 所以我们也常称为某分布的特征函数.  \n例 4.1.1: 常用分布的特征函数  \n1. 单点分布: $P(X=a)=1$, 其特征函数为  \n$$\n\\varphi(t)=\\mathrm{e}^{i t z} .\n$$  \n2. 0-1 分布: $P(X=x)=p^{x}(1-p)^{1-x}, x=0,1$, 其特征函数为  \n$$\n\\varphi(t)=p \\mathrm{e}^{i t}+q \\text {, 其中 } q=1-p \\text {. }\n$$  \n3. 泊松分布: $P(X=k)=\\left(\\lambda^{k} / k !\\right) \\mathrm{e}^{-\\lambda}, k=0,1, \\cdots$, 其特征函数为  \n$$\n\\varphi(t)=\\sum_{k=0}^{+\\infty} \\mathrm{e}^{i k t} \\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}=\\mathrm{e}^{\\lambda} \\mathrm{e}^{\\lambda \\mathrm{e}^{i t}}=\\mathrm{e}^{\\lambda\\left(\\mathrm{e}^{i t}\\right)-1} .\n$$  \n4. 均匀分布 $U(a, b)$ : 因为密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{b-a}, & a<x<b, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n所以特征函数为  \n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.1 特征函数的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n3. 泊松分布: $P(X=k)=\\left(\\lambda^{k} / k !\\right) \\mathrm{e}^{-\\lambda}, k=0,1, \\cdots$, 其特征函数为  \n$$\n\\varphi(t)=\\sum_{k=0}^{+\\infty} \\mathrm{e}^{i k t} \\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}=\\mathrm{e}^{\\lambda} \\mathrm{e}^{\\lambda \\mathrm{e}^{i t}}=\\mathrm{e}^{\\lambda\\left(\\mathrm{e}^{i t}\\right)-1} .\n$$  \n4. 均匀分布 $U(a, b)$ : 因为密度函数为  \n$$\np(x)= \\begin{cases}\\frac{1}{b-a}, & a<x<b, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n所以特征函数为  \n$$\n\\varphi(t)=\\int_{a}^{b} \\frac{\\mathrm{e}^{i t x}}{b-a} \\mathrm{~d} x=\\frac{\\mathrm{e}^{i b t}-\\mathrm{e}^{i a t}}{i t(b-a)} .\n$$  \n5. 标准正态分布 $N(0,1)$ : 因为密度函数为  \n$$\np(x)=\\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-\\frac{x^{2}}{2}\\right), \\quad-\\infty<x<+\\infty\n$$  \n所以特征函数为  \n$$\n\\begin{aligned}\n\\varphi(t) & =\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} \\exp \\left(i t x-\\frac{x^{2}}{2}\\right) \\mathrm{d} x \\\\\n& =\\exp \\left(-\\frac{t^{2}}{2}\\right) \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} \\exp \\left(-\\frac{(x-i t)^{2}}{2}\\right) \\mathrm{d} x \\\\",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.1 特征函数的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n5. 标准正态分布 $N(0,1)$ : 因为密度函数为  \n$$\np(x)=\\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-\\frac{x^{2}}{2}\\right), \\quad-\\infty<x<+\\infty\n$$  \n所以特征函数为  \n$$\n\\begin{aligned}\n\\varphi(t) & =\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} \\exp \\left(i t x-\\frac{x^{2}}{2}\\right) \\mathrm{d} x \\\\\n& =\\exp \\left(-\\frac{t^{2}}{2}\\right) \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{+\\infty} \\exp \\left(-\\frac{(x-i t)^{2}}{2}\\right) \\mathrm{d} x \\\\\n& =\\exp \\left(-\\frac{t^{2}}{2}\\right) \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty-i t}^{+\\infty-i t} \\exp \\left(-\\frac{x^{2}}{2}\\right) \\mathrm{d} x \\\\\n& =\\exp \\left(-\\frac{t^{2}}{2}\\right),\n\\end{aligned}\n$$  \n其中  \n$$\n\\int_{-\\infty-i t}^{+\\infty-i t} \\exp \\left(-\\frac{x^{2}}{2}\\right) \\mathrm{d} x=\\sqrt{2 \\pi}\n$$  \n是利用复变函数中的围道积分求得的. 有了标准正态分布的特征函数, 再利用下节给出的特征函数的性质, 就很容易得到一般正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的特征函数, 见例 4.1.2.  \n6. 指数分布 $\\operatorname{Exp}(\\lambda)$ : 因为密度函数为  \n$$\np(x)= \\begin{cases}\\lambda \\mathrm{e}^{-\\lambda x}, & x>0, \\\\ 0, & x \\leqslant 0 .\\end{cases}\n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.1 特征函数的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\exp \\left(-\\frac{t^{2}}{2}\\right),\n\\end{aligned}\n$$  \n其中  \n$$\n\\int_{-\\infty-i t}^{+\\infty-i t} \\exp \\left(-\\frac{x^{2}}{2}\\right) \\mathrm{d} x=\\sqrt{2 \\pi}\n$$  \n是利用复变函数中的围道积分求得的. 有了标准正态分布的特征函数, 再利用下节给出的特征函数的性质, 就很容易得到一般正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的特征函数, 见例 4.1.2.  \n6. 指数分布 $\\operatorname{Exp}(\\lambda)$ : 因为密度函数为  \n$$\np(x)= \\begin{cases}\\lambda \\mathrm{e}^{-\\lambda x}, & x>0, \\\\ 0, & x \\leqslant 0 .\\end{cases}\n$$  \n所以特征函数为  \n$$\n\\begin{aligned}\n\\varphi(t) & =\\int_{0}^{+\\infty} \\mathrm{e}^{i t x} \\lambda \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x \\\\\n& =\\lambda\\left(\\int_{0}^{+\\infty} \\cos (t x) \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x+i \\int_{0}^{+\\infty} \\sin (t x) \\mathrm{e}^{-\\lambda x} \\mathrm{~d} x\\right) \\\\\n& =\\lambda\\left(\\frac{\\lambda}{\\lambda^{2}+t^{2}}+i \\frac{t}{\\lambda^{2}+t^{2}}\\right) \\\\\n& =\\left(1-\\frac{i t}{\\lambda}\\right)^{-1} .\n\\end{aligned}\n$$  \n以上积分中用到了复变函数中的欧拉公式: $\\mathrm{e}^{i t x}=\\cos (t x)+i \\sin (t x)$.",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.1 特征函数的定义"
        },
        "type": "Document"
    },
    {
        "page_content": "现在我们来研究特征函数的一些性质, 其中 $\\varphi_{X}(t)$ 表示 $X$ 的特征函数, 其他类似.  \n性质 4.1.1:  \n$$\n\\begin{equation*}\n|\\varphi(t)| \\leqslant \\varphi(0)=1 . \\tag{4.1.4}\n\\end{equation*}\n$$  \n性质 4.1.2:  \n$$\n\\begin{equation*}\n\\varphi(-t)=\\overline{\\varphi(t)} \\tag{4.1.5}\n\\end{equation*}\n$$  \n其中 $\\overline{\\varphi(t)}$ 表示 $\\varphi(t)$ 的共轭.  \n性质 4.1.3: 若 $Y=a X+b$, 其中 $a, b$ 是常数, 则  \n$$\n\\begin{equation*}\n\\varphi_{Y}(t)=\\mathrm{e}^{i b t} \\varphi_{X}(a t) \\tag{4.1.6}\n\\end{equation*}\n$$  \n性质 4.1.4: 独立随机变量和的特征函数为特征函数的积, 即设 $X$ 与 $Y$ 相互独立, 则  \n$$\n\\begin{equation*}\n\\varphi_{X+Y}(t)=\\varphi_{X}(t) \\cdot \\varphi_{Y}(t) \\tag{4.1.7}\n\\end{equation*}\n$$  \n性质 4.1.5: 若 $E\\left(x^{l}\\right)$ 存在, 则 $X$ 的特征函数 $\\varphi(t)$ 可 $l$ 次求导, 且对 $1 \\leqslant k \\leqslant l$, 有  \n$$\n\\begin{equation*}\n\\varphi^{(k)}(0)=i^{k} E\\left(X^{k}\\right) . \\tag{4.1.8}\n\\end{equation*}\n$$  \n上式提供了一条求随机变量的各阶矩的途径, 特别可用下式去求数学期望和方差.  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n性质 4.1.4: 独立随机变量和的特征函数为特征函数的积, 即设 $X$ 与 $Y$ 相互独立, 则  \n$$\n\\begin{equation*}\n\\varphi_{X+Y}(t)=\\varphi_{X}(t) \\cdot \\varphi_{Y}(t) \\tag{4.1.7}\n\\end{equation*}\n$$  \n性质 4.1.5: 若 $E\\left(x^{l}\\right)$ 存在, 则 $X$ 的特征函数 $\\varphi(t)$ 可 $l$ 次求导, 且对 $1 \\leqslant k \\leqslant l$, 有  \n$$\n\\begin{equation*}\n\\varphi^{(k)}(0)=i^{k} E\\left(X^{k}\\right) . \\tag{4.1.8}\n\\end{equation*}\n$$  \n上式提供了一条求随机变量的各阶矩的途径, 特别可用下式去求数学期望和方差.  \n$$\n\\begin{equation*}\nE(X)=\\frac{\\varphi^{\\prime}(0)}{i}, \\quad \\operatorname{Var}(X)=-\\varphi^{\\prime \\prime}(0)+\\left(\\varphi^{\\prime}(0)\\right)^{2} \\tag{4.1.9}\n\\end{equation*}\n$$  \n证明: 在此我们仅对连续场合进行证明, 而在离散场合的证明是类似的.  \n1.  \n$$\n\\begin{aligned}\n|\\varphi(t)| & =\\left|\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x\\right| \\leqslant \\int_{-\\infty}^{+\\infty}\\left|\\mathrm{e}^{i t x}\\right| p(x) \\mathrm{d} x \\\\\n& =\\int_{-\\infty}^{+\\infty} p(x) \\mathrm{d} x=\\varphi(0)=1 .\n\\end{aligned}\n$$  \n2.  \n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "E(X)=\\frac{\\varphi^{\\prime}(0)}{i}, \\quad \\operatorname{Var}(X)=-\\varphi^{\\prime \\prime}(0)+\\left(\\varphi^{\\prime}(0)\\right)^{2} \\tag{4.1.9}\n\\end{equation*}\n$$  \n证明: 在此我们仅对连续场合进行证明, 而在离散场合的证明是类似的.  \n1.  \n$$\n\\begin{aligned}\n|\\varphi(t)| & =\\left|\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x\\right| \\leqslant \\int_{-\\infty}^{+\\infty}\\left|\\mathrm{e}^{i t x}\\right| p(x) \\mathrm{d} x \\\\\n& =\\int_{-\\infty}^{+\\infty} p(x) \\mathrm{d} x=\\varphi(0)=1 .\n\\end{aligned}\n$$  \n2.  \n$$\n\\varphi(-t)=\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i t x} p(x) \\mathrm{d} x=\\overline{\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x}=\\overline{\\varphi(t)}\n$$  \n$$\n\\begin{equation*}\n\\varphi_{Y}(t)=E\\left(\\mathrm{e}^{i t(a X+b)}\\right)=\\mathrm{e}^{i b t} E\\left(\\mathrm{e}^{i a t X}\\right)=\\mathrm{e}^{i b t} \\varphi(a t) . \\tag{3.}\n\\end{equation*}\n$$  \n4. 因为 $X$ 与 $Y$ 相互独立, 所以 $\\mathrm{e}^{i t X}$ 与 $\\mathrm{e}^{i t Y}$ 也是独立的, 从而有  \n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n2.  \n$$\n\\varphi(-t)=\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i t x} p(x) \\mathrm{d} x=\\overline{\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x}=\\overline{\\varphi(t)}\n$$  \n$$\n\\begin{equation*}\n\\varphi_{Y}(t)=E\\left(\\mathrm{e}^{i t(a X+b)}\\right)=\\mathrm{e}^{i b t} E\\left(\\mathrm{e}^{i a t X}\\right)=\\mathrm{e}^{i b t} \\varphi(a t) . \\tag{3.}\n\\end{equation*}\n$$  \n4. 因为 $X$ 与 $Y$ 相互独立, 所以 $\\mathrm{e}^{i t X}$ 与 $\\mathrm{e}^{i t Y}$ 也是独立的, 从而有  \n$$\nE\\left(\\mathrm{e}^{i t(X+Y)}\\right)=E\\left(\\mathrm{e}^{i t X} \\mathrm{e}^{i t Y}\\right)=\\varphi_{X}(t) \\cdot \\varphi_{Y}(t) .\n$$  \n5. 因为 $E\\left(X^{l}\\right)$ 存在, 也就是  \n$$\n\\int_{-\\infty}^{+\\infty}|x|^{l} p(x) \\mathrm{d} x<+\\infty\n$$  \n于是含参变量 $t$ 的广义积分 $\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x$ 可以对 $t$ 求导 $l$ 次, 于是对 $0 \\leqslant k \\leqslant l$, 有  \n$$\n\\varphi^{(k)}(t)=\\int_{-\\infty}^{+\\infty} i^{k} x^{k} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x=i^{k} E\\left(X^{k} \\mathrm{e}^{i t X}\\right) .\n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n5. 因为 $E\\left(X^{l}\\right)$ 存在, 也就是  \n$$\n\\int_{-\\infty}^{+\\infty}|x|^{l} p(x) \\mathrm{d} x<+\\infty\n$$  \n于是含参变量 $t$ 的广义积分 $\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x$ 可以对 $t$ 求导 $l$ 次, 于是对 $0 \\leqslant k \\leqslant l$, 有  \n$$\n\\varphi^{(k)}(t)=\\int_{-\\infty}^{+\\infty} i^{k} x^{k} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x=i^{k} E\\left(X^{k} \\mathrm{e}^{i t X}\\right) .\n$$  \n令 $t=0$ 即得  \n$$\n\\varphi^{(k)}(0)=i^{k} E\\left(X^{k}\\right) \\text {. }\n$$  \n至此上述 5 条性质全部得证.  \n下例是利用 (4.1.6) 和 (4.1.7) 来求一些常用分布的特征函数.  \n例 4.1.2: 常用分布的特征函数 (二)  \n1. 二项分布 $b(n, p)$ : 设 $Y \\sim b(n, p)$, 则 $Y=X_{1}+x_{2}+\\cdots X_{n}$, 其中诸 $X_{i}$ 是相互独立同分布的随机变量, 且 $X_{i} \\sim b(1, p)$, 由例 4.1.2 2 知  \n$$\n\\varphi_{X_{i}}(t)=p \\mathrm{e}^{i t}+q,\n$$  \n所以由独立随机变量和的特征函数为特征函数的积, 得  \n$$\n\\varphi_{Y}(t)=\\left(p \\mathrm{e}^{i t}+q\\right)^{\\pi}\n$$  \n2. 正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ : 设 $Y \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 则 $X=(Y-\\mu) / \\sigma \\sim N(0,1)$. 由例 4.1.1 知  \n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "至此上述 5 条性质全部得证.  \n下例是利用 (4.1.6) 和 (4.1.7) 来求一些常用分布的特征函数.  \n例 4.1.2: 常用分布的特征函数 (二)  \n1. 二项分布 $b(n, p)$ : 设 $Y \\sim b(n, p)$, 则 $Y=X_{1}+x_{2}+\\cdots X_{n}$, 其中诸 $X_{i}$ 是相互独立同分布的随机变量, 且 $X_{i} \\sim b(1, p)$, 由例 4.1.2 2 知  \n$$\n\\varphi_{X_{i}}(t)=p \\mathrm{e}^{i t}+q,\n$$  \n所以由独立随机变量和的特征函数为特征函数的积, 得  \n$$\n\\varphi_{Y}(t)=\\left(p \\mathrm{e}^{i t}+q\\right)^{\\pi}\n$$  \n2. 正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ : 设 $Y \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 则 $X=(Y-\\mu) / \\sigma \\sim N(0,1)$. 由例 4.1.1 知  \n$$\n\\varphi_{X}(t)=\\exp \\left(-\\frac{t^{2}}{2}\\right)\n$$  \n所以由 $Y=\\sigma X+\\mu$ 得  \n$$\n\\varphi_{Y}(t)=\\varphi_{\\alpha X+\\mu}(t)=\\mathrm{e}^{i \\mu t} \\varphi_{X}(\\sigma t)=\\exp \\left(i \\mu t-\\frac{\\sigma^{2} t^{2}}{2}\\right)\n$$  \n表 4.1.1: 常用分布的特征函数  \n| 分布 | 分布列 $p_{k}$ 或分布密度 $p(x)$ | 特征函数 $\\varphi(t)$ |\n| :---: | :---: | :---: |\n| 单点分布 | $P(X=a)=1$ | $\\mathrm{e}^{i t z}$ |\n| $0-1$ 分布 | $P_{k}=p^{k} q^{1-k}, k=0,1$ | $p \\mathrm{e}^{i t}+q$ |",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\varphi_{X}(t)=\\exp \\left(-\\frac{t^{2}}{2}\\right)\n$$  \n所以由 $Y=\\sigma X+\\mu$ 得  \n$$\n\\varphi_{Y}(t)=\\varphi_{\\alpha X+\\mu}(t)=\\mathrm{e}^{i \\mu t} \\varphi_{X}(\\sigma t)=\\exp \\left(i \\mu t-\\frac{\\sigma^{2} t^{2}}{2}\\right)\n$$  \n表 4.1.1: 常用分布的特征函数  \n| 分布 | 分布列 $p_{k}$ 或分布密度 $p(x)$ | 特征函数 $\\varphi(t)$ |\n| :---: | :---: | :---: |\n| 单点分布 | $P(X=a)=1$ | $\\mathrm{e}^{i t z}$ |\n| $0-1$ 分布 | $P_{k}=p^{k} q^{1-k}, k=0,1$ | $p \\mathrm{e}^{i t}+q$ |\n| 二项分布 | $p_{k}=\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right) p^{k} q^{1-k}, k=0,1, \\cdots, n$ | $\\left(p \\mathrm{e}^{i t}+q\\right)^{\\pi}$ |\n| 泊松分布 <br> $P(\\lambda)$ | $P_{k}=\\left(\\lambda^{k} / k !\\right) \\mathrm{e}^{-\\lambda}, k=0,1, \\cdots$ | $\\mathrm{e}^{\\lambda\\left(\\mathrm{e}^{i t}\\right)-1}$ |\n| 均匀分布 | $p(x)=1 /(b-a), a \\leqslant x \\leqslant b$ | $\\frac{\\mathrm{e}^{i b t}-\\mathrm{e}^{i a t}}{i t(b-a)}$ |\n| $U(a, b)$ |  |  |",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "| 二项分布 | $p_{k}=\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right) p^{k} q^{1-k}, k=0,1, \\cdots, n$ | $\\left(p \\mathrm{e}^{i t}+q\\right)^{\\pi}$ |\n| 泊松分布 <br> $P(\\lambda)$ | $P_{k}=\\left(\\lambda^{k} / k !\\right) \\mathrm{e}^{-\\lambda}, k=0,1, \\cdots$ | $\\mathrm{e}^{\\lambda\\left(\\mathrm{e}^{i t}\\right)-1}$ |\n| 均匀分布 | $p(x)=1 /(b-a), a \\leqslant x \\leqslant b$ | $\\frac{\\mathrm{e}^{i b t}-\\mathrm{e}^{i a t}}{i t(b-a)}$ |\n| $U(a, b)$ |  |  |\n| 正态分布 <br> $N\\left(\\mu, \\sigma^{2}\\right)$ | $p(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right)$ | $\\exp \\left(i \\mu t-\\frac{\\sigma^{2} t^{2}}{2}\\right)$ |\n| 指数分布 | $p(x)=\\lambda \\mathrm{e}^{-\\lambda x}, x>0$ | $\\left(1-\\frac{i t}{\\lambda}\\right)^{-1}$ |\n| 伽玛分布 <br> $G a(a, \\lambda)$ | $p(x)=\\frac{\\lambda^{\\alpha}}{\\Gamma(a)} x^{\\alpha-1} \\mathrm{e}^{-\\lambda x}, x \\geqslant 0$ | $\\left(1-\\frac{i t}{\\lambda}\\right)^{-a}$ |",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "| $U(a, b)$ |  |  |\n| 正态分布 <br> $N\\left(\\mu, \\sigma^{2}\\right)$ | $p(x)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right)$ | $\\exp \\left(i \\mu t-\\frac{\\sigma^{2} t^{2}}{2}\\right)$ |\n| 指数分布 | $p(x)=\\lambda \\mathrm{e}^{-\\lambda x}, x>0$ | $\\left(1-\\frac{i t}{\\lambda}\\right)^{-1}$ |\n| 伽玛分布 <br> $G a(a, \\lambda)$ | $p(x)=\\frac{\\lambda^{\\alpha}}{\\Gamma(a)} x^{\\alpha-1} \\mathrm{e}^{-\\lambda x}, x \\geqslant 0$ | $\\left(1-\\frac{i t}{\\lambda}\\right)^{-a}$ |\n| $\\chi^{2}(n)$ 分布 | $p(x)=\\frac{x^{n / 2-1} \\mathrm{e}^{-x / 2}}{\\Gamma(n / 2) 2^{n / 2}}, x>0$ | $(1-2 i t)^{-n / 2}$ |  \n3. 伽玛分布 $G a(n, \\lambda)$ : 设 $Y \\sim G a(n, \\lambda)$, 则 $Y=X_{1}+X_{2}+\\cdots+X_{n}$, 其中 $X_{i}$ 独立同分布, 且 $X_{i} \\sim \\operatorname{Exp}(\\lambda)$. 由例 4.1.1 知  \n$$\n\\varphi_{X_{i}}(t)=\\left(1-\\frac{i t}{\\lambda}\\right)^{-1}\n$$  \n所以由独立随机变量和的特征函数为特征函数的积, 得  \n$$\n\\varphi_{Y}(t)=\\left(\\varphi_{X_{i}}(t)\\right)^{n}=\\left(1-\\frac{i t}{\\lambda}\\right)^{-n}\n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\chi^{2}(n)$ 分布 | $p(x)=\\frac{x^{n / 2-1} \\mathrm{e}^{-x / 2}}{\\Gamma(n / 2) 2^{n / 2}}, x>0$ | $(1-2 i t)^{-n / 2}$ |  \n3. 伽玛分布 $G a(n, \\lambda)$ : 设 $Y \\sim G a(n, \\lambda)$, 则 $Y=X_{1}+X_{2}+\\cdots+X_{n}$, 其中 $X_{i}$ 独立同分布, 且 $X_{i} \\sim \\operatorname{Exp}(\\lambda)$. 由例 4.1.1 知  \n$$\n\\varphi_{X_{i}}(t)=\\left(1-\\frac{i t}{\\lambda}\\right)^{-1}\n$$  \n所以由独立随机变量和的特征函数为特征函数的积, 得  \n$$\n\\varphi_{Y}(t)=\\left(\\varphi_{X_{i}}(t)\\right)^{n}=\\left(1-\\frac{i t}{\\lambda}\\right)^{-n}\n$$  \n进一步, 当 $a$ 为任一正实数时, 我们可得 $G a(n, \\lambda)$ 分布的特征函数为  \n$$\n\\varphi(t)=\\left(1-\\frac{i t}{\\lambda}\\right)^{-a}\n$$  \n4. $\\chi^{2}(n)$ 分布: 因为 $\\chi^{2}(n)=G a(n / 2,1 / 2)$, 所以 $\\chi^{2}(n)$ 分布的特征函数为  \n$$\n\\varphi(t)=(1-2 i t)^{-n / 2} .\n$$  \n上述常用分布的特征函数汇总在表 4.1.1 中.  \n下例是利用 (4.1.8) 来求分布的数学期望和方差.  \n例 4.1.3: 试利用特征函数的方法求伽玛分布 $G a(n, \\lambda)$ 的数学期望和方差.  \n解：因为伽玛分布 $G a(a, \\lambda)$ 的特征函数及其一、二阶导数为  \n$$\n\\begin{gathered}\n\\varphi(t)=\\left(1-\\frac{i t}{\\lambda}\\right)^{-a}, \\\\",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n进一步, 当 $a$ 为任一正实数时, 我们可得 $G a(n, \\lambda)$ 分布的特征函数为  \n$$\n\\varphi(t)=\\left(1-\\frac{i t}{\\lambda}\\right)^{-a}\n$$  \n4. $\\chi^{2}(n)$ 分布: 因为 $\\chi^{2}(n)=G a(n / 2,1 / 2)$, 所以 $\\chi^{2}(n)$ 分布的特征函数为  \n$$\n\\varphi(t)=(1-2 i t)^{-n / 2} .\n$$  \n上述常用分布的特征函数汇总在表 4.1.1 中.  \n下例是利用 (4.1.8) 来求分布的数学期望和方差.  \n例 4.1.3: 试利用特征函数的方法求伽玛分布 $G a(n, \\lambda)$ 的数学期望和方差.  \n解：因为伽玛分布 $G a(a, \\lambda)$ 的特征函数及其一、二阶导数为  \n$$\n\\begin{gathered}\n\\varphi(t)=\\left(1-\\frac{i t}{\\lambda}\\right)^{-a}, \\\\\n\\varphi^{\\prime}(t)=\\frac{a i}{\\lambda}\\left(1-\\frac{i t}{\\lambda}\\right)^{-a-1}, \\varphi^{\\prime}(0)=\\frac{a i}{\\lambda}, \\\\\n\\varphi^{\\prime \\prime}(t)=\\frac{a(a+1) i^{2}}{\\lambda^{2}}\\left(1-\\frac{i t}{\\lambda}\\right)^{-a-2}, \\varphi^{\\prime \\prime}(0)=-\\frac{a(a+1)}{\\lambda^{2}},\n\\end{gathered}\n$$  \n所以由 (4.1.9) 得  \n$$\nE(X)=\\frac{\\varphi^{\\prime}(0)}{i}=\\frac{a}{\\lambda},\n$$  \n特征函数还有以下一些优良性质.  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{gathered}\n\\varphi(t)=\\left(1-\\frac{i t}{\\lambda}\\right)^{-a}, \\\\\n\\varphi^{\\prime}(t)=\\frac{a i}{\\lambda}\\left(1-\\frac{i t}{\\lambda}\\right)^{-a-1}, \\varphi^{\\prime}(0)=\\frac{a i}{\\lambda}, \\\\\n\\varphi^{\\prime \\prime}(t)=\\frac{a(a+1) i^{2}}{\\lambda^{2}}\\left(1-\\frac{i t}{\\lambda}\\right)^{-a-2}, \\varphi^{\\prime \\prime}(0)=-\\frac{a(a+1)}{\\lambda^{2}},\n\\end{gathered}\n$$  \n所以由 (4.1.9) 得  \n$$\nE(X)=\\frac{\\varphi^{\\prime}(0)}{i}=\\frac{a}{\\lambda},\n$$  \n特征函数还有以下一些优良性质.  \n$$\n\\begin{aligned}\n\\operatorname{Var}(X) & =-\\varphi^{\\prime \\prime}(0)+\\left(\\varphi^{\\prime}(0)\\right)^{2}=\\frac{a(a+1)}{\\lambda^{2}}+\\left(\\frac{a i}{\\lambda}\\right)^{2} \\\\\n& =\\frac{a(a+1)}{\\lambda^{2}}-\\frac{a^{2}}{\\lambda^{2}}=\\frac{a}{\\lambda^{2}} .\n\\end{aligned}\n$$  \n定理 4.1 .1 (一致连续性). 随机变量 $X$ 的特征函数 $\\varphi(t)$ 在 $(-\\infty,+\\infty)$ 上一致连续.  \n证明：设 $X$ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $p(x)$, 则对任意实数 $t, h$ 和正数 $a>0$, 有  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n特征函数还有以下一些优良性质.  \n$$\n\\begin{aligned}\n\\operatorname{Var}(X) & =-\\varphi^{\\prime \\prime}(0)+\\left(\\varphi^{\\prime}(0)\\right)^{2}=\\frac{a(a+1)}{\\lambda^{2}}+\\left(\\frac{a i}{\\lambda}\\right)^{2} \\\\\n& =\\frac{a(a+1)}{\\lambda^{2}}-\\frac{a^{2}}{\\lambda^{2}}=\\frac{a}{\\lambda^{2}} .\n\\end{aligned}\n$$  \n定理 4.1 .1 (一致连续性). 随机变量 $X$ 的特征函数 $\\varphi(t)$ 在 $(-\\infty,+\\infty)$ 上一致连续.  \n证明：设 $X$ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $p(x)$, 则对任意实数 $t, h$ 和正数 $a>0$, 有  \n$$\n\\begin{aligned}\n|\\varphi(t+h)-\\varphi(t)| & =\\left|\\int_{-\\infty}^{+\\infty}\\left(\\mathrm{e}^{i h x}-1\\right) \\mathrm{e}^{i t x} p(x) \\mathrm{d} x\\right| \\\\\n& \\leqslant \\int_{-\\infty}^{+\\infty}\\left|\\mathrm{e}^{i h x}-1\\right| p(x) \\mathrm{d} x \\\\\n& \\leqslant \\int_{-a}^{a}\\left|\\mathrm{e}^{i h x}-1\\right| p(x) \\mathrm{d} x+2 \\int_{|x| \\geqslant a} p(x) \\mathrm{d} x .\n\\end{aligned}\n$$  \n对任意的 $\\varepsilon>0$, 先取定一个充分大的 $a$, 使得  \n$$\n2 \\int_{|x| \\geqslant a} p(x) \\mathrm{d} x<\\frac{\\varepsilon}{2}\n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "|\\varphi(t+h)-\\varphi(t)| & =\\left|\\int_{-\\infty}^{+\\infty}\\left(\\mathrm{e}^{i h x}-1\\right) \\mathrm{e}^{i t x} p(x) \\mathrm{d} x\\right| \\\\\n& \\leqslant \\int_{-\\infty}^{+\\infty}\\left|\\mathrm{e}^{i h x}-1\\right| p(x) \\mathrm{d} x \\\\\n& \\leqslant \\int_{-a}^{a}\\left|\\mathrm{e}^{i h x}-1\\right| p(x) \\mathrm{d} x+2 \\int_{|x| \\geqslant a} p(x) \\mathrm{d} x .\n\\end{aligned}\n$$  \n对任意的 $\\varepsilon>0$, 先取定一个充分大的 $a$, 使得  \n$$\n2 \\int_{|x| \\geqslant a} p(x) \\mathrm{d} x<\\frac{\\varepsilon}{2}\n$$  \n然后对任意的 $x \\in[-a, a]$, 只要取 $\\delta=\\varepsilon /(2 a)$, 则当 $|h|<\\delta$ 时, 便有  \n$$\n\\begin{aligned}\n\\left|\\mathrm{e}^{i h x}-1\\right| & =\\left|\\mathrm{e}^{i \\frac{h}{2} x}\\left(\\mathrm{e}^{i \\frac{h}{2} x}-\\mathrm{e}^{-i \\frac{h}{2} x}\\right)\\right| \\\\\n& =2\\left|\\sin \\frac{h x}{2}\\right| \\leqslant 2\\left|\\frac{h x}{2}\\right|<h a<\\frac{\\varepsilon}{2},\n\\end{aligned}\n$$  \n即 $\\varphi(t)$ 在 $(-\\infty,+\\infty)$ 上一致连续.",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n2 \\int_{|x| \\geqslant a} p(x) \\mathrm{d} x<\\frac{\\varepsilon}{2}\n$$  \n然后对任意的 $x \\in[-a, a]$, 只要取 $\\delta=\\varepsilon /(2 a)$, 则当 $|h|<\\delta$ 时, 便有  \n$$\n\\begin{aligned}\n\\left|\\mathrm{e}^{i h x}-1\\right| & =\\left|\\mathrm{e}^{i \\frac{h}{2} x}\\left(\\mathrm{e}^{i \\frac{h}{2} x}-\\mathrm{e}^{-i \\frac{h}{2} x}\\right)\\right| \\\\\n& =2\\left|\\sin \\frac{h x}{2}\\right| \\leqslant 2\\left|\\frac{h x}{2}\\right|<h a<\\frac{\\varepsilon}{2},\n\\end{aligned}\n$$  \n即 $\\varphi(t)$ 在 $(-\\infty,+\\infty)$ 上一致连续.  \n定理 4.1 .2 (非㑔定性). 随机变量 $X$ 的特征函数 $\\varphi(t)$ 是非负定的, 即对任意正整数 $n$, 及 $n$ 个实数 $t_{1}, t_{2}, \\cdots, t_{n}$ 和 $n$ 个复数 $z_{1}, z_{2}, \\cdots, z_{n}$, 有  \n$$\n\\begin{equation*}\n\\sum_{k=1}^{n} \\sum_{j=1}^{n} \\varphi\\left(t_{k}-t_{j}\\right) z_{k} \\overline{z_{j}} \\geqslant 0 \\tag{4.1.10}\n\\end{equation*}\n$$  \n证明: 仍设 $X$ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $p(x)$, 则有  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n即 $\\varphi(t)$ 在 $(-\\infty,+\\infty)$ 上一致连续.  \n定理 4.1 .2 (非㑔定性). 随机变量 $X$ 的特征函数 $\\varphi(t)$ 是非负定的, 即对任意正整数 $n$, 及 $n$ 个实数 $t_{1}, t_{2}, \\cdots, t_{n}$ 和 $n$ 个复数 $z_{1}, z_{2}, \\cdots, z_{n}$, 有  \n$$\n\\begin{equation*}\n\\sum_{k=1}^{n} \\sum_{j=1}^{n} \\varphi\\left(t_{k}-t_{j}\\right) z_{k} \\overline{z_{j}} \\geqslant 0 \\tag{4.1.10}\n\\end{equation*}\n$$  \n证明: 仍设 $X$ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $p(x)$, 则有  \n$$\n\\begin{aligned}\n\\sum_{k=1}^{n} \\sum_{j=1}^{n} \\varphi\\left(t_{k}-t_{j}\\right) z_{k} \\overline{z_{j}} & =\\sum_{k=1}^{n} \\sum_{j=1}^{n} z_{k} \\overline{z_{j}} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i\\left(t_{k}-t_{j}\\right) x} p(x) \\mathrm{d} x \\\\\n& =\\int_{-\\infty}^{+\\infty} \\sum_{k=1}^{n} \\sum_{j=1}^{n} z_{k} \\overline{z_{j}} \\mathrm{e}^{i\\left(t_{k}-t_{j}\\right) x} p(x) \\mathrm{d} x \\\\\n& =\\int_{-\\infty}^{+\\infty}\\left(\\sum_{k=1}^{n} z_{k} \\mathrm{e}^{i t_{k} x}\\right)\\left(\\sum_{j=1}^{n} \\overline{z_{j}} \\mathrm{e}^{-i t_{j} x}\\right) p(x) \\mathrm{d} x \\\\",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\int_{-\\infty}^{+\\infty} \\sum_{k=1}^{n} \\sum_{j=1}^{n} z_{k} \\overline{z_{j}} \\mathrm{e}^{i\\left(t_{k}-t_{j}\\right) x} p(x) \\mathrm{d} x \\\\\n& =\\int_{-\\infty}^{+\\infty}\\left(\\sum_{k=1}^{n} z_{k} \\mathrm{e}^{i t_{k} x}\\right)\\left(\\sum_{j=1}^{n} \\overline{z_{j}} \\mathrm{e}^{-i t_{j} x}\\right) p(x) \\mathrm{d} x \\\\\n& =\\int_{-\\infty}^{+\\infty}\\left|\\sum_{k=1}^{n} z_{k} \\mathrm{e}^{i t_{k} x}\\right|^{2} p(x) \\mathrm{d} x \\geqslant 0 .\n\\end{aligned}\n$$  \n这就证明了 (4.1.10) 式.  \n由特征函数的定义可知, 随机变量的分布惟一地确定了它的特征函数. 前面的讨论实际上都是从随机变量的分布出发, 讨论特征函数及其性质. 要注意的是: 如果两个分布的数学期望、方差及各阶矩都相等, 也无法证明此两个分布相等. 但特征函数却不同, 它有着比数学期望、方差及各阶矩更优良的性质: 即特征函数也完全决定了分布, 也就是说, 两个分布函数相等当且仅当它们所对应的特征函数相等.\n以下定理 4.1 .3 给出了由特征函数求分布函数的公式, 定理 4.1.5 给出了连续随机变量时由特征函数求密度函数的公式. 而定理 4.1.4 说明了分布函数与特征函数是一一对应的.  \n定理 4.1 .3 (逆转公式). 设 $F(x)$ 和 $\\varphi(t)$ 分别为随机变量 $X$ 的分布函数和特征函数, 则对 $F(x)$ 的任意两个连续点 $x_{1}<x_{2}$, 有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n这就证明了 (4.1.10) 式.  \n由特征函数的定义可知, 随机变量的分布惟一地确定了它的特征函数. 前面的讨论实际上都是从随机变量的分布出发, 讨论特征函数及其性质. 要注意的是: 如果两个分布的数学期望、方差及各阶矩都相等, 也无法证明此两个分布相等. 但特征函数却不同, 它有着比数学期望、方差及各阶矩更优良的性质: 即特征函数也完全决定了分布, 也就是说, 两个分布函数相等当且仅当它们所对应的特征函数相等.\n以下定理 4.1 .3 给出了由特征函数求分布函数的公式, 定理 4.1.5 给出了连续随机变量时由特征函数求密度函数的公式. 而定理 4.1.4 说明了分布函数与特征函数是一一对应的.  \n定理 4.1 .3 (逆转公式). 设 $F(x)$ 和 $\\varphi(t)$ 分别为随机变量 $X$ 的分布函数和特征函数, 则对 $F(x)$ 的任意两个连续点 $x_{1}<x_{2}$, 有  \n$$\n\\begin{equation*}\nF\\left(x_{2}\\right)-F\\left(x_{1}\\right)=\\lim _{T \\rightarrow \\infty} \\frac{1}{2 \\pi} \\int_{-T}^{T} \\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\varphi(t) \\mathrm{d} t \\tag{4.1.11}\n\\end{equation*}\n$$  \n证明: 设 $X$ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $p(x)$. 记  \n$$\n\\begin{aligned}\nJ_{T} & =\\frac{1}{2 \\pi} \\int_{-T}^{T} \\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\varphi(t) \\mathrm{d} t \\\\",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nF\\left(x_{2}\\right)-F\\left(x_{1}\\right)=\\lim _{T \\rightarrow \\infty} \\frac{1}{2 \\pi} \\int_{-T}^{T} \\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\varphi(t) \\mathrm{d} t \\tag{4.1.11}\n\\end{equation*}\n$$  \n证明: 设 $X$ 是连续随机变量 (离散随机变量的证明是类似的), 其密度函数为 $p(x)$. 记  \n$$\n\\begin{aligned}\nJ_{T} & =\\frac{1}{2 \\pi} \\int_{-T}^{T} \\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\varphi(t) \\mathrm{d} t \\\\\n& =\\frac{1}{2 \\pi} \\int_{-T}^{T}\\left[\\int_{-\\infty}^{+\\infty} \\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\mathrm{e}^{i t x} p(x)\\right] \\mathrm{d} t .\n\\end{aligned}\n$$  \n对任意的实数 $a$, 有  \n$$\n\\left|\\mathrm{e}^{i a}-1\\right| \\leqslant|a|,\n$$  \n事实上, 对 $a \\geqslant 0$ 有  \n$$\n\\left|\\mathrm{e}^{i a}-1\\right|=\\left|\\int_{0}^{t} \\mathrm{e}^{i x} \\mathrm{~d} x\\right| \\leqslant \\int_{0}^{a}\\left|\\mathrm{e}^{i x}\\right| \\mathrm{d} x=0\n$$  \n对 $a<0$, 有  \n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{1}{2 \\pi} \\int_{-T}^{T}\\left[\\int_{-\\infty}^{+\\infty} \\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\mathrm{e}^{i t x} p(x)\\right] \\mathrm{d} t .\n\\end{aligned}\n$$  \n对任意的实数 $a$, 有  \n$$\n\\left|\\mathrm{e}^{i a}-1\\right| \\leqslant|a|,\n$$  \n事实上, 对 $a \\geqslant 0$ 有  \n$$\n\\left|\\mathrm{e}^{i a}-1\\right|=\\left|\\int_{0}^{t} \\mathrm{e}^{i x} \\mathrm{~d} x\\right| \\leqslant \\int_{0}^{a}\\left|\\mathrm{e}^{i x}\\right| \\mathrm{d} x=0\n$$  \n对 $a<0$, 有  \n$$\n\\left|\\mathrm{e}^{i a}-1\\right|=\\left|\\mathrm{e}^{i a}\\left(\\mathrm{e}^{|a|}-1\\right)\\right|=\\left|\\mathrm{e}^{i|a|}-1\\right| \\leqslant|a|\n$$  \n因此  \n$$\n\\left|\\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\mathrm{e}^{i t x}\\right| \\leqslant x_{2}-x_{1} .\n$$  \n即 $J_{T}$ 中被积函数有界, 所以可以交换积分次序, 从而得  \n$$\n\\begin{aligned}\nJ_{T} & =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty}\\left[\\int_{-T}^{T} \\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\mathrm{e}^{i t x} \\mathrm{~d} t\\right] p(x) \\mathrm{d} x \\\\",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n因此  \n$$\n\\left|\\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\mathrm{e}^{i t x}\\right| \\leqslant x_{2}-x_{1} .\n$$  \n即 $J_{T}$ 中被积函数有界, 所以可以交换积分次序, 从而得  \n$$\n\\begin{aligned}\nJ_{T} & =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty}\\left[\\int_{-T}^{T} \\frac{\\mathrm{e}^{-i t x_{1}}-\\mathrm{e}^{-i t x_{2}}}{i t} \\mathrm{e}^{i t x} \\mathrm{~d} t\\right] p(x) \\mathrm{d} x \\\\\n& =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty}\\left[\\int_{0}^{T} \\frac{\\mathrm{e}^{i t\\left(x-x_{1}\\right)}-\\mathrm{e}^{-i t\\left(x-x_{1}\\right)}-\\mathrm{e}^{i t\\left(x-x_{2}\\right)}+\\mathrm{e}^{-i t\\left(x-x_{2}\\right)}}{i t} \\mathrm{~d} t\\right] p(x) \\mathrm{d} x \\\\\n& =\\frac{1}{\\pi} \\int_{-\\infty}^{+\\infty}\\left[\\int_{0}^{T}\\left(\\frac{\\sin t\\left(x-x_{1}\\right)}{t}-\\frac{\\sin t\\left(x-x_{2}\\right)}{t}\\right) \\mathrm{d} t\\right] p(x) \\mathrm{d} x .\n\\end{aligned}\n$$  \n又记  \n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty}\\left[\\int_{0}^{T} \\frac{\\mathrm{e}^{i t\\left(x-x_{1}\\right)}-\\mathrm{e}^{-i t\\left(x-x_{1}\\right)}-\\mathrm{e}^{i t\\left(x-x_{2}\\right)}+\\mathrm{e}^{-i t\\left(x-x_{2}\\right)}}{i t} \\mathrm{~d} t\\right] p(x) \\mathrm{d} x \\\\\n& =\\frac{1}{\\pi} \\int_{-\\infty}^{+\\infty}\\left[\\int_{0}^{T}\\left(\\frac{\\sin t\\left(x-x_{1}\\right)}{t}-\\frac{\\sin t\\left(x-x_{2}\\right)}{t}\\right) \\mathrm{d} t\\right] p(x) \\mathrm{d} x .\n\\end{aligned}\n$$  \n又记  \n$$\ng\\left(T, x, x_{1}, x_{2}\\right)=\\frac{1}{\\pi} \\int_{0}^{T}\\left(\\frac{\\sin t\\left(x-x_{1}\\right)}{t}-\\frac{\\sin t\\left(x-x_{2}\\right)}{t}\\right) \\mathrm{d} t,\n$$  \n则由数学中的狄利克雷积分  \n$$\nD(a)=\\frac{1}{\\pi} \\int_{0}^{+\\infty} \\frac{\\sin a t}{t} \\mathrm{~d} t= \\begin{cases}\\frac{1}{2}, & a>0 \\\\ 0, & a=0, \\\\ -\\frac{1}{2}, & a<0 .\\end{cases}\n$$  \n知  \n$$\n\\lim _{t \\rightarrow+\\infty} g\\left(T, x, x_{1}, x_{2}\\right)=D\\left(x-x_{1}\\right)-D\\left(x-x_{2}\\right)\n$$  \n分别考察 $x$ 在区间 $\\left(x_{1}, x_{2}\\right)$ 的端点及内外时狄利克雷积分的值即可得",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n则由数学中的狄利克雷积分  \n$$\nD(a)=\\frac{1}{\\pi} \\int_{0}^{+\\infty} \\frac{\\sin a t}{t} \\mathrm{~d} t= \\begin{cases}\\frac{1}{2}, & a>0 \\\\ 0, & a=0, \\\\ -\\frac{1}{2}, & a<0 .\\end{cases}\n$$  \n知  \n$$\n\\lim _{t \\rightarrow+\\infty} g\\left(T, x, x_{1}, x_{2}\\right)=D\\left(x-x_{1}\\right)-D\\left(x-x_{2}\\right)\n$$  \n分别考察 $x$ 在区间 $\\left(x_{1}, x_{2}\\right)$ 的端点及内外时狄利克雷积分的值即可得  \n$$\n\\lim _{t \\rightarrow+\\infty} g\\left(T, x, x_{1}, x_{2}\\right)= \\begin{cases}0, & x<x_{1} \\text { 或 } x>x_{2}, \\\\ \\frac{1}{2}, & x=x_{1} \\text { 或 } x=x_{2}, \\\\ 1, & x_{1}<x<x_{2},\\end{cases}\n$$  \n且 $\\left|g\\left(T, x, x_{1}, x_{2}\\right)\\right|$ 有界, 从而可以把积分号和极限号互换, 故有  \n$$\n\\begin{aligned}\n\\lim _{T \\rightarrow+\\infty} J_{T} & =\\int_{-\\infty}^{+\\infty} \\lim _{T \\rightarrow+\\infty} g\\left(T, x, x_{1}, x_{2}\\right) p(x) \\mathrm{d} x \\\\\n& =\\int_{x_{1}}^{x_{2}} p(x) \\mathrm{d} x=F\\left(x_{2}\\right)-F\\left(x_{1}\\right) .\n\\end{aligned}\n$$  \n定理得证.  \n定理 4.1 .4 (唯一性定理). 随机变量的分布函数由其特征函数唯一决定.",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n且 $\\left|g\\left(T, x, x_{1}, x_{2}\\right)\\right|$ 有界, 从而可以把积分号和极限号互换, 故有  \n$$\n\\begin{aligned}\n\\lim _{T \\rightarrow+\\infty} J_{T} & =\\int_{-\\infty}^{+\\infty} \\lim _{T \\rightarrow+\\infty} g\\left(T, x, x_{1}, x_{2}\\right) p(x) \\mathrm{d} x \\\\\n& =\\int_{x_{1}}^{x_{2}} p(x) \\mathrm{d} x=F\\left(x_{2}\\right)-F\\left(x_{1}\\right) .\n\\end{aligned}\n$$  \n定理得证.  \n定理 4.1 .4 (唯一性定理). 随机变量的分布函数由其特征函数唯一决定.  \n证明: 对 $F(x)$ 的每一个连续点 $x$, 当 $y$ 沿着 $F(x)$ 的连续点趋于 $-\\infty$ 时, 由逆转公式得  \n$$\nF(x)=\\lim _{y \\rightarrow-\\infty} \\lim _{T \\rightarrow+\\infty} \\frac{1}{2 \\pi} \\int_{-T}^{T} \\frac{\\mathrm{e}^{-i t y}-\\mathrm{e}^{-i t x}}{i t} \\varphi(t) \\mathrm{d} t,\n$$  \n而分布函数由其连续点上的值惟一决定, 故结论成立.  \n由于分布函数 $F(x)$ 是非降函数, 因此我们一定能做到让 $y$ 沿着 $F(x)$ 的连续点趋于 $-\\infty$, 并且 $F(x)$ 由其连续点上的值唯一确定, 而这些性质的证明在此从略了.  \n特别, 当 $X$ 为连续随机变量, 有下述更强的结果.  \n定理 4.1.5. 若 $X$ 为连续随机变量, 其密度函数为 $p(x)$, 特征函数为 $\\varphi(t)$. 如果 $\\int_{-\\infty}^{+\\infty}|\\varphi(t)| \\mathrm{d} t<+\\infty$,则  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nF(x)=\\lim _{y \\rightarrow-\\infty} \\lim _{T \\rightarrow+\\infty} \\frac{1}{2 \\pi} \\int_{-T}^{T} \\frac{\\mathrm{e}^{-i t y}-\\mathrm{e}^{-i t x}}{i t} \\varphi(t) \\mathrm{d} t,\n$$  \n而分布函数由其连续点上的值惟一决定, 故结论成立.  \n由于分布函数 $F(x)$ 是非降函数, 因此我们一定能做到让 $y$ 沿着 $F(x)$ 的连续点趋于 $-\\infty$, 并且 $F(x)$ 由其连续点上的值唯一确定, 而这些性质的证明在此从略了.  \n特别, 当 $X$ 为连续随机变量, 有下述更强的结果.  \n定理 4.1.5. 若 $X$ 为连续随机变量, 其密度函数为 $p(x)$, 特征函数为 $\\varphi(t)$. 如果 $\\int_{-\\infty}^{+\\infty}|\\varphi(t)| \\mathrm{d} t<+\\infty$,则  \n$$\n\\begin{equation*}\np(x)=\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i t x} \\varphi(t) \\mathrm{d} t \\tag{4.1.12}\n\\end{equation*}\n$$  \n证明: 记 $X$ 的分布函数为 $F(x)$, 由逆转公式知  \n$$\n\\begin{aligned}\np(x) & =\\lim _{\\Delta x \\rightarrow 0} \\frac{F(x+\\Delta x)-F(x)}{\\Delta x} \\\\\n& =\\lim _{\\Delta x \\rightarrow 0} \\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\frac{\\mathrm{e}^{-i t x}-\\mathrm{e}^{-i t(x+\\Delta x)}}{i t \\cdot \\Delta x} \\varphi(t) \\mathrm{d} t .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\np(x)=\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i t x} \\varphi(t) \\mathrm{d} t \\tag{4.1.12}\n\\end{equation*}\n$$  \n证明: 记 $X$ 的分布函数为 $F(x)$, 由逆转公式知  \n$$\n\\begin{aligned}\np(x) & =\\lim _{\\Delta x \\rightarrow 0} \\frac{F(x+\\Delta x)-F(x)}{\\Delta x} \\\\\n& =\\lim _{\\Delta x \\rightarrow 0} \\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\frac{\\mathrm{e}^{-i t x}-\\mathrm{e}^{-i t(x+\\Delta x)}}{i t \\cdot \\Delta x} \\varphi(t) \\mathrm{d} t .\n\\end{aligned}\n$$  \n再次利用不等式 $\\left|\\mathrm{e}^{i a}-1\\right| \\leqslant|a|$, 就有  \n$$\n\\left|\\frac{\\mathrm{e}^{-i t x}-\\mathrm{e}^{-i t(x+\\Delta x)}}{i t \\cdot \\Delta x}\\right| \\leqslant 1\n$$  \n又因为 $\\int_{-\\infty}^{+\\infty}|\\varphi(t)|<+\\infty$, 所以可以交换极限号和积分号, 即  \n$$\n\\begin{aligned}\np(x) & =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\lim _{\\Delta x \\rightarrow 0} \\frac{\\mathrm{e}^{-i t x}-\\mathrm{e}^{-i t(x+\\Delta x)}}{i t \\cdot \\Delta x} \\varphi(t) \\mathrm{d} t \\\\",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n再次利用不等式 $\\left|\\mathrm{e}^{i a}-1\\right| \\leqslant|a|$, 就有  \n$$\n\\left|\\frac{\\mathrm{e}^{-i t x}-\\mathrm{e}^{-i t(x+\\Delta x)}}{i t \\cdot \\Delta x}\\right| \\leqslant 1\n$$  \n又因为 $\\int_{-\\infty}^{+\\infty}|\\varphi(t)|<+\\infty$, 所以可以交换极限号和积分号, 即  \n$$\n\\begin{aligned}\np(x) & =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\lim _{\\Delta x \\rightarrow 0} \\frac{\\mathrm{e}^{-i t x}-\\mathrm{e}^{-i t(x+\\Delta x)}}{i t \\cdot \\Delta x} \\varphi(t) \\mathrm{d} t \\\\\n& =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i t x} \\varphi(t) \\mathrm{d} t .\n\\end{aligned}\n$$  \n定理得证。  \n(4.1.12) 在数学分析中也称为傅里叶逆变换, 所以 (4.1.3) 和 (4.1.12) 实质上是一对互逆的变换:  \n$$\n\\begin{gathered}\n\\varphi(t)=\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x \\\\\nP(x)=\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i t x} \\varphi(t) \\mathrm{d} t\n\\end{gathered}\n$$  \n即特征函数是密度函数的傅里叶变换, 而密度函数是特征函数的傅星叶逆变换",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i t x} \\varphi(t) \\mathrm{d} t .\n\\end{aligned}\n$$  \n定理得证。  \n(4.1.12) 在数学分析中也称为傅里叶逆变换, 所以 (4.1.3) 和 (4.1.12) 实质上是一对互逆的变换:  \n$$\n\\begin{gathered}\n\\varphi(t)=\\int_{-\\infty}^{+\\infty} \\mathrm{e}^{i t x} p(x) \\mathrm{d} x \\\\\nP(x)=\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i t x} \\varphi(t) \\mathrm{d} t\n\\end{gathered}\n$$  \n即特征函数是密度函数的傅里叶变换, 而密度函数是特征函数的傅星叶逆变换  \n在此着重指出: 在概率论中, 独立随机变量和的问题占有 “中心” 地位, 用卷积公式去处理独立随机变量和的问题是相当复杂, 而引人了特征函数可以很方便地用特征函数相乘求得独立随机变量和的特征函数, 由此大大简化了处理独立随机变量和的难度. 读者可从下例中体会出这一点.例 4.1.4: 在 3.3.4 节中, 我们用卷积公式通过复杂的计算证明了二项分布、泊松分布、伽玛分布和\n$\\chi^{2}$ 分布的可加性. 现在用特征函数方法 (性质 4.1.2 和唯一性定理) 可以很方便地证明正态分布的可加性. 设 $X \\sim N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right), Y \\sim N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$ 且 $X$ 与 $Y$ 独立. 因为  \n$$\n\\varphi_{X}(t)=\\exp \\left(i t \\mu_{1}-\\frac{\\sigma_{1}^{2} t^{2}}{2}\\right), \\varphi_{Y}(t)=\\exp \\left(i t \\mu_{2}-\\frac{\\sigma_{2}^{2} t^{2}}{2}\\right)\n$$  \n所以由性质 4.1.2 得  \n$$",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$\\chi^{2}$ 分布的可加性. 现在用特征函数方法 (性质 4.1.2 和唯一性定理) 可以很方便地证明正态分布的可加性. 设 $X \\sim N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right), Y \\sim N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$ 且 $X$ 与 $Y$ 独立. 因为  \n$$\n\\varphi_{X}(t)=\\exp \\left(i t \\mu_{1}-\\frac{\\sigma_{1}^{2} t^{2}}{2}\\right), \\varphi_{Y}(t)=\\exp \\left(i t \\mu_{2}-\\frac{\\sigma_{2}^{2} t^{2}}{2}\\right)\n$$  \n所以由性质 4.1.2 得  \n$$\n\\varphi_{X+Y}(t)=\\varphi_{X}(t) \\cdot \\varphi_{Y}(t)=\\exp \\left(i t\\left(\\mu_{1}+\\mu_{2}\\right)-\\frac{\\left(\\sigma_{1}^{2}+\\sigma_{2}^{2}\\right) t^{2}}{2}\\right) .\n$$  \n这正是 $N\\left(\\mu_{1}+\\mu_{2}, \\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)$ 的特征函数, 再由特征函数的唯一性定理, 即知  \n$$\nX+Y \\sim N\\left(\\mu_{1}+\\mu_{2}, \\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)\n$$  \n同理可证: 若 $X_{j}$ 相互独立, 且 $X_{j} \\sim N\\left(\\mu_{j}, \\sigma_{j}^{2}\\right), j=1,2, \\cdots, n$, 则  \n$$\n\\sum_{j=1}^{n} X_{j} \\sim N\\left(\\sum_{j=1}^{n} \\mu_{j}, \\sum_{j=1}^{n} \\sigma_{J}^{2}\\right)\n$$  \n例 4.1.5: 已知连续随机变量的特征函数如下, 求其分布.  \n1. $\\varphi_{1}(t)=\\mathrm{e}^{-|t|}$,",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n这正是 $N\\left(\\mu_{1}+\\mu_{2}, \\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)$ 的特征函数, 再由特征函数的唯一性定理, 即知  \n$$\nX+Y \\sim N\\left(\\mu_{1}+\\mu_{2}, \\sigma_{1}^{2}+\\sigma_{2}^{2}\\right)\n$$  \n同理可证: 若 $X_{j}$ 相互独立, 且 $X_{j} \\sim N\\left(\\mu_{j}, \\sigma_{j}^{2}\\right), j=1,2, \\cdots, n$, 则  \n$$\n\\sum_{j=1}^{n} X_{j} \\sim N\\left(\\sum_{j=1}^{n} \\mu_{j}, \\sum_{j=1}^{n} \\sigma_{J}^{2}\\right)\n$$  \n例 4.1.5: 已知连续随机变量的特征函数如下, 求其分布.  \n1. $\\varphi_{1}(t)=\\mathrm{e}^{-|t|}$,\n2. $\\varphi_{2}(t)=\\frac{\\sim a t}{a t}$.  \n解:  \n1. 由逆转公式 (4.1.12) 可知其密度函数为  \n$$\n\\begin{aligned}\np(x) & =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i x t} \\cdot \\mathrm{e}^{-|t|} \\mathrm{d} t \\\\\n& =\\frac{1}{2 \\pi} \\int_{0}^{+\\infty} \\mathrm{e}^{-(1+i x) t} \\mathrm{~d} t+\\frac{1}{2 \\pi} \\int_{-\\infty}^{0} \\mathrm{e}^{(1-i x) t} \\mathrm{~d} t \\\\\n& =\\frac{1}{2 \\pi}\\left(\\frac{1}{1+i x}+\\frac{1}{1-i x}\\right)=\\frac{1}{\\pi\\left(1+x^{2}\\right)}\n\\end{aligned}\n$$  \n这是柯西分布, 所以特征函数 $\\varphi_{1}(t)=e^{-|t|}$ 对应的是柯西分布.",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "解:  \n1. 由逆转公式 (4.1.12) 可知其密度函数为  \n$$\n\\begin{aligned}\np(x) & =\\frac{1}{2 \\pi} \\int_{-\\infty}^{+\\infty} \\mathrm{e}^{-i x t} \\cdot \\mathrm{e}^{-|t|} \\mathrm{d} t \\\\\n& =\\frac{1}{2 \\pi} \\int_{0}^{+\\infty} \\mathrm{e}^{-(1+i x) t} \\mathrm{~d} t+\\frac{1}{2 \\pi} \\int_{-\\infty}^{0} \\mathrm{e}^{(1-i x) t} \\mathrm{~d} t \\\\\n& =\\frac{1}{2 \\pi}\\left(\\frac{1}{1+i x}+\\frac{1}{1-i x}\\right)=\\frac{1}{\\pi\\left(1+x^{2}\\right)}\n\\end{aligned}\n$$  \n这是柯西分布, 所以特征函数 $\\varphi_{1}(t)=e^{-|t|}$ 对应的是柯西分布.\n2. $\\varphi_{2}(t)=\\sin a t / a t$ 是均匀分布 $U(-a, a)$ 的特征函数, 由唯一性定理知, 该特征函数对应的分布不是别的, 只能是均匀分布 $U(-a, a)$.",
        "metadata": {
            "Header 2": "4.1 特征函数",
            "Header 3": "4.1.2 特征函数的性质"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设离微随机变量 $X$ 的分布列如下, 试求 $X$ 的特征函数.  \n| $X$ | 0 | 1 | 2 | 3 |\n| :---: | :---: | :---: | :---: | :---: |\n| $P$ | 0.4 | 0.3 | 0.2 | 0.1 |  \n2. 设离散随机变量 $X$ 服从几何分布  \n$$\nP(X=k)=(1-p)^{k-1} p, k=1,2, \\cdots .\n$$  \n试求 $X$ 的特征函数, 并以此求 $E(X)$ 和 $\\operatorname{Var}(X)$.  \n3. 设离散随机变量 $X$ 服从巴斯卡分布  \n$$\nP(X=k)=\\left(\\begin{array}{l}\nk-1 \\\\\nr-1\n\\end{array}\\right) p^{r}(1-p)^{k-r}, k=r, r+1, \\cdots\n$$  \n试求 $X$ 的特征函数.  \n4. 求下列分布函数的特征函数, 并由特征函数求其数学期望和方差.  \n(1) $F_{1}(x)=a / 2 \\int_{-\\infty}^{x} \\mathrm{e}^{-a|x|} \\mathrm{d} x,(a>0)$.  \n(2) $F_{2}(x)=a / \\pi \\int_{-\\infty}^{x} \\frac{1}{x^{2}+a^{2}} \\mathrm{~d} x,(a>0)$.  \n5. 设 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 试用特征函数的方法求 $X$ 的 3 阶及 4 阶中心矩.\n6. 试用特征函数的方法证明二项分布的可加性: 若 $X \\sim b(m, p), Y \\sim b(m, p)$, 且 $X$ 与 $Y$ 独立,\n则 $X+Y \\sim b(n+m, p)$.\n7. 试用特征函数的方法证明泊松分布的可加性: 若 $X \\sim P\\left(\\lambda_{1}\\right), Y \\sim P\\left(\\lambda_{2}\\right)$, 目 $X$ 与 $Y$ 独立, 则 $X+Y \\sim P\\left(\\lambda_{1}+\\lambda_{2}\\right)$.",
        "metadata": {
            "Header 2": "丑习题 4.1"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) $F_{2}(x)=a / \\pi \\int_{-\\infty}^{x} \\frac{1}{x^{2}+a^{2}} \\mathrm{~d} x,(a>0)$.  \n5. 设 $X \\sim N\\left(\\mu, \\sigma^{2}\\right)$, 试用特征函数的方法求 $X$ 的 3 阶及 4 阶中心矩.\n6. 试用特征函数的方法证明二项分布的可加性: 若 $X \\sim b(m, p), Y \\sim b(m, p)$, 且 $X$ 与 $Y$ 独立,\n则 $X+Y \\sim b(n+m, p)$.\n7. 试用特征函数的方法证明泊松分布的可加性: 若 $X \\sim P\\left(\\lambda_{1}\\right), Y \\sim P\\left(\\lambda_{2}\\right)$, 目 $X$ 与 $Y$ 独立, 则 $X+Y \\sim P\\left(\\lambda_{1}+\\lambda_{2}\\right)$.\n8. 试用特征函数的方法证明伽玛分布的可加性: 若 $X \\sim G a\\left(a_{1}, \\lambda\\right), Y \\sim G a\\left(a_{1}, \\lambda\\right)$, 且 $X$ 与 $Y$ 独立, 则 $X+Y \\sim G a\\left(a_{1}+a_{2}, \\lambda\\right)$.\n9. 试用特征函数的方法证明 $\\chi^{2}$ 分布的可加性: 若 $X \\sim \\chi^{2}(n), Y \\sim \\chi^{2}(m)$, 且 $X$ 与 $Y$ 独立, 则 $X+Y \\sim \\chi^{2}(m+n)$.\n10. 设 $X_{i}$ 独立同分布, 且 $X_{i} \\sim \\operatorname{Exp}(\\lambda), i=1,2, \\cdots, n$. 试用特征函敷的方法证明: $Y_{n}=\\sum_{i=1}^{n} X_{i} \\sim$ $G a(n, \\lambda)$.\n11. 设连续随机变量 $X$ 的密度函数如下:  \n$$\np(x)=\\frac{1}{\\pi} \\cdot \\frac{\\lambda}{\\lambda^{2}+(x-\\mu)^{2}},-\\infty<x<+\\infty\n$$",
        "metadata": {
            "Header 2": "丑习题 4.1"
        },
        "type": "Document"
    },
    {
        "page_content": "9. 试用特征函数的方法证明 $\\chi^{2}$ 分布的可加性: 若 $X \\sim \\chi^{2}(n), Y \\sim \\chi^{2}(m)$, 且 $X$ 与 $Y$ 独立, 则 $X+Y \\sim \\chi^{2}(m+n)$.\n10. 设 $X_{i}$ 独立同分布, 且 $X_{i} \\sim \\operatorname{Exp}(\\lambda), i=1,2, \\cdots, n$. 试用特征函敷的方法证明: $Y_{n}=\\sum_{i=1}^{n} X_{i} \\sim$ $G a(n, \\lambda)$.\n11. 设连续随机变量 $X$ 的密度函数如下:  \n$$\np(x)=\\frac{1}{\\pi} \\cdot \\frac{\\lambda}{\\lambda^{2}+(x-\\mu)^{2}},-\\infty<x<+\\infty\n$$  \n其中参数 $\\lambda>0,-\\infty<\\mu<+\\infty$. 试证  \n(1) $X$ 的特征函数为 $\\exp (i \\mu t-\\lambda|t|)$, 且利用此结果证明柯西分布的可加性.  \n(2) 当 $\\mu=0, \\lambda=1$ 时, 记 $Y=X$, 试证 $\\varphi_{X+Y}(t)=\\varphi_{X}(t) \\cdot \\varphi_{Y}(t)$, 但是 $X$ 与 $Y$ 不独立.  \n(3) 若 $X_{1}, X_{2}, \\cdots, X_{n}$ 相互独立, 且服从同一柯西分布, 试证: $(1 / n)\\left(X_{1}+X_{2}+\\cdots+X_{n}\\right)$ 与 $X_{1}$同分布.  \n12. 设连续随机变量 $X$ 的密度函数为 $p(x)$, 试证: $p(x)$ 关于原点对称的充要条件是它的特征函数是实的偶函数.\n13. 设 $X_{1}, X_{2}, \\cdots, X_{n}$ 独立同分布, 且都服从 $N\\left(\\mu, \\sigma^{2}\\right)$ 分布, 试求 $\\bar{X}=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}$ 的分布.",
        "metadata": {
            "Header 2": "丑习题 4.1"
        },
        "type": "Document"
    },
    {
        "page_content": "“概率是频率的稳定值”, 其中 “稳定”一词是什么含义? 在第一章我们从直观上描述稳定性：频率在其概率附近摆动. 但如何摆动仍没说清楚, 现在可用大数定律来彻底说清这个问题了.  \n大数定律有多种形式, 下面从最简单的伯努利大数定律说起, 逐步介绍各种大数定律.",
        "metadata": {
            "Header 2": "4.2 大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "记 $\\mu_{n}$ 为 $n$ 重伯努利试验中事件 $A$ 出现的次数, 称 $\\mu_{n} / n$ 为事件 $A$ 出现的频率.  \n如果记一次试验中 $A$ 发生的概率为 $p$, 则 $\\mu_{n}$ 服从二项分布 $b\\left(n, p\\right.$, 因此频率 $\\mu_{n} / n$ 的数学期望与方差分别为  \n$$\n\\begin{equation*}\nE\\left(\\frac{\\mu_{n}}{n}\\right)=p, \\operatorname{Var}\\left(\\frac{\\mu_{n}}{n}\\right)=\\frac{p(1-p)}{n} \\tag{4.2.1}\n\\end{equation*}\n$$  \n下面我们讨论 $n \\rightarrow+\\infty$ 时, 频率 $\\mu_{n} / n$ 的极限状态.  \n由 (4.2.1) 式, 当 $n \\rightarrow+\\infty$ 时, 频率的数学期望 $p$ 保持不变, 而方差趋于 0 . 我们已经知道方差为 0 的随机变量是常数, 那么现在的问题是频率 $\\mu_{n} / n$ 是如何 “收玫于” 概率 $p$, 即我们如何来理解 “收敛”一词.  \n按数学分析中的数列极限概念, 数列 $\\left\\{\\mu_{n} / n\\right\\}$ 的极限为 $p$,  \n$$\n\\lim _{n \\rightarrow+\\infty} \\frac{\\mu_{n}}{n}=p\n$$  \n即对任意的 $\\varepsilon>0$, 当 $n$ 充分大时, “必定” 有  \n$$\n\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon,\n$$  \n而其对立事件  \n$$\n\\left|\\frac{\\mu_{n}}{n}-p\\right| \\geqslant \\varepsilon\n$$  \n是 “必定” 不会发生的. 然而在随机现象中各种情况都可能出现, 甚至事件 “ $\\mu_{n}=n$ ” 也是可能发生的, 因为 $p\\left(\\mu_{n}=n\\right)=p^{n}>0$, 即事件 “ $\\mu_{n}=n$ ” 的概率大于零, 从而事件  \n$$",
        "metadata": {
            "Header 2": "4.2 大数定律",
            "Header 3": "4.2.1 伯努利大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "按数学分析中的数列极限概念, 数列 $\\left\\{\\mu_{n} / n\\right\\}$ 的极限为 $p$,  \n$$\n\\lim _{n \\rightarrow+\\infty} \\frac{\\mu_{n}}{n}=p\n$$  \n即对任意的 $\\varepsilon>0$, 当 $n$ 充分大时, “必定” 有  \n$$\n\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon,\n$$  \n而其对立事件  \n$$\n\\left|\\frac{\\mu_{n}}{n}-p\\right| \\geqslant \\varepsilon\n$$  \n是 “必定” 不会发生的. 然而在随机现象中各种情况都可能出现, 甚至事件 “ $\\mu_{n}=n$ ” 也是可能发生的, 因为 $p\\left(\\mu_{n}=n\\right)=p^{n}>0$, 即事件 “ $\\mu_{n}=n$ ” 的概率大于零, 从而事件  \n$$\n\\left|\\frac{\\mu_{n}}{n}-p\\right| \\geqslant \\varepsilon\n$$  \n就有可能发生. 这说明用数学分析中的极限来描述频率的极限是不妥当的, 是对频率随机性的认识不足的表现.  \n为此, 频率 “收玫于” 概率用以下方式描述是合适的: 当 $n$ 充分大时, 频率 $\\mu_{n} / n$ 与概率 $p$ 间有大偏差的概率很小, 而且随着 $n$ 的增大, 它愈来愈小. 用数学语言来讲, 就是对任意的 $\\varepsilon>0$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon\\right)=1 . \\tag{4.2.2}\n\\end{equation*}\n$$  \n或  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right| \\geqslant \\varepsilon\\right)=0 \\tag{4.2.3}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "4.2 大数定律",
            "Header 3": "4.2.1 伯努利大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n就有可能发生. 这说明用数学分析中的极限来描述频率的极限是不妥当的, 是对频率随机性的认识不足的表现.  \n为此, 频率 “收玫于” 概率用以下方式描述是合适的: 当 $n$ 充分大时, 频率 $\\mu_{n} / n$ 与概率 $p$ 间有大偏差的概率很小, 而且随着 $n$ 的增大, 它愈来愈小. 用数学语言来讲, 就是对任意的 $\\varepsilon>0$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon\\right)=1 . \\tag{4.2.2}\n\\end{equation*}\n$$  \n或  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right| \\geqslant \\varepsilon\\right)=0 \\tag{4.2.3}\n\\end{equation*}\n$$  \n这种收玫性就称作依概率收玫, 它的一般定义将在 $\\S 4.3$ 节中给出. 下面的伯努利大数定律就是对上述讨论作了一个很好的总结.  \n定理 4.2.1 (伯努利大数定律). 设 $\\mu_{n}$ 为 $n$ 重伯努利试验中事件 $\\mathrm{A}$ 发生的次数, $p$ 为每次试验中 $\\mathrm{A}$出现的概率, 则对任意的 $\\varepsilon>0$, 有  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon\\right)=1\n$$  \n证明: 因为 $\\mu_{n} \\sim b(n, p)$, 且 $\\mu_{n}$ 的数学期望和方差如 (4.2.1) 式所示. 所以由切比雪夫不等式得  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "4.2 大数定律",
            "Header 3": "4.2.1 伯努利大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n这种收玫性就称作依概率收玫, 它的一般定义将在 $\\S 4.3$ 节中给出. 下面的伯努利大数定律就是对上述讨论作了一个很好的总结.  \n定理 4.2.1 (伯努利大数定律). 设 $\\mu_{n}$ 为 $n$ 重伯努利试验中事件 $\\mathrm{A}$ 发生的次数, $p$ 为每次试验中 $\\mathrm{A}$出现的概率, 则对任意的 $\\varepsilon>0$, 有  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon\\right)=1\n$$  \n证明: 因为 $\\mu_{n} \\sim b(n, p)$, 且 $\\mu_{n}$ 的数学期望和方差如 (4.2.1) 式所示. 所以由切比雪夫不等式得  \n$$\n\\begin{equation*}\n1 \\geqslant P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon\\right) \\geqslant 1-\\frac{\\operatorname{Var}\\left(\\mu_{n} / n\\right)}{\\varepsilon^{2}}=1-\\frac{p(1-p)}{n \\varepsilon^{2}} . \\tag{4.2.4}\n\\end{equation*}\n$$  \n当 $n \\rightarrow+\\infty$ 时, 上式右端趋于 1 , 因此  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon\\right)=1\n$$  \n结论得证.  \n伯努利大数定律说明: 随着 $n$ 的增大, 事件 A 发生的频率 $\\mu_{n} / n$ 与其频率 $p$ 的偏差 $\\left|\\mu_{n} / n-p\\right|$大于预先给定的精度 $\\varepsilon$ 的可能性愈来愈小, 小到可以忽略不计. 这就是频率稳定于概率的含义, 或者说频率依概率收玫于概率.",
        "metadata": {
            "Header 2": "4.2 大数定律",
            "Header 3": "4.2.1 伯努利大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n当 $n \\rightarrow+\\infty$ 时, 上式右端趋于 1 , 因此  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{\\mu_{n}}{n}-p\\right|<\\varepsilon\\right)=1\n$$  \n结论得证.  \n伯努利大数定律说明: 随着 $n$ 的增大, 事件 A 发生的频率 $\\mu_{n} / n$ 与其频率 $p$ 的偏差 $\\left|\\mu_{n} / n-p\\right|$大于预先给定的精度 $\\varepsilon$ 的可能性愈来愈小, 小到可以忽略不计. 这就是频率稳定于概率的含义, 或者说频率依概率收玫于概率.  \n譬如, 抛一枚硬币出现正面的概率 $p=0.5$. 若把这枚硬币连抛 10 次, 则因为 $n$ 较小, 发生大偏差的可能性有时会大一些, 有时会小一些. 若把这枚硬币连抛 $n$, 当 $n$ 很大时, 由切比雪夫不等式知: 正面出现的频率与 0.5 的偏差大于预先给定的精度 $\\varepsilon$ (若取精度 $\\varepsilon=0.01$ ) 的可能性  \n$$\nP\\left(\\left|\\frac{\\mu_{n}}{n}-0.5\\right|>0.01\\right) \\leqslant \\frac{0.5 \\times 0.5}{n 0.01^{n}}=\\frac{10^{4}}{4 n} .\n$$  \n当 $n=10^{5}$ 时, 大偏差发生的可能性小于 $1 / 40=2.5 \\%$. 当 $n=10^{6}$ 时, 大偏差发生的可能性小于 $1 / 400=0.25 \\%$. 可见试验次数愈多, 偏差发生的可能性愈小.  \n伯努利大数定律提供了用频率来确定概率的理论依据. 譬如要估计某种产品的不合格品率 $p$,则可从该种产品中随机抽取 $n$ 件, 当 $n$ 很大时, 这 $n$ 件产品中的不合格品的比例可作为不合格品率 $p$ 的估计值.  \n例 4.2.1(用蒙特卡洛方法计算定积分 (随机投点法)): 设 $0 \\leqslant f(x) \\leqslant 1$, 求 $f(x)$ 在区间 $[0,1]$ 上的积分值:  \n$$",
        "metadata": {
            "Header 2": "4.2 大数定律",
            "Header 3": "4.2.1 伯努利大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP\\left(\\left|\\frac{\\mu_{n}}{n}-0.5\\right|>0.01\\right) \\leqslant \\frac{0.5 \\times 0.5}{n 0.01^{n}}=\\frac{10^{4}}{4 n} .\n$$  \n当 $n=10^{5}$ 时, 大偏差发生的可能性小于 $1 / 40=2.5 \\%$. 当 $n=10^{6}$ 时, 大偏差发生的可能性小于 $1 / 400=0.25 \\%$. 可见试验次数愈多, 偏差发生的可能性愈小.  \n伯努利大数定律提供了用频率来确定概率的理论依据. 譬如要估计某种产品的不合格品率 $p$,则可从该种产品中随机抽取 $n$ 件, 当 $n$ 很大时, 这 $n$ 件产品中的不合格品的比例可作为不合格品率 $p$ 的估计值.  \n例 4.2.1(用蒙特卡洛方法计算定积分 (随机投点法)): 设 $0 \\leqslant f(x) \\leqslant 1$, 求 $f(x)$ 在区间 $[0,1]$ 上的积分值:  \n$$\nJ=\\int_{0}^{1} f(x) \\mathrm{d} x\n$$  \n设 $(X, Y)$ 服从正方形 $\\{0 \\leqslant x \\leqslant 1,0 \\leqslant y \\leqslant 1\\}$ 上的均匀分布, 则可知 $X$ 服从 $[0,1]$ 上的均匀分布,\n$Y$ 也服从 $[0,1]$ 上的均匀分布, 且 $X$ 与 $Y$ 独立. 又记事件  \n$$\nA=\\{Y \\leqslant f(X)\\},\n$$  \n则 $A$ 的概率为  \n$$\np=P(Y \\leqslant f(x))=\\int_{0}^{1} \\int_{0}^{f(x)} \\mathrm{d} y \\mathrm{~d} x=\\int_{0}^{1} f(x) \\mathrm{d} x=J .\n$$  \n即定积分的值 $J$ 就是事件 $A$ 的概率 $p$. 由伯努利大数定律, 我们可以用重复试验中 $A$ 出现的  \n!  \n图 4.2.1: 随机投点法",
        "metadata": {
            "Header 2": "4.2 大数定律",
            "Header 3": "4.2.1 伯努利大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nJ=\\int_{0}^{1} f(x) \\mathrm{d} x\n$$  \n设 $(X, Y)$ 服从正方形 $\\{0 \\leqslant x \\leqslant 1,0 \\leqslant y \\leqslant 1\\}$ 上的均匀分布, 则可知 $X$ 服从 $[0,1]$ 上的均匀分布,\n$Y$ 也服从 $[0,1]$ 上的均匀分布, 且 $X$ 与 $Y$ 独立. 又记事件  \n$$\nA=\\{Y \\leqslant f(X)\\},\n$$  \n则 $A$ 的概率为  \n$$\np=P(Y \\leqslant f(x))=\\int_{0}^{1} \\int_{0}^{f(x)} \\mathrm{d} y \\mathrm{~d} x=\\int_{0}^{1} f(x) \\mathrm{d} x=J .\n$$  \n即定积分的值 $J$ 就是事件 $A$ 的概率 $p$. 由伯努利大数定律, 我们可以用重复试验中 $A$ 出现的  \n!  \n图 4.2.1: 随机投点法  \n额率作为 $p$ 的估计值. 这种求定积分的方法也称为随机投点法, 即将 $(X, Y)$ 看成是向正方形 $\\{0 \\leqslant x \\leqslant 1,0 \\leqslant y \\leqslant 1\\}$ 内的随机投点, 用随机点落在区域 $\\{y \\leqslant f(x)\\}$ 中的频率作为定积分的近似值.  \n下面用蒙特卡洛方法, 来得到 $A$ 出现的频率:  \n1. 先用计算机产生 $(0,1)$ 上均匀分布的 $2 n$ 个随机数: $x_{i}, y_{i}, i=1,2, \\cdots, n$, 这里 $n$ 可以很大,臂如 $n=10^{4}$, 甚至 $n=10^{5}$.\n2. 对 $n$ 对数据 $\\left(x_{i}, y_{i}\\right), i=1,2, \\cdots, n$, 记录满足如下不等式  \n$$\ny_{i} \\leqslant f(x)\n$$  \n的次数, 这就是事件 $\\mathrm{A}$ 发生的频数 $\\mu_{n}$. 由此可得事件 $A$ 发生的频率 $\\mu_{n} / n$, 则 $J \\approx \\mu_{n} / n$.",
        "metadata": {
            "Header 2": "4.2 大数定律",
            "Header 3": "4.2.1 伯努利大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "下面用蒙特卡洛方法, 来得到 $A$ 出现的频率:  \n1. 先用计算机产生 $(0,1)$ 上均匀分布的 $2 n$ 个随机数: $x_{i}, y_{i}, i=1,2, \\cdots, n$, 这里 $n$ 可以很大,臂如 $n=10^{4}$, 甚至 $n=10^{5}$.\n2. 对 $n$ 对数据 $\\left(x_{i}, y_{i}\\right), i=1,2, \\cdots, n$, 记录满足如下不等式  \n$$\ny_{i} \\leqslant f(x)\n$$  \n的次数, 这就是事件 $\\mathrm{A}$ 发生的频数 $\\mu_{n}$. 由此可得事件 $A$ 发生的频率 $\\mu_{n} / n$, 则 $J \\approx \\mu_{n} / n$.  \n| 譬如计算 $\\int_{0}^{1} \\mathrm{e}^{-x^{2} / 2} / \\sqrt{2 \\pi} \\mathrm{d} x$, , 其精确值和 $n=10^{4}, n=10^{5}$ 时的模拟值如下 |  |  |\n| :---: | :---: | :---: |\n| 精确值 | $n=10^{4}$ | $n=10^{5}$ |\n| 0.341344 | 0.340698 | 0.341355 |  \n注意,对于一般区间 $[a, b]$ 上的定积分  \n$$\nJ^{\\prime}=\\int_{a}^{b} g(x) \\mathrm{d} x\n$$  \n作线性变换 $y=(x-a) /(b-a)$, 即可化成 $[0,1]$ 区间上的积分. 进一步若 $c \\leqslant g(x) \\leqslant d$, 可令  \n$$\nf(y)=\\frac{1}{d-c}(g(a+(b-a) y)-c),\n$$  \n则 $0 \\leqslant f(y) \\leqslant 1$. 此时有  \n$$\nJ^{\\prime}=\\int_{a}^{b} g(x) \\mathrm{d} x=S_{0} \\int_{0}^{1} f(y) \\mathrm{d} y+c(b-a) .\n$$  \n其中 $S_{0}=(b-a)(d-c)$. 这说明以上用蒙特卡洛方法计算定积分方法带有普遍意义.",
        "metadata": {
            "Header 2": "4.2 大数定律",
            "Header 3": "4.2.1 伯努利大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "伯努利大数定律讨论的是一个相互独立同分布的随机变量序列 $\\left\\{X_{n}\\right\\}$, 其共同分布为二点分布. 若记  \n$$\nX_{i}=\\left\\{\\begin{array}{ll}\n1, & \\text { 第 } i \\text { 次试验中事件 } A \\text { 发生, } \\\\\n0, & \\text { 第 } i \\text { 次试验中事件 } A \\text { 不发生, }\n\\end{array} \\quad i=1,2, \\cdots, n, \\cdots,\\right.\n$$  \n则 $\\left\\{X_{n}\\right\\}$ 是独立的二点分布随机变量序列, 现考察该序列的前 $n$ 个随机变量之和 $\\mu_{n}=\\sum_{i=1}^{n} X_{i}$,其频率及频率的数学期望分别为  \n$$\n\\frac{\\mu_{n}}{n}=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}, \\quad p=E\\left(\\frac{1}{n} \\sum_{i=1}^{n} X_{i}\\right)=\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}\\right)\n$$  \n那么伯努利大数定律的结论为: 对任意的 $\\varepsilon>0$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} X_{i}-\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}\\right)\\right|<\\varepsilon\\right)=1 \\tag{4.2.5}\n\\end{equation*}\n$$  \n一般的大数定律都涉及一个随机变量序列 $\\left\\{X_{n}\\right\\}$, 大数定律的结论都是形如 (4.2.5), 为此我们给出如下定义.  \n定义 4.2.1. 设有一随机变量序列 $\\left\\{X_{n}\\right\\}$, 假如它具有形如 (4.2.5) 的性质, 则称该随机变量序列 $\\left\\{X_{n}\\right\\}$服从大数定律.",
        "metadata": {
            "Header 2": "一。大数定律的一般形式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n那么伯努利大数定律的结论为: 对任意的 $\\varepsilon>0$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} X_{i}-\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}\\right)\\right|<\\varepsilon\\right)=1 \\tag{4.2.5}\n\\end{equation*}\n$$  \n一般的大数定律都涉及一个随机变量序列 $\\left\\{X_{n}\\right\\}$, 大数定律的结论都是形如 (4.2.5), 为此我们给出如下定义.  \n定义 4.2.1. 设有一随机变量序列 $\\left\\{X_{n}\\right\\}$, 假如它具有形如 (4.2.5) 的性质, 则称该随机变量序列 $\\left\\{X_{n}\\right\\}$服从大数定律.  \n不同的大数定律的差别只是对不同的随机变量序列 $\\left\\{X_{n}\\right\\}$ 而言, 有的是相互独立的随机变量序列, 有的是相依的随机变量序列, 有的是同分布的随机变量序列, 有的是不同分布的随机变量序列等等.",
        "metadata": {
            "Header 2": "一。大数定律的一般形式"
        },
        "type": "Document"
    },
    {
        "page_content": "利用切比雪夫不等式就可证明下面的切比雪夫大数定律.  \n定理 4.2.2 (切比需火大数定律). 设 $\\left\\{X_{n}\\right\\}$ 为一列两两不相关的随机变量序列, 若每个 $X_{i}$ 的方差存在, 且有共同的上界, 即 $\\operatorname{Var}(X) \\leqslant c, i=1,2, \\cdots$, 则 $\\left\\{X_{n}\\right\\}$ 服从大数定律, 即对任意的 $\\varepsilon>0,(4.2 .5)$成立。  \n证明: 因为 $\\left\\{X_{n}\\right\\}$ 两两不相关, 故  \n$$\n\\operatorname{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{n} X_{i}\\right)=\\frac{1}{n^{2}} \\sum_{i=1}^{n} \\operatorname{Var}\\left(X_{i}\\right) \\leqslant \\frac{c}{n} .\n$$  \n再由切比雪夫不等式得到: 对任意的 $\\varepsilon>0$, 有  \n$$\nP\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} X_{i}-\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}\\right)\\right|<\\varepsilon\\right) \\geqslant 1-\\frac{\\operatorname{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{n} X_{i}\\right)}{\\varepsilon^{2}} \\geqslant 1-\\frac{c}{n \\varepsilon^{2}} .\n$$  \n于是当 $n \\rightarrow+\\infty$ 时, 有  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} X_{i}-\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}\\right)\\right|<\\varepsilon\\right)=1 .\n$$",
        "metadata": {
            "Header 2": "二、切比雪夫大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} X_{i}-\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}\\right)\\right|<\\varepsilon\\right) \\geqslant 1-\\frac{\\operatorname{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{n} X_{i}\\right)}{\\varepsilon^{2}} \\geqslant 1-\\frac{c}{n \\varepsilon^{2}} .\n$$  \n于是当 $n \\rightarrow+\\infty$ 时, 有  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} X_{i}-\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}\\right)\\right|<\\varepsilon\\right)=1 .\n$$  \n注意, 切比雪夫大数定律只要求 $\\left\\{X_{n}\\right\\}$ 互不相关, 并不要求它们是同分布的. 假如 $\\left\\{X_{n}\\right\\}$ 是独立同分布的随机变量序列, 且方差有限, 则 $\\left\\{X_{n}\\right\\}$ 必定服从大数定律.  \n例 4.2.2: 设 $\\left\\{X_{n}\\right\\}$ 是独立同分布的随机变量序列, $E\\left(X_{n}^{4}\\right)<+\\infty$. 若令 $E\\left(X_{n}^{4}\\right)<+\\infty, \\operatorname{Var}\\left(X_{n}\\right)=$ $\\sigma^{2}$, 考察  \n$$\nY_{n}=\\left(X_{n}-\\mu\\right)^{2}, \\quad n=1,2, \\cdots,\n$$  \n则随机变量序列 $\\left\\{Y_{n}\\right\\}$ 服从大数定律, 即对任意的 $\\varepsilon>0$, 有  \n$$",
        "metadata": {
            "Header 2": "二、切比雪夫大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n注意, 切比雪夫大数定律只要求 $\\left\\{X_{n}\\right\\}$ 互不相关, 并不要求它们是同分布的. 假如 $\\left\\{X_{n}\\right\\}$ 是独立同分布的随机变量序列, 且方差有限, 则 $\\left\\{X_{n}\\right\\}$ 必定服从大数定律.  \n例 4.2.2: 设 $\\left\\{X_{n}\\right\\}$ 是独立同分布的随机变量序列, $E\\left(X_{n}^{4}\\right)<+\\infty$. 若令 $E\\left(X_{n}^{4}\\right)<+\\infty, \\operatorname{Var}\\left(X_{n}\\right)=$ $\\sigma^{2}$, 考察  \n$$\nY_{n}=\\left(X_{n}-\\mu\\right)^{2}, \\quad n=1,2, \\cdots,\n$$  \n则随机变量序列 $\\left\\{Y_{n}\\right\\}$ 服从大数定律, 即对任意的 $\\varepsilon>0$, 有  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)^{2}-\\sigma^{2}\\right| \\geqslant \\varepsilon\\right)=0 .\n$$  \n证明: 显然 $\\left\\{Y_{n}\\right\\}$ 是独立同分布随机变量序列, 其方差  \n$$\n\\operatorname{Var}\\left(Y_{n}\\right)=\\operatorname{Var}\\left(X_{n}-\\mu\\right)^{2}=E\\left(X_{n}-\\mu\\right)^{4}-\\sigma^{4}\n$$  \n由于 $E\\left(X_{n}^{4}\\right)$ 存在, 故 $E\\left(X_{n}^{3}\\right), E\\left(X_{n}^{2}\\right)$ 皆存在, 从而 $E\\left(X_{n}-\\mu\\right)^{4}$ 也存在. 由切比雪夫大数定律知  \n$$",
        "metadata": {
            "Header 2": "二、切比雪夫大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)^{2}-\\sigma^{2}\\right| \\geqslant \\varepsilon\\right)=0 .\n$$  \n证明: 显然 $\\left\\{Y_{n}\\right\\}$ 是独立同分布随机变量序列, 其方差  \n$$\n\\operatorname{Var}\\left(Y_{n}\\right)=\\operatorname{Var}\\left(X_{n}-\\mu\\right)^{2}=E\\left(X_{n}-\\mu\\right)^{4}-\\sigma^{4}\n$$  \n由于 $E\\left(X_{n}^{4}\\right)$ 存在, 故 $E\\left(X_{n}^{3}\\right), E\\left(X_{n}^{2}\\right)$ 皆存在, 从而 $E\\left(X_{n}-\\mu\\right)^{4}$ 也存在. 由切比雪夫大数定律知  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} Y_{i}-\\frac{1}{n} \\sum_{i=1}^{n} E\\left(Y_{i}\\right)\\right| \\geqslant \\varepsilon\\right)=0 .\n$$  \n其中  \n$$\n\\frac{1}{n} \\sum_{i=1}^{n} Y_{n}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)^{2}, \\frac{1}{n} \\sum_{i=1}^{n} E\\left(Y_{n}\\right)=\\sigma^{2}\n$$  \n故 $\\left\\{Y_{n}\\right\\}$ 服从大数定律.",
        "metadata": {
            "Header 2": "二、切比雪夫大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "注意到以上大数定律的证明中, 只要有  \n$$\n\\frac{1}{n^{2}} \\operatorname{Var}\\left(\\sum_{i=1}^{n} X_{i}\\right) \\rightarrow 0\n$$  \n则大数定律就能成立. 这个条件三被称为马尔可夫条件.  \n定理 4.2.3 (马尔可夫大数定律). 对随机变量序列 $\\left\\{X_{n}\\right\\}$, 若三成立, 则 $\\left\\{X_{n}\\right\\}$ 服从大数定律, 即对任意的 $\\varepsilon>0,(4.2 .5)$ 成立.  \n证明: 利用切比雪夫不等式即可证得.  \n马尔可夫大数定律的重要性在于: 对 $\\left\\{X_{n}\\right\\}$ 已经没有任何同分布、独立性、不相关的假定. 切比雪夫大数定律显然可由马尔可夫大数定律推出.  \n例 4.2.3: 设 $\\left\\{X_{n}\\right\\}$ 为一同分布、方差存在的随机变量序列, 且 $X_{n}$ 仅与 $X_{n-1}$ 和 $X_{n+1}$ 相关, 而与其他的 $X_{i}$ 不相关. 试问该随机变量序列 $\\left\\{X_{n}\\right\\}$ 是否服从大数定律?  \n证明: $\\left\\{X_{n}\\right\\}$ 为相依随机变量序列, 考虑其马尔可夫条件  \n$$\n\\frac{1}{n^{2}} \\operatorname{Var}\\left(\\sum_{i=1}^{n} X_{i}\\right)=\\frac{1}{n^{2}}\\left(\\sum_{i=1}^{n} \\operatorname{Var}\\left(X_{i}\\right)+2 \\sum_{i=1}^{n-1} \\operatorname{Cov}\\left(X_{i}, X_{i-1}\\right)\\right)\n$$  \n记 $\\operatorname{Var}\\left(X_{i}\\right)=\\sigma^{2}$, 则 $\\left|\\operatorname{Cov}\\left(X_{i}, X_{j}\\right)\\right| \\leqslant \\sigma^{2}$, 于是有  \n$$",
        "metadata": {
            "Header 2": "三、马尔可夫大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "证明: $\\left\\{X_{n}\\right\\}$ 为相依随机变量序列, 考虑其马尔可夫条件  \n$$\n\\frac{1}{n^{2}} \\operatorname{Var}\\left(\\sum_{i=1}^{n} X_{i}\\right)=\\frac{1}{n^{2}}\\left(\\sum_{i=1}^{n} \\operatorname{Var}\\left(X_{i}\\right)+2 \\sum_{i=1}^{n-1} \\operatorname{Cov}\\left(X_{i}, X_{i-1}\\right)\\right)\n$$  \n记 $\\operatorname{Var}\\left(X_{i}\\right)=\\sigma^{2}$, 则 $\\left|\\operatorname{Cov}\\left(X_{i}, X_{j}\\right)\\right| \\leqslant \\sigma^{2}$, 于是有  \n$$\n\\frac{1}{n^{2}} \\operatorname{Var}\\left(\\sum_{i=1}^{n} X_{i}\\right) \\leqslant \\frac{1}{n^{2}}\\left(n \\sigma^{2}+2(n-1) \\sigma^{2}\\right) \\rightarrow 0,(n \\rightarrow+\\infty),\n$$  \n即马尔可夫条件成立, 故 $\\left\\{X_{n}\\right\\}$ 服从大数定律.",
        "metadata": {
            "Header 2": "三、马尔可夫大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "我们已经知道, 一个随机变量的方差存在, 则其数学期望必定存在; 但反之不成立, 即一个随机变量的数学期望存在, 则其方差不一定存在. 以上几个大数定律均假设随机变量序列 $\\left\\{X_{n}\\right\\}$ 的方差存在, 以下的辛钦大数定律去掉了这一假设, 仅设每个 $X_{i}$ 的数学期望存在, 但同时要求 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列. 伯努利大数定律仍然是辛钦大数定律的特例.  \n定理 4.2 .4 (辛钦大数定律). 设 $\\left\\{X_{n}\\right\\}$ 为一独立同分布的随机变量序列, 若 $X_{i}$ 的数学期望存在, 则\n$\\left\\{X_{n}\\right\\}$ 服从大数定律, 即对任意的 $\\varepsilon>0,(4.2 .5)$ 成立.  \n这个定理的证明要用到特征函数这一工具, 在下一节中给出具体证明.  \n辛钦大数定律提供了求随机变量数学期望 $E(X)$ 的近似值的方法. 设想对随机变量 $X$ 独立重复地观察 $n$ 次, 第 $k$ 次观察值为 $X_{k}$, 则 $X 1, X 2, \\cdots, X_{n}$ 应该是相互独立的, 且它们的分布应该与 $X$ 的分布相同. 所以, 在 $E(X)$ 存在的条件下, 按照辛钦大数定律, 当 $n$ 足够大时, 可以把平均观察值  \n$$\n\\frac{1}{n} \\sum_{i=1}^{n} X_{i}\n$$  \n作为 $E(X)$ 的近似值. 这样做法的一个优点是我们可以不必去管 $X$ 的分布究竟是怎样的, 我们的目的只是寻求数学期望  \n事实上, 用观察值的平均去作为随机变量的均值在实际生活中是常用的方法. 管如, 用观察到的某地区 5000 个人的平均寿命作为该地区的人均寿命的近似值是合适的, 这样做法的依据就是辛钦大数定律.  \n例 4.2.4(用蒙特卡洛方法计算定积分 (平均值法))：为计算定积分  \n$$\nJ=\\int_{0}^{1} f(x) \\mathrm{d} x\n$$  \n设随机变量 $X$ 服从 $(0,1)$ 上的均匀分布, 则 $Y=f(X)$ 的数学期望为  \n$$\nE(f(X))=\\int_{0}^{1} f(x) \\mathrm{d} x=J\n$$",
        "metadata": {
            "Header 2": "四、辛钦大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\frac{1}{n} \\sum_{i=1}^{n} X_{i}\n$$  \n作为 $E(X)$ 的近似值. 这样做法的一个优点是我们可以不必去管 $X$ 的分布究竟是怎样的, 我们的目的只是寻求数学期望  \n事实上, 用观察值的平均去作为随机变量的均值在实际生活中是常用的方法. 管如, 用观察到的某地区 5000 个人的平均寿命作为该地区的人均寿命的近似值是合适的, 这样做法的依据就是辛钦大数定律.  \n例 4.2.4(用蒙特卡洛方法计算定积分 (平均值法))：为计算定积分  \n$$\nJ=\\int_{0}^{1} f(x) \\mathrm{d} x\n$$  \n设随机变量 $X$ 服从 $(0,1)$ 上的均匀分布, 则 $Y=f(X)$ 的数学期望为  \n$$\nE(f(X))=\\int_{0}^{1} f(x) \\mathrm{d} x=J\n$$  \n所以估计 $J$ 的值就是估计 $f(X)$ 的数学期望的值. 由辛钦大数定律, 可以用 $f(X)$ 的观察值的平均去估计 $f(X)$ 的数学期望的值. 具体做法如下: 先用计算机产生 $n$ 个 $(0,1)$ 上均匀分布的随机数: $x_{i}, i=1,2, \\cdots, n$. 然后对每个 $x_{i}$ 计算 $f\\left(x_{i}\\right)$, 最后得 $J$ 的估计值为  \n$$\nJ \\approx \\frac{1}{n} \\sum_{i=1}^{n} f\\left(x_{i}\\right)\n$$  \n譬如计算 $\\int_{0}^{1} \\mathrm{e}^{-x^{2} / 2} / \\sqrt{2 \\pi} \\mathrm{d} x$, 其精确值和 $n=10^{4}, n=10^{5}$ 时的模拟值如下:  \n| 精确值 | $n=10^{4}$ | $n=10^{5}$ |\n| :---: | :---: | :---: |\n| 0.341344 | 0.341329 | 0.341334 |  \n正如例 4.2.1 中所说明的, 可以通过线性变换将 $[a, b]$ 区间上的定积分化成 $[0,1]$ 区间上的定积分, 所以以上方法计算定积分方法带有普遍意义。",
        "metadata": {
            "Header 2": "四、辛钦大数定律"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设 $\\left\\{X_{k}\\right\\}$ 为独立随机变量序列, 且  \n$$\nP\\left(X_{k}= \\pm \\sqrt{\\ln k}\\right)=\\frac{1}{2}, k=1,2, \\cdots\n$$  \n证明 $\\left\\{X_{k}\\right\\}$ 服从大数定律.  \n2. 设 $\\left\\{X_{k}\\right\\}$ 为独立随机变量序列, 且  \n$$\nP\\left(X_{k}= \\pm 2^{k}\\right)=\\frac{1}{2^{2 k+1}}, P\\left(X_{k}=0\\right)=1-\\frac{1}{2^{2 k}}, k=1,2, \\cdots .\n$$  \n证明 $\\left\\{X_{k}\\right\\}$ 服从大数定律.  \n3. 设 $\\left\\{X_{n}\\right\\}$ 为独立随机变量序列, 且 $P\\left(X_{1}=0\\right)=1$,  \n$$\nP\\left(X_{n}= \\pm \\sqrt{n}\\right)=\\frac{1}{n}, P\\left(X_{n}=0\\right)=1-\\frac{2}{n}, n=2,3, \\cdots .\n$$  \n证明 $\\left\\{X_{n}\\right\\}$ 服从大数定律.  \n4. 在伯努利试验中, 事件 $A$ 出现的概率为 $p$, 令  \n$$\nX+n= \\begin{cases}1, & \\text { 若在第 } n \\text { 次及第 } n+1 \\text { 次试验中 } A \\text { 出现 } \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n证明 $\\left\\{X_{n}\\right\\}$ 服从大数定律.  \n5. 设 $\\left\\{X_{n}\\right\\}$ 为独立的随机变量序列, 且  \n$$\nP\\left(X_{n}=1\\right)=p_{n}, P\\left(X_{n}=0\\right)=1-p_{n} .\n$$  \n证明 $\\left\\{X_{n}\\right\\}$ 服从大数定律.  \n6. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 其共同的分布函数为  \n$$",
        "metadata": {
            "Header 2": "如题 4.2"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n证明 $\\left\\{X_{n}\\right\\}$ 服从大数定律.  \n4. 在伯努利试验中, 事件 $A$ 出现的概率为 $p$, 令  \n$$\nX+n= \\begin{cases}1, & \\text { 若在第 } n \\text { 次及第 } n+1 \\text { 次试验中 } A \\text { 出现 } \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n证明 $\\left\\{X_{n}\\right\\}$ 服从大数定律.  \n5. 设 $\\left\\{X_{n}\\right\\}$ 为独立的随机变量序列, 且  \n$$\nP\\left(X_{n}=1\\right)=p_{n}, P\\left(X_{n}=0\\right)=1-p_{n} .\n$$  \n证明 $\\left\\{X_{n}\\right\\}$ 服从大数定律.  \n6. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 其共同的分布函数为  \n$$\nF(x)=\\frac{1}{2}+\\frac{1}{\\pi} \\arctan \\frac{a}{x},-\\infty<x<+\\infty\n$$  \n试问: 辛钦大数定律对此随机变量序列是否适用?  \n7. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 其共同分布为  \n$$\nP\\left(X_{n}=\\frac{2^{k}}{k^{2}}\\right)=\\frac{1}{2^{k}}, k=1,2, \\cdots .\n$$  \n试问 $\\left\\{X_{n}\\right\\}$ 是否服从大数定律?  \n8. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 其共同分布为  \n$$\nP\\left(X_{n}=k\\right)=\\frac{c}{k^{2} \\cdot \\log ^{2} k}, k=2,3, \\cdots\n$$  \n其中  \n$$\nc=\\left(\\sum_{k=2}^{+\\infty} \\frac{1}{k^{2} \\cdot \\log ^{2} k}\\right)^{-1}\n$$  \n试同 $\\left\\{X_{n}\\right\\}$ 是否服从大数定律?",
        "metadata": {
            "Header 2": "如题 4.2"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试问: 辛钦大数定律对此随机变量序列是否适用?  \n7. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 其共同分布为  \n$$\nP\\left(X_{n}=\\frac{2^{k}}{k^{2}}\\right)=\\frac{1}{2^{k}}, k=1,2, \\cdots .\n$$  \n试问 $\\left\\{X_{n}\\right\\}$ 是否服从大数定律?  \n8. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 其共同分布为  \n$$\nP\\left(X_{n}=k\\right)=\\frac{c}{k^{2} \\cdot \\log ^{2} k}, k=2,3, \\cdots\n$$  \n其中  \n$$\nc=\\left(\\sum_{k=2}^{+\\infty} \\frac{1}{k^{2} \\cdot \\log ^{2} k}\\right)^{-1}\n$$  \n试同 $\\left\\{X_{n}\\right\\}$ 是否服从大数定律?  \n9. 设 $\\left\\{X_{n}\\right\\}$ 为独立的随机变量序列, 其中 $X_{n}$ 服从参数为 $\\sqrt{n}$ 的泊松分布, 试问 $\\left\\{X_{n}\\right\\}$ 是否服从大数定律?\n10. 设 $\\left\\{X_{n}\\right\\}$ 为独立的随机变量序列, 每个 $X_{n}$ 的方差 $\\sigma^{2}$ 有限, 证明: 若  \n$$\n\\frac{\\sigma_{n}^{2}}{n} \\rightarrow 0, n \\rightarrow+\\infty\n$$  \n则 $\\left\\{X_{n}\\right\\}$ 服从大数定律.  \n11. (伯恩斯组大数定律) 设 $\\left\\{X_{n}\\right\\}$ 是方差有界的随机变量序列, 且当 $|k-l| \\rightarrow+\\infty$ 时, 一致地有 $\\operatorname{Cov}\\left(X_{k}, X_{l}\\right) \\rightarrow 0$, 证明 $\\left\\{X_{n}\\right\\}$ 服从大数定律.\n12. (格涅坚科大数定律) 设 $\\left\\{X_{n}\\right\\}$ 是随机变量序列, 若记  \n$$",
        "metadata": {
            "Header 2": "如题 4.2"
        },
        "type": "Document"
    },
    {
        "page_content": "10. 设 $\\left\\{X_{n}\\right\\}$ 为独立的随机变量序列, 每个 $X_{n}$ 的方差 $\\sigma^{2}$ 有限, 证明: 若  \n$$\n\\frac{\\sigma_{n}^{2}}{n} \\rightarrow 0, n \\rightarrow+\\infty\n$$  \n则 $\\left\\{X_{n}\\right\\}$ 服从大数定律.  \n11. (伯恩斯组大数定律) 设 $\\left\\{X_{n}\\right\\}$ 是方差有界的随机变量序列, 且当 $|k-l| \\rightarrow+\\infty$ 时, 一致地有 $\\operatorname{Cov}\\left(X_{k}, X_{l}\\right) \\rightarrow 0$, 证明 $\\left\\{X_{n}\\right\\}$ 服从大数定律.\n12. (格涅坚科大数定律) 设 $\\left\\{X_{n}\\right\\}$ 是随机变量序列, 若记  \n$$\nY_{n}=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}, a_{n}=\\frac{1}{n} \\sum_{i=1}^{n} E\\left(x_{i}\\right)\n$$  \n则 $\\left\\{X_{n}\\right\\}$ 服从大数定律的充要条件是  \n$$\n\\lim _{n \\rightarrow+\\infty} E\\left(\\frac{\\left(Y_{n}-a_{n}\\right)^{2}}{1+\\left(Y_{n}-a_{n}\\right)^{2}}\\right)=0\n$$  \n13. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 方差存在. 又设 $\\sum_{n=1}^{+\\infty} a_{n}$ 为绝对收玫级数. 令 $Y=$ $\\sum_{i=1}^{n} X_{i}$, 证明 $\\left\\{a_{n} Y_{n}\\right\\}$ 服从大数定律.",
        "metadata": {
            "Header 2": "如题 4.2"
        },
        "type": "Document"
    },
    {
        "page_content": "12. (格涅坚科大数定律) 设 $\\left\\{X_{n}\\right\\}$ 是随机变量序列, 若记  \n$$\nY_{n}=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}, a_{n}=\\frac{1}{n} \\sum_{i=1}^{n} E\\left(x_{i}\\right)\n$$  \n则 $\\left\\{X_{n}\\right\\}$ 服从大数定律的充要条件是  \n$$\n\\lim _{n \\rightarrow+\\infty} E\\left(\\frac{\\left(Y_{n}-a_{n}\\right)^{2}}{1+\\left(Y_{n}-a_{n}\\right)^{2}}\\right)=0\n$$  \n13. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 方差存在. 又设 $\\sum_{n=1}^{+\\infty} a_{n}$ 为绝对收玫级数. 令 $Y=$ $\\sum_{i=1}^{n} X_{i}$, 证明 $\\left\\{a_{n} Y_{n}\\right\\}$ 服从大数定律.\n14. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 方差存在, 令 $Y=\\sum_{i=1}^{n} X_{i}$. 又设 $\\left\\{a_{n}\\right\\}$ 为一列常数, 如果存在常数 $c>0$, 使得对一一切 $n$ 有 $\\left|n a_{n}\\right| \\leqslant c$, 证明 $\\left\\{a_{n} Y_{n}\\right\\}$ 服从大数定律.\n15. 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布的随机变量序列, 其方差有限, 且 $X_{n}$ 不恒为常数. 如果 $S_{n}=\\sum_{i=1}^{n} X_{i}$,试证: 随机变量序列 $\\left\\{S_{n}\\right\\}$ 不服从大数定律.\n16. 分别用随机投点法和平均值法计算下列定积分:  \n$$\nJ_{1}=\\int_{0}^{1} \\frac{e^{x}-1}{e-1} \\mathrm{~d} x, J_{2}=\\int_{-1}^{1} \\mathrm{e}^{x} \\mathrm{~d} x\n$$",
        "metadata": {
            "Header 2": "如题 4.2"
        },
        "type": "Document"
    },
    {
        "page_content": "随机变量序列的收玫性有多种, 其中常用的是两种: 依概率收玫和按分布收玫. 前面叙述的大数定律涉及的是一种依概率收玫, 后面叙述的中心极限定理将涉及按分布收玫. 这些极限定理不仅是概率论研究的中心议题, 而且在数理统计中有广泛的应用. 本节将给出这两种收玫性的定义及其有关性质, 读者应从中吸收其思考问题的方法.",
        "metadata": {
            "Header 2": "4.3 随机变量序列的两种收敛性"
        },
        "type": "Document"
    },
    {
        "page_content": "首先由随机变量序列 $\\left\\{X_{n}\\right\\}$ 服从 “大数定律” 的讨论启发我们引进如下定义.  \n定义 4.3.1 (依概率收玫). 设 $\\left\\{Y_{n}\\right\\}$ 为一随机变量序列, $Y$ 为一随机变量. 如果对任意的 $\\varepsilon>c$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(\\left|Y_{n}-Y\\right|<\\varepsilon\\right)=1 \\tag{4.3.1}\n\\end{equation*}\n$$  \n则称 $\\left\\{Y_{n}\\right\\}$ 依概率收玫 于 $Y$, 记作 $Y_{n} \\xrightarrow{P} Y$.  \n前面讨论的独立同分布随机变量序列 $\\left\\{X_{n}\\right\\}$ 服从大数定律是上述依概率收玫的特殊情况, 这只要构造另一个随机变量序列 $\\left\\{Y_{n}\\right\\}$, 其中  \n$$\nY_{n}=\\frac{1}{n} \\sum_{i=1}^{n} X_{n}, \\quad Y=\\frac{1}{n} \\sum_{i=1}^{n} E\\left(Y_{i}\\right)=\\mu\n$$  \n就可看出, $X_{n}$ 服从大数定律等价于 $Y_{n} \\xrightarrow{P} \\mu$. 如今的依概率收玫是把原收玫于一个常数 $\\mu$ 推广到收玫于一个随机变量场合.  \n定理 4.3.1. 设 $\\left\\{X_{n}\\right\\},\\left\\{Y_{n}\\right\\}$ 是两个随机变量序列, $a, b$ 是两个常数. 如果  \n$$\nX_{n} \\xrightarrow{P} a, \\quad Y_{n} \\xrightarrow{P} b,\n$$  \n则有  \n1. $X_{n} \\pm Y_{n} \\xrightarrow{P} a \\pm b$,\n2. $X_{n} \\times Y_{n} \\xrightarrow{P} a \\times b$,\n3. $X_{n} \\div Y_{n} \\xrightarrow{P} a \\div b(b \\neq 0)$.  \n证明:  \n1. 因为  \n$$",
        "metadata": {
            "Header 2": "一、依概率收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n就可看出, $X_{n}$ 服从大数定律等价于 $Y_{n} \\xrightarrow{P} \\mu$. 如今的依概率收玫是把原收玫于一个常数 $\\mu$ 推广到收玫于一个随机变量场合.  \n定理 4.3.1. 设 $\\left\\{X_{n}\\right\\},\\left\\{Y_{n}\\right\\}$ 是两个随机变量序列, $a, b$ 是两个常数. 如果  \n$$\nX_{n} \\xrightarrow{P} a, \\quad Y_{n} \\xrightarrow{P} b,\n$$  \n则有  \n1. $X_{n} \\pm Y_{n} \\xrightarrow{P} a \\pm b$,\n2. $X_{n} \\times Y_{n} \\xrightarrow{P} a \\times b$,\n3. $X_{n} \\div Y_{n} \\xrightarrow{P} a \\div b(b \\neq 0)$.  \n证明:  \n1. 因为  \n$$\n\\left\\{\\left|\\left(X_{n}+Y_{n}\\right)-(a+b)\\right| \\geqslant \\varepsilon\\right\\} \\subset\\left\\{\\left(\\left|X_{n}-a\\right| \\geqslant \\frac{\\varepsilon}{2}\\right) \\cup\\left(\\left|Y_{n}-b\\right| \\geqslant \\frac{\\varepsilon}{2}\\right)\\right\\}\n$$  \n所以  \n$$\n0 \\leqslant P\\left(\\left|\\left(X_{n}+Y_{n}\\right)-(a+b)\\right| \\geqslant \\varepsilon\\right) \\leqslant P\\left(\\left|X_{n}-a\\right| \\geqslant \\frac{\\varepsilon}{2}\\right)+P\\left(\\left|Y_{n}-b\\right| \\geqslant \\frac{\\varepsilon}{2}\\right) \\rightarrow 0(n \\rightarrow+\\infty)\n$$  \n即  \n$$",
        "metadata": {
            "Header 2": "一、依概率收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n所以  \n$$\n0 \\leqslant P\\left(\\left|\\left(X_{n}+Y_{n}\\right)-(a+b)\\right| \\geqslant \\varepsilon\\right) \\leqslant P\\left(\\left|X_{n}-a\\right| \\geqslant \\frac{\\varepsilon}{2}\\right)+P\\left(\\left|Y_{n}-b\\right| \\geqslant \\frac{\\varepsilon}{2}\\right) \\rightarrow 0(n \\rightarrow+\\infty)\n$$  \n即  \n$$\nP\\left(\\left|\\left(X_{n}+Y_{n}\\right)-(a+b)\\right|<\\varepsilon\\right) \\rightarrow 1(n \\rightarrow+\\infty),\n$$  \n由此得 $X_{n}+Y_{n} \\xrightarrow{P} a+b$. 类似可证 $X_{n}-Y_{n} \\xrightarrow{P} a-b$.  \n2. 为了证明 $X_{n} \\times Y_{n} \\xrightarrow{P} a \\times b$, 我们分几步进行:  \n(1) 若 $X_{n} \\xrightarrow{P} 0$, 则有 $X_{n}^{2} \\xrightarrow{P} 0$. 这是因为对任意 $\\varepsilon>0$, 有  \n$$\nP\\left(\\left|X_{n}^{2}\\right| \\geqslant \\varepsilon\\right)=P\\left(\\left|X_{n}\\right| \\geqslant \\sqrt{\\varepsilon}\\right) \\rightarrow 0, n \\rightarrow+\\infty .\n$$  \n(2) 若 $X_{n} \\xrightarrow{P} a$, 则有 $c X_{n} \\xrightarrow{P} c a$. 这是因为在 $c \\neq 0$ 时, 有  \n$$",
        "metadata": {
            "Header 2": "一、依概率收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "2. 为了证明 $X_{n} \\times Y_{n} \\xrightarrow{P} a \\times b$, 我们分几步进行:  \n(1) 若 $X_{n} \\xrightarrow{P} 0$, 则有 $X_{n}^{2} \\xrightarrow{P} 0$. 这是因为对任意 $\\varepsilon>0$, 有  \n$$\nP\\left(\\left|X_{n}^{2}\\right| \\geqslant \\varepsilon\\right)=P\\left(\\left|X_{n}\\right| \\geqslant \\sqrt{\\varepsilon}\\right) \\rightarrow 0, n \\rightarrow+\\infty .\n$$  \n(2) 若 $X_{n} \\xrightarrow{P} a$, 则有 $c X_{n} \\xrightarrow{P} c a$. 这是因为在 $c \\neq 0$ 时, 有  \n$$\nP\\left(\\left|c X_{n}-c a\\right| \\geqslant \\varepsilon\\right)=P\\left(\\left|X_{n}-a\\right| \\geqslant \\varepsilon /|c|\\right) \\rightarrow 0, n \\rightarrow+\\infty,\n$$  \n而当 $c=0$ 时, 结论显然成立.  \n(3) 若 $X_{n} \\xrightarrow{P} a$, 则有 $X_{n}^{2} \\xrightarrow{P} a^{2}$. 这是因为有以下一系列结论:  \n$$\n\\begin{gathered}\nX_{n}-a \\xrightarrow{P} 0,\\left(X_{n}-a\\right)^{2} \\xrightarrow{P} 0,2 a\\left(X_{n}-a\\right) \\xrightarrow{P} 0, \\\\\n\\left(X_{n}-a\\right)^{2}+2 a\\left(X_{n}-a\\right)=X_{n}^{2}-a^{2} \\xrightarrow{P} 0, \\text { 即 } X_{n}^{2} \\xrightarrow{P} a^{2} .\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "一、依概率收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n而当 $c=0$ 时, 结论显然成立.  \n(3) 若 $X_{n} \\xrightarrow{P} a$, 则有 $X_{n}^{2} \\xrightarrow{P} a^{2}$. 这是因为有以下一系列结论:  \n$$\n\\begin{gathered}\nX_{n}-a \\xrightarrow{P} 0,\\left(X_{n}-a\\right)^{2} \\xrightarrow{P} 0,2 a\\left(X_{n}-a\\right) \\xrightarrow{P} 0, \\\\\n\\left(X_{n}-a\\right)^{2}+2 a\\left(X_{n}-a\\right)=X_{n}^{2}-a^{2} \\xrightarrow{P} 0, \\text { 即 } X_{n}^{2} \\xrightarrow{P} a^{2} .\n\\end{gathered}\n$$  \n(4) 由 (3) 及 1 知  \n$$\nX_{n}^{2} \\xrightarrow{P} a^{2}, Y_{n}^{2} \\xrightarrow{P} b^{2},\\left(X_{n}+Y_{n}\\right)^{2} \\xrightarrow{P}(a+b)^{2} .\n$$  \n从而有  \n$$\n\\begin{aligned}\nX_{n} \\times Y_{n} & =\\frac{1}{2}\\left[\\left(X_{n}+y_{n}\\right)^{2}-X_{n}^{2}-Y_{n}^{2}\\right] \\\\\n& \\xrightarrow{P} \\frac{1}{2}\\left[(a+b)^{2}-a^{2}-b^{2}\\right]=a b .\n\\end{aligned}\n$$  \n3. 为了证明 $X_{n} / Y_{n} \\xrightarrow{P} a / b$, 我们先证: $1 / Y_{n} \\xrightarrow{P} 1 / b$. 这是因为对任意 $\\varepsilon>0$, 有  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "一、依概率收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n(4) 由 (3) 及 1 知  \n$$\nX_{n}^{2} \\xrightarrow{P} a^{2}, Y_{n}^{2} \\xrightarrow{P} b^{2},\\left(X_{n}+Y_{n}\\right)^{2} \\xrightarrow{P}(a+b)^{2} .\n$$  \n从而有  \n$$\n\\begin{aligned}\nX_{n} \\times Y_{n} & =\\frac{1}{2}\\left[\\left(X_{n}+y_{n}\\right)^{2}-X_{n}^{2}-Y_{n}^{2}\\right] \\\\\n& \\xrightarrow{P} \\frac{1}{2}\\left[(a+b)^{2}-a^{2}-b^{2}\\right]=a b .\n\\end{aligned}\n$$  \n3. 为了证明 $X_{n} / Y_{n} \\xrightarrow{P} a / b$, 我们先证: $1 / Y_{n} \\xrightarrow{P} 1 / b$. 这是因为对任意 $\\varepsilon>0$, 有  \n$$\n\\begin{aligned}\nP\\left(\\left|\\frac{1}{Y_{n}}-\\frac{1}{b}\\right| \\geqslant \\varepsilon\\right)= & P\\left(\\left|\\frac{Y_{n}-b}{Y_{n} b}\\right| \\geqslant \\varepsilon\\right) \\\\\n= & P\\left(\\left|\\frac{Y_{n}-b}{b^{2}+b\\left(Y_{n}-b\\right)}\\right| \\geqslant \\varepsilon,\\left|Y_{n}-b\\right|<\\varepsilon\\right) \\\\\n& +P\\left(\\left|\\frac{Y_{n}-b}{b^{2}+b\\left(Y_{n}-b\\right)}\\right| \\geqslant \\varepsilon,\\left|Y_{n}-b\\right| \\geqslant \\varepsilon\\right) \\\\",
        "metadata": {
            "Header 2": "一、依概率收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nP\\left(\\left|\\frac{1}{Y_{n}}-\\frac{1}{b}\\right| \\geqslant \\varepsilon\\right)= & P\\left(\\left|\\frac{Y_{n}-b}{Y_{n} b}\\right| \\geqslant \\varepsilon\\right) \\\\\n= & P\\left(\\left|\\frac{Y_{n}-b}{b^{2}+b\\left(Y_{n}-b\\right)}\\right| \\geqslant \\varepsilon,\\left|Y_{n}-b\\right|<\\varepsilon\\right) \\\\\n& +P\\left(\\left|\\frac{Y_{n}-b}{b^{2}+b\\left(Y_{n}-b\\right)}\\right| \\geqslant \\varepsilon,\\left|Y_{n}-b\\right| \\geqslant \\varepsilon\\right) \\\\\n= & P\\left(\\frac{\\left|Y_{n}-b\\right|}{b^{2}-\\varepsilon|b|} \\geqslant \\varepsilon\\right)+P\\left(\\left|Y_{n}+b\\right| \\geqslant \\varepsilon\\right) \\\\\n= & P\\left(\\left|Y_{n}-b\\right| \\geqslant\\left(b^{2}-\\varepsilon|b|\\right) \\varepsilon\\right)+P\\left(\\left|Y_{n}-b\\right| \\geqslant \\varepsilon\\right) \\\\\n\\rightarrow & 0, n \\rightarrow+\\infty .\n\\end{aligned}\n$$  \n这就证明了 $1 / Y_{n} \\xrightarrow{P} 1 / b$, 再与 $X_{n} \\xrightarrow{P} a$ 结合, 利用 2 即得 $X_{n} / Y_{n} \\xrightarrow{P} a / b$. 这就完成了全部证明.",
        "metadata": {
            "Header 2": "一、依概率收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "= & P\\left(\\frac{\\left|Y_{n}-b\\right|}{b^{2}-\\varepsilon|b|} \\geqslant \\varepsilon\\right)+P\\left(\\left|Y_{n}+b\\right| \\geqslant \\varepsilon\\right) \\\\\n= & P\\left(\\left|Y_{n}-b\\right| \\geqslant\\left(b^{2}-\\varepsilon|b|\\right) \\varepsilon\\right)+P\\left(\\left|Y_{n}-b\\right| \\geqslant \\varepsilon\\right) \\\\\n\\rightarrow & 0, n \\rightarrow+\\infty .\n\\end{aligned}\n$$  \n这就证明了 $1 / Y_{n} \\xrightarrow{P} 1 / b$, 再与 $X_{n} \\xrightarrow{P} a$ 结合, 利用 2 即得 $X_{n} / Y_{n} \\xrightarrow{P} a / b$. 这就完成了全部证明.  \n由此定理可以看出, 随机变量序列在概率意义下的极限 (即依概率收玫于常数 $a$ ) 在四则运算下仍然成立. 这与数学分析中的数列极限十分类似.",
        "metadata": {
            "Header 2": "一、依概率收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "我们知道分布函数全面描述了随机变量的统计规律，因此讨论一个分布函数序列 $\\left\\{F_{n}(x)\\right\\}$收玫到一个极限分布函数 $F(x)$ 是有实际意义的. 现在的问题是: 如何来定义 $\\left\\{F_{n}(x)\\right\\}$ 的收玫性呢? 很自然地, 由于 $\\left\\{F_{n}(x)\\right\\}$ 是实变量函数序列, 我们的一个猜想是: 对所有的 $x$, 要求 $F_{n}(x) \\rightarrow$ $F(x)(n \\rightarrow+\\infty)$ 都成立, 也即数学分析中的点点收玫. 然而遗憾的是, 以下例子告诉我们这个要求过严了.  \n例 4.3.1: 设 $\\left\\{X_{n}\\right\\}$ 服从如下的退化分布  \n$$\nP\\left(X_{n}=\\frac{1}{n}\\right)=1, \\quad n=1,2, \\cdots,\n$$  \n若记它们的分布函数分别为 $F_{x}(x)$, 则  \n$$\nF_{n}(x)= \\begin{cases}0, & x<1 / n \\\\ 1, & x \\geqslant 1 / n\\end{cases}\n$$  \n因为 $F_{n}(x)$ 是在点 $x=1$ 处有跳跃, 所以当 $n \\rightarrow+\\infty$ 时, 跳跃点位置趋于 0 , 于是我们很自然地认\n为 $\\left\\{F_{n}(x)\\right\\}$ 应该收玫于点 $x=0$ 处的退化分布, 即  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ 1, & x \\geqslant 0\\end{cases}\n$$  \n但是, 对任意的 $n$, 有 $F_{n}(0)=0$, 而 $F(0)=1$, 所以  \n$$\n\\lim _{n \\rightarrow+\\infty} F_{n}(0)=0 \\neq 1=F(0)\n$$  \n从这个例子我们得到启示:  \n1. 对分布函数序列 $\\left\\{F_{n}(x)\\right\\}$ 而言, 要求其点点收玫到一个极限分布函数 $F_{n}(x)$ 是太苛刻了, 以上这么简单的一个例于都无法达到要求. 甚至在点点收效这个苛刻的要求下, $\\left\\{F_{n}(x)\\right\\}$ 的极限函数  \n$$",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n因为 $F_{n}(x)$ 是在点 $x=1$ 处有跳跃, 所以当 $n \\rightarrow+\\infty$ 时, 跳跃点位置趋于 0 , 于是我们很自然地认\n为 $\\left\\{F_{n}(x)\\right\\}$ 应该收玫于点 $x=0$ 处的退化分布, 即  \n$$\nF(x)= \\begin{cases}0, & x<0 \\\\ 1, & x \\geqslant 0\\end{cases}\n$$  \n但是, 对任意的 $n$, 有 $F_{n}(0)=0$, 而 $F(0)=1$, 所以  \n$$\n\\lim _{n \\rightarrow+\\infty} F_{n}(0)=0 \\neq 1=F(0)\n$$  \n从这个例子我们得到启示:  \n1. 对分布函数序列 $\\left\\{F_{n}(x)\\right\\}$ 而言, 要求其点点收玫到一个极限分布函数 $F_{n}(x)$ 是太苛刻了, 以上这么简单的一个例于都无法达到要求. 甚至在点点收效这个苛刻的要求下, $\\left\\{F_{n}(x)\\right\\}$ 的极限函数  \n$$\ng(x)= \\begin{cases}0, & x \\leqslant 0 \\\\ 1, & x>0\\end{cases}\n$$  \n不满足右连续性, 即 $g(x)$ 不是一个分布函数.  \n2. 如何把点点收效这要求减 “弱”一些呢? 从这个例子又可以发现: 收玫关系不成立的点 $x=$ 0 , 恰好是 $F(x)$ 的间断点. 这就启示我们, 可以撤开这些间断点而只考虑 $F(x)$ 的连续点. 这就是以下给出的关于分布函数列的弱收玫定义.  \n定义 4.3.2. 设随机变量 $X, X_{1}, X_{2}, \\cdots$ 的分布函数分别为 $F(x), F_{1}(x), F_{2}(x), \\cdots$. 若对 $F(x)$ 的任一连续点 $x$, 都有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} F_{n}(x)=F(x) \\tag{4.3.2}\n\\end{equation*}\n$$  \n则称 $\\left\\{F_{n}(x)\\right\\}$ 弱收敛于 $F(x)$, 记作  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n不满足右连续性, 即 $g(x)$ 不是一个分布函数.  \n2. 如何把点点收效这要求减 “弱”一些呢? 从这个例子又可以发现: 收玫关系不成立的点 $x=$ 0 , 恰好是 $F(x)$ 的间断点. 这就启示我们, 可以撤开这些间断点而只考虑 $F(x)$ 的连续点. 这就是以下给出的关于分布函数列的弱收玫定义.  \n定义 4.3.2. 设随机变量 $X, X_{1}, X_{2}, \\cdots$ 的分布函数分别为 $F(x), F_{1}(x), F_{2}(x), \\cdots$. 若对 $F(x)$ 的任一连续点 $x$, 都有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} F_{n}(x)=F(x) \\tag{4.3.2}\n\\end{equation*}\n$$  \n则称 $\\left\\{F_{n}(x)\\right\\}$ 弱收敛于 $F(x)$, 记作  \n$$\n\\begin{equation*}\nF_{n}(x) \\xrightarrow{W} F(x) . \\tag{4.3.3}\n\\end{equation*}\n$$  \n也称 $\\left\\{X_{n}\\right\\}$ 按分布收玫于 $X$, 记作  \n$$\n\\begin{equation*}\nX_{n} \\xrightarrow{L} X . \\tag{4.3.4}\n\\end{equation*}\n$$  \n以上定义的 “弱收玫” 是自然的, 因为它比在每一点上都收玫的要求的确 “弱”了些. 若 $F(x)$是直线上的连续函数, 则弱收玫就是点点收玫.  \n注意, 在上述定义中, 对分布函数序列 $\\left\\{F_{n}(x)\\right\\}$ 称为弱收玫, 而对其随机变量序列 $\\left\\{X_{n}\\right\\}$ 则称为按分布收玫, 这是在两种不同场合给出的两个不同名称, 但其本质含义是一样的, 都要求在 $F(x)$的连续点上有 (4.3.2).  \n下面的定理说明依概率收玫是一种比按分布收玫更强的收玫性.  \n定理 4.3.2.  \n$$\nX_{n} \\xrightarrow{P} X \\Rightarrow X_{n} \\xrightarrow{L} X .\n$$",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n也称 $\\left\\{X_{n}\\right\\}$ 按分布收玫于 $X$, 记作  \n$$\n\\begin{equation*}\nX_{n} \\xrightarrow{L} X . \\tag{4.3.4}\n\\end{equation*}\n$$  \n以上定义的 “弱收玫” 是自然的, 因为它比在每一点上都收玫的要求的确 “弱”了些. 若 $F(x)$是直线上的连续函数, 则弱收玫就是点点收玫.  \n注意, 在上述定义中, 对分布函数序列 $\\left\\{F_{n}(x)\\right\\}$ 称为弱收玫, 而对其随机变量序列 $\\left\\{X_{n}\\right\\}$ 则称为按分布收玫, 这是在两种不同场合给出的两个不同名称, 但其本质含义是一样的, 都要求在 $F(x)$的连续点上有 (4.3.2).  \n下面的定理说明依概率收玫是一种比按分布收玫更强的收玫性.  \n定理 4.3.2.  \n$$\nX_{n} \\xrightarrow{P} X \\Rightarrow X_{n} \\xrightarrow{L} X .\n$$  \n证明: 设随机变量 $X, X_{1}, X_{2}, \\cdots$ 的分布函数分别为 $F(x), F_{1}(x), F_{2}(x), \\cdots$ 为证 $X_{n} \\xrightarrow{L} X$, 相当于证 $F_{n}(x) \\xrightarrow{W} F(x)$, 所以只须证: 对所有的 $x$, 有  \n$$\n\\begin{equation*}\nF(x-0) \\leqslant \\varliminf_{n \\rightarrow+\\infty} F_{n}(x) \\leqslant \\varlimsup_{n \\rightarrow+\\infty} F_{x}(x) \\leqslant F(x+0) . \\tag{4.3.5}\n\\end{equation*}\n$$  \n因为若上式成立, 则当 $x$ 是 $F(x)$ 的连续点时, 有 $F(x-0)=F(x+0)$, 由此即可得 $F_{n}(x) \\xrightarrow{W} F(x)$.  \n为证 (4.3.5), 先令 $x^{\\prime}<x$, 则  \n$$",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n证明: 设随机变量 $X, X_{1}, X_{2}, \\cdots$ 的分布函数分别为 $F(x), F_{1}(x), F_{2}(x), \\cdots$ 为证 $X_{n} \\xrightarrow{L} X$, 相当于证 $F_{n}(x) \\xrightarrow{W} F(x)$, 所以只须证: 对所有的 $x$, 有  \n$$\n\\begin{equation*}\nF(x-0) \\leqslant \\varliminf_{n \\rightarrow+\\infty} F_{n}(x) \\leqslant \\varlimsup_{n \\rightarrow+\\infty} F_{x}(x) \\leqslant F(x+0) . \\tag{4.3.5}\n\\end{equation*}\n$$  \n因为若上式成立, 则当 $x$ 是 $F(x)$ 的连续点时, 有 $F(x-0)=F(x+0)$, 由此即可得 $F_{n}(x) \\xrightarrow{W} F(x)$.  \n为证 (4.3.5), 先令 $x^{\\prime}<x$, 则  \n$$\n\\left\\{X \\leqslant x^{\\prime}\\right\\}=\\left\\{X_{n} \\leqslant x, X \\leqslant x^{\\prime}\\right\\} \\cup\\left\\{X_{n}>x, X \\leqslant x^{\\prime}\\right\\} \\subset\\left\\{X_{n} \\leqslant x\\right\\} \\cup\\left\\{\\left|X_{n}-X\\right| \\geqslant x-x^{\\prime}\\right\\}\n$$  \n从而有  \n$$\nF\\left(x^{\\prime}\\right) \\leqslant F_{n}(x)+P\\left(\\left|X_{n}-X\\right| \\geqslant x-x^{\\prime}\\right) .\n$$  \n由 $x_{n} \\xrightarrow{P} x$, 得 $P\\left(\\left|X_{n}-X\\right| \\geqslant x-x^{\\prime}\\right) \\rightarrow 0,(n \\rightarrow+\\infty)$. 所以有  \n$$",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n从而有  \n$$\nF\\left(x^{\\prime}\\right) \\leqslant F_{n}(x)+P\\left(\\left|X_{n}-X\\right| \\geqslant x-x^{\\prime}\\right) .\n$$  \n由 $x_{n} \\xrightarrow{P} x$, 得 $P\\left(\\left|X_{n}-X\\right| \\geqslant x-x^{\\prime}\\right) \\rightarrow 0,(n \\rightarrow+\\infty)$. 所以有  \n$$\nF\\left(x^{\\prime}\\right) \\leqslant \\underline{\\lim }_{n \\rightarrow+\\infty} F_{n}(x) .\n$$  \n再令 $x^{\\prime} \\rightarrow x$, 即得  \n$$\nF(x-0) \\leqslant \\lim _{n \\rightarrow+\\infty} F_{n}(x) .\n$$  \n同理可证,当 $x^{\\prime \\prime}>x$ 时, 有  \n$$\n\\varlimsup_{n \\rightarrow+\\infty} F_{n}(x) \\leqslant F\\left(x^{\\prime \\prime}\\right) .\n$$  \n令 $x^{\\prime \\prime} \\rightarrow x$, 即得  \n$$\n\\varlimsup_{n \\rightarrow+\\infty} F_{n}(x) \\leqslant F(x+0) .\n$$  \n这就证明了定理.  \n注意, 以上定理的逆命题不成立, 即由按分布收玫无法推出依概率收玫, 见下例.  \n例 4.3.2: 设 $X$ 的分布列为  \n$$\nP(X=-1)=\\frac{1}{2}, \\quad P(X=1)=\\frac{1}{2}\n$$  \n令 $X_{n}=-X$, 则 $X_{n}$ 与 $X$ 同分布, 即 $X_{n}$ 与 $X$ 有相同的分布函数, 故 $X_{n} \\xrightarrow{L} X$.  \n但对任意的 $0<\\varepsilon<2$, 有  \n$$",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "同理可证,当 $x^{\\prime \\prime}>x$ 时, 有  \n$$\n\\varlimsup_{n \\rightarrow+\\infty} F_{n}(x) \\leqslant F\\left(x^{\\prime \\prime}\\right) .\n$$  \n令 $x^{\\prime \\prime} \\rightarrow x$, 即得  \n$$\n\\varlimsup_{n \\rightarrow+\\infty} F_{n}(x) \\leqslant F(x+0) .\n$$  \n这就证明了定理.  \n注意, 以上定理的逆命题不成立, 即由按分布收玫无法推出依概率收玫, 见下例.  \n例 4.3.2: 设 $X$ 的分布列为  \n$$\nP(X=-1)=\\frac{1}{2}, \\quad P(X=1)=\\frac{1}{2}\n$$  \n令 $X_{n}=-X$, 则 $X_{n}$ 与 $X$ 同分布, 即 $X_{n}$ 与 $X$ 有相同的分布函数, 故 $X_{n} \\xrightarrow{L} X$.  \n但对任意的 $0<\\varepsilon<2$, 有  \n$$\nP\\left(\\left|X_{n}-X\\right| \\geqslant \\varepsilon\\right)=P(2|X| \\geqslant \\varepsilon)=1 \\nrightarrow 0 .\n$$  \n即 $X_{n}$ 不是依概率收敛于 $X$.  \n以上例子说明: 一般按分布收玫与依概率收玫是不等价的. 而下面的定理则说明: 当极限随机变量为常数 (服从退化分布) 时, 按分布收玫与依概率收玫是等价的.  \n定理 4.3.3. 若 $c$ 为常数, 则 $X_{n} \\xrightarrow{P} c$ 的充要条件是: $X_{n} \\xrightarrow{L} c$.  \n证明: 必要性已由定理 4.3.2 给出, 下证充分性. 记 $X_{n}$ 的分布函数为 $F(x), n=1,2, \\cdots$, 因为常数 $c$ 的分布函数 (退化分布) 为  \n$$\nF(x)= \\begin{cases}0, & x<c, \\\\ 1, & x \\geqslant c .\\end{cases}\n$$  \n所以对任意的 $\\varepsilon>0$, 有  \n$$",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n即 $X_{n}$ 不是依概率收敛于 $X$.  \n以上例子说明: 一般按分布收玫与依概率收玫是不等价的. 而下面的定理则说明: 当极限随机变量为常数 (服从退化分布) 时, 按分布收玫与依概率收玫是等价的.  \n定理 4.3.3. 若 $c$ 为常数, 则 $X_{n} \\xrightarrow{P} c$ 的充要条件是: $X_{n} \\xrightarrow{L} c$.  \n证明: 必要性已由定理 4.3.2 给出, 下证充分性. 记 $X_{n}$ 的分布函数为 $F(x), n=1,2, \\cdots$, 因为常数 $c$ 的分布函数 (退化分布) 为  \n$$\nF(x)= \\begin{cases}0, & x<c, \\\\ 1, & x \\geqslant c .\\end{cases}\n$$  \n所以对任意的 $\\varepsilon>0$, 有  \n$$\n\\begin{aligned}\nP\\left(\\left|X_{n}-c\\right| \\geqslant \\varepsilon\\right) & =P\\left(X_{n} \\geqslant c+\\varepsilon\\right)+P\\left(X_{n} \\leqslant c-\\varepsilon\\right) \\\\\n& \\leqslant P\\left(X_{n}>c+\\varepsilon / 2\\right)+P\\left(X_{n} \\leqslant c-\\varepsilon\\right) \\\\\n& =1-F_{n}(c+\\varepsilon / 2)+F_{n}(c-\\varepsilon) .\n\\end{aligned}\n$$  \n由于 $x=c+\\varepsilon / 2$ 和 $x=c-\\varepsilon$ 均为 $F(x)$ 的连续点, 且 $F_{n}(x) \\xrightarrow{W} F(x)$, 所以当 $n \\rightarrow+\\infty$ 时, 有  \n$$\nF_{n}(c+\\varepsilon / 2) \\rightarrow F(c+\\varepsilon / 2)=1, \\quad F_{n}(c-\\varepsilon) \\rightarrow F(c-\\varepsilon)=0\n$$  \n由此得  \n$$",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "& \\leqslant P\\left(X_{n}>c+\\varepsilon / 2\\right)+P\\left(X_{n} \\leqslant c-\\varepsilon\\right) \\\\\n& =1-F_{n}(c+\\varepsilon / 2)+F_{n}(c-\\varepsilon) .\n\\end{aligned}\n$$  \n由于 $x=c+\\varepsilon / 2$ 和 $x=c-\\varepsilon$ 均为 $F(x)$ 的连续点, 且 $F_{n}(x) \\xrightarrow{W} F(x)$, 所以当 $n \\rightarrow+\\infty$ 时, 有  \n$$\nF_{n}(c+\\varepsilon / 2) \\rightarrow F(c+\\varepsilon / 2)=1, \\quad F_{n}(c-\\varepsilon) \\rightarrow F(c-\\varepsilon)=0\n$$  \n由此得  \n$$\nP\\left(\\left|X_{n}-c\\right| \\geqslant \\varepsilon\\right) \\rightarrow 0\n$$  \n即 $X_{n} \\xrightarrow{P} X$. 定理证毕.",
        "metadata": {
            "Header 2": "二、按分布收敏、弱收敛"
        },
        "type": "Document"
    },
    {
        "page_content": "分布函数列的弱收玫是一个很有用的概念, 它可帮助我们寻求极限分布. 但判别一个分布函数列是否弱收玫于某个分布函数, 有时是很麻烦的, 这时我们就可利用特征函数这一工具, 为此要研究: 分布函数序列的弱收玫性与相应的特征函数序列的点点收玫性有什么关系? 下面的定理指出这是等价的.\n定理 4.3.4. 分布函数序列 $\\left\\{F_{n}(x)\\right\\}$ 弱收玫于分布函数 $F(x)$ 的充要条件是 $\\left\\{F_{n}(x)\\right\\}$ 的特征函数序列 $\\varphi_{n}(t)$ 收敛于 $F(x)$ 的特征函数 $\\varphi(t)$.  \n这个定理的证明只涉及数学分析的一些结果, 且证明比较冗长 (参阅文献 [1]), 在此就不介绍了. 通常把以上定理称为特征函数的连续性定理, 因为它表明分布函数与特征函数的一一对应关系有连续性.  \n例 4.3.3: 若 $X_{\\lambda}$ 服从参数为 $\\lambda$ 的泊松分布, 证明:  \n$$\n\\lim _{\\lambda \\rightarrow+\\infty}\\left(\\frac{X_{\\lambda}-\\lambda}{\\sqrt{\\lambda}} \\leqslant x\\right)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} \\exp \\left(-\\frac{t^{2}}{2}\\right) \\mathrm{d} t\n$$  \n证明: 已知 $X_{\\lambda}$ 的特征函数为 $\\varphi_{\\lambda}(t)=\\exp \\left(\\lambda\\left(\\mathrm{e}^{i t}-1\\right)\\right)$, 故 $Y_{n}=\\left(X_{n}-\\lambda\\right) / \\sqrt{\\lambda}$ 的特征函数为  \n$$",
        "metadata": {
            "Header 2": "三、判断弱收敛的方法"
        },
        "type": "Document"
    },
    {
        "page_content": "例 4.3.3: 若 $X_{\\lambda}$ 服从参数为 $\\lambda$ 的泊松分布, 证明:  \n$$\n\\lim _{\\lambda \\rightarrow+\\infty}\\left(\\frac{X_{\\lambda}-\\lambda}{\\sqrt{\\lambda}} \\leqslant x\\right)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} \\exp \\left(-\\frac{t^{2}}{2}\\right) \\mathrm{d} t\n$$  \n证明: 已知 $X_{\\lambda}$ 的特征函数为 $\\varphi_{\\lambda}(t)=\\exp \\left(\\lambda\\left(\\mathrm{e}^{i t}-1\\right)\\right)$, 故 $Y_{n}=\\left(X_{n}-\\lambda\\right) / \\sqrt{\\lambda}$ 的特征函数为  \n$$\ng_{\\lambda}(t)=\\varphi_{\\lambda}\\left(\\frac{t}{\\sqrt{\\lambda}}\\right) \\exp (-i \\sqrt{\\lambda} t)=\\exp \\left(\\lambda\\left(\\mathrm{e}^{i t / \\sqrt{\\lambda}}-1\\right)-i \\sqrt{\\lambda} t\\right) .\n$$  \n对任意的 $t$, 有  \n$$\n\\exp \\left(i \\frac{t}{\\sqrt{\\lambda}}\\right)=1+\\frac{i t}{\\sqrt{\\lambda}}-\\frac{t^{2}}{2 ! \\lambda}+o\\left(\\frac{1}{\\lambda}\\right)\n$$  \n于是  \n$$\n\\lambda\\left(\\mathrm{e}^{i t / \\sqrt{\\lambda}}-1\\right)-i \\sqrt{\\lambda} t=-\\frac{t^{2}}{2}+\\lambda \\cdot o\\left(\\frac{1}{\\lambda}\\right) \\rightarrow-\\frac{t^{2}}{2}, n \\rightarrow+\\infty .\n$$  \n从而有  \n$$",
        "metadata": {
            "Header 2": "三、判断弱收敛的方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n对任意的 $t$, 有  \n$$\n\\exp \\left(i \\frac{t}{\\sqrt{\\lambda}}\\right)=1+\\frac{i t}{\\sqrt{\\lambda}}-\\frac{t^{2}}{2 ! \\lambda}+o\\left(\\frac{1}{\\lambda}\\right)\n$$  \n于是  \n$$\n\\lambda\\left(\\mathrm{e}^{i t / \\sqrt{\\lambda}}-1\\right)-i \\sqrt{\\lambda} t=-\\frac{t^{2}}{2}+\\lambda \\cdot o\\left(\\frac{1}{\\lambda}\\right) \\rightarrow-\\frac{t^{2}}{2}, n \\rightarrow+\\infty .\n$$  \n从而有  \n$$\n\\lim _{\\lambda \\rightarrow+\\infty} g_{\\lambda}(t)=\\mathrm{e}^{-t^{2} / 2}\n$$  \n而 $\\mathrm{e}^{-t^{2} / 2}$ 正是标准正态分布 $N(0,1)$ 的特征函数, 由定理 4.3.4 即知结论成立.  \n最后, 我们利用以上的一些结论来证明 4.2 节中的辛钦大数定律.  \n辛软大数定律的证明: 设 $\\left\\{X_{n}\\right\\}$ 独立同分布, 且 $E\\left(X_{n}\\right)=a, i=1,2, \\cdots$. 现在要证明  \n$$\n\\frac{1}{n} \\sum_{k=1}^{n} X_{k} \\xrightarrow{P} a, n \\rightarrow+\\infty\n$$  \n为此记  \n$$\nY_{n}=\\frac{1}{n} \\sum_{k=1}^{n} X_{k}\n$$  \n由定理 4.3.3 知, 只须证 $Y_{n} \\xrightarrow{L} a$. 又由定理 4.3.4 知, 只须证 $\\varphi_{Y}(t) \\rightarrow \\mathrm{e}^{-i a t}$.",
        "metadata": {
            "Header 2": "三、判断弱收敛的方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n而 $\\mathrm{e}^{-t^{2} / 2}$ 正是标准正态分布 $N(0,1)$ 的特征函数, 由定理 4.3.4 即知结论成立.  \n最后, 我们利用以上的一些结论来证明 4.2 节中的辛钦大数定律.  \n辛软大数定律的证明: 设 $\\left\\{X_{n}\\right\\}$ 独立同分布, 且 $E\\left(X_{n}\\right)=a, i=1,2, \\cdots$. 现在要证明  \n$$\n\\frac{1}{n} \\sum_{k=1}^{n} X_{k} \\xrightarrow{P} a, n \\rightarrow+\\infty\n$$  \n为此记  \n$$\nY_{n}=\\frac{1}{n} \\sum_{k=1}^{n} X_{k}\n$$  \n由定理 4.3.3 知, 只须证 $Y_{n} \\xrightarrow{L} a$. 又由定理 4.3.4 知, 只须证 $\\varphi_{Y}(t) \\rightarrow \\mathrm{e}^{-i a t}$.  \n因为 $\\left\\{X_{n}\\right\\}$ 同分布, 所以它们有相同的特征函数, 记这个特征函数为 $\\varphi(t)$. 又因为 $\\varphi(0) / i=$ $E\\left(X_{i}\\right)=a$, 从而 $\\varphi(t)$ 在 0 点展开式为  \n$$\n\\varphi(t)=\\varphi(0)+\\varphi^{\\prime}(0) t+o(t)=1+i a t+o(t) .\n$$  \n再由 $\\left\\{X_{n}\\right\\}$ 的独立性知 $Y_{n}$ 的特征函数为  \n$$\n\\varphi_{Y_{n}}(t)=(\\varphi(t / n))^{n}=(1+i a t / n+o(1 / n))^{n} .\n$$  \n对任意的 $t$ 有  \n$$\n\\lim _{n \\rightarrow+\\infty}(\\varphi(t / n))^{n}=\\lim _{n \\rightarrow+\\infty}(1+i a t / n+o(1 / n))^{n}=\\mathrm{e}^{i a t} .\n$$",
        "metadata": {
            "Header 2": "三、判断弱收敛的方法"
        },
        "type": "Document"
    },
    {
        "page_content": "因为 $\\left\\{X_{n}\\right\\}$ 同分布, 所以它们有相同的特征函数, 记这个特征函数为 $\\varphi(t)$. 又因为 $\\varphi(0) / i=$ $E\\left(X_{i}\\right)=a$, 从而 $\\varphi(t)$ 在 0 点展开式为  \n$$\n\\varphi(t)=\\varphi(0)+\\varphi^{\\prime}(0) t+o(t)=1+i a t+o(t) .\n$$  \n再由 $\\left\\{X_{n}\\right\\}$ 的独立性知 $Y_{n}$ 的特征函数为  \n$$\n\\varphi_{Y_{n}}(t)=(\\varphi(t / n))^{n}=(1+i a t / n+o(1 / n))^{n} .\n$$  \n对任意的 $t$ 有  \n$$\n\\lim _{n \\rightarrow+\\infty}(\\varphi(t / n))^{n}=\\lim _{n \\rightarrow+\\infty}(1+i a t / n+o(1 / n))^{n}=\\mathrm{e}^{i a t} .\n$$  \n而 $\\mathrm{e}^{i a t}$ 正是退化分布的特征函数, 由此证得了 $Y_{n} \\xrightarrow{L} a$. 至此定理得证.",
        "metadata": {
            "Header 2": "三、判断弱收敛的方法"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 如果 $X_{n} \\xrightarrow{P} X$, 且 $X_{n} \\xrightarrow{P} Y$. 试证: $P(X=Y)=1$.\n2. 如果 $X_{n} \\xrightarrow{P} X, Y_{n} \\xrightarrow{P} Y$. 试证:  \n(1) $X_{n}+Y_{n} \\xrightarrow{P} X+Y$;  \n(2) $X_{n} \\times Y_{n} \\xrightarrow{P} X \\times Y$.  \n3. 如果 $X_{n} \\xrightarrow{P} X, g(x)$ 是直线上的连续函数, 试证: $g\\left(X_{n}\\right) \\xrightarrow{P} g(X)$.\n4. 如果 $X_{n} \\xrightarrow{P} a$, 则对任意常数 $c$, 有  \n$$\nc X_{n} \\xrightarrow{P} c a .\n$$  \n5. 试证: $X_{n} \\xrightarrow{P} X$ 的充要条件为: $n \\rightarrow+\\infty$ 时, 有\n6. 设 $D(x)$ 为退化分布:  \n$$\nE\\left(\\frac{\\left|X_{n}-X\\right|}{1+\\left|X_{n}-X\\right|}\\right) \\rightarrow 0\n$$  \n$$\nD(x)= \\begin{cases}0, & x<0 \\\\ 1, & x \\geqslant 0\\end{cases}\n$$  \n试问下列分布函数列的极限函数是否仍是分布函数?（其中 $n=1,2, \\cdots$. )  \n(1) $\\{D(x+n)\\}$,  \n(2) $\\{D(x+1 / n)\\}$,  \n(3) $\\{D(x-1 / n)\\}$.  \n7. 设分布函数列 $\\left\\{F_{n}(x)\\right\\}$ 弱收玫于连续的分布函数 $F(x)$, 试证: $\\left\\{F_{n}(x)\\right\\}$ 在 $(-\\infty,+\\infty)$ 上一致收敛于分布函数 $F(x)$.",
        "metadata": {
            "Header 2": "如题 4.3"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n5. 试证: $X_{n} \\xrightarrow{P} X$ 的充要条件为: $n \\rightarrow+\\infty$ 时, 有\n6. 设 $D(x)$ 为退化分布:  \n$$\nE\\left(\\frac{\\left|X_{n}-X\\right|}{1+\\left|X_{n}-X\\right|}\\right) \\rightarrow 0\n$$  \n$$\nD(x)= \\begin{cases}0, & x<0 \\\\ 1, & x \\geqslant 0\\end{cases}\n$$  \n试问下列分布函数列的极限函数是否仍是分布函数?（其中 $n=1,2, \\cdots$. )  \n(1) $\\{D(x+n)\\}$,  \n(2) $\\{D(x+1 / n)\\}$,  \n(3) $\\{D(x-1 / n)\\}$.  \n7. 设分布函数列 $\\left\\{F_{n}(x)\\right\\}$ 弱收玫于连续的分布函数 $F(x)$, 试证: $\\left\\{F_{n}(x)\\right\\}$ 在 $(-\\infty,+\\infty)$ 上一致收敛于分布函数 $F(x)$.\n8. 利用特征函数方法证明如下的泊松定理: 设有一列二项分布 $\\left\\{b\\left(k, n, p_{n}\\right)\\right\\}$, 若 $\\lim _{n \\rightarrow+\\infty} n p_{n}=\\lambda>$ 0 , 则  \n$$\n\\lim _{n \\rightarrow+\\infty} b\\left(k, n, p_{n}\\right)=\\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}, k=0,1,2, \\cdots\n$$  \n9. 如果 $X_{n} \\xrightarrow{L} X$, 且数列 $a_{n} \\rightarrow a, b_{n} \\rightarrow b$. 试证: $a_{n} X_{n}+b_{n} \\xrightarrow{L} a X+b$.\n10. 如果 $X_{n} \\xrightarrow{L} X, Y_{n} \\xrightarrow{P} a$, 试证: $X_{n}+Y_{n} \\xrightarrow{L} X+a$.",
        "metadata": {
            "Header 2": "如题 4.3"
        },
        "type": "Document"
    },
    {
        "page_content": "8. 利用特征函数方法证明如下的泊松定理: 设有一列二项分布 $\\left\\{b\\left(k, n, p_{n}\\right)\\right\\}$, 若 $\\lim _{n \\rightarrow+\\infty} n p_{n}=\\lambda>$ 0 , 则  \n$$\n\\lim _{n \\rightarrow+\\infty} b\\left(k, n, p_{n}\\right)=\\frac{\\lambda^{k}}{k !} \\mathrm{e}^{-\\lambda}, k=0,1,2, \\cdots\n$$  \n9. 如果 $X_{n} \\xrightarrow{L} X$, 且数列 $a_{n} \\rightarrow a, b_{n} \\rightarrow b$. 试证: $a_{n} X_{n}+b_{n} \\xrightarrow{L} a X+b$.\n10. 如果 $X_{n} \\xrightarrow{L} X, Y_{n} \\xrightarrow{P} a$, 试证: $X_{n}+Y_{n} \\xrightarrow{L} X+a$.\n11. 如果 $X_{n} \\xrightarrow{L} X, Y_{n} \\xrightarrow{P} 0$, 试证: $X_{n} Y_{n} \\xrightarrow{P} 0$.\n12. 如果 $X_{n} \\xrightarrow{L} X, Y_{n} \\xrightarrow{P} a$, 且 $Y_{n} \\neq 0$, 常数 $a \\neq 0$, 试证: $X_{n} / Y_{n} \\xrightarrow{L} X / a$.\n13. 设随机变量 $X_{n}$ 服从柯西分布, 其密度函数为  \n$$\np_{n}(x)=\\frac{n}{\\pi\\left(1+n^{2} x^{2}\\right)},-\\infty<x<+\\infty .\n$$  \n试证 $X_{n} \\xrightarrow{P} 0$.  \n14. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 其密度函数为  \n$$\np(x)= \\begin{cases}1 / \\beta, & 0<x<\\beta, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$",
        "metadata": {
            "Header 2": "如题 4.3"
        },
        "type": "Document"
    },
    {
        "page_content": "12. 如果 $X_{n} \\xrightarrow{L} X, Y_{n} \\xrightarrow{P} a$, 且 $Y_{n} \\neq 0$, 常数 $a \\neq 0$, 试证: $X_{n} / Y_{n} \\xrightarrow{L} X / a$.\n13. 设随机变量 $X_{n}$ 服从柯西分布, 其密度函数为  \n$$\np_{n}(x)=\\frac{n}{\\pi\\left(1+n^{2} x^{2}\\right)},-\\infty<x<+\\infty .\n$$  \n试证 $X_{n} \\xrightarrow{P} 0$.  \n14. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 其密度函数为  \n$$\np(x)= \\begin{cases}1 / \\beta, & 0<x<\\beta, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n其中常数 $\\beta>0$. 令 $Y_{n}=\\max \\left(X_{1}, X_{2}, \\cdots, X_{n}\\right)$, 试证: $Y_{n} \\xrightarrow{P} \\beta$.  \n15. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 其密度函数为  \n$$\np(x)= \\begin{cases}\\mathrm{e}^{-(x-a)}, & x \\geqslant a \\\\ 0, & x<a\\end{cases}\n$$  \n令 $Y_{n}=\\min \\left(X_{1}, X_{2}, \\cdots, X_{n}\\right)$, 试证: $Y_{n} \\xrightarrow{P} a$.  \n16. 设分布函数列 $\\left\\{F_{n}(x)\\right\\}$ 弱收玫于分布函数 $F(x)$, 且 $F_{n}(x)$ 和 $F(x)$ 都是连续、严格单调函数, 又设 $\\xi$ 服从 $(0,1)$ 上的均匀分布, 试证: $F_{n}^{-1}(\\xi) \\xrightarrow{P} F^{-1}(\\xi)$.",
        "metadata": {
            "Header 2": "如题 4.3"
        },
        "type": "Document"
    },
    {
        "page_content": "15. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 其密度函数为  \n$$\np(x)= \\begin{cases}\\mathrm{e}^{-(x-a)}, & x \\geqslant a \\\\ 0, & x<a\\end{cases}\n$$  \n令 $Y_{n}=\\min \\left(X_{1}, X_{2}, \\cdots, X_{n}\\right)$, 试证: $Y_{n} \\xrightarrow{P} a$.  \n16. 设分布函数列 $\\left\\{F_{n}(x)\\right\\}$ 弱收玫于分布函数 $F(x)$, 且 $F_{n}(x)$ 和 $F(x)$ 都是连续、严格单调函数, 又设 $\\xi$ 服从 $(0,1)$ 上的均匀分布, 试证: $F_{n}^{-1}(\\xi) \\xrightarrow{P} F^{-1}(\\xi)$.\n17. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 数学期望、方差均存在, 且 $E\\left(x_{n}\\right)=\\mu$, 试证:  \n$$\n\\frac{2}{n(n+1)} \\sum_{k=1}^{n} k \\cdot X_{k} \\xrightarrow{P} \\mu\n$$  \n18. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 数学期望、方差均存在, 且  \n$$\nE\\left(X_{n}\\right)=0, \\operatorname{Var}\\left(X_{n}\\right)=\\sigma^{2}\n$$  \n试证:  \n$$\n\\frac{1}{n} \\sum_{k=1}^{n} X_{k}^{2} \\xrightarrow{P} \\sigma^{2}\n$$  \n19. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 且 $\\operatorname{Var}\\left(X_{n}\\right)=\\sigma^{2}$ 存在, 令  \n$$\n\\bar{X}=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}, S_{n}^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}\n$$",
        "metadata": {
            "Header 2": "如题 4.3"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n18. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 数学期望、方差均存在, 且  \n$$\nE\\left(X_{n}\\right)=0, \\operatorname{Var}\\left(X_{n}\\right)=\\sigma^{2}\n$$  \n试证:  \n$$\n\\frac{1}{n} \\sum_{k=1}^{n} X_{k}^{2} \\xrightarrow{P} \\sigma^{2}\n$$  \n19. 设随机变量序列 $\\left\\{X_{n}\\right\\}$ 独立同分布, 且 $\\operatorname{Var}\\left(X_{n}\\right)=\\sigma^{2}$ 存在, 令  \n$$\n\\bar{X}=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}, S_{n}^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}\n$$  \n试证: $S_{n}^{2} \\xrightarrow{P} \\sigma^{2}$.  \n20. 设随机变量 $X \\sim G a(a, \\lambda)$, 证明: 当 $a \\rightarrow+\\infty$ 时, 随机变量 $(\\lambda X-a) / \\sqrt{a}$ 按分布收玫于标准正态变量.",
        "metadata": {
            "Header 2": "如题 4.3"
        },
        "type": "Document"
    },
    {
        "page_content": "大数定律讨论的是多个随机变量的平均 $\\frac{1}{n} \\sum_{i=1}^{n} X_{i}$ 的渐近性质. 现在我们来讨论独立随机变量和  \n$$\nY_{n}=\\sum_{i=1}^{n} X_{i}\n$$  \n的极限分布. 以下我们先给出一个独立随机变量和的例子.  \n例 4.4.1: 误差分析是人们经常遇到且感兴趣的随机变量, 大量的研究表明, 误差的产生是由大量微小的相互独立的随机因素叠加而成的, 譬如一位操作者在机床加工机械轴, 使其直径符合规定要求, 但加工后的机械轴与规定要求总有一定的误差, 这是因为在加工时受到一些随机因素的影响, 它们是  \n- 在机床方面有机床振动与转速的影响;\n- 在刀具方面有装配与磨损的影响;\n- 在材料方面有钢材的成分、产地的影响;\n- 在操作者方面有注意力集中程度、当天的情绪的影响;\n- 在测量方面有量具误差、测量技术的影响;  \n○在环境方面有车间的温度、湿度、照明、工作电压的影响:  \n- 在具体场合还可列出许多其他影响因素.  \n由于这些因素很多, 每个因素对加工精度的影响都是很微小的, 每个因素的出现都是人们无法控制的、是随机的、时有时无、时大时小、时正时负. 这些因素的综合影响最后使每个加工轴的直径产生误差, 若将这个误差记为 $Y_{n}$, 那么 $Y_{n}$ 是随机变量, 且可以将 $Y_{n}$ 看作很多微小的随机波动 $X_{1}, X_{2}, \\cdots, X_{n}$ 之和, 即  \n$$\nY_{n}=X_{1}+X_{2}+\\cdots X_{n}\n$$  \n这里 $n$ 是很大的, 人们关心的是当 $n \\rightarrow+\\infty$ 时, “ $Y_{n}$ 的分布是什么?\"  \n当然, 我们可以用卷积公式去计算 $Y_{n}$ 的分布, 但是这样的计算是相当复杂的、不易实现的. 有的可写出 $Y_{n}$ 的分布, 由于其形式复杂而无法使用, 这从下面例子可以看出这一点.  \n例 4.4.2: 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布随机变量序列, 其共同分布为区间 $(0,1)$ 上的均匀分布. 记 $Y_{n}=$ $\\sum_{i=1}^{n} X_{i}, p_{n}(y)$ 为 $Y_{n}$ 的密度函数, 用卷积公式可以求出  \n$$",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.1 独立随机变量和"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nY_{n}=X_{1}+X_{2}+\\cdots X_{n}\n$$  \n这里 $n$ 是很大的, 人们关心的是当 $n \\rightarrow+\\infty$ 时, “ $Y_{n}$ 的分布是什么?\"  \n当然, 我们可以用卷积公式去计算 $Y_{n}$ 的分布, 但是这样的计算是相当复杂的、不易实现的. 有的可写出 $Y_{n}$ 的分布, 由于其形式复杂而无法使用, 这从下面例子可以看出这一点.  \n例 4.4.2: 设 $\\left\\{X_{n}\\right\\}$ 为独立同分布随机变量序列, 其共同分布为区间 $(0,1)$ 上的均匀分布. 记 $Y_{n}=$ $\\sum_{i=1}^{n} X_{i}, p_{n}(y)$ 为 $Y_{n}$ 的密度函数, 用卷积公式可以求出  \n$$\np_{1}(y)= \\begin{cases}1, & 0<y<1, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n!  \n图 4.4.1: 均匀分布的卷积  \n$$\n\\begin{aligned}\n& p_{2}(y)= \\begin{cases}y, & 0<y<1, \\\\\n2-y, & 1 \\leqslant y<2, \\\\\n0, & \\text { 其他. }\\end{cases} \\\\\n& p_{3}(y)= \\begin{cases}y^{2} / 2, & 0<y<1, \\\\\n-(y-3 / 2)^{2}+3 / 4, & 1 \\leqslant y<2, \\\\\n(3-y)^{2} / 2, & 2 \\leqslant y<3, \\\\\n0, \\text { 其他. }\\end{cases} \\\\\n& p_{4}(y)= \\begin{cases}y^{2} / 6, & 0<y<1, \\\\\n\\left(y^{3}-4(y-1)^{3}\\right) / 6, & 1 \\leqslant y<2, \\\\\n\\left((4-y)^{3}-4(3-y)^{3}\\right) / 6, & 2 \\leqslant y<3, \\\\\n(4-y)^{3} / 6, & 3 \\leqslant y<4, \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.1 独立随机变量和"
        },
        "type": "Document"
    },
    {
        "page_content": "2-y, & 1 \\leqslant y<2, \\\\\n0, & \\text { 其他. }\\end{cases} \\\\\n& p_{3}(y)= \\begin{cases}y^{2} / 2, & 0<y<1, \\\\\n-(y-3 / 2)^{2}+3 / 4, & 1 \\leqslant y<2, \\\\\n(3-y)^{2} / 2, & 2 \\leqslant y<3, \\\\\n0, \\text { 其他. }\\end{cases} \\\\\n& p_{4}(y)= \\begin{cases}y^{2} / 6, & 0<y<1, \\\\\n\\left(y^{3}-4(y-1)^{3}\\right) / 6, & 1 \\leqslant y<2, \\\\\n\\left((4-y)^{3}-4(3-y)^{3}\\right) / 6, & 2 \\leqslant y<3, \\\\\n(4-y)^{3} / 6, & 3 \\leqslant y<4, \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$  \n将 $p_{1}(y), p_{2}(y), p_{3}(y), p_{4}(y)$ 表示在图 4.4.1 中. 从图上我们可以看出: 随着 $n$ 的增加, $p_{n}(y)$ 的图形愈来愈光滑, 且愈来愈接近正态曲线.  \n可以设想, 当 $n=100$ 时, $p_{100}(x)$ 的非零区城为 $(0,100)$, 若用卷积公式可以分 100 段求出 $p_{100}(x)$ 的表达式, 它们分别是 99 次多项式. 如此复杂的形式即使求出 (当然没有人去求), 也无法使用. 这就迫使人们去寻求近似分布. 若记 $Y_{n}$ 的分布函数为 $F_{n}(x)$, 在弱收玫的含义下, 求出其极限分布 $F(x)$, 那么当 $n$ 很大时, 就可用 $F(x)$ 作为 $F_{n}(x)$ 的近似分布.",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.1 独立随机变量和"
        },
        "type": "Document"
    },
    {
        "page_content": "(4-y)^{3} / 6, & 3 \\leqslant y<4, \\\\\n0, & \\text { 其他. }\\end{cases}\n\\end{aligned}\n$$  \n将 $p_{1}(y), p_{2}(y), p_{3}(y), p_{4}(y)$ 表示在图 4.4.1 中. 从图上我们可以看出: 随着 $n$ 的增加, $p_{n}(y)$ 的图形愈来愈光滑, 且愈来愈接近正态曲线.  \n可以设想, 当 $n=100$ 时, $p_{100}(x)$ 的非零区城为 $(0,100)$, 若用卷积公式可以分 100 段求出 $p_{100}(x)$ 的表达式, 它们分别是 99 次多项式. 如此复杂的形式即使求出 (当然没有人去求), 也无法使用. 这就迫使人们去寻求近似分布. 若记 $Y_{n}$ 的分布函数为 $F_{n}(x)$, 在弱收玫的含义下, 求出其极限分布 $F(x)$, 那么当 $n$ 很大时, 就可用 $F(x)$ 作为 $F_{n}(x)$ 的近似分布.  \n为了使寻求 $Y_{n}$ 的极限分布有意义, 有必要先研究一下问题的提法. 在图 4.4.1 上可以看出: 当 $n$ 增大时, $p_{n}(y)$ 的中心右移, 且 $p_{n}(y)$ 的方差增大. 这意味着当 $n \\rightarrow+\\infty$ 时, $Y_{n}$ 的分布中心会趋向 $+\\infty$, 其方差也趋向 $+\\infty$. 这种情况就没有什么意义了. 为了克服这个缺点, 在中心极限定理的研究中均对 $Y_{n}$ 进行标准化  \n$$\nY_{n}^{*}=\\frac{Y_{n}-E\\left(Y_{n}\\right)}{\\sqrt{\\operatorname{Var}\\left(Y_{n}\\right)}} .\n$$  \n由于 $E\\left(Y_{n}\\right)=0, \\operatorname{Var}\\left(Y_{n}\\right)=1$, 这就有可能得出 $Y_{n}$ 的极限分布为标准正态分布 $N(0,1)$.  \n中心极限定理就是研究独立随机变量和的极限分布为正态分布的问题.",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.1 独立随机变量和"
        },
        "type": "Document"
    },
    {
        "page_content": "定理 4.4 .1 (林德贝格-勒维中心极限定理). 设 $\\left\\{X_{n}\\right\\}$ 是独立同分布的随机变量序列, 且 $E\\left(X_{n}\\right)=\\mu$, $\\operatorname{Var}\\left(X_{n}\\right)=\\sigma^{2}>0$. 记  \n$$\nY_{n}^{*}=\\frac{X_{1}+X_{2}+\\cdots+X_{n}-n \\mu}{\\sigma \\sqrt{n}},\n$$  \n则对任意实数 $y$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} P\\left(Y_{n}^{*} \\leqslant y\\right)=\\Phi(y)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{y} \\mathrm{e}^{-t^{2} / 2} \\mathrm{~d} t . \\tag{4.4.1}\n\\end{equation*}\n$$  \n证明: 为证 (4.4.1), 只须证 $\\left\\{Y_{n}^{*}\\right\\}$ 的分布函数列弱收玫于标准正态分布. 又由定理 4.3.4, 只须证 $\\left\\{Y_{n}^{*}\\right\\}$ 的特征函数列收玫于标准正态分布的特征函数. 为此设 $X_{n}-\\mu$ 的特征函数为 $\\varphi(t)$, 则 $\\left\\{Y_{n}^{*}\\right\\}$ 的特征函数为  \n$$\n\\varphi_{Y_{n}^{*}}(t)=\\left(\\varphi\\left(\\frac{t}{\\sigma \\sqrt{n}}\\right)\\right)^{n}\n$$  \n又因为 $E\\left(X_{n}-\\mu\\right)=0, \\operatorname{Var}\\left(X_{n}-\\mu\\right)=\\sigma^{2}$, 所以有  \n$$\n\\varphi^{\\prime}(0)=0, \\varphi^{\\prime \\prime}(0)=-\\sigma^{2}\n$$  \n于是特征函数 $\\varphi(t)$ 有展开式  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.2 独立同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\varphi_{Y_{n}^{*}}(t)=\\left(\\varphi\\left(\\frac{t}{\\sigma \\sqrt{n}}\\right)\\right)^{n}\n$$  \n又因为 $E\\left(X_{n}-\\mu\\right)=0, \\operatorname{Var}\\left(X_{n}-\\mu\\right)=\\sigma^{2}$, 所以有  \n$$\n\\varphi^{\\prime}(0)=0, \\varphi^{\\prime \\prime}(0)=-\\sigma^{2}\n$$  \n于是特征函数 $\\varphi(t)$ 有展开式  \n$$\n\\begin{aligned}\n\\varphi(t) & =\\varphi(0)+\\varphi^{\\prime}(0) t+\\varphi^{\\prime \\prime}(0) \\frac{t^{2}}{2}+o\\left(t^{2}\\right) \\\\\n& =1-\\frac{1}{2} \\sigma^{2} t^{2}+o\\left(t^{2}\\right) .\n\\end{aligned}\n$$  \n从而有  \n$$\n\\lim _{n \\rightarrow+\\infty} \\varphi_{Y_{n}^{*}}(t)=\\lim _{n \\rightarrow+\\infty}\\left(1-\\frac{t^{2}}{2 n}+o\\left(\\frac{t^{2}}{n}\\right)\\right)^{n}=\\mathrm{e}^{-t^{2} / n}\n$$  \n而 $\\mathrm{e}^{-t^{2} / 2}$ 正是 $N(0,1)$ 分布的特征函数, 定理得证.  \n定理 4.4.1 有广泛的应用, 它只假设 $\\left\\{X_{n}\\right\\}$ 独立同分布、方差存在, 不管原来的分布是什么, 只要 $n$ 充分大, 就可以用正态分布去逼近. 以下给出一些林德贝格-勒维中心极限定理的应用例子.",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.2 独立同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "& =1-\\frac{1}{2} \\sigma^{2} t^{2}+o\\left(t^{2}\\right) .\n\\end{aligned}\n$$  \n从而有  \n$$\n\\lim _{n \\rightarrow+\\infty} \\varphi_{Y_{n}^{*}}(t)=\\lim _{n \\rightarrow+\\infty}\\left(1-\\frac{t^{2}}{2 n}+o\\left(\\frac{t^{2}}{n}\\right)\\right)^{n}=\\mathrm{e}^{-t^{2} / n}\n$$  \n而 $\\mathrm{e}^{-t^{2} / 2}$ 正是 $N(0,1)$ 分布的特征函数, 定理得证.  \n定理 4.4.1 有广泛的应用, 它只假设 $\\left\\{X_{n}\\right\\}$ 独立同分布、方差存在, 不管原来的分布是什么, 只要 $n$ 充分大, 就可以用正态分布去逼近. 以下给出一些林德贝格-勒维中心极限定理的应用例子.  \n例 4.4.3 正态随机数的产生：在随机模拟 (蒙特卡洛方法) 中经常需要产生正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的随机数, 但一般计算机软件只具备产生区间 $(0,1)$ 上的均匀分布随机数的功能, 现在我们要用中心极限定理通过 $(0,1)$ 上均匀分布的随机数来产生正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的随机数.  \n设 $X$ 服从 $(0,1)$ 上的均匀分布, 则其数学期望与方差分别为 $1 / 2$ 和 $1 / 12$. 由此得 12 个相互独立的 $(0,1)$ 上均匀分布随机变量和的数学期望与方差分别为 6 和 1 . 因此我们可以如下产生正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的随机数.  \n1. 从计算机中产生 12 个 $(0,1)$ 上均匀分布的随机数, 记为 $x_{1}, x_{2}, \\cdots, x_{12}$.\n2. 计算 $y=x_{1}+x_{2}+\\cdots+x_{12}-6$, 则由林德贝格-勒维中心极限定理知, 可将 $y$ 看成来自标准正态分布 $N(0,1)$ 的一个随机数.",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.2 独立同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $X$ 服从 $(0,1)$ 上的均匀分布, 则其数学期望与方差分别为 $1 / 2$ 和 $1 / 12$. 由此得 12 个相互独立的 $(0,1)$ 上均匀分布随机变量和的数学期望与方差分别为 6 和 1 . 因此我们可以如下产生正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的随机数.  \n1. 从计算机中产生 12 个 $(0,1)$ 上均匀分布的随机数, 记为 $x_{1}, x_{2}, \\cdots, x_{12}$.\n2. 计算 $y=x_{1}+x_{2}+\\cdots+x_{12}-6$, 则由林德贝格-勒维中心极限定理知, 可将 $y$ 看成来自标准正态分布 $N(0,1)$ 的一个随机数.\n3. 计算 $z=\\mu+\\sigma y$, 则可将 $z$ 看成来自标准正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的一个随机数.\n4. 重复 1-3 $n$ 次, 就可得到 $N\\left(\\mu, \\sigma^{2}\\right)$ 分布的 $n$ 个随机数.  \n从这个例子可以看出, 由 12 个均匀分布的随机数得到 1 个正态分布的随机数是利用了林德贝格-勒维中心极限定理.  \n例 4.4.4 数值计算中的误差分析: 在数值计算中, 任何实数 $x$ 都只能用一定位数的小数 $x^{\\prime}$ 来近似.譬如在计算中取 5 位小数, 第 6 位以后的小数都用四舍五人的方法舍去, 则 $\\pi=3.141592654 \\ldots$和 $\\mathrm{e}=2.718281828 \\ldots$ 的近似数为 $\\pi^{\\prime}=3.14159$ 和 $\\mathrm{e}^{\\prime}=2.71828$.  \n现在如果要求 $n$ 个实数 $x_{i}(i=1,2, \\cdots, n)$ 的和 $S$, 在数值计算中, 只能用 $x_{i}$ 的近似数 $x_{i}^{\\prime}$ 来得到 $S$ 的近似数 $S^{\\prime}$, 记个别误差为 $\\varepsilon_{i}=x_{i}-x_{i}^{\\prime}$, 则总误差为  \n$$",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.2 独立同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "从这个例子可以看出, 由 12 个均匀分布的随机数得到 1 个正态分布的随机数是利用了林德贝格-勒维中心极限定理.  \n例 4.4.4 数值计算中的误差分析: 在数值计算中, 任何实数 $x$ 都只能用一定位数的小数 $x^{\\prime}$ 来近似.譬如在计算中取 5 位小数, 第 6 位以后的小数都用四舍五人的方法舍去, 则 $\\pi=3.141592654 \\ldots$和 $\\mathrm{e}=2.718281828 \\ldots$ 的近似数为 $\\pi^{\\prime}=3.14159$ 和 $\\mathrm{e}^{\\prime}=2.71828$.  \n现在如果要求 $n$ 个实数 $x_{i}(i=1,2, \\cdots, n)$ 的和 $S$, 在数值计算中, 只能用 $x_{i}$ 的近似数 $x_{i}^{\\prime}$ 来得到 $S$ 的近似数 $S^{\\prime}$, 记个别误差为 $\\varepsilon_{i}=x_{i}-x_{i}^{\\prime}$, 则总误差为  \n$$\nS-S^{\\prime}=\\sum_{i=1}^{n} x_{i}-\\sum_{i=1}^{n} x_{i}^{\\prime}=\\sum_{i=1}^{n} \\varepsilon_{i}\n$$  \n若在数值计算中, 取 $k$ 位小数, 则可认为 $\\varepsilon_{i}$ 服从区间 $\\left(-0.5 \\times 10^{-k}, 0.5 \\times 10^{-k}\\right)$ 上的均匀分布,且相互独立. 下面我们来估计总误差.一种粗略的估计方法是: 由于 $\\left|\\varepsilon_{i}\\right| \\leqslant 0.5 \\times 10^{-k}$, 所以  \n$$\n\\begin{equation*}\n\\left|\\sum_{i=1}^{n} \\varepsilon_{i}\\right| \\leqslant n \\times 0.5 \\times 10^{-k} \\tag{4.4.2}\n\\end{equation*}\n$$  \n现在用中心极限定理来估计: 因为 $\\left\\{\\varepsilon_{i}\\right\\}$ 独立同分布, 且  \n因此对总误差有  \n$$",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.2 独立同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n若在数值计算中, 取 $k$ 位小数, 则可认为 $\\varepsilon_{i}$ 服从区间 $\\left(-0.5 \\times 10^{-k}, 0.5 \\times 10^{-k}\\right)$ 上的均匀分布,且相互独立. 下面我们来估计总误差.一种粗略的估计方法是: 由于 $\\left|\\varepsilon_{i}\\right| \\leqslant 0.5 \\times 10^{-k}$, 所以  \n$$\n\\begin{equation*}\n\\left|\\sum_{i=1}^{n} \\varepsilon_{i}\\right| \\leqslant n \\times 0.5 \\times 10^{-k} \\tag{4.4.2}\n\\end{equation*}\n$$  \n现在用中心极限定理来估计: 因为 $\\left\\{\\varepsilon_{i}\\right\\}$ 独立同分布, 且  \n因此对总误差有  \n$$\nE\\left(\\varepsilon_{i}\\right)=0, \\quad \\operatorname{Var}\\left(\\varepsilon_{i}\\right)=\\frac{10^{-2 k}}{12}\n$$  \n$$\nE\\left(\\sum_{i=1}^{n} \\varepsilon_{i}\\right)=0, \\quad \\operatorname{Var}\\left(\\sum_{i=1}^{n} \\varepsilon_{i}\\right)=\\frac{n 10^{-2 k}}{12}\n$$  \n由林德贝格-勒维中心极限定理知, 对任意的 $x$, 有  \n$$\n\\begin{aligned}\nP\\left(\\left|\\sum_{i=1}^{n} \\varepsilon_{i}\\right| \\leqslant z\\right) & \\approx \\Phi\\left(\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}\\right)-\\Phi\\left(-\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}\\right) \\\\\n& =2 \\Phi\\left(\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}\\right)-1",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.2 独立同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n$$\nE\\left(\\sum_{i=1}^{n} \\varepsilon_{i}\\right)=0, \\quad \\operatorname{Var}\\left(\\sum_{i=1}^{n} \\varepsilon_{i}\\right)=\\frac{n 10^{-2 k}}{12}\n$$  \n由林德贝格-勒维中心极限定理知, 对任意的 $x$, 有  \n$$\n\\begin{aligned}\nP\\left(\\left|\\sum_{i=1}^{n} \\varepsilon_{i}\\right| \\leqslant z\\right) & \\approx \\Phi\\left(\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}\\right)-\\Phi\\left(-\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}\\right) \\\\\n& =2 \\Phi\\left(\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}\\right)-1\n\\end{aligned}\n$$  \n要从上式中求出总误差的上限 $z$, 可令上式右边的概率为 0.99 , 由此得  \n$$\n\\Phi\\left(\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}\\right)=0.995\n$$  \n再查标准正态分布函数的 0.995 分位数得  \n由此解得  \n$$\n\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}=2.575\n$$  \n$$\n\\begin{aligned}\nz & =\\frac{2.575 \\sqrt{n \\times 10^{-2 k}}}{\\sqrt{12}}=0.7433 \\times \\sqrt{n \\times 10^{-2 k}} \\\\\n& =0.7433 \\times \\sqrt{n} \\times 10^{-k}\n\\end{aligned}\n$$  \n也就是我们有 $99 \\%$ 的把握程度, 可以说  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.2 独立同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n要从上式中求出总误差的上限 $z$, 可令上式右边的概率为 0.99 , 由此得  \n$$\n\\Phi\\left(\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}\\right)=0.995\n$$  \n再查标准正态分布函数的 0.995 分位数得  \n由此解得  \n$$\n\\frac{z \\sqrt{12}}{\\sqrt{n 10^{-2 k}}}=2.575\n$$  \n$$\n\\begin{aligned}\nz & =\\frac{2.575 \\sqrt{n \\times 10^{-2 k}}}{\\sqrt{12}}=0.7433 \\times \\sqrt{n \\times 10^{-2 k}} \\\\\n& =0.7433 \\times \\sqrt{n} \\times 10^{-k}\n\\end{aligned}\n$$  \n也就是我们有 $99 \\%$ 的把握程度, 可以说  \n$$\n\\begin{equation*}\n\\left|\\sum_{i=1}^{n} \\varepsilon_{i}\\right| \\leqslant 0.7433 \\times \\sqrt{n} \\times 10^{-k} \\tag{4.4.3}\n\\end{equation*}\n$$  \n譬如在数值计算中保留 5 位小数, 以概率 0.99 可以保证, 10000 个近似数之和的总误差, 用 (4.4.3) 式估计为 0.0007433 , 即万分之七左右.  \n从上例可以看出, 利用中心极限定理不但可以求概率, 还可以求随机变量和的上限 $z$.",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.2 独立同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "由林德贝格-勒维中心极限定理, 马上就可以得到下面的棣莫弗-拉普拉斯极限定理.  \n定理 4.4.2 (棣莫弗-拉普拉斯极限定理). 设 $n$ 重伯努利试验中, 事件 $A$ 在每次试验中出现的概率为 $p(0<p<1)$. 记 $\\mu_{n}$ 为 $n$ 次试验中事件 $A$ 出现的次数, 且记  \n则对任意实数 $y$, 有  \n$$\nT_{n}^{*}=\\frac{\\mu_{n}-n p}{\\sqrt{n p q}}\n$$  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left(Y_{n}^{*} \\leqslant y\\right)=\\Phi(y)=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{y} \\mathrm{e}^{-t^{2} / 2} .\n$$  \n棣莫弗-拉普拉斯极限定理是概率论历史上的第一个中心极限定理, 它是专门针对二项分布的, 因此称为 “二项分布的正态近似”. 前面第二章中定理 2.4.1 (泊松定理) 给出了 “二项分布的泊松近似”. 两者相比,一般在 $p$ 较小时, 用泊松分布近似较好; 而在 $n p>5$ 和 $n(1-p)>5$ 时, 用正态分布近似较好.  \n下面在给出棣莫弗-拉普拉斯极限定理定理的应用之前, 先说明两点:  \n1. 因为二项分布是离散分布, 而正态分布是连续分布, 所以用正态分布作为二项分布的近似计算中, 作些修正可以提高精度. 若 $k_{1}<k_{2}$ 均为整数, 一般先作如下修正后再用正态近似  \n!  \n图 4.4.2: 二项分布正态近似时的修正  \n$P\\left(k_{1} \\leqslant \\mu_{n} \\leqslant k_{2}\\right)=P\\left(k_{1}-0.6<\\mu_{n}<k_{2}+0.5\\right)$.  \n譬如 $\\mu_{n} \\sim b(25,0.4), P\\left(5 \\leqslant \\mu_{n} \\leqslant 15\\right)$ 的值为图 4.4.2 中长条矩形的面积, 其精确值为 0.9780 .  \n使用修正的正态近似  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.3 二项分布的正态近似"
        },
        "type": "Document"
    },
    {
        "page_content": "下面在给出棣莫弗-拉普拉斯极限定理定理的应用之前, 先说明两点:  \n1. 因为二项分布是离散分布, 而正态分布是连续分布, 所以用正态分布作为二项分布的近似计算中, 作些修正可以提高精度. 若 $k_{1}<k_{2}$ 均为整数, 一般先作如下修正后再用正态近似  \n!  \n图 4.4.2: 二项分布正态近似时的修正  \n$P\\left(k_{1} \\leqslant \\mu_{n} \\leqslant k_{2}\\right)=P\\left(k_{1}-0.6<\\mu_{n}<k_{2}+0.5\\right)$.  \n譬如 $\\mu_{n} \\sim b(25,0.4), P\\left(5 \\leqslant \\mu_{n} \\leqslant 15\\right)$ 的值为图 4.4.2 中长条矩形的面积, 其精确值为 0.9780 .  \n使用修正的正态近似  \n$$\n\\begin{aligned}\nP\\left(5 \\leqslant \\mu_{n} \\leqslant 15\\right) & =P\\left(5-0.5<\\mu_{n}<15+0.5\\right) \\\\\n& \\sim \\Phi\\left(\\frac{15+0.5-10}{\\sqrt{6}}\\right)-\\Phi\\left(\\frac{5-0.5-10}{\\sqrt{6}}\\right) \\\\\n& =2 \\Phi(2.245)-1=0.9754 .\n\\end{aligned}\n$$  \n不用修正的正态近似  \n$$\n\\begin{aligned}\nP\\left(5 \\leqslant \\mu_{n} \\leqslant 15\\right) & \\sim \\Phi\\left(\\frac{15-10}{\\sqrt{6}}\\right)-\\Phi(\\operatorname{frac} 5-10 \\sqrt{6}) \\\\\n& =2 \\Phi(2.041)-1=0.9588 .\n\\end{aligned}\n$$  \n可见不用修正的正态近似误差较大.  \n2. 若记 $\\beta=\\Phi(y)$, 则由棣莫弗-拉普拉斯极限定理给出的近似式  \n$$\nP\\left(Y_{n}^{*} \\leqslant y\\right) \\sim \\Phi(y)=\\beta\n$$  \n可用来解决三类计算问题:",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.3 二项分布的正态近似"
        },
        "type": "Document"
    },
    {
        "page_content": "& =2 \\Phi(2.245)-1=0.9754 .\n\\end{aligned}\n$$  \n不用修正的正态近似  \n$$\n\\begin{aligned}\nP\\left(5 \\leqslant \\mu_{n} \\leqslant 15\\right) & \\sim \\Phi\\left(\\frac{15-10}{\\sqrt{6}}\\right)-\\Phi(\\operatorname{frac} 5-10 \\sqrt{6}) \\\\\n& =2 \\Phi(2.041)-1=0.9588 .\n\\end{aligned}\n$$  \n可见不用修正的正态近似误差较大.  \n2. 若记 $\\beta=\\Phi(y)$, 则由棣莫弗-拉普拉斯极限定理给出的近似式  \n$$\nP\\left(Y_{n}^{*} \\leqslant y\\right) \\sim \\Phi(y)=\\beta\n$$  \n可用来解决三类计算问题:  \n(1) 已知 $n, y$ 求 $\\beta$,  \n(2) 已知 $n, \\beta$ 求 $y$,  \n(3) 已知 $y, \\beta$ 求 $n$,  \n以下我们就分这三类情况给出一些具体的例子.",
        "metadata": {
            "Header 2": "4.4 中心极限定理",
            "Header 3": "4.4.3 二项分布的正态近似"
        },
        "type": "Document"
    },
    {
        "page_content": "例 4.4.5: 一复杂系统由 100 个相互独立工作的部件组成, 每个部件正常工作的概率为 0.9. 已知整个系统中至少有 85 个部件正常工作, 系统工作才正常. 试求系统正常工作的概率.  \n解: 记 $n=100, Y_{n}$ 为 100 个部件中正常工作的部件数, 则  \n$$\nY_{n} \\sim b(100,0.9), E\\left(Y_{n}\\right)=90, \\operatorname{Var}\\left(Y_{n}\\right)=9\n$$  \n所求概率为  \n$$\n\\begin{aligned}\nP\\left(Y_{n} \\geqslant 85\\right) & \\sim 1-\\Phi\\left(\\frac{85-0.5-90}{3}\\right) \\\\\n& =1-\\Phi\\left(-\\frac{5.5}{3}\\right)=\\Phi(1.83)=0.966 .\n\\end{aligned}\n$$  \n例 4.4.6: 某药厂生产的某种药品, 声称对某疾病的治愈率为 $80 \\%$. 现为了检验此治愈率, 住意抽\n取 100 个此种病患者进行临床试验, 如果有多于 75 人治愈, 则此药通过检验. 试在以下两种情况下, 分别计算此药通过检验的可能性.  \n1. 此药的实际治愈率为 $80 \\%$,\n2. 此药的实际治愈率为 $70 \\%$  \n解: 记 $n=100, Y_{n}$ 为 100 个临床受试者中的治愈者人数.  \n1. 因为 $Y_{n} \\sim b(100,0.8), E\\left(Y_{n}\\right)=80, \\operatorname{Var}\\left(Y_{n}\\right)=16$. 所以通过检验的可能性为  \n$$\n\\begin{aligned}\nP\\left(Y_{n}>75\\right) & \\sim 1-\\Phi\\left(\\frac{75-0.5-80}{4}\\right) \\\\\n& =1-\\Phi\\left(-\\frac{5.5}{4}\\right)=\\Phi(1.375)=0.9155 .\n\\end{aligned}\n$$  \n即此药通过检验的可能性是较大的.",
        "metadata": {
            "Header 2": "一、给定 $n, y$ 求 $\\beta$"
        },
        "type": "Document"
    },
    {
        "page_content": "取 100 个此种病患者进行临床试验, 如果有多于 75 人治愈, 则此药通过检验. 试在以下两种情况下, 分别计算此药通过检验的可能性.  \n1. 此药的实际治愈率为 $80 \\%$,\n2. 此药的实际治愈率为 $70 \\%$  \n解: 记 $n=100, Y_{n}$ 为 100 个临床受试者中的治愈者人数.  \n1. 因为 $Y_{n} \\sim b(100,0.8), E\\left(Y_{n}\\right)=80, \\operatorname{Var}\\left(Y_{n}\\right)=16$. 所以通过检验的可能性为  \n$$\n\\begin{aligned}\nP\\left(Y_{n}>75\\right) & \\sim 1-\\Phi\\left(\\frac{75-0.5-80}{4}\\right) \\\\\n& =1-\\Phi\\left(-\\frac{5.5}{4}\\right)=\\Phi(1.375)=0.9155 .\n\\end{aligned}\n$$  \n即此药通过检验的可能性是较大的.  \n2. 因为 $Y_{n} \\sim b(100,0.7), E\\left(Y_{n}\\right)=70, \\operatorname{Var}\\left(Y_{n}\\right)=21$. 所以通过检验的可能性为  \n$$\n\\begin{aligned}\nP\\left(Y_{n}>75\\right) & \\sim 1-\\Phi\\left(\\frac{75-0.5-70}{\\sqrt{21}}\\right) \\\\\n& =1-\\Phi(0.982)=1-0.8370=0.1630\n\\end{aligned}\n$$  \n即此药通过检验的可能性是很小的.  \n二、给定 $n, \\beta$ 求 $y$  \n例 4.4.7: 某车间有同型号的机床 200 台, 在一小时内每台机床约有 $70 \\%$ 的时间是工作的. 假定各机床工作是相互独立的, 工作时每台机床要消耗电能 $15 \\mathrm{~kW}$. 问至少要多少电能, 才可以有 $95 \\%$ 的可能性保证此车间正常生产.",
        "metadata": {
            "Header 2": "一、给定 $n, y$ 求 $\\beta$"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n即此药通过检验的可能性是较大的.  \n2. 因为 $Y_{n} \\sim b(100,0.7), E\\left(Y_{n}\\right)=70, \\operatorname{Var}\\left(Y_{n}\\right)=21$. 所以通过检验的可能性为  \n$$\n\\begin{aligned}\nP\\left(Y_{n}>75\\right) & \\sim 1-\\Phi\\left(\\frac{75-0.5-70}{\\sqrt{21}}\\right) \\\\\n& =1-\\Phi(0.982)=1-0.8370=0.1630\n\\end{aligned}\n$$  \n即此药通过检验的可能性是很小的.  \n二、给定 $n, \\beta$ 求 $y$  \n例 4.4.7: 某车间有同型号的机床 200 台, 在一小时内每台机床约有 $70 \\%$ 的时间是工作的. 假定各机床工作是相互独立的, 工作时每台机床要消耗电能 $15 \\mathrm{~kW}$. 问至少要多少电能, 才可以有 $95 \\%$ 的可能性保证此车间正常生产.  \n解: 记 $n=200, Y_{n}$ 为 200 台机床中同时工作的机床数, 则 $Y_{n} \\sim b(200,0.7), E\\left(Y_{n}\\right)=140$, $\\operatorname{Var}\\left(Y_{n}\\right)=42$.  \n因为 $Y_{n}$ 台机床同时工作需消耗 $15 Y_{n}(\\mathrm{~kW})$ 电能, 所以设供电数为 $y(\\mathrm{~kW})$, 则正常生产为 $\\left\\{15 Y_{n} \\leqslant y\\right\\}$, 由题设 $P\\left(15 Y_{n} \\leqslant y\\right) \\geqslant 0.95$, 其中  \n$$\nP\\left(15 Y_{n} \\leqslant y\\right) \\approx \\Phi\\left(\\frac{y / 15+0.5-140}{\\sqrt{42}}\\right) \\geqslant 0.95 .\n$$  \n查正态分布表得  \n$$\n\\frac{y / 15+0.5-140}{\\sqrt{42}} \\geqslant 1.645\n$$",
        "metadata": {
            "Header 2": "一、给定 $n, y$ 求 $\\beta$"
        },
        "type": "Document"
    },
    {
        "page_content": "因为 $Y_{n}$ 台机床同时工作需消耗 $15 Y_{n}(\\mathrm{~kW})$ 电能, 所以设供电数为 $y(\\mathrm{~kW})$, 则正常生产为 $\\left\\{15 Y_{n} \\leqslant y\\right\\}$, 由题设 $P\\left(15 Y_{n} \\leqslant y\\right) \\geqslant 0.95$, 其中  \n$$\nP\\left(15 Y_{n} \\leqslant y\\right) \\approx \\Phi\\left(\\frac{y / 15+0.5-140}{\\sqrt{42}}\\right) \\geqslant 0.95 .\n$$  \n查正态分布表得  \n$$\n\\frac{y / 15+0.5-140}{\\sqrt{42}} \\geqslant 1.645\n$$  \n从中解得 $y \\geqslant 2252(\\mathrm{~kW})$, 即此车间每小时至少需要 $2252(\\mathrm{~kW})$ 电能, 才有 $95 \\%$ 的可能性保证此车间正常生产.",
        "metadata": {
            "Header 2": "一、给定 $n, y$ 求 $\\beta$"
        },
        "type": "Document"
    },
    {
        "page_content": "例 4.4.8: 某调查公司受委托, 调查某电视节目在 $\\mathrm{S}$ 市的收视率 $p$, 调查公司将所有调查对象中收看此节目的额率作为 $p$ 的估计 $\\hat{p}$. 现在要保证有 $90 \\%$ 的把握, 使得调查所得收视率 $\\hat{p}$ 与真实收视率 $p$ 之间的差异不大于 $5 \\%$. 问至少要调查多少对象?  \n解: 设共调查 $n$ 个对象, 记  \n$$\nX_{i}= \\begin{cases}1, & \\text { 第 } i \\text { 个调查对象收看此电视节目, } \\\\ 0, & \\text { 第 } i \\text { 个调查对象不看此电视节目, }\\end{cases}\n$$  \n则 $X_{i}$ 独立同分布, 且 $P\\left(X_{i}=1\\right)=p, P\\left(X_{i}=0\\right)=1-p, i=1,2, \\cdots, n$. 又记 $n$ 个被调查对象中, 收看此电视节目的人数为 $Y_{n}$, 则有  \n$$\nY_{n}=\\sum_{i=1}^{n} X_{i} \\sim b(n, p)\n$$  \n由大数定律知, 当 $n$ 很大时, 频率 $Y_{n} / n$ 与概率 $p$ 很接近, 即用频率作为 $p$ 的估计是合适的. 根据题意有  \n$$\nP\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} X_{i}-p\\right|<0.05\\right) \\approx 2 \\Phi\\left(0.05 \\sqrt{\\frac{n}{p(1-p)}}\\right)-1 \\geqslant 0.90\n$$  \n所以  \n$$\n\\Phi\\left(0.05 \\sqrt{\\frac{n}{p(1-p)}}\\right) \\geqslant 0.95\n$$  \n查正态分布表得  \n$$\n0.05 \\sqrt{\\frac{n}{p(1-p)}} \\geqslant 1.645 \\text {. }\n$$  \n从中解得  \n$$\nn \\geqslant p(1-p) \\frac{1.645^{2}}{0.05^{2}}=p(1-p) \\times 1082.41 .\n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由大数定律知, 当 $n$ 很大时, 频率 $Y_{n} / n$ 与概率 $p$ 很接近, 即用频率作为 $p$ 的估计是合适的. 根据题意有  \n$$\nP\\left(\\left|\\frac{1}{n} \\sum_{i=1}^{n} X_{i}-p\\right|<0.05\\right) \\approx 2 \\Phi\\left(0.05 \\sqrt{\\frac{n}{p(1-p)}}\\right)-1 \\geqslant 0.90\n$$  \n所以  \n$$\n\\Phi\\left(0.05 \\sqrt{\\frac{n}{p(1-p)}}\\right) \\geqslant 0.95\n$$  \n查正态分布表得  \n$$\n0.05 \\sqrt{\\frac{n}{p(1-p)}} \\geqslant 1.645 \\text {. }\n$$  \n从中解得  \n$$\nn \\geqslant p(1-p) \\frac{1.645^{2}}{0.05^{2}}=p(1-p) \\times 1082.41 .\n$$  \n又因为 $p(1-p) \\leqslant 0.25$, 所以 $n \\geqslant 270.6$, 即至少调查 271 个对象.",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$"
        },
        "type": "Document"
    },
    {
        "page_content": "前面我们已经在独立同分布的条件下, 解决了随机变量和的极限分布问题. 在实际问题中说诸 $X_{i}$ 具有独立性是常见的, 但是很难说诸 $X_{i}$ 是 “同分布” 的随机变量. 正如前面所提到的测量误差 $Y_{n}$ 的产生是由大量 “微小的” 相互独立的随机因素叠加而成的, 即 $Y_{n}=\\sum_{i=1}^{n} X_{i}$, 则诸 $X_{i}$ 间具有独立性, 但不一定同分布. 本节研究独立不同分布随机变量和的极限分布问题, 目的是给出极限分布为正态分布的条件.  \n为使极限分布是正态分布, 必须对 $Y_{n}=\\sum i=1^{n} X_{i}$ 的各项有一定的要求. 譬如若允许从第二项起都等于 0 , 则极限分布显然出 $X_{1}$ 的分布完全确定, 这时就很难得到什么有意思的结果. 这就告诉我们, 要使中心极限定理成立, 在和的各项中不应有起突出作用的项, 或者说, 要求各项在概率意义下 “均匀地小”.下面我们来分析如何从数学式子上明确表达这个要求.  \n设 $\\left\\{X_{n}\\right\\}$ 是一个相互独立的随机变量序列, 它们具有有限的数学期望和方差:  \n$$\nE\\left(X_{i}\\right) \\mu_{i}, \\operatorname{Var}\\left(X_{i}\\right)=\\sigma_{i}^{2}, i=1,2, \\cdots\n$$  \n要讨论随机变量的和 $Y_{n}=\\sum i=1^{n} X_{i}$, 我们先将其标准化, 即将它减去均值、除以标准差, 由于  \n$$\n\\begin{aligned}\n& E\\left(Y_{n}\\right)=\\mu_{1}+\\mu_{2}+\\cdots+\\mu_{n} \\\\\n& \\sigma\\left(T_{n}\\right)=\\sqrt{\\operatorname{Var}\\left(X_{i}\\right)}=\\sqrt{\\sigma_{1}^{2}+\\sigma_{2}^{2}+\\cdots+\\sigma_{n}^{2}}\n\\end{aligned}\n$$  \n且记 $\\sigma\\left(Y_{n}\\right)=B$, 则 $Y_{n}$ 的标准化为  \n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nE\\left(X_{i}\\right) \\mu_{i}, \\operatorname{Var}\\left(X_{i}\\right)=\\sigma_{i}^{2}, i=1,2, \\cdots\n$$  \n要讨论随机变量的和 $Y_{n}=\\sum i=1^{n} X_{i}$, 我们先将其标准化, 即将它减去均值、除以标准差, 由于  \n$$\n\\begin{aligned}\n& E\\left(Y_{n}\\right)=\\mu_{1}+\\mu_{2}+\\cdots+\\mu_{n} \\\\\n& \\sigma\\left(T_{n}\\right)=\\sqrt{\\operatorname{Var}\\left(X_{i}\\right)}=\\sqrt{\\sigma_{1}^{2}+\\sigma_{2}^{2}+\\cdots+\\sigma_{n}^{2}}\n\\end{aligned}\n$$  \n且记 $\\sigma\\left(Y_{n}\\right)=B$, 则 $Y_{n}$ 的标准化为  \n$$\nY_{n}^{*}=\\frac{Y_{n}-\\left(\\mu_{1}+\\mu_{2}+\\cdots+\\mu_{n}\\right)}{B_{n}}=\\sum_{i=1}^{n} \\frac{X_{i}-\\mu_{i}}{B_{n}} .\n$$  \n如果要求 $Y_{n}^{*}$ 中各项 $\\left(X_{i}-\\mu_{i}\\right) / B_{n}$ “均匀地小”, 即对任意的 $\\tau>0$, 要求事件  \n$$\nA_{k}=\\left\\{\\frac{\\left|X_{i}-\\mu_{i}\\right|}{B_{n}}>\\tau\\right\\}=\\left\\{\\left|X_{i}-\\mu_{i}\\right|>\\tau B_{n}\\right\\}\n$$  \n发生的可能性小, 或直接要求其概率趋于 0 . 为达到这个目的, 我们要求  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left\\{\\max _{1 \\leqslant i \\leqslant n}\\left|X_{i}-\\mu_{i}\\right|>\\tau B_{n}\\right\\}=0\n$$  \n因为  \n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n如果要求 $Y_{n}^{*}$ 中各项 $\\left(X_{i}-\\mu_{i}\\right) / B_{n}$ “均匀地小”, 即对任意的 $\\tau>0$, 要求事件  \n$$\nA_{k}=\\left\\{\\frac{\\left|X_{i}-\\mu_{i}\\right|}{B_{n}}>\\tau\\right\\}=\\left\\{\\left|X_{i}-\\mu_{i}\\right|>\\tau B_{n}\\right\\}\n$$  \n发生的可能性小, 或直接要求其概率趋于 0 . 为达到这个目的, 我们要求  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left\\{\\max _{1 \\leqslant i \\leqslant n}\\left|X_{i}-\\mu_{i}\\right|>\\tau B_{n}\\right\\}=0\n$$  \n因为  \n$$\nP\\left\\{\\max _{1 \\leqslant i \\leqslant n}\\left|X_{i}-\\mu_{i}\\right|>\\tau B_{n}\\right\\}=P\\left\\{\\cup_{i=1}^{n}\\left(\\left|X_{i}-\\mu_{i}\\right|>\\tau B_{n}\\right)\\right\\}\n$$  \n$$\n\\leqslant \\sum_{i=1}^{n} P\\left(\\left|X_{i}-\\mu_{i}\\right|>\\tau B_{n}\\right)\n$$  \n若设诸 $X_{i}$ 为连续随机变量, 其密度函数为 $p_{i}(x)$, 则  \n$$\n\\begin{aligned}\n\\text { 上式 } & =\\sum_{i=1}^{n} \\int_{\\left|x-\\mu_{i}\\right|>\\tau B_{n}} p_{i}(x) \\mathrm{d} x \\\\\n& \\leqslant \\frac{1}{\\tau^{2} B_{n}^{2}} \\sum_{i=1}^{n} \\int_{\\left|x-\\mu_{i}\\right|>\\tau B_{n}}\\left(x-\\mu_{i}\\right)^{2} p_{i}(x) \\mathrm{d} x .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n$$\n\\leqslant \\sum_{i=1}^{n} P\\left(\\left|X_{i}-\\mu_{i}\\right|>\\tau B_{n}\\right)\n$$  \n若设诸 $X_{i}$ 为连续随机变量, 其密度函数为 $p_{i}(x)$, 则  \n$$\n\\begin{aligned}\n\\text { 上式 } & =\\sum_{i=1}^{n} \\int_{\\left|x-\\mu_{i}\\right|>\\tau B_{n}} p_{i}(x) \\mathrm{d} x \\\\\n& \\leqslant \\frac{1}{\\tau^{2} B_{n}^{2}} \\sum_{i=1}^{n} \\int_{\\left|x-\\mu_{i}\\right|>\\tau B_{n}}\\left(x-\\mu_{i}\\right)^{2} p_{i}(x) \\mathrm{d} x .\n\\end{aligned}\n$$  \n因此, 只要对任意的 $\\tau>0$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} \\frac{1}{\\tau^{2} B_{n}^{2}} \\sum_{i=1}^{n} \\int_{\\left|x-\\mu_{i}\\right|>\\tau B_{n}}\\left(x-\\mu_{i}\\right)^{2} p_{i}(x) \\mathrm{d} x=0 \\tag{4.4.4}\n\\end{equation*}\n$$  \n就可保证 $Y_{n}^{*}$ 中各加项 “均匀地小”.  \n上述条件 (4.4.4) 称为林德贝格条件. 林德贝格证明了满足 (4.4.4) 条件的和 $Y_{n}$ 的极限分布是正态分布, 这就是下面的给出的林德贝格中心极限定理, 由于这个定理的证明需要更多的数学工具, 所以以下仅叙述定理,略去其证明.  \n定理 4.4 .3 (林德贝格中心极限定理). 设独立随机变量序列 $\\left\\{X_{n}\\right\\}$ 满足林德贝格条件, 则对任意的 $\\mathrm{x}$,有  \n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n因此, 只要对任意的 $\\tau>0$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} \\frac{1}{\\tau^{2} B_{n}^{2}} \\sum_{i=1}^{n} \\int_{\\left|x-\\mu_{i}\\right|>\\tau B_{n}}\\left(x-\\mu_{i}\\right)^{2} p_{i}(x) \\mathrm{d} x=0 \\tag{4.4.4}\n\\end{equation*}\n$$  \n就可保证 $Y_{n}^{*}$ 中各加项 “均匀地小”.  \n上述条件 (4.4.4) 称为林德贝格条件. 林德贝格证明了满足 (4.4.4) 条件的和 $Y_{n}$ 的极限分布是正态分布, 这就是下面的给出的林德贝格中心极限定理, 由于这个定理的证明需要更多的数学工具, 所以以下仅叙述定理,略去其证明.  \n定理 4.4 .3 (林德贝格中心极限定理). 设独立随机变量序列 $\\left\\{X_{n}\\right\\}$ 满足林德贝格条件, 则对任意的 $\\mathrm{x}$,有  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left\\{\\frac{1}{B_{n}} \\sum_{i=1}^{n}\\left(X_{i}-\\mu_{i}\\right) \\leqslant x\\right\\}=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} \\mathrm{e}^{-t^{2} / 2} \\mathrm{~d} t\n$$  \n假如独立随机变量序列 $\\left\\{X_{n}\\right\\}$ 具有同分布和方差有限的条件, 则必定满足以上 (4.4.4) 林德贝格条件, 也就是说定理 4.4.1 是定理 4.4.3 的特例. 这一点是很容易证明的:  \n设 $\\left\\{X_{n}\\right\\}$ 是独立同分布随机变量序列, 为确定起见, 设诸 $X_{n}$ 是连续随机变量, 其共同的密度函数为 $p(x), \\mu_{i}=\\mu, \\sigma_{i}=\\sigma$. 这时 $B_{n}=\\sigma \\sqrt{\\mu}$, 由此得  \n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\lim _{n \\rightarrow+\\infty} P\\left\\{\\frac{1}{B_{n}} \\sum_{i=1}^{n}\\left(X_{i}-\\mu_{i}\\right) \\leqslant x\\right\\}=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} \\mathrm{e}^{-t^{2} / 2} \\mathrm{~d} t\n$$  \n假如独立随机变量序列 $\\left\\{X_{n}\\right\\}$ 具有同分布和方差有限的条件, 则必定满足以上 (4.4.4) 林德贝格条件, 也就是说定理 4.4.1 是定理 4.4.3 的特例. 这一点是很容易证明的:  \n设 $\\left\\{X_{n}\\right\\}$ 是独立同分布随机变量序列, 为确定起见, 设诸 $X_{n}$ 是连续随机变量, 其共同的密度函数为 $p(x), \\mu_{i}=\\mu, \\sigma_{i}=\\sigma$. 这时 $B_{n}=\\sigma \\sqrt{\\mu}$, 由此得  \n$$\n\\frac{1}{B_{n}^{2}} \\sum_{i=1}^{n} \\int_{\\left|x-\\mu_{i}\\right|>\\tau B_{n}}\\left(x-\\mu_{i}\\right)^{2} p(x) \\mathrm{d} x=\\frac{n}{n \\sigma^{2}} \\int_{|x-\\mu|>\\tau \\sigma \\sqrt{n}}(x-\\mu)^{2} p(x) \\mathrm{d} x .\n$$  \n因为方差存在, 即  \n$$\n\\operatorname{Var}\\left(X_{i}\\right)=\\int_{-\\infty}^{+\\infty}(x-\\mu)^{2} p(x) \\mathrm{d} x<+\\infty\n$$  \n所以其尾部积分一定有  \n$$\n\\lim _{n \\rightarrow+\\infty} \\int_{|x-\\mu|>\\tau \\sigma \\sqrt{n}}(x-\\mu)^{2} p(x) \\mathrm{d} x=0,\n$$  \n故林德贝格条件满足.",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\frac{1}{B_{n}^{2}} \\sum_{i=1}^{n} \\int_{\\left|x-\\mu_{i}\\right|>\\tau B_{n}}\\left(x-\\mu_{i}\\right)^{2} p(x) \\mathrm{d} x=\\frac{n}{n \\sigma^{2}} \\int_{|x-\\mu|>\\tau \\sigma \\sqrt{n}}(x-\\mu)^{2} p(x) \\mathrm{d} x .\n$$  \n因为方差存在, 即  \n$$\n\\operatorname{Var}\\left(X_{i}\\right)=\\int_{-\\infty}^{+\\infty}(x-\\mu)^{2} p(x) \\mathrm{d} x<+\\infty\n$$  \n所以其尾部积分一定有  \n$$\n\\lim _{n \\rightarrow+\\infty} \\int_{|x-\\mu|>\\tau \\sigma \\sqrt{n}}(x-\\mu)^{2} p(x) \\mathrm{d} x=0,\n$$  \n故林德贝格条件满足.  \n林德贝格条件虽然比较一般, 但该条件较难验证, 下面的李雅普诺夫条件则比较容易验证, 因为它只对矩提出要求, 因而便于应用. 下面我们仅叙述其结论, 证明从略.  \n定理 4.4 .4 (李雅普诺夫中心极限定理). 设 $\\left\\{X_{n}\\right\\}$ 为独立随机变量序列, 若存在 $\\delta>0$, 满足  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} \\frac{1}{B_{n}^{2+\\delta}} \\sum_{i=1}^{n} E\\left(\\left|X_{i}-\\mu\\right|^{2+\\delta}\\right)=0 \\tag{4.4.5}\n\\end{equation*}\n$$  \n则对任意的 $x$, 有  \n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n所以其尾部积分一定有  \n$$\n\\lim _{n \\rightarrow+\\infty} \\int_{|x-\\mu|>\\tau \\sigma \\sqrt{n}}(x-\\mu)^{2} p(x) \\mathrm{d} x=0,\n$$  \n故林德贝格条件满足.  \n林德贝格条件虽然比较一般, 但该条件较难验证, 下面的李雅普诺夫条件则比较容易验证, 因为它只对矩提出要求, 因而便于应用. 下面我们仅叙述其结论, 证明从略.  \n定理 4.4 .4 (李雅普诺夫中心极限定理). 设 $\\left\\{X_{n}\\right\\}$ 为独立随机变量序列, 若存在 $\\delta>0$, 满足  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} \\frac{1}{B_{n}^{2+\\delta}} \\sum_{i=1}^{n} E\\left(\\left|X_{i}-\\mu\\right|^{2+\\delta}\\right)=0 \\tag{4.4.5}\n\\end{equation*}\n$$  \n则对任意的 $x$, 有  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left\\{\\frac{1}{B_{n}} \\sum_{i=1}^{n}\\left(X_{i}-\\mu_{i}\\right) \\leqslant x\\right\\}=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} \\mathrm{e}^{-t^{2} / 2} \\mathrm{~d} t\n$$  \n其中 $\\mu_{i}$ 与 $B_{n}$ 如前所述.  \n例 4.4.9: 一份考卷由 99 个题目组成, 并按由易到难顺序排列, 某学生答对第 1 题的概率为 0.99;答对第 2 题的概率为 0.98 ; 一般地, 他答对第 $i$ 题的概率为 $1-i / 100, i=1,2, \\cdots$. 假如该学生回\n答各题目是相互独立的, 并且要正确回答其中 60 个题日以上 (包括 60 个) 才算通过考试. 试计算该学生通过考试的可能性多大?  \n解: 设  \n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n则对任意的 $x$, 有  \n$$\n\\lim _{n \\rightarrow+\\infty} P\\left\\{\\frac{1}{B_{n}} \\sum_{i=1}^{n}\\left(X_{i}-\\mu_{i}\\right) \\leqslant x\\right\\}=\\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{x} \\mathrm{e}^{-t^{2} / 2} \\mathrm{~d} t\n$$  \n其中 $\\mu_{i}$ 与 $B_{n}$ 如前所述.  \n例 4.4.9: 一份考卷由 99 个题目组成, 并按由易到难顺序排列, 某学生答对第 1 题的概率为 0.99;答对第 2 题的概率为 0.98 ; 一般地, 他答对第 $i$ 题的概率为 $1-i / 100, i=1,2, \\cdots$. 假如该学生回\n答各题目是相互独立的, 并且要正确回答其中 60 个题日以上 (包括 60 个) 才算通过考试. 试计算该学生通过考试的可能性多大?  \n解: 设  \n$$\nX_{i}= \\begin{cases}1, & \\text { 若学生答对第 } i \\text { 题, } \\\\ 0, & \\text { 若学生答错第 } i \\text { 题. }\\end{cases}\n$$  \n于是 $X_{i}$ 相互独立, 且服从不同的二点分布:  \n而我们要求的是  \n$$\nP\\left(X_{i}=1\\right)=p_{i}=1-\\frac{i}{100}, P\\left(X_{i}=0\\right)=1-p_{i}=\\frac{i}{100}, i=1,2, \\cdots, 99 .\n$$  \n$$\nP\\left(\\sum_{i=1}^{9} 9 X_{i} \\geqslant 60\\right)\n$$  \n为使用中心极限定理, 我们可以设想从 $X_{100}$ 开始的随机变量都与 $X_{99}$ 同分布, 且相互独立.下面我们用 $\\delta=1$ 来验证随机变量序列 $\\left\\{X_{n}\\right\\}$ 满足李雅普诺夫条件 (4.4.5), 因为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 设  \n$$\nX_{i}= \\begin{cases}1, & \\text { 若学生答对第 } i \\text { 题, } \\\\ 0, & \\text { 若学生答错第 } i \\text { 题. }\\end{cases}\n$$  \n于是 $X_{i}$ 相互独立, 且服从不同的二点分布:  \n而我们要求的是  \n$$\nP\\left(X_{i}=1\\right)=p_{i}=1-\\frac{i}{100}, P\\left(X_{i}=0\\right)=1-p_{i}=\\frac{i}{100}, i=1,2, \\cdots, 99 .\n$$  \n$$\nP\\left(\\sum_{i=1}^{9} 9 X_{i} \\geqslant 60\\right)\n$$  \n为使用中心极限定理, 我们可以设想从 $X_{100}$ 开始的随机变量都与 $X_{99}$ 同分布, 且相互独立.下面我们用 $\\delta=1$ 来验证随机变量序列 $\\left\\{X_{n}\\right\\}$ 满足李雅普诺夫条件 (4.4.5), 因为  \n$$\n\\begin{aligned}\n& B_{n}=\\sqrt{\\sum_{i=1}^{n} \\operatorname{Var}\\left(X_{i}\\right)}=\\sqrt{\\sum_{i=1}^{n} p_{i}\\left(1-p_{i}\\right)} \\rightarrow+\\infty, n \\rightarrow+\\infty \\\\\n& E\\left(\\left|X_{i}-p_{i}\\right|^{3}\\right)\\left(1-p_{i}\\right)^{3} p_{i}+p_{i}^{3}\\left(1-p_{i}\\right) \\leqslant p_{i}\\left(1-p_{i}\\right),\n\\end{aligned}\n$$  \n于是  \n$$",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n为使用中心极限定理, 我们可以设想从 $X_{100}$ 开始的随机变量都与 $X_{99}$ 同分布, 且相互独立.下面我们用 $\\delta=1$ 来验证随机变量序列 $\\left\\{X_{n}\\right\\}$ 满足李雅普诺夫条件 (4.4.5), 因为  \n$$\n\\begin{aligned}\n& B_{n}=\\sqrt{\\sum_{i=1}^{n} \\operatorname{Var}\\left(X_{i}\\right)}=\\sqrt{\\sum_{i=1}^{n} p_{i}\\left(1-p_{i}\\right)} \\rightarrow+\\infty, n \\rightarrow+\\infty \\\\\n& E\\left(\\left|X_{i}-p_{i}\\right|^{3}\\right)\\left(1-p_{i}\\right)^{3} p_{i}+p_{i}^{3}\\left(1-p_{i}\\right) \\leqslant p_{i}\\left(1-p_{i}\\right),\n\\end{aligned}\n$$  \n于是  \n$$\n\\frac{1}{B_{n}^{3}} \\sum_{i=1}^{n} E\\left(\\left|X_{i}-p_{i}\\right|^{3}\\right) \\leqslant \\frac{1}{\\left(\\sum_{i=1}^{n} p_{i}\\left(1-p_{i}\\right)\\right)^{1 / 2}} \\rightarrow 0, n \\rightarrow+\\infty\n$$  \n即 $\\left\\{X_{n}\\right\\}$ 满足李雅普诺夫条件 (4.4.5), 所以可以使用中心极限定理. 又因为  \n$$\n\\begin{aligned}\n& E\\left(\\sum_{i=1}^{99} X_{i}\\right)=\\sum_{i=1}^{99} p_{i}=\\sum_{i=1}^{99}\\left(1-\\frac{i}{100}\\right)=49.5 \\\\",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n于是  \n$$\n\\frac{1}{B_{n}^{3}} \\sum_{i=1}^{n} E\\left(\\left|X_{i}-p_{i}\\right|^{3}\\right) \\leqslant \\frac{1}{\\left(\\sum_{i=1}^{n} p_{i}\\left(1-p_{i}\\right)\\right)^{1 / 2}} \\rightarrow 0, n \\rightarrow+\\infty\n$$  \n即 $\\left\\{X_{n}\\right\\}$ 满足李雅普诺夫条件 (4.4.5), 所以可以使用中心极限定理. 又因为  \n$$\n\\begin{aligned}\n& E\\left(\\sum_{i=1}^{99} X_{i}\\right)=\\sum_{i=1}^{99} p_{i}=\\sum_{i=1}^{99}\\left(1-\\frac{i}{100}\\right)=49.5 \\\\\n& B_{99}^{2}=\\sum_{i=1}^{99} \\operatorname{Var}\\left(X_{i}\\right)=\\sum_{i=1}^{99}\\left(1-\\frac{i}{100}\\right)\\left(\\frac{i}{100}\\right)=16.665\n\\end{aligned}\n$$  \n所以该学生通过考试的可能性为  \n$$\n\\begin{aligned}\nP\\left(\\sum_{i=1}^{99} X_{i} \\geqslant 60\\right) & =P\\left(\\frac{\\sum_{i=1}^{99} X_{i}-49.5}{\\sqrt{16.665}} \\geqslant \\frac{60-49.5}{\\sqrt{16.665}}\\right) \\\\\n& \\approx 1-\\Phi(2.5735)=0.005 .\n\\end{aligned}\n$$  \n由此看出: 此学生通过考试的可能性很小, 大约只有千分之五.",
        "metadata": {
            "Header 2": "三、给定 $y, \\beta$ 求 $n$",
            "Header 3": "4.4.4 独立不同分布下的中心极限定理"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 某保险公司多年的统计资料表明, 在索赔户中被森素赔户占 $20 \\%$, 以 $X$ 表示在随意抽查的 100 个家赔户中因被盗向保险公司素赔的户数.  \n(1) 写出 $X$ 的分布列,  \n(2) 求被盗索赔户不少于 14 户且不多于 30 户的概率的近似值.  \n2. 某电于计算机主机有 100 个终端, 每个终端有 $80 \\%$ 的时间被使用. 若各个终端是否被使用是相互独立的, 试求至少有 15 个终端空闲的概率.\n3. 有一批建筑房屋用的木柱, 其中 $80 \\%$ 的长度不小于 $3 \\mathrm{~m}$, 现从这批木柱中随机地取出 100 根,问其中至少有 30 根短于 $3 \\mathrm{~m}$ 的概率是多少?\n4. 朕一颗散子 100 次, 记第 $i$ 次挪出的点数为 $X_{i}, i=1,2, \\cdots, 100$, 点数之平均为 $\\bar{X}=\\frac{1}{n} \\sum_{i=1}^{100} X_{i}$.试求薇率 $P(3 \\leqslant \\bar{X} \\leqslant 4)$.\n5. 设 $X_{1}, X_{2}, \\cdots, X_{48}$ 为独立同分布的随机变量, 共同分布为 $U(0,5)$. 其算术平均为 $\\bar{X}=\\frac{1}{n} \\sum_{i=1}^{48} X_{i}$,\n试求概率 $P(2 \\leqslant \\bar{X} \\leqslant 3)$.\n6. 某汽车销售点每天出售的汽车数服从参数为 $\\lambda=2$ 的泊松分布. 若一年 365 天都经营汽车销售, 且每天出修的汽车数是相互独立的, 求一年中售出 700 辆以上汽车的概率.\n7. 某餐厅每天接待 400 名顾客, 设每位顾客的消费额 (元) 服从 $(20,100)$ 上的均匀分布, 且顾客的消费额是相互独立的. 试求:  \n(1) 该餐厅每天的平均营业额,  \n(2) 该餐厅每天的营业额在平均营业额 $\\pm 760$ 元内的概率.",
        "metadata": {
            "Header 2": "如 题 4.4"
        },
        "type": "Document"
    },
    {
        "page_content": "5. 设 $X_{1}, X_{2}, \\cdots, X_{48}$ 为独立同分布的随机变量, 共同分布为 $U(0,5)$. 其算术平均为 $\\bar{X}=\\frac{1}{n} \\sum_{i=1}^{48} X_{i}$,\n试求概率 $P(2 \\leqslant \\bar{X} \\leqslant 3)$.\n6. 某汽车销售点每天出售的汽车数服从参数为 $\\lambda=2$ 的泊松分布. 若一年 365 天都经营汽车销售, 且每天出修的汽车数是相互独立的, 求一年中售出 700 辆以上汽车的概率.\n7. 某餐厅每天接待 400 名顾客, 设每位顾客的消费额 (元) 服从 $(20,100)$ 上的均匀分布, 且顾客的消费额是相互独立的. 试求:  \n(1) 该餐厅每天的平均营业额,  \n(2) 该餐厅每天的营业额在平均营业额 $\\pm 760$ 元内的概率.  \n8. 一仪器同时收到 50 个信号 $U_{i}, i=1,2, \\cdots, 50$. 设 $U_{i}$ 是相互猫立的, 且都服从 $(0,10)$ 内的均匀分布, 试求 $P\\left(\\sum_{i=1}^{50} U_{i}>300\\right)$.\n9. 计算机在进行加法运算时对每个加数取整数 (取最为接近于它的整数). 设所有的取整误差是相互独立的, 且它们都服从 $(-0.5,0.5)$ 上的均匀分布.  \n(1) 若将 1500 个数相加, 求误差总和的绝对值超过 15 的概率,  \n(2) 最多几个数加在一起可使得误差总和的绝对值小于 10 的概率不小于 $95 \\%$.  \n10. 设各零件的重量都是随机变量, 它们相互独立, 且服从相同的分布, 其数学期望为 $0.5 \\mathrm{~kg}$, 标准差为 $0.1 \\mathrm{~kg}$, 问 5000 只零件的总重量超过 $2510 \\mathrm{~kg}$ 的概率是多少?",
        "metadata": {
            "Header 2": "如 题 4.4"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 该餐厅每天的平均营业额,  \n(2) 该餐厅每天的营业额在平均营业额 $\\pm 760$ 元内的概率.  \n8. 一仪器同时收到 50 个信号 $U_{i}, i=1,2, \\cdots, 50$. 设 $U_{i}$ 是相互猫立的, 且都服从 $(0,10)$ 内的均匀分布, 试求 $P\\left(\\sum_{i=1}^{50} U_{i}>300\\right)$.\n9. 计算机在进行加法运算时对每个加数取整数 (取最为接近于它的整数). 设所有的取整误差是相互独立的, 且它们都服从 $(-0.5,0.5)$ 上的均匀分布.  \n(1) 若将 1500 个数相加, 求误差总和的绝对值超过 15 的概率,  \n(2) 最多几个数加在一起可使得误差总和的绝对值小于 10 的概率不小于 $95 \\%$.  \n10. 设各零件的重量都是随机变量, 它们相互独立, 且服从相同的分布, 其数学期望为 $0.5 \\mathrm{~kg}$, 标准差为 $0.1 \\mathrm{~kg}$, 问 5000 只零件的总重量超过 $2510 \\mathrm{~kg}$ 的概率是多少?\n11. 某种产品由 20 个相同部件连接而成, 每个部件的长度是均值为 $2 \\mathrm{~mm}$ 、标准差为 $0.02 \\mathrm{~mm}$ 的随机变量. 假如这 20 个部件的长度相互独立同分布, 且规定产品总长为 $40 \\mathrm{~mm} \\pm 0.2 \\mathrm{~mm}$ 时为合格品, 求该产品的不合格品率.\n12. 进行独立重复试验, 每次试验中事件 A 发生的概率为 0.25 . 试问能以 $95 \\%$ 的把握保近 1000 次试验中事件 A 发生的频率与概率相差多少? 此时 A 发生的次数在什么范围内?\n13. 设某生产线上组装每件产品的时间服从指数分布, 平均需要 $10 \\mathrm{~min}$, 且各件产品的组装时间是相互独立的.  \n(1) 试求组装 100 件产品需要 $15 \\mathrm{~h}$ 至 $20 \\mathrm{~h}$ 的概率,  \n(2) 保证有 $95 \\%$ 的可能性, 问 $16 \\mathrm{~h}$ 内最多可以组装多少件产品.  \n14. 某种福利彩票的奖金额 $X$ 由摇奖决定, 其分布列为",
        "metadata": {
            "Header 2": "如 题 4.4"
        },
        "type": "Document"
    },
    {
        "page_content": "12. 进行独立重复试验, 每次试验中事件 A 发生的概率为 0.25 . 试问能以 $95 \\%$ 的把握保近 1000 次试验中事件 A 发生的频率与概率相差多少? 此时 A 发生的次数在什么范围内?\n13. 设某生产线上组装每件产品的时间服从指数分布, 平均需要 $10 \\mathrm{~min}$, 且各件产品的组装时间是相互独立的.  \n(1) 试求组装 100 件产品需要 $15 \\mathrm{~h}$ 至 $20 \\mathrm{~h}$ 的概率,  \n(2) 保证有 $95 \\%$ 的可能性, 问 $16 \\mathrm{~h}$ 内最多可以组装多少件产品.  \n14. 某种福利彩票的奖金额 $X$ 由摇奖决定, 其分布列为  \n| $X$ 万 <br> 元) | 5 | 10 | 20 | 30 | 40 | 50 | 100 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P$ | 0.2 | 0.2 | 0.2 | 0.1 | 0.1 | 0.1 | 0.1 |  \n若一年中要开出 300 个奖, 问需要多少奖金总额, 才有 $95 \\%$ 的把握能够发放奖金.  \n15. 一家有 500 间客房的大旅馆的每间客房装有一台 $2 \\mathrm{~kW}$ 的空调机. 若开房率为 $80 \\%$, 需要多少 $\\mathrm{kW}$ 的电力才能有 $99 \\%$ 的可能性保证有足够的电力使用空调机.\n16. 独立重复地对某物体的长度 $a$ 进行 $n$ 次测量, 设各次测量结果 $X_{i}$ 跟从正态分布 $N\\left(a, 0.2^{2}\\right)$. 记 $\\bar{X}$ 为 $a$ 次测量结果的算术平均值, 为保证有 $95 \\%$ 的把握使平均值与实际值 $a$ 的差异小于 0.1 ,问至少需要测量多少次?\n17. 某工厂每月生产 10000 台液晶投影机, 但它的液晶片车间生产液晶片合格品率为 $80 \\%$, 为了以 $99.7 \\%$ 的可能性保证出厂的液晶投影机都能装上合格的液晶片, 试问该液晶片车间每月至少应该生产多少片液晶片?",
        "metadata": {
            "Header 2": "如 题 4.4"
        },
        "type": "Document"
    },
    {
        "page_content": "若一年中要开出 300 个奖, 问需要多少奖金总额, 才有 $95 \\%$ 的把握能够发放奖金.  \n15. 一家有 500 间客房的大旅馆的每间客房装有一台 $2 \\mathrm{~kW}$ 的空调机. 若开房率为 $80 \\%$, 需要多少 $\\mathrm{kW}$ 的电力才能有 $99 \\%$ 的可能性保证有足够的电力使用空调机.\n16. 独立重复地对某物体的长度 $a$ 进行 $n$ 次测量, 设各次测量结果 $X_{i}$ 跟从正态分布 $N\\left(a, 0.2^{2}\\right)$. 记 $\\bar{X}$ 为 $a$ 次测量结果的算术平均值, 为保证有 $95 \\%$ 的把握使平均值与实际值 $a$ 的差异小于 0.1 ,问至少需要测量多少次?\n17. 某工厂每月生产 10000 台液晶投影机, 但它的液晶片车间生产液晶片合格品率为 $80 \\%$, 为了以 $99.7 \\%$ 的可能性保证出厂的液晶投影机都能装上合格的液晶片, 试问该液晶片车间每月至少应该生产多少片液晶片?\n18. 某产品的合格品率为 $99 \\%$, 问包装箱中应该装多少个此种产品, 才能有 $95 \\%$ 的可能性使每箱中至少有 100 个合格产品.\n19. 为确定某城市成年男子中吸烟者的比例 $p$, 任意调查 $n$ 个成年男子, 记其中的吸烟人数为 $m$, 问 $n$ 至少为多大才能保证 $m / n$ 与 $p$ 的差异小于 0.01 的概率大于 $95 \\%$.",
        "metadata": {
            "Header 2": "如 题 4.4"
        },
        "type": "Document"
    },
    {
        "page_content": "前四章的研究属于概率论的范畴. 我们已经看到, 随机变量及其概率分布全面地描述了随机现象的通解规律性. 在概率论的许多问题中, 概率分布通常被假定为已知的, 而一切计算及推理均基于这个已知的分布进行, 在实际问题中, 情况往往并非如此, 看一个例子.  \n例 5.0.1: 某公司要采购一批产品, 每件产品不是合格品就是不合格品, 但该产品总有一个不合格品率 $p$. 由此, 若从该批产品中随机抽取一件, 用 $X$ 表示这一件产品的不合格数, 不难看出 $X$ 服从一个二点分布 $b(1, p)$, 但分布中的参数 $p$ 却是不知道的. 显然, $p$ 的大小决定了该批产品的质量,它直接影响采购行为的经济效益. 因此, 人们会对 $p$ 提出一些问题, 比如,  \n- $p$ 的大小如何;\n- $p$ 大概落在什么范围内;\n- 能否认为 $p$ 满足设定要求 (如 $p \\leqslant 0.05$ ).  \n诸如例 5.0.1 研究的问题属于数理统计的范畴. 接下来我们从统计中最基本的概念一一总体和样本开始介绍统计学内容.",
        "metadata": {
            "Header 2": "第 5 章 统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "在一个统计问题中, 我们把研究对象的全体称为总体, 构成总体的每个成员称为个体. 对多数实际问题, 总体中的个体是一些实在的人或物. 比如, 我们要研究某大学的学生身高情况, 则该大学的全体学生构成问题的总体, 而每一个学生即使一个个体. 事实上, 每个学生都有许多特征: 性别、年龄、身高、体重、名字、籍贯等等, 而在该问题中, 我们关心的只是该校学生的身高如何, 对其他的特征暂不予考虑. 这样, 每个学生 (个体) 所具有的数量指标值—身高就是个体, 而将所有身高全体看成总体. 这样一来, 若抛开实际背景, 总体就是一堆数, 这堆数中有大有小, 有的出现的机会多, 有的出现机会小, 因此用一个概率分布去描述和归纳总体是恰当的, 从这个意义看, 总体就是一个分布, 而其数量指标就是服从这个分布的随机变量. 以后说 “从总体中抽样” 与 “从分布中抽样”是同一个意思.  \n例 5.1.1: 考察某厂的产品质量, 将其产品只分为合格品与不合格品, 并以 0 记合格品, 以 1 记不合格品, 则  \n$$\n\\text { 总体 }=\\{\\text { 该厂生产的全部合格品与不合格品 }\\}=\\{\\text { 由 } 0 \\text { 或 } 1 \\text { 组成的一堆数 }\\} .\n$$  \n若以 $p$ 表示这堆数中 1 的比例 (不合格品率), 则该总体可由一个二点分布表示:  \n| $X$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1-p$ | $p$ |  \n不同的 $p$ 反映了总体间的差异. 譬如, 两个生产同类产品的工厂的产品总体分布为  \n| $X$ | 0 | 1 |  | $X$ | 0 | 1 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P$ | 0.983 | 0.017 |  | $P$ | 0.915 | 0.085 |  \n我们可以看到, 第一个工厂的产品质量优于第二个工厂. 实际中, 分布中的不合格率是未知的,如何对之进行估计是统计学要研究的问题.",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\text { 总体 }=\\{\\text { 该厂生产的全部合格品与不合格品 }\\}=\\{\\text { 由 } 0 \\text { 或 } 1 \\text { 组成的一堆数 }\\} .\n$$  \n若以 $p$ 表示这堆数中 1 的比例 (不合格品率), 则该总体可由一个二点分布表示:  \n| $X$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1-p$ | $p$ |  \n不同的 $p$ 反映了总体间的差异. 譬如, 两个生产同类产品的工厂的产品总体分布为  \n| $X$ | 0 | 1 |  | $X$ | 0 | 1 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P$ | 0.983 | 0.017 |  | $P$ | 0.915 | 0.085 |  \n我们可以看到, 第一个工厂的产品质量优于第二个工厂. 实际中, 分布中的不合格率是未知的,如何对之进行估计是统计学要研究的问题.  \n例 5.1.2: 彩电的彩色浓度是彩电质量好坏的一个重要指标. 20 世纪 70 年代在美国销售的 SONY 牌彩电有两个产地: 美国和日本, 两地的工厂是按统一设计方案和相同的生产线生产同一型号",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n若以 $p$ 表示这堆数中 1 的比例 (不合格品率), 则该总体可由一个二点分布表示:  \n| $X$ | 0 | 1 |\n| :---: | :---: | :---: |\n| $P$ | $1-p$ | $p$ |  \n不同的 $p$ 反映了总体间的差异. 譬如, 两个生产同类产品的工厂的产品总体分布为  \n| $X$ | 0 | 1 |  | $X$ | 0 | 1 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $P$ | 0.983 | 0.017 |  | $P$ | 0.915 | 0.085 |  \n我们可以看到, 第一个工厂的产品质量优于第二个工厂. 实际中, 分布中的不合格率是未知的,如何对之进行估计是统计学要研究的问题.  \n例 5.1.2: 彩电的彩色浓度是彩电质量好坏的一个重要指标. 20 世纪 70 年代在美国销售的 SONY 牌彩电有两个产地: 美国和日本, 两地的工厂是按统一设计方案和相同的生产线生产同一型号  \nSONY 彩电, 连使用说明书和检验合格的标准也是一样的. 其中关于彩色浓度 X 的标准是: 目标值为 $m$, 公差为 5 , 即当 $X$ 在 $[m-5, m+5]$ 内该彩电的热情高于购买美产 SONY 彩电, 原因何在? 这就要考察这两个总体有什么差别. 1979 年 4 月 17 日日本《朝日新闻》刊登调查报告指出, 日产 SONY 彩电的彩色浓度服从正态分布 $N\\left(m,(5 / 3)^{2}\\right)$, 而美产 SONY 彩电的彩色浓度服从 $(m-5, m+5)$ 上的均匀分布, 见图 5.1.1. 这两个不同的分布代表了不同的总体, 其均值相同 (都为 $m$ ), 但方差不同. 若彩色浓度与 $m$ 的距离在 $5 / 3$ 以内为 I 级品, 在 5/3 到 $10 / 3$ 之间为 II 级品, 在 $10 / 3$ 到 5 之间为 III 级品, 其他为 IV 级品. 于是日产 SONY 彩电的 I 级品为美产 SONY 的两倍出头 (见表 5.1.1), 这就是美国消费者愿意购买日产 SONY 的主要原因.  \n!  \n图 5.1.1: SONY 彩电彩色浓度分布图",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n图 5.1.1: SONY 彩电彩色浓度分布图  \n表 5.1.1: 各等级彩电的比例 $(\\%)$  \n| 等级 | I | II | III | IV |\n| :---: | :---: | :---: | :---: | :---: |\n| 美产 | 33.3 | 33.3 | 33.3 | 0 |\n| 日产 | 68.3 | 27.1 | 4.3 | 0.3 |  \n在有些问题中, 我们对每一研究对象可能要观测两个甚至更多个指标, 此时可用多维随机向量及其联合分布来描述总体. 这种总体称为多维总体. 譬如, 我们要了解某校大学生的三个指标:年龄、身高、月生活支出. 则我们可用一个三维随机向量描述该总体. 这是一个三维总体, 它是多元分析所研究的对象. 本书中主要研究一维总体, 某些地方也会涉及二维总体.  \n总体还有有限总体和无限总体, 本书将以无限总体作为主要研究对象.",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体"
        },
        "type": "Document"
    },
    {
        "page_content": "为了了解总体的分布, 我们从总体中随机地抽取 $n$ 个个体, 记其指标值为 $x_{1}, x_{2}, \\cdots, x_{n}$, 则 $x_{1}, x_{2}, \\cdots, x_{n}$ 称为总体的一个样本, $n$ 称为 样本容量, 或简称为 样本量, 样本中的个体称为 样品.  \n我们首先指出, 样本具有二重性: 一方面, 由于样本是从总体中随机抽取的, 抽取前无法预知它们的数值, 因此, 样本是随机变量, 用大写字母 $X_{1}, X_{2}, \\cdots, X_{n}$ 表示; 另一方面, 样本在抽取以后经观测就有确定的观测值, 因此, 样本又是一组数值. 此时用小写字母 $x_{1}, x_{2}, \\cdots, x_{n}$ 表示是恰当的.简单起见, 无论是样本还是其观测值, 本书中样本一般均用 $x_{1}, x_{2}, \\cdots, x_{n}$ 表示, 读者应能从上下文中加以区别.  \n例 5.1.3: 啤酒厂生产的瓶装啤酒规定净含量为 $640 \\mathrm{~g}$. 现从某厂生产的啤酒中随机抽取 10 瓶测定其含量, 得到如下结果:  \n| 表 5.1.2: 100 只元件的寿命数据 |  |  |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 寿命范围 | 元件数 | 寿命范围 | 元件数 | 寿命范围 | 元件数 |  |\n| $(0,24]$ | 4 | $(192,216]$ | 6 | $(384,408]$ | 4 |  |\n| $(24,48]$ | 8 | $(216,240]$ | 3 | $(408,432]$ | 4 |  |\n| $(48,72]$ | 6 | $(240,264]$ | 3 | $(432,456]$ | 1 |  |\n| $(72,96]$ | 5 | $(264,288]$ | 5 | $(456,480]$ | 2 |  |\n| $(96,120]$ | 3 | $(288,312]$ | 5 | $(480,504]$ | 2 |  |\n| $(120,144]$ | 4 | $(312,336]$ | 3 | $(504,528]$ | 3 |  |",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体",
            "Header 3": "5.1.2 样本"
        },
        "type": "Document"
    },
    {
        "page_content": "| 表 5.1.2: 100 只元件的寿命数据 |  |  |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 寿命范围 | 元件数 | 寿命范围 | 元件数 | 寿命范围 | 元件数 |  |\n| $(0,24]$ | 4 | $(192,216]$ | 6 | $(384,408]$ | 4 |  |\n| $(24,48]$ | 8 | $(216,240]$ | 3 | $(408,432]$ | 4 |  |\n| $(48,72]$ | 6 | $(240,264]$ | 3 | $(432,456]$ | 1 |  |\n| $(72,96]$ | 5 | $(264,288]$ | 5 | $(456,480]$ | 2 |  |\n| $(96,120]$ | 3 | $(288,312]$ | 5 | $(480,504]$ | 2 |  |\n| $(120,144]$ | 4 | $(312,336]$ | 3 | $(504,528]$ | 3 |  |\n| $(144,168]$ | 5 | $(336,360]$ | 5 | $(528,552]$ | 1 |  |\n| $(168,192]$ | 4 | $(360,384]$ | 1 | $>552$ | 13 |  |  \n$\\begin{array}{llllllllll}641 & 635 & 640 & 637 & 642 & 638 & 645 & 643 & 639 & 640\\end{array}$  \n这是一个容量为 10 的样本的观测值, 对应的总体为该厂生产的瓶装啤酒的净含量.  \n例 5.1.4: (分组样本)我们考察某厂生产的某种电子元件的寿命, 该厂生产的一级将要生产的所有元件是总体是总体 (通常可以认为是无限总体), 我们选了 100 只进行寿命试验, 由于一些原因, 我们不可能每时每刻对试验进行观察, 而只能定期 (比如每隔 $24 \\mathrm{~h}$ ) 进行观察, 于是, 对每个元件, 我们只能观察到其寿命落在某个范围内, 这就产生了表 5.1.2 所示的一组样本:",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体",
            "Header 3": "5.1.2 样本"
        },
        "type": "Document"
    },
    {
        "page_content": "| $(144,168]$ | 5 | $(336,360]$ | 5 | $(528,552]$ | 1 |  |\n| $(168,192]$ | 4 | $(360,384]$ | 1 | $>552$ | 13 |  |  \n$\\begin{array}{llllllllll}641 & 635 & 640 & 637 & 642 & 638 & 645 & 643 & 639 & 640\\end{array}$  \n这是一个容量为 10 的样本的观测值, 对应的总体为该厂生产的瓶装啤酒的净含量.  \n例 5.1.4: (分组样本)我们考察某厂生产的某种电子元件的寿命, 该厂生产的一级将要生产的所有元件是总体是总体 (通常可以认为是无限总体), 我们选了 100 只进行寿命试验, 由于一些原因, 我们不可能每时每刻对试验进行观察, 而只能定期 (比如每隔 $24 \\mathrm{~h}$ ) 进行观察, 于是, 对每个元件, 我们只能观察到其寿命落在某个范围内, 这就产生了表 5.1.2 所示的一组样本:  \n表 5.1.2 中的样本观测值没有具体的数值, 只有一个范围, 这样的样本称为分组样本. 相应的,例 5.1.3 中的 10 个啤酒净含量称为完全样本. 分组样本与完全样本相比在信息上总有损失, 这是分组样本的缺点. 为了获得更多信息, 应尽量设法获得完全样本, 在不得已场合可使用分组样本 (如上例). 但在实际中, 在样本量特别大时 (如 $n \\geqslant 100$ ), 又常用分组样本来代替完全样本, 这时需要对样本进行分组整理, 它能简明扼要地表示样本, 使人们能更好地认识总体, 这是分组样本的优点.  \n从总体中抽取样本可以有不同的抽法, 为了能由样本对总体作出比较可靠的推断, 就希望样本能很好的代表总体. 这就需要对抽样方法提出一些要求, 最常用的 “简单随机样本” 有如下两个要求:  \n- 样本具有 随机性, 即要求总体中每一个个体都有同等机会会被选人样本, 这便意味着每一样品 $x_{i}$ 与总体 $X$ 有相同的分布.\n- 样本要有独立性, 即要求样本中每一样品的取值不影响其他样品的取值, 这意味着 $x_{1}, x_{2}, \\cdots, x_{n}$相互独立.",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体",
            "Header 3": "5.1.2 样本"
        },
        "type": "Document"
    },
    {
        "page_content": "从总体中抽取样本可以有不同的抽法, 为了能由样本对总体作出比较可靠的推断, 就希望样本能很好的代表总体. 这就需要对抽样方法提出一些要求, 最常用的 “简单随机样本” 有如下两个要求:  \n- 样本具有 随机性, 即要求总体中每一个个体都有同等机会会被选人样本, 这便意味着每一样品 $x_{i}$ 与总体 $X$ 有相同的分布.\n- 样本要有独立性, 即要求样本中每一样品的取值不影响其他样品的取值, 这意味着 $x_{1}, x_{2}, \\cdots, x_{n}$相互独立.  \n用简单抽样方法得到的样本称为 简单随机样本, 也简称 样本. 除非特别指明, 本书中的样本皆为简单随机样本. 于是, 样本 $x_{1}, x_{2}, \\cdots, x_{n}$ 可以看成是相互独立的具有同一分布的随机变量, 其共同分布即为总体分布.  \n设总体 $X$ 具有分布函数 $F(x), x_{1}, x_{2}, \\cdots, x_{n}$ 为取自该总体的容量为 $n$ 的样本, 则样本 联合分布函数为  \n$$\nF\\left(x_{1}, x_{2}, \\cdots, x_{n}\\right)=\\prod_{i=1}^{n} F\\left(x_{i}\\right)\n$$  \n对无限总体, 随机性与独立性容易实现, 困难在于排除有意或无意的认为干扰. 对有限总体, 只要总体所含个体数很大, 特别是与样本量相比很大, 则独立性也可基本得到满足.  \n例 5.1.5: 设有一批产品共 $N$ 个, 需要进行抽样检验以了解其不合格品率 $p$, 现从中抽出 $n$ 个逐一检查它们是否是不合格的. 如果把合格品记为 0 , 不合格品记为 1 , 则总体为一个二点分布,  \n$$\nP(X=1)=p, P(X=0)=1-p,\n$$  \n设想样本是一个一个抽出的, 结果记为 $x_{1}, x_{2}, \\cdots, x_{n}$. 如果采取有放回抽样, 则 $x_{1}, x_{2}, \\cdots, x_{n}$ 为独立同分布, 若采取不放回抽样, 这是, 第二次抽到不合格品的概率依赖于第一次抽到的是否是不合\n格品, 如果第一次抽到不合格品, 则  \n$$\nP\\left(x_{2}=1 \\mid x_{1}=0\\right)=\\frac{N p}{N-1} .\n$$",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体",
            "Header 3": "5.1.2 样本"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n对无限总体, 随机性与独立性容易实现, 困难在于排除有意或无意的认为干扰. 对有限总体, 只要总体所含个体数很大, 特别是与样本量相比很大, 则独立性也可基本得到满足.  \n例 5.1.5: 设有一批产品共 $N$ 个, 需要进行抽样检验以了解其不合格品率 $p$, 现从中抽出 $n$ 个逐一检查它们是否是不合格的. 如果把合格品记为 0 , 不合格品记为 1 , 则总体为一个二点分布,  \n$$\nP(X=1)=p, P(X=0)=1-p,\n$$  \n设想样本是一个一个抽出的, 结果记为 $x_{1}, x_{2}, \\cdots, x_{n}$. 如果采取有放回抽样, 则 $x_{1}, x_{2}, \\cdots, x_{n}$ 为独立同分布, 若采取不放回抽样, 这是, 第二次抽到不合格品的概率依赖于第一次抽到的是否是不合\n格品, 如果第一次抽到不合格品, 则  \n$$\nP\\left(x_{2}=1 \\mid x_{1}=0\\right)=\\frac{N p}{N-1} .\n$$  \n显然, 如此得到的样本不是简单随机样本. 但是, 当 $N$ 很大时, 我们可以看待上述两种情形的概率都近似等于 $p$. 所以当 $N$ 很大, 而 $n$ 不大 (一个经验法则是 $n / N \\leqslant 0.1$ ) 时可以把该样本近似地看成简单随机样本.",
        "metadata": {
            "Header 2": "5.1 .1 总体与个体",
            "Header 3": "5.1.2 样本"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 某地电视台想了解某电视栏目 (如: 每日九点至九点半的体育节目) 在该地区的收视率情况, 于是委托一家市场咨询公司进行一次电话访查.  \n(1) 该项研究的总体是什么?  \n(2) 该项研究的样本是什么?  \n2. 为了了解统计学专业本科毕业生的就业情况, 我们调查了某地区 30 名 2000 年毕业的统计学专业本科生实习期满后的月薪情况.  \n(1) 什么是总体?  \n(2) 什么是样本?  \n(3) 样本量是什么?  \n3. 设某厂大量生产某种产品, 其产品不合格率 $p$ 未知, 每 $m$ 件产品包装为一盒. 为了检查产品的质量, 任意抽取 $n$ 盒, 查其中的不合格品数, 试说明什么是总体, 什么是样本, 并指出样本的分布.\n4. 假设一位运动员在完全相同的条件下重复进行 $n$ 次打靶, 试给出总体和样本的统计描述.\n5. 某厂生产的电容器的使用寿命服从指数分布, 为了解其平均寿命, 从中抽出 $n$ 个产品测其实际使用寿命, 试说明什么是总体, 什么是样本, 并指出样本的分布.\n6. 美国某高校根据毕业生返校情况记录, 宣布该校毕业生的年平均工资为 5 万美元, 你对此有何平均?",
        "metadata": {
            "Header 2": "如习题 5.1"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是取自总体分布函数为 $F(x)$ 的样本, 若将样本观测值由小到大进行排列, 为 $x_{(1)}, x_{(2)}, \\cdots, x_{(n)}$, 则 $x_{(1)}, x_{(2)}, \\cdots, x_{(n)}$ 称为有序样本, 用有序样本定义如下函数  \n$$\nF_{n}(x)= \\begin{cases}0, & \\text { 当 } x<x_{(1)},  \\tag{5.2.1}\\\\ k / n, & \\text { 当 } x_{(k)} \\leqslant x<x_{(k+1)}, k=1,2 \\cdots, n-1, \\\\ 1, & \\text { 当 } x>x_{(n)},\\end{cases}\n$$  \n则 $F_{n}(x)$ 是一非减右连续函数, 且满足  \n$$\nF_{n}(-\\infty)=0 \\text { 和 } F_{n}(+\\infty)=1 \\text {. }\n$$  \n由此可见, $F_{n}(x)$ 是一个分布函数, 并称 $F_{n}(x)$ 为 经验分布函数.  \n例 5.2.1: 某食品厂生产听装饮料, 现从生产线上随机抽取 5 听饮料, 称得其净重为 (单位:g)  \n$$\n\\begin{array}{lllll}\n351 & 347 & 355 & 344 & 351\n\\end{array}\n$$  \n这是一个容量为 5 的样本, 经排序可得有序样本:  \n$$\nx_{(1)}=344, x_{(2)}=347, x_{(3)}=351, x_{(4)}=351, x_{(5)}=351 \\text {, }\n$$  \n其经验分布函数为  \n$$\nF_{n}(x)= \\begin{cases}0, & x<344 \\\\ 0.2, & 344 \\leqslant x<347 \\\\ 0.4, & 347 \\leqslant x<351 \\\\ 0.8, & 351 \\leqslant x<355 \\\\ 1, & x \\geqslant 355\\end{cases}\n$$  \n!  \n图 5.2.1: 经验分布函数",
        "metadata": {
            "Header 2": "5.2 .1 经验分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由此可见, $F_{n}(x)$ 是一个分布函数, 并称 $F_{n}(x)$ 为 经验分布函数.  \n例 5.2.1: 某食品厂生产听装饮料, 现从生产线上随机抽取 5 听饮料, 称得其净重为 (单位:g)  \n$$\n\\begin{array}{lllll}\n351 & 347 & 355 & 344 & 351\n\\end{array}\n$$  \n这是一个容量为 5 的样本, 经排序可得有序样本:  \n$$\nx_{(1)}=344, x_{(2)}=347, x_{(3)}=351, x_{(4)}=351, x_{(5)}=351 \\text {, }\n$$  \n其经验分布函数为  \n$$\nF_{n}(x)= \\begin{cases}0, & x<344 \\\\ 0.2, & 344 \\leqslant x<347 \\\\ 0.4, & 347 \\leqslant x<351 \\\\ 0.8, & 351 \\leqslant x<355 \\\\ 1, & x \\geqslant 355\\end{cases}\n$$  \n!  \n图 5.2.1: 经验分布函数  \n对每一固定的 $x, F_{n}(x)$ 是样本中事件 “ $x_{i} \\leqslant x$ ” 发生的频率. 当 $n$ 固定时, $F_{n}(x)$ 是样本的函数, 它是一个随机变量, 由伯努利大数定律: 只要 $n$ 相当大, $F_{n}(x)$ 依概率收玫于 $F(x)$. 更深刻的结果也是存在的, 这就是格里纹科定理, 下面我们不加证明地加以介绍.  \n定理 5.2 .1 (格里纹科定理). 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是取自总体分布函数为 $F(x)$ 的样本, $F_{n}(x)$ 是其经验分布函数, 当 $n \\rightarrow \\infty$ 时, 有  \n$$\nP\\left\\{\\sup _{-\\infty<x<+\\infty}\\left|F_{n}(x)-F(x)\\right| \\rightarrow 0\\right\\}=1 .\n$$  \n定理 5.2.1 表明, 当 $n$ 相当大时, 经验分布函数是总体分布函数 $F(x)$ 的一个良好的近似. 经典的统计学中一切统计推断都以样本为依据, 其理由就在于此.",
        "metadata": {
            "Header 2": "5.2 .1 经验分布函数"
        },
        "type": "Document"
    },
    {
        "page_content": "样本数据的整理是统计研究的基础, 整理数据的最常用方法之一是给出其频数分布表或频率分布表. 我们从一个例子开始介绍.  \n例 5.2.2: 为研究某厂工人生产某种产品的能力, 我们随机调查了 20 位工人某天生产的该种产品的数量, 数据如下  \n| 160 | 196 | 164 | 148 | 170 |\n| :--- | :--- | :--- | :--- | :--- |\n| 175 | 178 | 166 | 181 | 162 |\n| 161 | 168 | 166 | 162 | 172 |\n| 156 | 170 | 157 | 162 | 154 |  \n对这 20 个数据 (样本) 进行整理, 具体步骤如下  \n- 对样本进行分组. 首先确定组数 $k$, 作为一般性的原则, 组数通常在 $5 \\sim 20$ 个, 对容量较小的样本, 通常将其分为 5 组或 6 组, 容量为 100 左右的样本可分 7 到 10 组, 容量为 200 左右的样本可分 9 到 13 组, 容量为 300 左右及以上的样本可分 12 到 20 组, 目的是使用足够的组来表示数据的变异. 本例中只有 20 个数据, 我们将之分为 5 组, 即 $k=5$.\n- 确定每组组距. 每组区间长度可以相同也可以不同, 实用中常选用长度相同的区间以便于进行比较, 此时各组区间的长度称为 组距, 其近似公式为  \n$$\n\\text { 组距 } d=\\text { 样本最大观测值-样本最小观测值 }) / \\text { 组数 }\n$$  \n本例中, 数据最大观测值为 196, 最小观测值为 148 , 故组距近似为  \n方便起见, 取组距为 10.  \n$$\nd=\\frac{196-148}{5}=9.6 \\text {, }\n$$  \n- 确定每组组限. 各组区间端点为 $a_{0}, a_{0}+d=a 1, a_{0}+2 d=a_{2}, a_{0}+2 d=a_{2}, \\cdots, a_{0}+k d=$ $a_{k}$, 形成如下的分组区间  \n$$\n\\left(a_{0}, a_{1}\\right],\\left(a_{1}, a_{2}\\right], \\cdots,\\left(a_{k-1}, a_{k}\\right]\n$$",
        "metadata": {
            "Header 2": "5.2 .1 经验分布函数",
            "Header 3": "5.2.2 频数频率分布表"
        },
        "type": "Document"
    },
    {
        "page_content": "- 确定每组组距. 每组区间长度可以相同也可以不同, 实用中常选用长度相同的区间以便于进行比较, 此时各组区间的长度称为 组距, 其近似公式为  \n$$\n\\text { 组距 } d=\\text { 样本最大观测值-样本最小观测值 }) / \\text { 组数 }\n$$  \n本例中, 数据最大观测值为 196, 最小观测值为 148 , 故组距近似为  \n方便起见, 取组距为 10.  \n$$\nd=\\frac{196-148}{5}=9.6 \\text {, }\n$$  \n- 确定每组组限. 各组区间端点为 $a_{0}, a_{0}+d=a 1, a_{0}+2 d=a_{2}, a_{0}+2 d=a_{2}, \\cdots, a_{0}+k d=$ $a_{k}$, 形成如下的分组区间  \n$$\n\\left(a_{0}, a_{1}\\right],\\left(a_{1}, a_{2}\\right], \\cdots,\\left(a_{k-1}, a_{k}\\right]\n$$  \n其中 $a_{0}$ 略小于最小观测值, $a_{k}$ 略大于最大观测值, 本例中可取 $a_{0}=147, a_{5}=197$, 于是本例的分组区间为:  \n$$\n(147,157],(157,167],(167,177],(177,187],(187,197],\n$$  \n通常可用每组的组中值来代表该组的变量取值, 组中值 $=($ 组上限 + 组下限 $) / 2$.  \n- 统计样本数据落人每个区间的个数——频数, 并列出其频数频率分布表. 本例的频数频率分布表见表 5.2.1. 从表中可以读出很多信息, 如: $40 \\%$ 的工人产量在 157 到 167 之间; 产量少于 167 个的有 12 人, 占 $60 \\%$; 产量高于 177 的有 3 人, 占 $15 \\%$.  \n表 5.2.1: 例 5.2.2 的频数频率分布表  \n| 组序 | 分组区间 | 组中值 | 频数 | 频率 | 累计频率/\\% |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | $(147,157]$ | 152 | 4 | 0.20 | 20 |",
        "metadata": {
            "Header 2": "5.2 .1 经验分布函数",
            "Header 3": "5.2.2 频数频率分布表"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n(147,157],(157,167],(167,177],(177,187],(187,197],\n$$  \n通常可用每组的组中值来代表该组的变量取值, 组中值 $=($ 组上限 + 组下限 $) / 2$.  \n- 统计样本数据落人每个区间的个数——频数, 并列出其频数频率分布表. 本例的频数频率分布表见表 5.2.1. 从表中可以读出很多信息, 如: $40 \\%$ 的工人产量在 157 到 167 之间; 产量少于 167 个的有 12 人, 占 $60 \\%$; 产量高于 177 的有 3 人, 占 $15 \\%$.  \n表 5.2.1: 例 5.2.2 的频数频率分布表  \n| 组序 | 分组区间 | 组中值 | 频数 | 频率 | 累计频率/\\% |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | $(147,157]$ | 152 | 4 | 0.20 | 20 |\n| 2 | $(157,167]$ | 162 | 8 | 0.40 | 60 |\n| 3 | $(167,177]$ | 172 | 5 | 0.25 | 85 |\n| 4 | $(177,187]$ | 182 | 2 | 0.10 | 95 |\n| 5 | $(187,197]$ | 192 | 1 | 0.05 | 100 |\n| 合计 |  |  | 20 | 1 |  |",
        "metadata": {
            "Header 2": "5.2 .1 经验分布函数",
            "Header 3": "5.2.2 频数频率分布表"
        },
        "type": "Document"
    },
    {
        "page_content": "前面我们介绍了频数频率分布的表格形式, 它也可以用图形表示, 这在许多场合更直观.",
        "metadata": {
            "Header 2": "5.2 .1 经验分布函数",
            "Header 3": "5.2.3 样本数据的图形显示"
        },
        "type": "Document"
    },
    {
        "page_content": "频数分布最常用的图形表示是直方图, 它在组距相等场合常用宽度相等的长条矩形表示, 矩形的高低表示频数的大小. 在图形上, 横坐标表示所关心变量的取值区间, 纵坐标表示频数, 这样就得到频数直方图, 图 5.2.2 画出了例 5.2.2 的频数直方图. 若把纵轴改成频率就得到频率直方图为使诸长条矩形面积和为 1 , 可将纵轴取为频率/组距, 如此得到的直方图称为单位频率直方图, 或简称频率直方图. 凡此三种直方图的差别仅在于纵轴刻度的选择, 直方图本身并无变化.",
        "metadata": {
            "Header 2": "一、直方图"
        },
        "type": "Document"
    },
    {
        "page_content": "除直方图外, 另一种常用的方法是茎叶图, 下面我们从一个例子谈起.  \n例 5.2.3: 某公司对应聘人员进行能力测试, 测试成绩总分为 150 分. 下面是 50 位应聘人员的测试成绩 (已经过排序):  \n| 64 | 67 | 70 | 72 | 74 | 76 | 76 | 79 | 80 | 81 |\n| ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |\n| 82 | 82 | 83 | 85 | 86 | 88 | 91 | 91 | 92 | 93 |\n| 93 | 93 | 95 | 95 | 95 | 97 | 97 | 99 | 100 | 100 |  \n!  \n图 5.2.2: 例 5.2.2 的频数直方图  \n!  \n图 5.2.3: 测试成绩的茎叶图  \n| 102 | 104 | 106 | 106 | 107 | 108 | 108 | 112 | 112 | 114 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 116 | 118 | 119 | 119 | 122 | 123 | 125 | 126 | 128 | 133 |  \n我们用这批数据给出一个茎叶图. 把每一个数值分为两部分, 前面一部分 (百位和十位) 称为 茎, 后面部分 (个位) 称为 叶, 如  \n!  \n然后画一条坚线, 在坚线的左侧写上茎, 右侧写上叶, 就形成了茎叶图. 应聘人员测试成绩的茎叶图见图 5.2.3.  \n茎叶图的外观很像横放的直方图, 但茎叶图中叶增加了具体的数值, 使我们对数据的具体取值一目了然, 从面保留了数据中全部的信息.  \n在要比较两组样本时, 可画出它们的背靠背的茎叶图, 这是一个简单直观而有效的对比方法.例 5.2.4: 下面的数据是某厂两个车间某天各 40 名员工生产的产品数量 (表 5.2.2). 为对其进行比较, 我们将这些数据放到一个背靠背茎叶图上 (图 5.2.4).  \n表 5.2.2: 某厂两个车间 40 名员工的产量  \n| 甲车间 |  |  |  |  |  | 乙车间 |  |  |  |  |  |",
        "metadata": {
            "Header 2": "二、茎叶图"
        },
        "type": "Document"
    },
    {
        "page_content": "| 116 | 118 | 119 | 119 | 122 | 123 | 125 | 126 | 128 | 133 |  \n我们用这批数据给出一个茎叶图. 把每一个数值分为两部分, 前面一部分 (百位和十位) 称为 茎, 后面部分 (个位) 称为 叶, 如  \n!  \n然后画一条坚线, 在坚线的左侧写上茎, 右侧写上叶, 就形成了茎叶图. 应聘人员测试成绩的茎叶图见图 5.2.3.  \n茎叶图的外观很像横放的直方图, 但茎叶图中叶增加了具体的数值, 使我们对数据的具体取值一目了然, 从面保留了数据中全部的信息.  \n在要比较两组样本时, 可画出它们的背靠背的茎叶图, 这是一个简单直观而有效的对比方法.例 5.2.4: 下面的数据是某厂两个车间某天各 40 名员工生产的产品数量 (表 5.2.2). 为对其进行比较, 我们将这些数据放到一个背靠背茎叶图上 (图 5.2.4).  \n表 5.2.2: 某厂两个车间 40 名员工的产量  \n| 甲车间 |  |  |  |  |  | 乙车间 |  |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 50 | 52 | 56 | 61 | 61 | 62 | 56 | 66 | 67 | 67 | 68 | 68 |\n| 64 | 65 | 65 | 65 | 67 | 67 | 72 | 72 | 74 | 75 | 75 | 75 |\n| 67 | 68 | 71 | 72 | 74 | 74 | 75 | 76 | 76 | 76 | 76 | 78 |\n| 76 | 76 | 77 | 77 | 78 | 82 | 78 | 79 | 80 | 81 | 81 | 83 |\n| 83 | 85 | 87 | 88 | 90 | 91 | 83 | 83 | 84 | 84 | 84 | 86 |\n| 86 | 92 | 86 | 93 | 93 | 97 | 86 | 87 | 87 | 88 | 92 | 92 |\n| 100 | 100 | 103 | 105 |  |  | 93 | 95 | 98 | 107 |  |  |",
        "metadata": {
            "Header 2": "二、茎叶图"
        },
        "type": "Document"
    },
    {
        "page_content": "| 50 | 52 | 56 | 61 | 61 | 62 | 56 | 66 | 67 | 67 | 68 | 68 |\n| 64 | 65 | 65 | 65 | 67 | 67 | 72 | 72 | 74 | 75 | 75 | 75 |\n| 67 | 68 | 71 | 72 | 74 | 74 | 75 | 76 | 76 | 76 | 76 | 78 |\n| 76 | 76 | 77 | 77 | 78 | 82 | 78 | 79 | 80 | 81 | 81 | 83 |\n| 83 | 85 | 87 | 88 | 90 | 91 | 83 | 83 | 84 | 84 | 84 | 86 |\n| 86 | 92 | 86 | 93 | 93 | 97 | 86 | 87 | 87 | 88 | 92 | 92 |\n| 100 | 100 | 103 | 105 |  |  | 93 | 95 | 98 | 107 |  |  |  \n甲车间 | 620 | 5 | 6 | 乙车间 |\n| ---: | :--- | :--- | :--- |\n| 87775554211 | 6 | 67788 |  |\n| 877664421 | 7 | 2245555666889 |  |\n| 8766532 | 8 | 01133344466778 |  |\n| 73210 | 9 | 22358 |  |\n| 5300 | 10 | 7 |  |  \n图 5.2.4: 两车间产量的背靠背茎叶图  \n在图 5.2.4 中, 茎在中间, 左边表示甲车间的数据, 右边表示乙车间的数据. 从茎叶图可以看出,甲车间员工的产量偏于上方, 而乙车间员工的产量大多位于中间, 乙车间的平均产量要高于甲车间,乙车间各员工的产量比较集中, 而甲车间员工的产量则比较分散.",
        "metadata": {
            "Header 2": "二、茎叶图"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 以下是某工厂通过抽样调查得到的 10 名工人一周内生产的产品数  \n$$\n\\begin{array}{llllllllll}\n149 & 156 & 160 & 138 & 149 & 153 & 153 & 169 & 156 & 156\n\\end{array}\n$$  \n试由这批数据构造经验分布函数并作图.  \n2. 下表是经过整理后得到的分组样本 试写出此分组样本的经验分布函数.  \n| 组序 | 1 | 2 | 3 | 4 | 5 |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 分组区间 | $(38,48]$ | $(48,58]$ | $(58,68]$ | $(68,78]$ | $(78,88]$ |\n| 频数 | 3 | 4 | 8 | 3 | 2 |  \n3. 假若某地区 30 名 2000 年某专业毕业生实习期满后的月薪数据如下:  \n| 909 | 1086 | 1120 | 999 | 1320 | 1091 |\n| ---: | ---: | ---: | ---: | ---: | ---: |\n| 1071 | 1081 | 1130 | 1336 | 967 | 1572 |\n| 825 | 914 | 992 | 1232 | 950 | 775 |\n| 1203 | 1025 | 1096 | 808 | 1224 | 1044 |\n| 871 | 1164 | 971 | 950 | 866 | 738 |  \n（1）构造该批数据的频率分布表 (分 6 组);  \n(2) 画出直方图.  \n4. 某公司对其 250 名职工上班所需时间进行了调查, 下面是其不完整的额率分布表  \n| 所需时间/min | 频率 |\n| :---: | :---: |\n| $0 \\sim 10$ | 0.10 |\n| $10 \\sim 20$ | 0.24 |\n| $20 \\sim 30$ |  |\n| $30 \\sim 40$ | 0.18 |\n| $40 \\sim 50$ | 0.14 |  \n(1) 试将频率分布表补充完整.  \n(2) 该公司上班所需时间在半小时以内有多少人?  \n5. 40 种刊物的月发行量如下: (单位: 百册)",
        "metadata": {
            "Header 2": "习习题 5.2"
        },
        "type": "Document"
    },
    {
        "page_content": "| 1071 | 1081 | 1130 | 1336 | 967 | 1572 |\n| 825 | 914 | 992 | 1232 | 950 | 775 |\n| 1203 | 1025 | 1096 | 808 | 1224 | 1044 |\n| 871 | 1164 | 971 | 950 | 866 | 738 |  \n（1）构造该批数据的频率分布表 (分 6 组);  \n(2) 画出直方图.  \n4. 某公司对其 250 名职工上班所需时间进行了调查, 下面是其不完整的额率分布表  \n| 所需时间/min | 频率 |\n| :---: | :---: |\n| $0 \\sim 10$ | 0.10 |\n| $10 \\sim 20$ | 0.24 |\n| $20 \\sim 30$ |  |\n| $30 \\sim 40$ | 0.18 |\n| $40 \\sim 50$ | 0.14 |  \n(1) 试将频率分布表补充完整.  \n(2) 该公司上班所需时间在半小时以内有多少人?  \n5. 40 种刊物的月发行量如下: (单位: 百册)  \n| 5954 | 5022 | 14667 | 6582 | 6870 | 1840 | 2662 | 4508 |\n| ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |\n| 1208 | 3852 | 618 | 3008 | 1268 | 1978 | 7963 | 2048 |\n| 3077 | 993 | 353 | 14263 | 1714 | 11127 | 6926 | 2047 |\n| 714 | 5923 | 6006 | 14267 | 1697 | 13876 | 4001 | 2280 |\n| 1223 | 12579 | 13588 | 7315 | 4538 | 13304 | 1615 | 8612 |  \n(1) 建立该批数据的频数分布表, 取组距为 1700 百册.  \n(2) 画出直方图.  \n6. 对下列数据构造茎叶图:  \n| 472 | 425 | 447 | 377 | 341 | 369 | 412 | 419 |",
        "metadata": {
            "Header 2": "习习题 5.2"
        },
        "type": "Document"
    },
    {
        "page_content": "5. 40 种刊物的月发行量如下: (单位: 百册)  \n| 5954 | 5022 | 14667 | 6582 | 6870 | 1840 | 2662 | 4508 |\n| ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |\n| 1208 | 3852 | 618 | 3008 | 1268 | 1978 | 7963 | 2048 |\n| 3077 | 993 | 353 | 14263 | 1714 | 11127 | 6926 | 2047 |\n| 714 | 5923 | 6006 | 14267 | 1697 | 13876 | 4001 | 2280 |\n| 1223 | 12579 | 13588 | 7315 | 4538 | 13304 | 1615 | 8612 |  \n(1) 建立该批数据的频数分布表, 取组距为 1700 百册.  \n(2) 画出直方图.  \n6. 对下列数据构造茎叶图:  \n| 472 | 425 | 447 | 377 | 341 | 369 | 412 | 419 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 400 | 382 | 366 | 425 | 399 | 398 | 423 | 384 |\n| 418 | 392 | 372 | 418 | 374 | 385 | 439 | 428 |\n| 429 | 428 | 430 | 413 | 405 | 381 | 403 | 479 |\n| 381 | 443 | 441 | 433 | 419 | 379 | 386 | 387 |  \n7. 根据调查, 某集团公司的中层管理人员的年薪数据如下 (单位: 千元)  \n| 40.6 | 39.6 | 43.8 | 36.2 | 40.8 |\n| :--- | :--- | :--- | :--- | :--- |\n| 38.6 | 39.6 | 40.0 | 34.7 | 41.7 |  \n| 44.9 | 45.4 | 37.0 | 35.1 | 36.7 |\n| :--- | :--- | :--- | :--- | :--- |",
        "metadata": {
            "Header 2": "习习题 5.2"
        },
        "type": "Document"
    },
    {
        "page_content": "| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 400 | 382 | 366 | 425 | 399 | 398 | 423 | 384 |\n| 418 | 392 | 372 | 418 | 374 | 385 | 439 | 428 |\n| 429 | 428 | 430 | 413 | 405 | 381 | 403 | 479 |\n| 381 | 443 | 441 | 433 | 419 | 379 | 386 | 387 |  \n7. 根据调查, 某集团公司的中层管理人员的年薪数据如下 (单位: 千元)  \n| 40.6 | 39.6 | 43.8 | 36.2 | 40.8 |\n| :--- | :--- | :--- | :--- | :--- |\n| 38.6 | 39.6 | 40.0 | 34.7 | 41.7 |  \n| 44.9 | 45.4 | 37.0 | 35.1 | 36.7 |\n| :--- | :--- | :--- | :--- | :--- |\n| 37.1 | 37.7 | 39.2 | 36.9 | 44.5 |  \n试画出茎叶图。",
        "metadata": {
            "Header 2": "习习题 5.2"
        },
        "type": "Document"
    },
    {
        "page_content": "样本来自总体, 样本的观测值中含有总体各方面的信息, 但这些信息较为分散, 有时显得杂乱无章, 为将这些分散在样本中的有关总体的信息集中起来以反映总体的各种特征, 需要对样本进行加工, 表和图是一类加工形式, 它是人们从中获得对总体的初步认识. 当人们需要从样本获得对总体各种参数的认识时, 最常用的加工方法是构造样本的函数, 不同的函数反映总体的不同特征.  \n定义 5.3 .1 (统计量). 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 为取自某总体的样本, 若样本函数 $T=T\\left(x_{1}, x_{2}, \\cdots, x_{n}\\right)$ 中不含有任何未知参数, 则称 $T$ 为统计量. 统计量的分布称为 抽样分布.  \n按照这一定义, 若 $x_{1}, x_{2}, \\cdots, x_{n}$ 为样本, 则 $\\sum_{i=1}^{n} x_{i}, \\sum_{i=1}^{n} x_{i}^{2}$ 以及 5.2.1 节中的 $F_{n}(x)$ 都是统计量. 而当 $\\mu, \\sigma^{2}$ 未知时, $x_{1}-\\mu, x_{1} / \\sigma$ 等均不是统计量. 必须指出的是: 尽管统计量不依赖于未知参数, 但是它的分布一般是依赖于未知参数的.  \n下面几小节及 5.4 节我们介绍一些常见的统计量及其抽样分布.",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.1 统计量与抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 5.3 .2 (样本均值). 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 为取自某总体的样本, 其算术平均值为 样本均值, 一般用 $\\bar{x}$ 表示, 即  \n$$\n\\begin{equation*}\n\\bar{x}=\\frac{x_{1}+\\cdots+x_{n}}{n}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i} \\tag{5.3.1}\n\\end{equation*}\n$$  \n在分组样本场合, 样本均值的近似公式为  \n$$\n\\begin{equation*}\n\\bar{x}=\\frac{x_{1} f_{1}+\\cdots+x_{k} f_{k}}{n} \\quad\\left(n=\\sum_{i=1}^{k} f_{i}\\right) \\tag{5.3.2}\n\\end{equation*}\n$$  \n其中 $k$ 为组数, $x_{i}$ 为第 $i$ 组的组中值, $f_{i}$ 为第 $i$ 组的频数.  \n例 5.3.1：某单位收集到 20 名青年人的某月的娱乐支出费用数据:  \n| 79 | 84 | 84 | 88 | 92 | 93 | 94 | 97 | 98 | 99 |\n| ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |\n| 100 | 101 | 101 | 102 | 102 | 108 | 110 | 113 | 118 | 125 |  \n则该月这 20 名青年的平均娱乐支出为  \n$$\n\\bar{x}=\\frac{1}{20}(79+84+\\cdots+125)=99.4 .\n$$  \n将这 20 个数据分组可得到如表 5.3.1的频数频率分布:  \n表 5.3.1: 5.3.1的频数频率分布表  \n| 组序 | 分组区间 | 组中值 | 频数 | 频率 $/ \\%$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 1 | $(77,87]$ | 82 | 3 | 15 |\n| 2 | $(87,97]$ | 92 | 5 | 25 |\n| 3 | $(97,107]$ | 102 | 7 | 35 |",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.2 样本均值及其抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| 79 | 84 | 84 | 88 | 92 | 93 | 94 | 97 | 98 | 99 |\n| ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |\n| 100 | 101 | 101 | 102 | 102 | 108 | 110 | 113 | 118 | 125 |  \n则该月这 20 名青年的平均娱乐支出为  \n$$\n\\bar{x}=\\frac{1}{20}(79+84+\\cdots+125)=99.4 .\n$$  \n将这 20 个数据分组可得到如表 5.3.1的频数频率分布:  \n表 5.3.1: 5.3.1的频数频率分布表  \n| 组序 | 分组区间 | 组中值 | 频数 | 频率 $/ \\%$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 1 | $(77,87]$ | 82 | 3 | 15 |\n| 2 | $(87,97]$ | 92 | 5 | 25 |\n| 3 | $(97,107]$ | 102 | 7 | 35 |\n| 4 | $(107,117]$ | 112 | 3 | 15 |\n| 5 | $(117,127]$ | 122 | 2 | 10 |\n| 合计 |  |  | 20 | 100 |  \n对表 5.3.1 的分组样本, 使用公式 (5.3.2) 进行计算可得  \n$$\n\\bar{x}=\\frac{1}{20}(82 \\times 3+92 \\times 5+\\cdots+122 \\times 2)=100 .\n$$  \n我们看到两种计算结果不同. 事实上, 由于 (5.3.2) 式未用到真实的样本观测数据, 因而给出的是近似结果.  \n关于样本均值, 有如下几个性质.  \n定理 5.3.1. 若把样本中的数据与样本均值之差称为偏差, 则样本所有偏差之和为 0 , 即 $\\sum_{i=1}^{n}\\left(x_{i}-\\right.$ $\\bar{x})=0$.  \n证明: $\\sum\\left(x_{i}-\\bar{x}\\right)=\\sum x_{i}-n \\bar{x}=\\sum x_{i}-n \\cdot\\left(\\sum x_{i}\\right) / n=0$.",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.2 样本均值及其抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| 5 | $(117,127]$ | 122 | 2 | 10 |\n| 合计 |  |  | 20 | 100 |  \n对表 5.3.1 的分组样本, 使用公式 (5.3.2) 进行计算可得  \n$$\n\\bar{x}=\\frac{1}{20}(82 \\times 3+92 \\times 5+\\cdots+122 \\times 2)=100 .\n$$  \n我们看到两种计算结果不同. 事实上, 由于 (5.3.2) 式未用到真实的样本观测数据, 因而给出的是近似结果.  \n关于样本均值, 有如下几个性质.  \n定理 5.3.1. 若把样本中的数据与样本均值之差称为偏差, 则样本所有偏差之和为 0 , 即 $\\sum_{i=1}^{n}\\left(x_{i}-\\right.$ $\\bar{x})=0$.  \n证明: $\\sum\\left(x_{i}-\\bar{x}\\right)=\\sum x_{i}-n \\bar{x}=\\sum x_{i}-n \\cdot\\left(\\sum x_{i}\\right) / n=0$.  \n从均值的计算公式看, 它使用了所有的数据, 而且每一个数据在计算公式中处于平等的地位.所有数据与样本中心的误差被互相抵消, 从而样本的所有偏差之和必为零.  \n定理 5.3.2. 数据观察值与均值的偏差平方和最小, 即在形如 $\\sum\\left(x_{i}-c\\right)^{2}$ 的函数中, $\\sum\\left(x_{i}-\\bar{x}\\right)^{2}$ 最小, 其中 $c$ 为任意给定常数.  \n证明: 对任意给定的常数 $c$,  \n$$\n\\begin{aligned}\n& \\sum\\left(x_{i}-c\\right)^{2}=\\sum\\left(x_{i}-\\bar{x}+\\bar{x}-c\\right)^{2} \\\\\n= & \\sum\\left(x_{i}-\\bar{x}\\right)^{2}+n(\\bar{x}-c)^{2}+2 \\sum\\left(x_{i}-\\bar{x}\\right)(\\bar{x}-c) \\\\\n= & \\sum\\left(x_{i}-\\bar{x}\\right)^{2}+n(\\bar{x}-c)^{2} \\geqslant \\sum\\left(x_{i}-\\bar{x}\\right)^{2} .",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.2 样本均值及其抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "定理 5.3.2. 数据观察值与均值的偏差平方和最小, 即在形如 $\\sum\\left(x_{i}-c\\right)^{2}$ 的函数中, $\\sum\\left(x_{i}-\\bar{x}\\right)^{2}$ 最小, 其中 $c$ 为任意给定常数.  \n证明: 对任意给定的常数 $c$,  \n$$\n\\begin{aligned}\n& \\sum\\left(x_{i}-c\\right)^{2}=\\sum\\left(x_{i}-\\bar{x}+\\bar{x}-c\\right)^{2} \\\\\n= & \\sum\\left(x_{i}-\\bar{x}\\right)^{2}+n(\\bar{x}-c)^{2}+2 \\sum\\left(x_{i}-\\bar{x}\\right)(\\bar{x}-c) \\\\\n= & \\sum\\left(x_{i}-\\bar{x}\\right)^{2}+n(\\bar{x}-c)^{2} \\geqslant \\sum\\left(x_{i}-\\bar{x}\\right)^{2} .\n\\end{aligned}\n$$  \n下面考虑样本均值的分布.  \n例 5.3.2: 设有一个由 20 个数组成的总体, 现从该总体抽取容量为 5 的样本. 图 5.3.1 画出第一个样本的抽样过程, 左侧是该总体, 右侧是从总体中随机地抽出的样本, 这里一共抽出 4 个样本, 每个样本有 5 个观测值, 我们计算了各个样本的样本均值. 从例中可以看到, 每一个样本的样本均值都有差别.  \n!  \n设想类似抽取样本 5 、样本 $6 \\cdots \\cdots .$. 每次都计算样本均值, 他们之间的差异是由于抽样的随机性引起的. 假如无限制地抽下去, 这样我们可以得到大量的 $\\bar{x}$ 的值, 图 5.3 .2 就是用这样得到的 500 个的值所形成的直方图, 它反映了 $\\bar{x}$ 的抽样分布.  \n类似地, 样本方差也有一个抽样分布, 样本标准差也有一个抽样分布.  \n例 5.3.2 中我们给了样本均值的分布一个直观的描述, 下面是关于样本均值的抽样分布的一个重要结论.  \n定理 5.3.3. 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是来自某个总体的样本, $\\bar{x}$ 为样本均值.",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.2 样本均值及其抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "例 5.3.2: 设有一个由 20 个数组成的总体, 现从该总体抽取容量为 5 的样本. 图 5.3.1 画出第一个样本的抽样过程, 左侧是该总体, 右侧是从总体中随机地抽出的样本, 这里一共抽出 4 个样本, 每个样本有 5 个观测值, 我们计算了各个样本的样本均值. 从例中可以看到, 每一个样本的样本均值都有差别.  \n!  \n设想类似抽取样本 5 、样本 $6 \\cdots \\cdots .$. 每次都计算样本均值, 他们之间的差异是由于抽样的随机性引起的. 假如无限制地抽下去, 这样我们可以得到大量的 $\\bar{x}$ 的值, 图 5.3 .2 就是用这样得到的 500 个的值所形成的直方图, 它反映了 $\\bar{x}$ 的抽样分布.  \n类似地, 样本方差也有一个抽样分布, 样本标准差也有一个抽样分布.  \n例 5.3.2 中我们给了样本均值的分布一个直观的描述, 下面是关于样本均值的抽样分布的一个重要结论.  \n定理 5.3.3. 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是来自某个总体的样本, $\\bar{x}$ 为样本均值.  \n1. 若总体分布为 $N\\left(\\mu, \\sigma^{2}\\right)$, 则 $\\bar{x}$ 的精确分布为 $N\\left(\\mu, \\sigma^{2} / n\\right)$;\n2. 若总体分布位置或不是正态分布, 但 $E(x)=\\mu, \\operatorname{Var}(x)=\\sigma^{2}$, 则 $n$ 较大时 $\\bar{x}$ 的渐近分布为  \n!  \n图 5.3.2: 500 个样本均值形成的直方图  \n$N\\left(\\mu, \\sigma^{2}\\right)$, 常记为 $\\bar{x} \\dot{\\sim} N\\left(\\mu, \\sigma^{2} / n\\right)$. 这里渐近分布是指 $n$ 较大时的近似分布.证明:  \n1. 利用卷积公式, 可得知 $\\sum_{i=1}^{n} x_{i} \\sim N\\left(n \\mu, n \\sigma^{2}\\right)$, 由此可知 $\\bar{x} \\sim N\\left(\\mu, \\sigma^{2} / n\\right)$",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.2 样本均值及其抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 若总体分布为 $N\\left(\\mu, \\sigma^{2}\\right)$, 则 $\\bar{x}$ 的精确分布为 $N\\left(\\mu, \\sigma^{2} / n\\right)$;\n2. 若总体分布位置或不是正态分布, 但 $E(x)=\\mu, \\operatorname{Var}(x)=\\sigma^{2}$, 则 $n$ 较大时 $\\bar{x}$ 的渐近分布为  \n!  \n图 5.3.2: 500 个样本均值形成的直方图  \n$N\\left(\\mu, \\sigma^{2}\\right)$, 常记为 $\\bar{x} \\dot{\\sim} N\\left(\\mu, \\sigma^{2} / n\\right)$. 这里渐近分布是指 $n$ 较大时的近似分布.证明:  \n1. 利用卷积公式, 可得知 $\\sum_{i=1}^{n} x_{i} \\sim N\\left(n \\mu, n \\sigma^{2}\\right)$, 由此可知 $\\bar{x} \\sim N\\left(\\mu, \\sigma^{2} / n\\right)$\n2. 由中心极限定理, $\\sqrt{n}(\\bar{x}-\\mu) / \\sigma \\xrightarrow{L} N(0,1)$, 这表明 $n$ 较大时 $\\bar{x}$ 的渐近分布为 $N\\left(\\mu, \\sigma^{2} / n\\right)$, 证毕.  \n例 5.3.3: 图 5.3.3 给出三个不同总体样本均值的分布. 三个总体分别是: (1)均匀分布、(2)倒三角分布、(3)指数分布, 随着样本量的增加, 样本均值的抽样分布逐渐向正态分布逼近, 他们均值保持不变, 而方差则缩小为原来的 $1 / n$. 当样本量为 30 时, 我们看到三个抽样分布都近似于正态分布. 下面对之进行说明.  \n!  \n图 5.3.3: 不同总体样本均值的分布  \n(1)的总体分布为均匀分布 $U(1,5)$, 该总体的均值和方差分别为 3 和 $4 / 3$, 若从该总体抽取样本容量为 30 的样本, 则其样本均值的渐近分布为  \n$$\n\\bar{x}_{1} \\dot{\\sim} N\\left(3, \\frac{4}{3 \\times 40}\\right)=N\\left(3,0.21^{2}\\right)",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.2 样本均值及其抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "例 5.3.3: 图 5.3.3 给出三个不同总体样本均值的分布. 三个总体分别是: (1)均匀分布、(2)倒三角分布、(3)指数分布, 随着样本量的增加, 样本均值的抽样分布逐渐向正态分布逼近, 他们均值保持不变, 而方差则缩小为原来的 $1 / n$. 当样本量为 30 时, 我们看到三个抽样分布都近似于正态分布. 下面对之进行说明.  \n!  \n图 5.3.3: 不同总体样本均值的分布  \n(1)的总体分布为均匀分布 $U(1,5)$, 该总体的均值和方差分别为 3 和 $4 / 3$, 若从该总体抽取样本容量为 30 的样本, 则其样本均值的渐近分布为  \n$$\n\\bar{x}_{1} \\dot{\\sim} N\\left(3, \\frac{4}{3 \\times 40}\\right)=N\\left(3,0.21^{2}\\right)\n$$  \n(2)的总体分布的概率密度函数为  \n$$\np(x)= \\begin{cases}(3-x) / 4, & 1 \\leqslant x<3 ; \\\\ (x-3) / 4, & 3 \\leqslant x \\leqslant 5 ; \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n这是一个倒三角分布, 可以算得其均值与方差分别为 3 和 2 , 若从该总体抽取样本容量为 30 的样本, 则其样本均值的渐近分布为  \n$$\n\\bar{x}_{2} \\dot{\\sim} N\\left(3, \\frac{2}{30}\\right)=N\\left(3,0.26^{2}\\right)\n$$  \n(3)的总体分布为指数分布 $\\operatorname{Exp}(1)$, 其均值与方差都等于 1, 若从该总体抽取样本容量为 30 的样本, 则其样本均值 $\\bar{x}_{3}$ 的分布近似为  \n$$\n\\bar{x}_{3} \\dot{\\sim} N\\left(1, \\frac{1}{30}\\right)=N\\left(1,0.18^{2}\\right) .\n$$  \n这三个总体都不是正态分布, 但其样本均值的分布都十分近似于正态分布, 差别表现在均值与标准差上. 图 5.3.3 所示曲线既展示它们的共同之处, 又显示它们之间的差别.",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.2 样本均值及其抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 5.3.3. 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 为取自某总体的样本, 则它关于样本均值 $\\bar{x}$ 的平均偏差平方和  \n$$\n\\begin{equation*}\ns^{* 2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2} \\tag{5.3.3}\n\\end{equation*}\n$$  \n称为 样本方差. 其算术根 $s^{*}=\\sqrt{s^{* 2}}$ 称为样本标准差. 相对样本方差而言, 样本标准差通常更有实际意义, 因为它与样本均值具有相同的度量单位. 在 $n$ 不大时, 常用  \n$$\n\\begin{equation*}\ns^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2} \\tag{5.3.4}\n\\end{equation*}\n$$  \n作为样本方差 (也称无偏方差, 其含义在第六章讲述), 其算术根 $s=\\sqrt{s^{2}}$ 也称为样本标准差.在实际中, $s^{2}$ 比 $s^{* 2}$ 更常用, 在以后讲样本方差通常指的是 $s^{2}$.  \n在这个定义中, $n$ 为 样本量, $\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}$ 称为偏差平方和, $n-1$ 称为偏差平方和的自由度.其含义是: 在 $\\bar{x}$ 确定后, $n$ 个偏差 $x_{1}-\\bar{x}, x_{2}-\\bar{x}, \\cdots, x_{n}-\\bar{x}$ 中只有 $n-1$ 个数据可以自由变动, 而第 $n$ 个则不能自由取值, 因为 $\\sum\\left(x_{i}-\\bar{x}\\right)=0$.  \n样本偏差平方和有三个不同的表达式:  \n$$\n\\begin{equation*}\n\\sum\\left(x_{i}-\\bar{x}\\right)^{2}=\\sum x_{i}^{2}-\\frac{\\left(\\sum x_{i}\\right)^{2}}{n}=\\sum x_{i}^{2}-n \\bar{x}^{2} . \\tag{5.3.5}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.3 样本方差与样本标准差"
        },
        "type": "Document"
    },
    {
        "page_content": "在这个定义中, $n$ 为 样本量, $\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}$ 称为偏差平方和, $n-1$ 称为偏差平方和的自由度.其含义是: 在 $\\bar{x}$ 确定后, $n$ 个偏差 $x_{1}-\\bar{x}, x_{2}-\\bar{x}, \\cdots, x_{n}-\\bar{x}$ 中只有 $n-1$ 个数据可以自由变动, 而第 $n$ 个则不能自由取值, 因为 $\\sum\\left(x_{i}-\\bar{x}\\right)=0$.  \n样本偏差平方和有三个不同的表达式:  \n$$\n\\begin{equation*}\n\\sum\\left(x_{i}-\\bar{x}\\right)^{2}=\\sum x_{i}^{2}-\\frac{\\left(\\sum x_{i}\\right)^{2}}{n}=\\sum x_{i}^{2}-n \\bar{x}^{2} . \\tag{5.3.5}\n\\end{equation*}\n$$  \n它们都可用来计算样本方差.  \n在分组样本场合, 样本方差的近似计算公式为  \n$$\n\\begin{equation*}\ns^{2}=\\frac{1}{n-1} \\sum_{i=1}^{k} f_{i}\\left(x_{i}-\\bar{x}\\right)^{2}=\\frac{1}{n-1}\\left[\\sum_{i=1}^{k} f_{i} x_{i}^{2}-n \\bar{x}^{2}\\right] \\tag{5.3.6}\n\\end{equation*}\n$$  \n其中 $x_{i}, f_{i}$ 分别为第 $i$ 个区间的组中值和频数, $\\bar{x}$ 为 (5.3.2) 中给出的样本均值.  \n例 5.3.4: 考察例 5.3.1 的样本, 我们已经算得 $\\bar{x}=99.4$, 其样本方差与样本标准差分别为  \n$$\n\\begin{aligned}\ns^{2} & =\\frac{1}{20-1}\\left[(79-99.4)^{2}+(84-99.4)^{2}+\\cdots+(125-99.4)^{2}\\right] 133.9368 \\\\\ns & =\\sqrt{133.9368}=11.5731\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.3 样本方差与样本标准差"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\ns^{2}=\\frac{1}{n-1} \\sum_{i=1}^{k} f_{i}\\left(x_{i}-\\bar{x}\\right)^{2}=\\frac{1}{n-1}\\left[\\sum_{i=1}^{k} f_{i} x_{i}^{2}-n \\bar{x}^{2}\\right] \\tag{5.3.6}\n\\end{equation*}\n$$  \n其中 $x_{i}, f_{i}$ 分别为第 $i$ 个区间的组中值和频数, $\\bar{x}$ 为 (5.3.2) 中给出的样本均值.  \n例 5.3.4: 考察例 5.3.1 的样本, 我们已经算得 $\\bar{x}=99.4$, 其样本方差与样本标准差分别为  \n$$\n\\begin{aligned}\ns^{2} & =\\frac{1}{20-1}\\left[(79-99.4)^{2}+(84-99.4)^{2}+\\cdots+(125-99.4)^{2}\\right] 133.9368 \\\\\ns & =\\sqrt{133.9368}=11.5731\n\\end{aligned}\n$$  \n对表 5.3.1 的分组样本, 我们可以如表 5.3.2 计算 (样本均值也由分组样本计算): 于是 $\\bar{x}=\\frac{2000}{20}=$ $100, s^{2}=\\frac{2720}{20-1}=143.16, s=\\sqrt{143.16}=11.96$.  \n下面的定理给出样本均值的数学期望和方差以及样本方差的数学期望, 它不依赖于总体的分  \n| 表 5.3.2: 分组样本方差的计算表 |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| 组中值 $x$ | $x f$ | $x-\\bar{x}$ | $(x-\\bar{x})^{2} f$ |  |\n| 82 | 频数 $f$ | 246 | -18 | 972 |\n| 92 | 3 | 460 | -8 | 320 |\n| 102 | 5 | 714 | 2 | 28 |\n| 112 | 7 | 336 | 12 | 432 |\n| 122 | 3 | 244 | 22 | 968 |\n| 和 | 2 | 2000 |  | 2720 |",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.3 样本方差与样本标准差"
        },
        "type": "Document"
    },
    {
        "page_content": "对表 5.3.1 的分组样本, 我们可以如表 5.3.2 计算 (样本均值也由分组样本计算): 于是 $\\bar{x}=\\frac{2000}{20}=$ $100, s^{2}=\\frac{2720}{20-1}=143.16, s=\\sqrt{143.16}=11.96$.  \n下面的定理给出样本均值的数学期望和方差以及样本方差的数学期望, 它不依赖于总体的分  \n| 表 5.3.2: 分组样本方差的计算表 |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| 组中值 $x$ | $x f$ | $x-\\bar{x}$ | $(x-\\bar{x})^{2} f$ |  |\n| 82 | 频数 $f$ | 246 | -18 | 972 |\n| 92 | 3 | 460 | -8 | 320 |\n| 102 | 5 | 714 | 2 | 28 |\n| 112 | 7 | 336 | 12 | 432 |\n| 122 | 3 | 244 | 22 | 968 |\n| 和 | 2 | 2000 |  | 2720 |  \n布形式. 这些结果在后面的讨论中是有用的.  \n定理 5.3.4. 设总体 $X$ 具有二阶矩, 即 $E(X)=\\mu, \\operatorname{Var}(X)=\\sigma^{2}<+\\infty, x_{1}, x_{2}, \\cdots, x_{n}$ 为从该总体得到的样本, $\\bar{x}$ 和 $s^{2}$ 分别是样本均值和样本方差, 则  \n$$\n\\begin{gather*}\nE(\\bar{x})=\\mu, \\quad \\operatorname{Var}(\\bar{x})=\\sigma^{2} / n,  \\tag{5.3.7}\\\\\nE\\left(s^{2}\\right)=\\sigma^{2} . \\tag{5.3.8}\n\\end{gather*}\n$$  \n此定理表明, 样本均值的均值与总体均值相同, 而样本均值的方差是总体方差的 $1 / n$.证明: 由于  \n$$\n\\begin{gathered}",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.3 样本方差与样本标准差"
        },
        "type": "Document"
    },
    {
        "page_content": "| 122 | 3 | 244 | 22 | 968 |\n| 和 | 2 | 2000 |  | 2720 |  \n布形式. 这些结果在后面的讨论中是有用的.  \n定理 5.3.4. 设总体 $X$ 具有二阶矩, 即 $E(X)=\\mu, \\operatorname{Var}(X)=\\sigma^{2}<+\\infty, x_{1}, x_{2}, \\cdots, x_{n}$ 为从该总体得到的样本, $\\bar{x}$ 和 $s^{2}$ 分别是样本均值和样本方差, 则  \n$$\n\\begin{gather*}\nE(\\bar{x})=\\mu, \\quad \\operatorname{Var}(\\bar{x})=\\sigma^{2} / n,  \\tag{5.3.7}\\\\\nE\\left(s^{2}\\right)=\\sigma^{2} . \\tag{5.3.8}\n\\end{gather*}\n$$  \n此定理表明, 样本均值的均值与总体均值相同, 而样本均值的方差是总体方差的 $1 / n$.证明: 由于  \n$$\n\\begin{gathered}\nE(\\bar{x})=\\frac{1}{n} E\\left(\\sum_{i=1}^{n} x_{i}\\right)=\\frac{n \\mu}{n}=\\mu, \\\\\n\\operatorname{Var}(\\bar{x})=\\frac{1}{n^{2}} \\operatorname{Var}\\left(\\sum_{i=1}^{n} x_{i}\\right)=\\frac{n \\sigma^{2}}{n^{2}}=\\frac{\\sigma^{2}}{n},\n\\end{gathered}\n$$  \n故 (5.3.7) 成立. 下证 (5.3.8), 注意到  \n$$\n\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}=\\sum_{i=1}^{n} x_{i}^{2}-n \\bar{x}^{2}\n$$",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.3 样本方差与样本标准差"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{gather*}\n$$  \n此定理表明, 样本均值的均值与总体均值相同, 而样本均值的方差是总体方差的 $1 / n$.证明: 由于  \n$$\n\\begin{gathered}\nE(\\bar{x})=\\frac{1}{n} E\\left(\\sum_{i=1}^{n} x_{i}\\right)=\\frac{n \\mu}{n}=\\mu, \\\\\n\\operatorname{Var}(\\bar{x})=\\frac{1}{n^{2}} \\operatorname{Var}\\left(\\sum_{i=1}^{n} x_{i}\\right)=\\frac{n \\sigma^{2}}{n^{2}}=\\frac{\\sigma^{2}}{n},\n\\end{gathered}\n$$  \n故 (5.3.7) 成立. 下证 (5.3.8), 注意到  \n$$\n\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}=\\sum_{i=1}^{n} x_{i}^{2}-n \\bar{x}^{2}\n$$  \n而 $E x_{i}^{2}=\\left(E x_{i}\\right)^{2}+\\operatorname{Var}\\left(x_{i}\\right)=\\mu^{2}+\\sigma^{2}, E\\left(\\bar{x}^{2}\\right)=(E \\bar{x})^{2}+(\\operatorname{Var})(\\bar{x})=\\mu^{2}+\\sigma^{2} / n$, 于是  \n$$\nE\\left(\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}\\right)=n\\left(\\mu^{2}+\\sigma^{2}\\right)-n\\left(\\mu^{2}+\\sigma^{2} / n\\right)=(n-1) \\sigma^{2}\n$$  \n两边各除以 $n-1$, 即得 (5.3.8).",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.3 样本方差与样本标准差"
        },
        "type": "Document"
    },
    {
        "page_content": "样本均值和样本方差的更一般的推广是样本矩, 这是一类常见的统计量.  \n定义 5.3.4. 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 则统计量  \n$$\n\\begin{equation*}\na_{k}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}^{k} \\tag{5.3.9}\n\\end{equation*}\n$$  \n称为样本 $k$ 阶原点矩. 特别, 样本一阶原点矩就是样本均值. 统计量  \n$$\n\\begin{equation*}\nb_{k}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{k} \\tag{5.3.10}\n\\end{equation*}\n$$  \n称为样本 $k$ 阶中心矩. 特别, 样本二阶中心矩就是样本方差.  \n当总体关于分布中心对称时, 我们用 $\\bar{x}$ 和 $s$ 刻画样本特征很有代表性, 而当其不对称时, 只用 $\\bar{x}, s$ 就显得很不够. 为此, 需要一些刻画分布形状的统计量. 这里我们介绍样本偏度和样本峰度, 它们都是样本中心矩的函数.\n定义 5.3.5. 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 则称统计量  \n$$\n\\begin{equation*}\n\\gamma_{1}=b_{3} / b_{2}^{3 / 2} \\tag{5.3.11}\n\\end{equation*}\n$$  \n为样本偏度.",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.4 样本矩及其函数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n称为样本 $k$ 阶原点矩. 特别, 样本一阶原点矩就是样本均值. 统计量  \n$$\n\\begin{equation*}\nb_{k}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{k} \\tag{5.3.10}\n\\end{equation*}\n$$  \n称为样本 $k$ 阶中心矩. 特别, 样本二阶中心矩就是样本方差.  \n当总体关于分布中心对称时, 我们用 $\\bar{x}$ 和 $s$ 刻画样本特征很有代表性, 而当其不对称时, 只用 $\\bar{x}, s$ 就显得很不够. 为此, 需要一些刻画分布形状的统计量. 这里我们介绍样本偏度和样本峰度, 它们都是样本中心矩的函数.\n定义 5.3.5. 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 则称统计量  \n$$\n\\begin{equation*}\n\\gamma_{1}=b_{3} / b_{2}^{3 / 2} \\tag{5.3.11}\n\\end{equation*}\n$$  \n为样本偏度.  \n样本偏度 $\\gamma_{1}$ 反映了总体分布密度曲线的对称性信息. 如果数据完全对称, 则不难看出 $b_{3}=0$.对不对称的数据则 $b_{3}=0$. 这里用 $b_{3}$ 除以 $b_{2}^{3 / 2}$ 是为了消除量纲的影响, $\\gamma_{1}$ 是个相对数, 它很好地刻画了数据分布的偏斜方向和程度. 如果 $\\gamma_{1}$ 表示样本对称 (见图 5.3.4a), 如果 $\\gamma_{1}>0$ 表示样本的右尾长, 即样本中有几个较大的数, 这反映总体分布是正偏的或右偏的 (见图 $5.3 .4 \\mathrm{~b}$ ), 如果 $\\gamma_{1}<0$表示分布的左尾长, 即样本中有几个特小的数, 这反映总体分布是负偏的或左偏的 (见图 5.3.4c).  \n!  \n(a) 样本 $(4,7,8,9,12)$ 的偏度  \n!  \n(b) 样本 $(7,8,9,12,15)$ 的偏度  \n!  \n(c) 样本 $(1,4,7,8,9)$ 的偏度  \n图 5.3.4: 样本偏度 $\\gamma_{1}$ 的例子 (样本量 $n=5$ )",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.4 样本矩及其函数"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n(a) 样本 $(4,7,8,9,12)$ 的偏度  \n!  \n(b) 样本 $(7,8,9,12,15)$ 的偏度  \n!  \n(c) 样本 $(1,4,7,8,9)$ 的偏度  \n图 5.3.4: 样本偏度 $\\gamma_{1}$ 的例子 (样本量 $n=5$ )  \n定义 5.3.6. 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 则统计量  \n$$\n\\begin{equation*}\n\\gamma_{2}=\\frac{b_{4}}{b_{2}^{2}}-3 \\tag{5.3.12}\n\\end{equation*}\n$$  \n为样本峰度.  \n样本峰度 $\\gamma_{2}$ 反映了总体分布密度曲线在其峰值附近的陡峭程度. 当 $\\gamma_{2}>0$ 时, 分布密度曲线在其峰值附近比正态分布来得陡, 称为尖顶型; 当 $\\gamma_{2}<0$ 时, 分布密度曲线在其峰值附近比正态分布来得平坦, 称为平顶型.  \n例 5.3.5: 表 5.3.3 是两个班 (每班 50 名同学) 的英语课程的考试成绩.  \n表 5.3.3: 两个班级的英语成绩  \n| 成绩 | 组中值 | 甲班人数 $f_{\\text {甲 }}$ | 乙班人数 $f_{\\text {乙 }}$ |\n| :---: | :---: | :---: | :---: |\n| $90 \\sim 100$ | 95 | 5 | 4 |\n| $80 \\sim 89$ | 85 | 10 | 14 |\n| $70 \\sim 79$ | 75 | 22 | 16 |\n| $60 \\sim 69$ | 65 | 11 | 14 |\n| $50 \\sim 59$ | 55 | 1 | 2 |\n| $40 \\sim 49$ | 45 | 1 | 0 |  \n下面我们分别计算两个班级的平均成绩、标准差、样本偏度及样本峰度. 表 5.3.4 和表 5.3.5 分别给出甲班和乙班的计算过程. 可算得两个班的平均成绩、标准差、偏态系数、峰态系数分别为:  \n表 5.3.4: 甲班成绩的计算过程",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.4 样本矩及其函数"
        },
        "type": "Document"
    },
    {
        "page_content": "例 5.3.5: 表 5.3.3 是两个班 (每班 50 名同学) 的英语课程的考试成绩.  \n表 5.3.3: 两个班级的英语成绩  \n| 成绩 | 组中值 | 甲班人数 $f_{\\text {甲 }}$ | 乙班人数 $f_{\\text {乙 }}$ |\n| :---: | :---: | :---: | :---: |\n| $90 \\sim 100$ | 95 | 5 | 4 |\n| $80 \\sim 89$ | 85 | 10 | 14 |\n| $70 \\sim 79$ | 75 | 22 | 16 |\n| $60 \\sim 69$ | 65 | 11 | 14 |\n| $50 \\sim 59$ | 55 | 1 | 2 |\n| $40 \\sim 49$ | 45 | 1 | 0 |  \n下面我们分别计算两个班级的平均成绩、标准差、样本偏度及样本峰度. 表 5.3.4 和表 5.3.5 分别给出甲班和乙班的计算过程. 可算得两个班的平均成绩、标准差、偏态系数、峰态系数分别为:  \n表 5.3.4: 甲班成绩的计算过程  \n| $x$ | $f_{\\text {甲 }}$ | $x \\cdot f_{\\text {甲 }}$ | $\\left(x-\\bar{x}_{\\square}\\right)^{2} f_{\\text {甲 }}$ | $\\left(x-\\bar{x}_{\\square}\\right)^{3} f_{\\text {甲 }}$ | $\\left(x-\\bar{x}_{\\square}\\right)^{4} f_{\\text {甲 }}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 95 | 5 | 475 | 1843.20 | 35389.440 | 679477.2480 |\n| 85 | 10 | 850 | 846.40 | 7786.880 | 71639.2960 |\n| 75 | 22 | 1650 | 14.08 | -11.264 | 9.0112 |\n| 65 | 11 | 715 | 1283.04 | -13856.832 | 149653.7856 |\n| 55 | 1 | 55 | 432.64 | -8998.912 | 187177.3696 |",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.4 样本矩及其函数"
        },
        "type": "Document"
    },
    {
        "page_content": "| :---: | :---: | :---: | :---: | :---: | :---: |\n| 95 | 5 | 475 | 1843.20 | 35389.440 | 679477.2480 |\n| 85 | 10 | 850 | 846.40 | 7786.880 | 71639.2960 |\n| 75 | 22 | 1650 | 14.08 | -11.264 | 9.0112 |\n| 65 | 11 | 715 | 1283.04 | -13856.832 | 149653.7856 |\n| 55 | 1 | 55 | 432.64 | -8998.912 | 187177.3696 |\n| 45 | 1 | 45 | 948.64 | -29218.112 | 899917.8496 |\n| 和 | 50 | 3790 | 5368 | -8908.8 | 1987874.56 |  \n表 5.3.5: 乙班成绩的计算过程  \n| $x$ | $f_{\\text {乙 }}$ | $x \\cdot f_{\\text {乙 }}$ | $\\left(x-\\bar{x}_{\\square}\\right)^{2} f_{\\text {乙 }}$ | $\\left(x-\\bar{x}_{\\square}\\right)^{3} f_{\\text {乙 }}$ | $\\left(x-\\bar{x}_{\\square}\\right)^{4} f_{\\text {乙 }}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 95 | 4 | 380 | 1474.56 | 28311.552 | 543581.7984 |\n| 85 | 14 | 1190 | 1184.96 | 10901.632 | 100295.0144 |\n| 75 | 16 | 1200 | 10.24 | -8.192 | 6.5536 |\n| 65 | 14 | 910 | 1632.96 | -17635.968 | 190468.4544 |\n| 55 | 2 | 110 | 865.28 | -17997.824 | 374354.7392 |",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.4 样本矩及其函数"
        },
        "type": "Document"
    },
    {
        "page_content": "| :---: | :---: | :---: | :---: | :---: | :---: |\n| 95 | 4 | 380 | 1474.56 | 28311.552 | 543581.7984 |\n| 85 | 14 | 1190 | 1184.96 | 10901.632 | 100295.0144 |\n| 75 | 16 | 1200 | 10.24 | -8.192 | 6.5536 |\n| 65 | 14 | 910 | 1632.96 | -17635.968 | 190468.4544 |\n| 55 | 2 | 110 | 865.28 | -17997.824 | 374354.7392 |\n| 和 | 50 | 3790 | 5168 | 3571.2 | 1208706.56 |  \n$$\n\\begin{array}{cc}\n\\bar{x}_{\\text {甲 }}=\\frac{3790}{50}=75.8, & \\bar{x}_{\\text {乙 }}=\\frac{3790}{50}=75.8, \\\\\ns_{\\text {甲 }}=\\sqrt{\\frac{5368}{49}=10.47,} & s_{\\text {乙 }}=\\sqrt{\\frac{5168}{49}}=10.27, \\\\\n\\gamma_{\\text {甲 }}=\\frac{-8908.8 / 50}{(5368 / 50)^{3 / 2}}=-0.16, & \\gamma_{1 乙}=\\frac{3571.2 / 50}{(5168 / 50)^{3 / 2}}=0.068, \\\\\n\\gamma_{2 \\text { 甲 }}=\\frac{1987874.56 / 50}{(5368 / 50)^{2}}-3=0.45, & \\gamma_{2 \\square}=\\frac{1208706.56 / 50}{(5168 / 50)^{2}}-3=-0.74 .\n\\end{array}\n$$",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.4 样本矩及其函数"
        },
        "type": "Document"
    },
    {
        "page_content": "除了样本矩以外, 另一类常见的统计量是 次序统计量, 它在实际和理论中都有广泛的应用.  \n一、定义  \n定义 5.3.7. 设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是取自总体 $\\mathrm{X}$ 的样本, $x_{(i)}$ 称为该样本的第 $i$ 个次序统计量, 它的取值是将样本观测值由小到大排列后得到的第 $i$ 个观测值. 其中 $x_{(1)}=\\min \\left\\{x_{1}, \\cdots, x_{n}\\right\\}$ 称为该样本的 最小次序统计量, $x_{(n)}=\\max \\left\\{x_{1}, \\cdots, x_{n}\\right\\}$ 称为该样本的 最大次序统计量.  \n在一个 (简单随机) 样本中, $x_{1}, x_{2}, \\cdots, x_{n}$ 是独立同分布的, 而次序统计量 $x_{(1)}, x_{(2)}, \\cdots, x_{(n)}$则既不独立, 分布也不相同, 看下例.  \n例 5.3.6: 设总体 $X$ 的分布为仅取 $0,1,2$ 的离散均匀分布, 分布列为  \n| $x$ | 0 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $p$ | $1 / 3$ | $1 / 3$ | $1 / 3$ |  \n现从中抽取容量为 3 的样本, 其一切可能取值有 $3^{3}=27$ 种, 现将它们列在表 5.3.6 左侧, 其右侧相应的次序统计量观测值.  \n表 5.3.6: 例 5.3.6 中样本取值及其次序统计量  \n| $x_{1}$ | $x_{2}$ | $x_{3}$ | $x_{(1)}$ | $x_{(2)}$ | $x_{(3)}$ | $x_{1}$ | $x_{2}$ | $x_{3}$ | $x_{(1)}$ | $x_{(2)}$ | $x_{(3)}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 0 | 0 | 1 | 2 |",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| $x$ | 0 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $p$ | $1 / 3$ | $1 / 3$ | $1 / 3$ |  \n现从中抽取容量为 3 的样本, 其一切可能取值有 $3^{3}=27$ 种, 现将它们列在表 5.3.6 左侧, 其右侧相应的次序统计量观测值.  \n表 5.3.6: 例 5.3.6 中样本取值及其次序统计量  \n| $x_{1}$ | $x_{2}$ | $x_{3}$ | $x_{(1)}$ | $x_{(2)}$ | $x_{(3)}$ | $x_{1}$ | $x_{2}$ | $x_{3}$ | $x_{(1)}$ | $x_{(2)}$ | $x_{(3)}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 0 | 0 | 1 | 2 |\n| 0 | 0 | 1 | 0 | 0 | 1 | 2 | 1 | 0 | 0 | 1 | 2 |\n| 0 | 1 | 0 | 0 | 0 | 1 | 0 | 2 | 2 | 0 | 2 | 2 |\n| 1 | 0 | 0 | 0 | 0 | 1 | 2 | 0 | 2 | 0 | 2 | 2 |\n| 0 | 0 | 2 | 0 | 0 | 2 | 2 | 2 | 0 | 0 | 2 | 2 |\n| 0 | 2 | 0 | 0 | 0 | 2 | 1 | 1 | 2 | 1 | 1 | 2 |\n| 2 | 0 | 0 | 0 | 0 | 2 | 1 | 2 | 1 | 1 | 1 | 2 |\n| 0 | 1 | 1 | 0 | 1 | 1 | 2 | 1 | 1 | 1 | 1 | 2 |\n| 1 | 0 | 1 | 0 | 1 | 1 | 1 | 2 | 2 | 1 | 2 | 2 |\n| 1 | 1 | 0 | 0 | 1 | 1 | 2 | 1 | 2 | 1 | 2 | 2 |\n| 0 | 1 | 2 | 0 | 1 | 2 | 2 | 2 | 1 | 1 | 2 | 2 |",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| 0 | 0 | 1 | 0 | 0 | 1 | 2 | 1 | 0 | 0 | 1 | 2 |\n| 0 | 1 | 0 | 0 | 0 | 1 | 0 | 2 | 2 | 0 | 2 | 2 |\n| 1 | 0 | 0 | 0 | 0 | 1 | 2 | 0 | 2 | 0 | 2 | 2 |\n| 0 | 0 | 2 | 0 | 0 | 2 | 2 | 2 | 0 | 0 | 2 | 2 |\n| 0 | 2 | 0 | 0 | 0 | 2 | 1 | 1 | 2 | 1 | 1 | 2 |\n| 2 | 0 | 0 | 0 | 0 | 2 | 1 | 2 | 1 | 1 | 1 | 2 |\n| 0 | 1 | 1 | 0 | 1 | 1 | 2 | 1 | 1 | 1 | 1 | 2 |\n| 1 | 0 | 1 | 0 | 1 | 1 | 1 | 2 | 2 | 1 | 2 | 2 |\n| 1 | 1 | 0 | 0 | 1 | 1 | 2 | 1 | 2 | 1 | 2 | 2 |\n| 0 | 1 | 2 | 0 | 1 | 2 | 2 | 2 | 1 | 1 | 2 | 2 |\n| 0 | 2 | 1 | 0 | 1 | 2 | 1 | 1 | 1 | 1 | 1 | 1 |\n| 1 | 0 | 2 | 0 | 1 | 2 | 2 | 2 | 2 | 2 | 2 | 2 |\n| 2 | 0 | 1 | 0 | 1 | 2 |  |  |  |  |  |  |  \n由于样本取上述每一组观测值的概率相同, 都为 $1 / 27$, 由此可给出 $x_{(1)}, x_{(2)}, x_{(3)}$ 的分布列如下:  \n| $x_{(1)}$ | 0 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $p$ | $\\frac{19}{27}$ | $\\frac{7}{27}$ | $\\frac{1}{27}$ |  \n| $x_{(2)}$ | 0 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $p$ | $\\frac{7}{27}$ | $\\frac{13}{27}$ | $\\frac{7}{27}$ |  \n| $x_{(3)}$ | 0 | 1 | 2 |",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| 0 | 2 | 1 | 0 | 1 | 2 | 1 | 1 | 1 | 1 | 1 | 1 |\n| 1 | 0 | 2 | 0 | 1 | 2 | 2 | 2 | 2 | 2 | 2 | 2 |\n| 2 | 0 | 1 | 0 | 1 | 2 |  |  |  |  |  |  |  \n由于样本取上述每一组观测值的概率相同, 都为 $1 / 27$, 由此可给出 $x_{(1)}, x_{(2)}, x_{(3)}$ 的分布列如下:  \n| $x_{(1)}$ | 0 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $p$ | $\\frac{19}{27}$ | $\\frac{7}{27}$ | $\\frac{1}{27}$ |  \n| $x_{(2)}$ | 0 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $p$ | $\\frac{7}{27}$ | $\\frac{13}{27}$ | $\\frac{7}{27}$ |  \n| $x_{(3)}$ | 0 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $p$ | $\\frac{1}{27}$ | $\\frac{7}{27}$ | $\\frac{19}{27}$ |  \n我们可以清楚地看到这三个次序统计量的分布是不相同的.  \n进一步, 我们可以给出两个次序统计量的联合分布, 如, $x_{(1)}$ 和 $x_{(2)}$ 的联合分布列为  \n| $x_{(1)}$ | $x_{(2)}$ |  |  |\n| :---: | :---: | :---: | :---: |\n|  | 1 | 2 | 3 |\n| 0 | $7 / 27$ | $9 / 27$ | $3 / 27$ |\n| 1 | 0 | $4 / 27$ | $3 / 27$ |\n| 2 | 0 | 0 | $1 / 27$ |",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| :---: | :---: | :---: | :---: |\n| $p$ | $\\frac{7}{27}$ | $\\frac{13}{27}$ | $\\frac{7}{27}$ |  \n| $x_{(3)}$ | 0 | 1 | 2 |\n| :---: | :---: | :---: | :---: |\n| $p$ | $\\frac{1}{27}$ | $\\frac{7}{27}$ | $\\frac{19}{27}$ |  \n我们可以清楚地看到这三个次序统计量的分布是不相同的.  \n进一步, 我们可以给出两个次序统计量的联合分布, 如, $x_{(1)}$ 和 $x_{(2)}$ 的联合分布列为  \n| $x_{(1)}$ | $x_{(2)}$ |  |  |\n| :---: | :---: | :---: | :---: |\n|  | 1 | 2 | 3 |\n| 0 | $7 / 27$ | $9 / 27$ | $3 / 27$ |\n| 1 | 0 | $4 / 27$ | $3 / 27$ |\n| 2 | 0 | 0 | $1 / 27$ |  \n因为 $P\\left(x_{(1)}=0\\right) P\\left(x_{(2)}=0\\right)=\\frac{19}{27} \\times \\frac{7}{27}$, 而 $P\\left(x_{(1)}=0, x_{(2)}=0\\right)=7 / 27$, 两者不等, 由此可看出 $x_{(1)}$ 和 $x_{(2)}$ 是不独立的.  \n接下来我们讨论次序统计量的抽样分布, 它们常用在连续总体上, 故我们仅就总体 $X$ 的分布为连续情况进行叙述.  \n二、单个次序统计量的分布  \n定理 5.3.5. 设总体 $X$ 的密度函数为 $p(x)$, 分布函数为 $F(x), x_{1}, x_{2}, \\cdots, x_{n}$ 为样本, 则第 $k$ 个次序统计量 $x_{(k)}$ 的密度函数为  \n$$\n\\begin{equation*}\np_{k}(x)=\\frac{n !}{(k-1) !(n-k) !}(F(x))^{k-1}(1-F(x))^{n-k} p(x) . \\tag{5.3.13}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "因为 $P\\left(x_{(1)}=0\\right) P\\left(x_{(2)}=0\\right)=\\frac{19}{27} \\times \\frac{7}{27}$, 而 $P\\left(x_{(1)}=0, x_{(2)}=0\\right)=7 / 27$, 两者不等, 由此可看出 $x_{(1)}$ 和 $x_{(2)}$ 是不独立的.  \n接下来我们讨论次序统计量的抽样分布, 它们常用在连续总体上, 故我们仅就总体 $X$ 的分布为连续情况进行叙述.  \n二、单个次序统计量的分布  \n定理 5.3.5. 设总体 $X$ 的密度函数为 $p(x)$, 分布函数为 $F(x), x_{1}, x_{2}, \\cdots, x_{n}$ 为样本, 则第 $k$ 个次序统计量 $x_{(k)}$ 的密度函数为  \n$$\n\\begin{equation*}\np_{k}(x)=\\frac{n !}{(k-1) !(n-k) !}(F(x))^{k-1}(1-F(x))^{n-k} p(x) . \\tag{5.3.13}\n\\end{equation*}\n$$  \n证明：对任意的实数 $x$, 考虑次序统计量 $x_{(k)}$ 取值落在小区间 $(x, x+\\Delta x]$ 内这一事件, 它等价“样本容量为 $n$ 的样本中有 1 个观测值落在 $(x, x+\\square x]$ 之间, 而有 $k-1$ 个观测值小于等于 $x$, 有 $n \\square k$ 个观测值大于 $x+\\square x$ ”, 其直观示意见图 5.3.5.  \n!  \n图 5.3.5: $x_{(k)}$ 取值的示意图  \n样本的每一个分量小于等于 $x$ 的概率为 $F(x)$, 落人区间 $(x, x+\\Delta x]$ 的概率为 $F(x+\\Delta x)-F(x)$, 大于 $x+\\Delta x$ 的概率为 $1-F(x+\\Delta x)$, 而将 $n$ 个分量分成这样的三组, 总的分法有 $\\frac{n !}{(k-1) ! 1 !(n-k) !}$ 种. 于是, 若以 $F_{k}(x)$ 记 $x_{(k)}$ 的分布函数, 则由多项分布可得  \n$$",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n证明：对任意的实数 $x$, 考虑次序统计量 $x_{(k)}$ 取值落在小区间 $(x, x+\\Delta x]$ 内这一事件, 它等价“样本容量为 $n$ 的样本中有 1 个观测值落在 $(x, x+\\square x]$ 之间, 而有 $k-1$ 个观测值小于等于 $x$, 有 $n \\square k$ 个观测值大于 $x+\\square x$ ”, 其直观示意见图 5.3.5.  \n!  \n图 5.3.5: $x_{(k)}$ 取值的示意图  \n样本的每一个分量小于等于 $x$ 的概率为 $F(x)$, 落人区间 $(x, x+\\Delta x]$ 的概率为 $F(x+\\Delta x)-F(x)$, 大于 $x+\\Delta x$ 的概率为 $1-F(x+\\Delta x)$, 而将 $n$ 个分量分成这样的三组, 总的分法有 $\\frac{n !}{(k-1) ! 1 !(n-k) !}$ 种. 于是, 若以 $F_{k}(x)$ 记 $x_{(k)}$ 的分布函数, 则由多项分布可得  \n$$\nF_{k}(x+\\Delta x)-F_{k}(x) \\approx \\frac{n !}{(k-1) ! 1 !(n-k) !}(F(x))^{k-1}(F(x+\\Delta x)-F(x))(1-F(x+\\Delta x))^{n-k},\n$$  \n两边除以 $\\Delta x$, 并令 $\\Delta x \\rightarrow 0$, 即有  \n$$\n\\begin{aligned}\np_{k}(x) & =\\lim _{\\Delta x \\rightarrow 0} \\frac{F_{k}(x+\\Delta x)-F_{k}(x)}{\\Delta x} \\\\\n& =\\frac{n !}{(k-1) !(n-k) !}(F(x))^{k-1} p(x)(1-F(x))^{n-k},\n\\end{aligned}\n$$  \n其中 $p_{k}(x)$ 的非零区间与总体的非零区间相同. 特别, 令 $k=1$ 和 $k=n$ 即得到最小次序统计量 $x_{(1)}$ 和最大次序统计量 $x_{(n)}$ 的密度函数分别为:  \n$$\n\\begin{gather*}",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nF_{k}(x+\\Delta x)-F_{k}(x) \\approx \\frac{n !}{(k-1) ! 1 !(n-k) !}(F(x))^{k-1}(F(x+\\Delta x)-F(x))(1-F(x+\\Delta x))^{n-k},\n$$  \n两边除以 $\\Delta x$, 并令 $\\Delta x \\rightarrow 0$, 即有  \n$$\n\\begin{aligned}\np_{k}(x) & =\\lim _{\\Delta x \\rightarrow 0} \\frac{F_{k}(x+\\Delta x)-F_{k}(x)}{\\Delta x} \\\\\n& =\\frac{n !}{(k-1) !(n-k) !}(F(x))^{k-1} p(x)(1-F(x))^{n-k},\n\\end{aligned}\n$$  \n其中 $p_{k}(x)$ 的非零区间与总体的非零区间相同. 特别, 令 $k=1$ 和 $k=n$ 即得到最小次序统计量 $x_{(1)}$ 和最大次序统计量 $x_{(n)}$ 的密度函数分别为:  \n$$\n\\begin{gather*}\np_{1}(x)=n \\cdot(F(x))^{n-1} p(x),  \\tag{5.3.14}\\\\\np_{n}(x)=n \\cdot(1-F(x))^{n-1} p(x) . \\tag{5.3.15}\n\\end{gather*}\n$$  \n例 5.3.7: 设总体密度函数为  \n$$\np(x)=3 x^{2}, \\quad 0<x<1\n$$  \n现从该总体抽得一个容量为 5 的样本, 试计算 $P\\left(x_{(2)}<1 / 2\\right)$.  \n解: 我们首先应求出 $x_{(2)}$ 的分布. 由总体密度函数不难求出总体分布函数为  \n$$\nF(x)= \\begin{cases}0, & x \\leqslant 0 \\\\ x^{3}, & 0<x<1 \\\\ 1, & x \\geqslant 1\\end{cases}\n$$  \n由公式 (5.3.8) 可以得到 $x_{(2)}$ 的密度函数为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{gather*}\np_{1}(x)=n \\cdot(F(x))^{n-1} p(x),  \\tag{5.3.14}\\\\\np_{n}(x)=n \\cdot(1-F(x))^{n-1} p(x) . \\tag{5.3.15}\n\\end{gather*}\n$$  \n例 5.3.7: 设总体密度函数为  \n$$\np(x)=3 x^{2}, \\quad 0<x<1\n$$  \n现从该总体抽得一个容量为 5 的样本, 试计算 $P\\left(x_{(2)}<1 / 2\\right)$.  \n解: 我们首先应求出 $x_{(2)}$ 的分布. 由总体密度函数不难求出总体分布函数为  \n$$\nF(x)= \\begin{cases}0, & x \\leqslant 0 \\\\ x^{3}, & 0<x<1 \\\\ 1, & x \\geqslant 1\\end{cases}\n$$  \n由公式 (5.3.8) 可以得到 $x_{(2)}$ 的密度函数为  \n$$\n\\begin{aligned}\np_{2}(x) & =\\frac{5 !}{(2-1) !(5-2) !}(F(x))^{2-1} p(x)\\left(1_{F}(x)\\right)^{5-2} \\\\\n& =20 \\cdot x^{3} \\cdot 3 x^{2} \\cdot\\left(1-x^{3}\\right)^{3}=60 x^{5}\\left(1-x^{3}\\right)^{3}, \\quad 0<x<1,\n\\end{aligned}\n$$  \n于是  \n$$\n\\begin{aligned}\nP\\left(x_{(2)}<1 / 2\\right) & =\\int_{0}^{1 / 2} 60 x^{5}\\left(1-x^{3}\\right)^{3} \\mathrm{~d} x \\\\\n& =\\int_{0}^{1 / 8} 20 y(1-y)^{5} \\mathrm{~d} y=\\int_{7 / 8}^{1} 20\\left(z^{3}-z^{4}\\right) \\mathrm{d} z \\\\\n& =5\\left(1-(7 / 8)^{4}\\right)-4\\left(1-(7 / 8)^{5}\\right)=0.1207\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =20 \\cdot x^{3} \\cdot 3 x^{2} \\cdot\\left(1-x^{3}\\right)^{3}=60 x^{5}\\left(1-x^{3}\\right)^{3}, \\quad 0<x<1,\n\\end{aligned}\n$$  \n于是  \n$$\n\\begin{aligned}\nP\\left(x_{(2)}<1 / 2\\right) & =\\int_{0}^{1 / 2} 60 x^{5}\\left(1-x^{3}\\right)^{3} \\mathrm{~d} x \\\\\n& =\\int_{0}^{1 / 8} 20 y(1-y)^{5} \\mathrm{~d} y=\\int_{7 / 8}^{1} 20\\left(z^{3}-z^{4}\\right) \\mathrm{d} z \\\\\n& =5\\left(1-(7 / 8)^{4}\\right)-4\\left(1-(7 / 8)^{5}\\right)=0.1207\n\\end{aligned}\n$$  \n例 5.3.8: 设总体分布为 $U(0,1), x_{1}, x_{2}, \\cdots, x_{n}$ 为样本, 则其第 $k$ 个次序统计量的密度函数为  \n$$\np_{k}(x)=\\frac{n !}{(k-1) !(n-k) !} x^{k-1}(1-x)^{n-k}, \\quad 0<x<1\n$$  \n这就是 $\\S ?$ ? 中介绍的贝塔分布 $B e(k, n-k+1)$, 从而有 $E\\left(x_{(k)}\\right)=\\frac{k}{n+1}$.",
        "metadata": {
            "Header 2": "5.3 统计量及其分布",
            "Header 3": "5.3.5 次序统计量及其分布"
        },
        "type": "Document"
    },
    {
        "page_content": "下面我们讨论任意二个次序统计量的联合分布. 对三个或三个以上次序统计量的分布可参照进行.  \n定理 5.3.6. 在定理 5.3.5 的记号下, 次序统计量 $\\left(x_{(i)}, x_{(j)}\\right)(i<j)$ 的联合分布密度函数为  \n$$\n\\begin{array}{r}\np_{i j}(y, z)=\\frac{n !}{(i-1) !(j-i-1) !(n-j) !}[F(y)]^{i-1}[F(z)-F(y)]^{j-i-1}  \\tag{5.3.16}\\\\\n\\cdot[1-F(z)]^{n-j} p(y) p(z), \\quad y \\leqslant z,\n\\end{array}\n$$  \n证明：对正能量 $\\Delta y, \\Delta z$ 以及 $y<z$, 事件 “ $x_{(i)} \\in(y, y+\\Delta y], x_{(j)} \\in(z, z+\\Delta z]$ ” 可以表示为 “容量为 $n$ 的样本 $x_{1}, \\cdots, x_{n}$ 中有 $i-1$ 个观测值小于等于 $y$, 一个落人区间 $(y, y+\\Delta y], j-i-1$ 个落人区间 $(y+\\Delta y, z]$,一个落人区间 $(z, z+\\Delta z$ ], 而余下 $n-j$ 个大于 $z+\\Delta z$ ”(见图 5.3.6).  \n!  \n图 5.3.6: $x_{(i)}$ 与 $x_{(j)}$ 取值的示意图  \n于是由多项分布可得  \n$$\n\\begin{aligned}\nP\\left(x_{(i)} \\in(y, y+\\Delta y), x_{(j)} \\in(z, z+\\Delta z)\\right) \\approx & \\frac{n !}{(i-1) ! 1 !(j-i-1) ! 1 !(n-j) !}[F(y)]^{i-1} p(y) \\Delta y \\\\\n& \\cdot[F(z)-F(y+\\Delta y)]^{j-i-1} p(z) \\Delta z[1-F(z+\\Delta z)]^{n-j},\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "三、多个次序统计量的联合分布"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n图 5.3.6: $x_{(i)}$ 与 $x_{(j)}$ 取值的示意图  \n于是由多项分布可得  \n$$\n\\begin{aligned}\nP\\left(x_{(i)} \\in(y, y+\\Delta y), x_{(j)} \\in(z, z+\\Delta z)\\right) \\approx & \\frac{n !}{(i-1) ! 1 !(j-i-1) ! 1 !(n-j) !}[F(y)]^{i-1} p(y) \\Delta y \\\\\n& \\cdot[F(z)-F(y+\\Delta y)]^{j-i-1} p(z) \\Delta z[1-F(z+\\Delta z)]^{n-j},\n\\end{aligned}\n$$  \n考虑到 $F(x)$ 的连续性, 当 $\\Delta y \\rightarrow 0, \\Delta z \\rightarrow 0$ 时有 $F(y+\\Delta y) \\rightarrow F(y), F(z+\\Delta z) \\rightarrow F(z)$, 于是  \n$$\n\\begin{aligned}\np_{i j}(y, z) & =\\lim _{\\Delta y \\rightarrow 0, \\Delta z \\rightarrow 0} \\frac{x_{(i)} \\in(y, y+\\Delta y), x_{(j)} \\in(z, z+\\Delta z)}{\\Delta y \\cdot \\Delta z} \\\\\n& =\\frac{n !}{(i-1) !(j-i-1) !(n-j) !}[F(y)]^{i-1}[F(z)-F(y)]^{j-i-1}[1-F(z)]^{n-j} p(y) p(z)\n\\end{aligned}\n$$  \n定理得证.  \n在实际问题中会用到一些次序统计量的函数, 如 $R_{n}=x_{(n)}-x_{(1)}$ 称为 样本极差, 是一个很常用的统计量, 要推导这个统计量的分布原则上并不难, 我们只要使用定理 5.3.6 以及第三章讲过的随机变量函数的分布求法即可解决. 但它们的分布常用积分表示, 只在很少几种场合可用初等函数表示, 下面是一个样本极差的分布可用初等函数表示的例子.",
        "metadata": {
            "Header 2": "三、多个次序统计量的联合分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\np_{i j}(y, z) & =\\lim _{\\Delta y \\rightarrow 0, \\Delta z \\rightarrow 0} \\frac{x_{(i)} \\in(y, y+\\Delta y), x_{(j)} \\in(z, z+\\Delta z)}{\\Delta y \\cdot \\Delta z} \\\\\n& =\\frac{n !}{(i-1) !(j-i-1) !(n-j) !}[F(y)]^{i-1}[F(z)-F(y)]^{j-i-1}[1-F(z)]^{n-j} p(y) p(z)\n\\end{aligned}\n$$  \n定理得证.  \n在实际问题中会用到一些次序统计量的函数, 如 $R_{n}=x_{(n)}-x_{(1)}$ 称为 样本极差, 是一个很常用的统计量, 要推导这个统计量的分布原则上并不难, 我们只要使用定理 5.3.6 以及第三章讲过的随机变量函数的分布求法即可解决. 但它们的分布常用积分表示, 只在很少几种场合可用初等函数表示, 下面是一个样本极差的分布可用初等函数表示的例子.  \n例 5.3.9: 设总体分布为 $U(0,1), x_{1}, x_{2}, \\cdots, x_{n}$ 为样本, 则 $\\left(x_{(1)}, x_{(n)}\\right)$ 的联合密度函数为  \n$$\np_{1, n}(y, z)=n(n-1)(z-y)^{n-2}, \\quad 0<y<z<1\n$$  \n令 $R=x_{(n)}-x_{(1)}$, 由 $R>0$ 可以推出 $0<x_{(1)}=x_{(n)}-R \\leqslant 1-R$, 则  \n$$\np_{R}(r)=\\int_{0}^{1-r} n(n-1)[(y+r)-y]^{n-2} \\mathrm{~d} y=n(n-1) r^{n-2}(1-r) \\text {. }\n$$  \n这正是参数为 $(n-1,2)$ 的贝塔分布.",
        "metadata": {
            "Header 2": "三、多个次序统计量的联合分布"
        },
        "type": "Document"
    },
    {
        "page_content": "样本中位数也是一个很常见的统计量, 它也是次序统计量的函数, 通常如下定义. 设 $x_{(1)}, \\cdots, x_{(n)}$是有序样本, 则 样本中位数 $m_{0,5}$ 定义为  \n$$\nm_{0,5}= \\begin{cases}x_{\\left(\\frac{n+1}{2}\\right),} & n \\text { 为奇数 } \\\\ \\frac{1}{2}\\left(x_{(n / 2)}+x_{(n / 2+1)}\\right), & \\text { 为偶数. }\\end{cases}\n$$  \n譬如, 若 $n=5$, 则 $m_{0,5}=x_{(3)}$, 若 $n=6$, 则 $m_{0,5}=\\frac{1}{2}\\left(x_{(3)}+x_{(4)}\\right)$.  \n更一般地, 样本 $p$ 分位数 $m_{p}$ 可如下定义:  \n$$\nm_{p}= \\begin{cases}x_{[n p+1]}, & \\text { 若 } n p \\text { 不是整数; } \\\\ \\frac{1}{2}\\left(x_{n p}+x_{(n p+1)}\\right), & \\text { 若 } n p \\text { 是整数. }\\end{cases}\n$$  \n譬如, 若 $n=10, p=0.35$, 则 $m_{0.35}=x_{(4)}$, 若 $n=20, p=0.45$, 则 $m_{0.45}=\\frac{1}{2}\\left(x_{(9)}+x_{(10)}\\right)$.  \n对多数总体而言, 要给出样本 $\\mathrm{p}$ 分位数的精确分布通常不是一件容易的事. 幸运的是当 $n \\rightarrow$ $+\\infty$ 时样本 $p$ 分位数的渐近分布有比较简单的表达式, 我们这里不加证明地给出如下定理.  \n定理 5.3.7. 设总体密度函数为 $p(x), x_{p}$ 为其 $p$ 分位数, $p(x)$ 在 $x_{p}$ 处连续且 $p\\left(x_{p}\\right)>0$, 则当 $n \\rightarrow+\\infty$ 时样本 $p$ 分位数 $m_{p}$ 的渐近分布为  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "5.3 .6 样本分位数与样本中位数"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n譬如, 若 $n=10, p=0.35$, 则 $m_{0.35}=x_{(4)}$, 若 $n=20, p=0.45$, 则 $m_{0.45}=\\frac{1}{2}\\left(x_{(9)}+x_{(10)}\\right)$.  \n对多数总体而言, 要给出样本 $\\mathrm{p}$ 分位数的精确分布通常不是一件容易的事. 幸运的是当 $n \\rightarrow$ $+\\infty$ 时样本 $p$ 分位数的渐近分布有比较简单的表达式, 我们这里不加证明地给出如下定理.  \n定理 5.3.7. 设总体密度函数为 $p(x), x_{p}$ 为其 $p$ 分位数, $p(x)$ 在 $x_{p}$ 处连续且 $p\\left(x_{p}\\right)>0$, 则当 $n \\rightarrow+\\infty$ 时样本 $p$ 分位数 $m_{p}$ 的渐近分布为  \n$$\n\\begin{equation*}\nm_{p} \\dot{\\sim} N\\left(x_{p}, \\frac{p(1-p)}{n \\cdot p^{2}\\left(x_{p}\\right)}\\right) \\tag{5.3.17}\n\\end{equation*}\n$$  \n特别, 对样本中位数, 当 $n \\rightarrow+\\infty$ 时近似地有  \n$$\n\\begin{equation*}\nm_{0.5} \\dot{\\sim}\\left(x_{0.5}, \\frac{1}{4 n \\cdot p^{2}\\left(x_{0.5}\\right)}\\right) . \\tag{5.3.18}\n\\end{equation*}\n$$  \n例 5.3.10：设总体为柯西分布, 密度函数为  \n其分布函数为  \n$$\np(x ; \\theta)=\\frac{1}{\\pi\\left(1+(x-\\theta)^{2}\\right)}, \\quad-\\infty<x<+\\infty,\n$$  \n$$\nF(x ; \\theta)=\\frac{1}{2}+\\frac{1}{\\pi} \\arctan (x-\\theta) .\n$$",
        "metadata": {
            "Header 2": "5.3 .6 样本分位数与样本中位数"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n特别, 对样本中位数, 当 $n \\rightarrow+\\infty$ 时近似地有  \n$$\n\\begin{equation*}\nm_{0.5} \\dot{\\sim}\\left(x_{0.5}, \\frac{1}{4 n \\cdot p^{2}\\left(x_{0.5}\\right)}\\right) . \\tag{5.3.18}\n\\end{equation*}\n$$  \n例 5.3.10：设总体为柯西分布, 密度函数为  \n其分布函数为  \n$$\np(x ; \\theta)=\\frac{1}{\\pi\\left(1+(x-\\theta)^{2}\\right)}, \\quad-\\infty<x<+\\infty,\n$$  \n$$\nF(x ; \\theta)=\\frac{1}{2}+\\frac{1}{\\pi} \\arctan (x-\\theta) .\n$$  \n不难看出 $\\theta$ 是该总体的分位数, 即 $x_{0.5}=\\theta$. 设 $x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, 当样本量 $n$ 较大\n时, 样本中位数 $m_{0.5}$ 的渐近分布为  \n$$\nm_{0.5} \\dot{\\sim} N\\left(\\theta, \\frac{\\pi^{2}}{4 n}\\right)\n$$  \n通常, 样本均值在概括数据方面具有一定的优势. 但样本均值也有其不足之处. 设我们有 5 个数 $3,5,9,10,13$, 则其均值为 $(3+5+9+10+13) / 5=8$. 如果我们不小心将 13 错输人为 133 (比如在计算机输人时将 3 连按 2 下), 则均值即变为 $(3+5+9+10+133) / 5=32$. 这说明均值受极端数值影响较大, 与之相对应, 中位数则不受极端值的影响, 因此, 当数据中含有极端值时, 使用中位数比使用均值更好, 中位数的这种抗干扰性在统计中称为具有 稳健性.",
        "metadata": {
            "Header 2": "5.3 .6 样本分位数与样本中位数"
        },
        "type": "Document"
    },
    {
        "page_content": "次序统计量的应用之一是五数概括与箱线图. 在得到有序样本后, 容易计算如下五个值: 最小观测值 $x_{\\text {min }}=x_{(1)}$; 最大观测值 $x_{\\text {max }}=x_{(n)}$, 中位数 $m_{0.5}$, 第一 4 分位数 $Q_{1}=m_{0.25}$ 和第三 4 分位数 $Q_{3}=m_{0.75}$. 所谓五数概括就是指用这五个数:  \n$$\nx_{\\min }, \\quad Q_{1}, \\quad m_{0.5}, \\quad Q_{3}, \\quad x_{\\max }\n$$  \n来大致描述一批数据的轮廓.  \n例 5.3.11：表 5.3.7 是某厂 160 名销售人员某月的销售量数据的有序样本, 由该批数据可计算得到 $x_{\\min }=45, x_{\\max }=319, m_{0.5}=181, Q_{1}=144, Q_{3}=212$.  \n表 5.3.7: 某厂 160 名销售员的月销售量的有序样本  \n| 45 | 74 | 76 | 80 | 87 | 91 | 92 | 93 | 95 | 96 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 98 | 99 | 104 | 106 | 111 | 113 | 117 | 120 | 122 | 122 |\n| 124 | 126 | 127 | 127 | 129 | 129 | 130 | 131 | 131 | 133 |\n| 134 | 134 | 135 | 136 | 137 | 137 | 139 | 141 | 141 | 143 |\n| 145 | 148 | 149 | 149 | 149 | 150 | 150 | 153 | 153 | 153 |\n| 153 | 154 | 157 | 160 | 160 | 162 | 163 | 163 | 165 | 165 |\n| 167 | 167 | 168 | 170 | 171 | 172 | 173 | 174 | 175 | 175 |",
        "metadata": {
            "Header 2": "5.3 .7 五数概括与箱线图"
        },
        "type": "Document"
    },
    {
        "page_content": "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 98 | 99 | 104 | 106 | 111 | 113 | 117 | 120 | 122 | 122 |\n| 124 | 126 | 127 | 127 | 129 | 129 | 130 | 131 | 131 | 133 |\n| 134 | 134 | 135 | 136 | 137 | 137 | 139 | 141 | 141 | 143 |\n| 145 | 148 | 149 | 149 | 149 | 150 | 150 | 153 | 153 | 153 |\n| 153 | 154 | 157 | 160 | 160 | 162 | 163 | 163 | 165 | 165 |\n| 167 | 167 | 168 | 170 | 171 | 172 | 173 | 174 | 175 | 175 |\n| 176 | 178 | 178 | 178 | 179 | 179 | 179 | 180 | 181 | 181 |\n| 181 | 182 | 182 | 185 | 185 | 186 | 186 | 187 | 188 | 188 |\n| 188 | 189 | 189 | 191 | 191 | 191 | 192 | 192 | 194 | 194 |\n| 194 | 194 | 195 | 196 | 197 | 197 | 198 | 198 | 198 | 199 |\n| 200 | 201 | 202 | 204 | 204 | 205 | 205 | 206 | 207 | 210 |\n| 214 | 214 | 215 | 215 | 216 | 217 | 218 | 219 | 219 | 221 |\n| 221 | 221 | 221 | 221 | 222 | 223 | 223 | 224 | 227 | 227 |\n| 228 | 229 | 232 | 234 | 234 | 238 | 240 | 242 | 242 | 242 |",
        "metadata": {
            "Header 2": "5.3 .7 五数概括与箱线图"
        },
        "type": "Document"
    },
    {
        "page_content": "| 176 | 178 | 178 | 178 | 179 | 179 | 179 | 180 | 181 | 181 |\n| 181 | 182 | 182 | 185 | 185 | 186 | 186 | 187 | 188 | 188 |\n| 188 | 189 | 189 | 191 | 191 | 191 | 192 | 192 | 194 | 194 |\n| 194 | 194 | 195 | 196 | 197 | 197 | 198 | 198 | 198 | 199 |\n| 200 | 201 | 202 | 204 | 204 | 205 | 205 | 206 | 207 | 210 |\n| 214 | 214 | 215 | 215 | 216 | 217 | 218 | 219 | 219 | 221 |\n| 221 | 221 | 221 | 221 | 222 | 223 | 223 | 224 | 227 | 227 |\n| 228 | 229 | 232 | 234 | 234 | 238 | 240 | 242 | 242 | 242 |\n| 244 | 246 | 253 | 253 | 255 | 258 | 282 | 290 | 314 | 319 |  \n五数概括的图形表示称为箱线图, 由箱子和线段组成. 图 5.3.7 是例 5.3.11 中样本数据的箱线图, 其作法如下:  \n(1) 画一个箱子, 其两侧恰为第一 4 分位数和第三 4 分位数, 在中位数位置上画一条坚线, 它在箱子内. 这个箱子包含了样本中 $50 \\%$ 的数据;  \n(2) 在箱子左右两侧各引出一条水平线, 分别至最小值和最大值为止. 每条线段包含了样本中 $25 \\%$ 的数据.  \n箱线图可用来对样本数据分布的形状进行大致的判断. 图 5.3.8 给出三种常见的箱线图, 分别对应对称分布、左偏分布和右偏分布.  \n如果我们要对几批数据进行比较, 则可以在一张纸上同时画出这批数据的箱线图. 图 5.3.9 是某厂 20 天生产的某种产品的直径数据画成的箱线图, 从图中可以清楚地看出, 第 18 天的产品出现了异常.  \n!  \n图 5.3.7: 月销售量的箱线图  \n!  \n图 5.3.8: 三种常见的箱线图及其对应的分布轮廓  \n!",
        "metadata": {
            "Header 2": "5.3 .7 五数概括与箱线图"
        },
        "type": "Document"
    },
    {
        "page_content": "五数概括的图形表示称为箱线图, 由箱子和线段组成. 图 5.3.7 是例 5.3.11 中样本数据的箱线图, 其作法如下:  \n(1) 画一个箱子, 其两侧恰为第一 4 分位数和第三 4 分位数, 在中位数位置上画一条坚线, 它在箱子内. 这个箱子包含了样本中 $50 \\%$ 的数据;  \n(2) 在箱子左右两侧各引出一条水平线, 分别至最小值和最大值为止. 每条线段包含了样本中 $25 \\%$ 的数据.  \n箱线图可用来对样本数据分布的形状进行大致的判断. 图 5.3.8 给出三种常见的箱线图, 分别对应对称分布、左偏分布和右偏分布.  \n如果我们要对几批数据进行比较, 则可以在一张纸上同时画出这批数据的箱线图. 图 5.3.9 是某厂 20 天生产的某种产品的直径数据画成的箱线图, 从图中可以清楚地看出, 第 18 天的产品出现了异常.  \n!  \n图 5.3.7: 月销售量的箱线图  \n!  \n图 5.3.8: 三种常见的箱线图及其对应的分布轮廓  \n!  \n图 5.3.9: 20 天某产品的直径的箱线图",
        "metadata": {
            "Header 2": "5.3 .7 五数概括与箱线图"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 在一本书上我们随机地检查了 10 页, 发现每页上的错误数为  \n$$\n\\begin{array}{llllllllll}\n4 & 5 & 6 & 0 & 3 & 1 & 4 & 2 & 1 & 4\n\\end{array}\n$$  \n试计算其样本均值、样本方差和样本标准差.  \n2. 证明: 对任意常数 $c, d$, 有  \n$$\n\\sum_{i=1}^{n}\\left(x_{i}-c\\right)\\left(y_{i}-d\\right)=\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)+n(\\bar{x}-c)(\\bar{y}-d)\n$$  \n3. 设 $x_{1}, \\cdots, x_{n}$ 和 $y_{1}, \\cdots, y_{n}$ 是两组样本观测值, 且有如下关系: $y_{I}=3 x_{i}-4, i=1, \\cdots, n$, 试求样本值 $\\bar{x}$ 和 $\\bar{y}$ 间的关系以及样本方差 $s_{x}^{2}$ 和 $s_{y}^{2}$ 间的关系.\n4. 记 $\\bar{x}_{n}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}, s_{n}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{I}-\\bar{x}_{n}\\right)^{2}, n=1,2, \\cdots$, 证明:  \n$$\n\\begin{aligned}\n\\bar{x}_{n+1} & =\\bar{x}_{n}+\\frac{1}{n+1}\\left(x_{n+1}-\\bar{x}_{n}\\right), \\\\\ns_{n+1}^{2} & =\\frac{n-1}{n} s_{n}^{2}+\\frac{1}{n+1}\\left(x_{n+1}-\\bar{x}_{n}\\right)^{2} .\n\\end{aligned}\n$$  \n5. 从同一总体中抽取二个容量分别为 $n, m$ 的样本, 样本均值分别为 $\\bar{x}_{1}, \\bar{x}_{2}$, 样本方差分别为 $s_{1}^{2}, s_{2}^{2}$,将二组样本合并, 其均值、方差分别为 $\\bar{x}, s^{2}$, 证明:  \n$$",
        "metadata": {
            "Header 2": "如题 5.3"
        },
        "type": "Document"
    },
    {
        "page_content": "4. 记 $\\bar{x}_{n}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}, s_{n}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{I}-\\bar{x}_{n}\\right)^{2}, n=1,2, \\cdots$, 证明:  \n$$\n\\begin{aligned}\n\\bar{x}_{n+1} & =\\bar{x}_{n}+\\frac{1}{n+1}\\left(x_{n+1}-\\bar{x}_{n}\\right), \\\\\ns_{n+1}^{2} & =\\frac{n-1}{n} s_{n}^{2}+\\frac{1}{n+1}\\left(x_{n+1}-\\bar{x}_{n}\\right)^{2} .\n\\end{aligned}\n$$  \n5. 从同一总体中抽取二个容量分别为 $n, m$ 的样本, 样本均值分别为 $\\bar{x}_{1}, \\bar{x}_{2}$, 样本方差分别为 $s_{1}^{2}, s_{2}^{2}$,将二组样本合并, 其均值、方差分别为 $\\bar{x}, s^{2}$, 证明:  \n$$\n\\bar{x}=\\frac{n \\bar{x}_{1}+m \\bar{x}_{2}}{n+m},\n$$  \n$$\ns^{2}=\\frac{(n-1) S_{1}^{2}+(m-1) s_{2}^{2}}{n+m-1}+\\frac{n m\\left(\\bar{x}_{1}=\\bar{x}_{2}\\right)^{2}}{(n+m)(n+m+1)} .\n$$  \n6. 设有容量为 $n$ 的样本 $A$, 它的样本均值为 $\\bar{x}_{A}$, 样本标准差为 $s_{A}$, 样本极差为 $R_{A}$, 样本中位数为 $m_{A}$. 现对样本中每一个观测值施行如下变换  \n$$\ny=a x+b\n$$  \n如此得到样本 $B$, 试写出样本 $\\mathrm{B}$ 的均值、标准差、极差和中位数.  \n7. 证明: 容量为 2 的样本 $x_{1}, x_{2}$ 的方差为  \n$$\ns^{2}=\\frac{1}{2}\\left(x_{1}-x_{2}\\right)^{2}\n$$",
        "metadata": {
            "Header 2": "如题 5.3"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\bar{x}=\\frac{n \\bar{x}_{1}+m \\bar{x}_{2}}{n+m},\n$$  \n$$\ns^{2}=\\frac{(n-1) S_{1}^{2}+(m-1) s_{2}^{2}}{n+m-1}+\\frac{n m\\left(\\bar{x}_{1}=\\bar{x}_{2}\\right)^{2}}{(n+m)(n+m+1)} .\n$$  \n6. 设有容量为 $n$ 的样本 $A$, 它的样本均值为 $\\bar{x}_{A}$, 样本标准差为 $s_{A}$, 样本极差为 $R_{A}$, 样本中位数为 $m_{A}$. 现对样本中每一个观测值施行如下变换  \n$$\ny=a x+b\n$$  \n如此得到样本 $B$, 试写出样本 $\\mathrm{B}$ 的均值、标准差、极差和中位数.  \n7. 证明: 容量为 2 的样本 $x_{1}, x_{2}$ 的方差为  \n$$\ns^{2}=\\frac{1}{2}\\left(x_{1}-x_{2}\\right)^{2}\n$$  \n8. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $U(-1,1)$ 的样本, 试求 $E(\\bar{x})$ 和 $\\operatorname{Var}(\\bar{x})$.\n9. 设总体二阶矩存在, $x_{1}, \\cdots, x_{n}$ 是样本, 证明 $x_{i}-\\bar{x}$ 与 $x_{j}-\\bar{x}(i \\neq j)$ 的相关系数为 $-(n-1)^{-1}$.对此你能够给予解释吗?\n10. 利用契贝晓夫不等式求抛均匀硬币多少次才能使正面朝上的频率落在 $(0.4,0.6)$ 间的概率至少为 0.9 . 如何才能更精确地计算这个次数? 是多少?\n11. 从指数总体 $\\operatorname{Exp}(1)$ 抽取了 40 个样品, 试求 $\\bar{x}$ 的渐近分布.\n12. 设 $x_{1}, \\cdots, x_{25}$ 是从均匀分布 $U(0,5)$ 抽取的样本, 试求样本均值 $\\bar{x}$ 的渐近分布.\n13. 设 $x_{1}, \\cdots, x_{20}$ 是从二点分布 $b(1, p)$ 抽取的样本, 试求样本均值 $\\bar{x}$ 的渐近分布.",
        "metadata": {
            "Header 2": "如题 5.3"
        },
        "type": "Document"
    },
    {
        "page_content": "9. 设总体二阶矩存在, $x_{1}, \\cdots, x_{n}$ 是样本, 证明 $x_{i}-\\bar{x}$ 与 $x_{j}-\\bar{x}(i \\neq j)$ 的相关系数为 $-(n-1)^{-1}$.对此你能够给予解释吗?\n10. 利用契贝晓夫不等式求抛均匀硬币多少次才能使正面朝上的频率落在 $(0.4,0.6)$ 间的概率至少为 0.9 . 如何才能更精确地计算这个次数? 是多少?\n11. 从指数总体 $\\operatorname{Exp}(1)$ 抽取了 40 个样品, 试求 $\\bar{x}$ 的渐近分布.\n12. 设 $x_{1}, \\cdots, x_{25}$ 是从均匀分布 $U(0,5)$ 抽取的样本, 试求样本均值 $\\bar{x}$ 的渐近分布.\n13. 设 $x_{1}, \\cdots, x_{20}$ 是从二点分布 $b(1, p)$ 抽取的样本, 试求样本均值 $\\bar{x}$ 的渐近分布.\n14. 设 $x_{1}, \\cdots, x_{8}$ 是从正态总体 $N(10,9)$ 中抽取的样本, 试求样本均值 $\\bar{x}$ 的标准差.\n15. 切尾均值也是一个常用的反映样本数据的特征量, 其想法是将数据的两端的值舍去, 而用剩下的当中的值为计算样本均值, 其计算公式是  \n$$\n\\bar{x}_{n}=\\frac{x_{([n \\alpha]+1)}+x_{([n \\alpha]+2)}+\\cdots+x_{(n-[n \\alpha])}}{n-2[n \\alpha]} \\text {, 其中 } 0<\\alpha<1 / 2 \\text { 是切尾系数, }\n$$  \n$x_{(1)} \\leqslant x_{(2)} \\leqslant \\cdots \\leqslant x_{(n)}$ 是有序样本. 现我们在某高校采访了 16 名大学生, 了解他们平时的学习情况, 以下数据是大学生每周用于看电视的时间:  \n$$\n\\begin{array}{llllllllllllllll}\n15 & 14 & 12 & 9 & 20 & 4 & 17 & 26 & 15 & 18 & 6 & 10 & 16 & 15 & 5 & 8\n\\end{array}\n$$",
        "metadata": {
            "Header 2": "如题 5.3"
        },
        "type": "Document"
    },
    {
        "page_content": "15. 切尾均值也是一个常用的反映样本数据的特征量, 其想法是将数据的两端的值舍去, 而用剩下的当中的值为计算样本均值, 其计算公式是  \n$$\n\\bar{x}_{n}=\\frac{x_{([n \\alpha]+1)}+x_{([n \\alpha]+2)}+\\cdots+x_{(n-[n \\alpha])}}{n-2[n \\alpha]} \\text {, 其中 } 0<\\alpha<1 / 2 \\text { 是切尾系数, }\n$$  \n$x_{(1)} \\leqslant x_{(2)} \\leqslant \\cdots \\leqslant x_{(n)}$ 是有序样本. 现我们在某高校采访了 16 名大学生, 了解他们平时的学习情况, 以下数据是大学生每周用于看电视的时间:  \n$$\n\\begin{array}{llllllllllllllll}\n15 & 14 & 12 & 9 & 20 & 4 & 17 & 26 & 15 & 18 & 6 & 10 & 16 & 15 & 5 & 8\n\\end{array}\n$$  \n取 $\\alpha=1 / 16$, 试计算其切尾均值.  \n16. 有一个分组样本如下:  \n| 区间 | 组中值 | 频数 |\n| :---: | :---: | :---: |\n| $(145,155)$ | 150 | 4 |\n| $(155,165)$ | 160 | 8 |\n| $(175,185)$ | 180 | 2 |  \n试求该分组样本的样本均值、样本标准差、样本偏度和样本峰度.  \n17. 检查四批产品, 其批量与不合格品率如下:  \n| 批号 | 批量 | 不合格品率 |\n| :---: | :---: | :---: |\n| 1 | 100 | 0.05 |\n| 2 | 300 | 0.06 |\n| 3 | 250 | 0.04 |\n| 4 | 150 | 0.03 |  \n试求这四批产品的总不合格品率.  \n18. 设总体以等概率取 $1,2,3,4,5$, 现从中抽取一个容量为 4 的样本, 试分别求 $x_{(1)}$ 和 $x_{(4)}$ 的分布.\n19. 设 $x_{1}, \\cdots, x_{16}$ 是来自 $N(8,4)$ 的样本, 试求下列概率:",
        "metadata": {
            "Header 2": "如题 5.3"
        },
        "type": "Document"
    },
    {
        "page_content": "16. 有一个分组样本如下:  \n| 区间 | 组中值 | 频数 |\n| :---: | :---: | :---: |\n| $(145,155)$ | 150 | 4 |\n| $(155,165)$ | 160 | 8 |\n| $(175,185)$ | 180 | 2 |  \n试求该分组样本的样本均值、样本标准差、样本偏度和样本峰度.  \n17. 检查四批产品, 其批量与不合格品率如下:  \n| 批号 | 批量 | 不合格品率 |\n| :---: | :---: | :---: |\n| 1 | 100 | 0.05 |\n| 2 | 300 | 0.06 |\n| 3 | 250 | 0.04 |\n| 4 | 150 | 0.03 |  \n试求这四批产品的总不合格品率.  \n18. 设总体以等概率取 $1,2,3,4,5$, 现从中抽取一个容量为 4 的样本, 试分别求 $x_{(1)}$ 和 $x_{(4)}$ 的分布.\n19. 设 $x_{1}, \\cdots, x_{16}$ 是来自 $N(8,4)$ 的样本, 试求下列概率:  \n(1) $P\\left(x_{(16)}>10\\right)$.  \n(2) $P\\left(x_{(1)}>5\\right)$.  \n20. 设总体为威布尔分布, 其密度函数为  \n$$\np(x ; m, \\eta)=\\frac{m x^{m-1}}{\\eta^{m}} \\exp \\left\\{-\\left(\\frac{x}{\\eta}\\right)^{m}\\right\\}, \\quad x>0, m>0, \\eta>0 .\n$$  \n现从中得到样本 $x_{1}, \\cdots, x_{n}$, 证明 $x_{(1)}$ 仍复从威布尔分布, 并指出其参数.  \n21. 设总体密度函数为 $p(x)=6 x(1-x), 0<x<1, x_{1}, \\cdots, x_{9}$ 是来自该总体的样本, 试求样本中位数的分布.\n22. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $U(0, \\theta)$ 的样本, $x_{(1)} \\leqslant \\cdots \\leqslant x_{(n)}$ 为次序统计量, 令  \n$$",
        "metadata": {
            "Header 2": "如题 5.3"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) $P\\left(x_{(16)}>10\\right)$.  \n(2) $P\\left(x_{(1)}>5\\right)$.  \n20. 设总体为威布尔分布, 其密度函数为  \n$$\np(x ; m, \\eta)=\\frac{m x^{m-1}}{\\eta^{m}} \\exp \\left\\{-\\left(\\frac{x}{\\eta}\\right)^{m}\\right\\}, \\quad x>0, m>0, \\eta>0 .\n$$  \n现从中得到样本 $x_{1}, \\cdots, x_{n}$, 证明 $x_{(1)}$ 仍复从威布尔分布, 并指出其参数.  \n21. 设总体密度函数为 $p(x)=6 x(1-x), 0<x<1, x_{1}, \\cdots, x_{9}$ 是来自该总体的样本, 试求样本中位数的分布.\n22. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $U(0, \\theta)$ 的样本, $x_{(1)} \\leqslant \\cdots \\leqslant x_{(n)}$ 为次序统计量, 令  \n$$\ny_{i}=\\frac{x_{(i)}}{x_{(i+1)}}, i=1, \\cdots, n-1, \\quad y_{n}=x_{(n)}\n$$  \n证明 $y_{1}, \\cdots, y_{n}$ 相互独立.  \n23. 对下列数据构造箱线图:  \n| 472 | 425 | 447 | 377 | 341 | 369 | 412 | 419 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 400 | 382 | 366 | 425 | 399 | 398 | 423 | 384 |\n| 418 | 392 | 372 | 418 | 374 | 385 | 439 | 428 |\n| 429 | 428 | 430 | 413 | 405 | 381 | 403 | 479 |\n| 381 | 443 | 441 | 433 | 419 | 379 | 386 | 387 |  \n24. 根据调查, 某集团公司的中层管理人员的年薪数据如下 (单位: 千元):",
        "metadata": {
            "Header 2": "如题 5.3"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\ny_{i}=\\frac{x_{(i)}}{x_{(i+1)}}, i=1, \\cdots, n-1, \\quad y_{n}=x_{(n)}\n$$  \n证明 $y_{1}, \\cdots, y_{n}$ 相互独立.  \n23. 对下列数据构造箱线图:  \n| 472 | 425 | 447 | 377 | 341 | 369 | 412 | 419 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 400 | 382 | 366 | 425 | 399 | 398 | 423 | 384 |\n| 418 | 392 | 372 | 418 | 374 | 385 | 439 | 428 |\n| 429 | 428 | 430 | 413 | 405 | 381 | 403 | 479 |\n| 381 | 443 | 441 | 433 | 419 | 379 | 386 | 387 |  \n24. 根据调查, 某集团公司的中层管理人员的年薪数据如下 (单位: 千元):  \n| 40.6 | 39.6 | 43.8 | 36.2 | 40.8 | 37.3 | 39.2 | 42.9 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 38.6 | 39.6 | 40.0 | 34.7 | 41.7 | 45.4 | 36.9 | 37.8 |\n| 44.9 | 45.4 | 37.0 | 35.1 | 36.7 | 41.3 | 38.1 | 37.9 |\n| 37.1 | 37.7 | 39.2 | 36.9 | 44.5 | 40.4 | 38.4 | 38.9 |\n| 39.9 | 42.2 | 43.5 | 44.8 | 37.7 | 34.7 | 36.3 | 39.7 |\n| 42.1 | 41.5 | 40.6 | 38.9 | 42.2 | 40.3 | 35.8 | 39.2 |  \n试画出箱线图.",
        "metadata": {
            "Header 2": "如题 5.3"
        },
        "type": "Document"
    },
    {
        "page_content": "大家很快会看到, 有很多统计推断是基于正态分布的假设的, 以标准正态变量为基石而构造的三个著名统计量在实际中有广泛的应用, 这是因为这三个统计量不仅有明确背景, 而且其抽样分布的密度函数有明显表达式, 它们被称为统计中的 “三大抽样分布”.  \n若设 $x_{1}, \\cdots, x_{n}$ 和 $y_{1}, \\cdots, y_{n}$ 是来自标准正态分布的两个相互独立的样本, 则此三个统计量的构造及其抽样分布如表 5.4.1 所示.  \n表 5.4.1: 三个著名统计量的构造及其抽样分布  \n| 统计量的构造 | 抽样分布密度函数 | 期望 | 方差 |\n| :--- | :--- | :---: | :---: |\n| $\\chi^{2}=x_{1}^{2}+x_{2}^{2}+\\cdots+x_{n}^{2}$ | $p(y)=\\frac{1}{\\Gamma\\left(\\frac{n}{2}\\right) 2^{n / 2}} y^{n / 2-1} \\mathrm{e}^{-\\frac{y}{2}}(y>0)$ | $n$ | $2 n$ |\n| $F=\\frac{\\left(y_{1}^{2}+\\cdots+y_{m}^{2}\\right) / m}{\\left(x_{1}^{2}+\\cdots+x_{n}^{2}\\right) / n}$ | $p(y)=\\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)\\left(\\frac{m}{n}\\right)^{m / 2}}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)} y^{\\frac{m}{2}-1}\\left(1+\\frac{m}{n} y\\right)^{-\\frac{m+n}{2}}$ | $\\frac{n}{n-2}$ | $\\frac{2 n^{2}(m+n-2)}{m(n-2)^{2}(n-4)}$ |",
        "metadata": {
            "Header 2": "5.4 三大抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| $F=\\frac{\\left(y_{1}^{2}+\\cdots+y_{m}^{2}\\right) / m}{\\left(x_{1}^{2}+\\cdots+x_{n}^{2}\\right) / n}$ | $p(y)=\\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)\\left(\\frac{m}{n}\\right)^{m / 2}}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)} y^{\\frac{m}{2}-1}\\left(1+\\frac{m}{n} y\\right)^{-\\frac{m+n}{2}}$ | $\\frac{n}{n-2}$ | $\\frac{2 n^{2}(m+n-2)}{m(n-2)^{2}(n-4)}$ |\n| $t=\\frac{y_{1}}{\\sqrt{\\left(x_{1}^{2}+\\cdots+x_{n}^{2}\\right) / n}}$ | $p(y)=\\frac{\\Gamma\\left(\\frac{n+1}{2}\\right)}{\\sqrt{n \\pi} \\Gamma\\left(\\frac{n}{2}\\right)}\\left(1+\\frac{y^{2}}{n}\\right)^{-\\frac{n+1}{2}}$ | 0 | $(n>4)$ |\n|  | $(-\\infty<y<+\\infty)$ | $n-1$ | $(n>2)$ |  \n下面我们将对它们逐个进行推导与说明.",
        "metadata": {
            "Header 2": "5.4 三大抽样分布"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 5.4.1. 设 $X_{1}, X_{2}, \\cdots, X_{n}$ 独立同分布于标准正态分布 $N(0,1)$, 则 $\\chi^{2}=X_{1}^{2}+\\cdots+X_{n}^{2}$ 的分布称为自由度为 $n$ 的 $\\chi^{2}$ 分布, 记为 $\\chi^{2} \\sim \\chi^{2}(n)$.  \n在第三章我们已经指出, 若 $X \\sim N(0,1)$, 则 $X^{2} \\sim G a(1 / 2,1 / 2)$, 根据伽玛分布的可加性立有 $\\chi^{2} \\sim G a(n / 2, n / 2)=\\chi^{2}(n)$, 由此可见, $\\chi^{2}(n)$ 分布是伽玛分布的特例, 故 $\\chi^{2}(n)$ 分布的密度函数为  \n$$\np(y)=\\frac{(1 / 2)^{\\frac{n}{2}}}{\\Gamma(n / 2)} y^{\\frac{n}{2}-1} \\mathrm{e}^{-\\frac{y}{2}}, \\quad y>0\n$$  \n该密度函数的图像是一个只取非负值的偏态分布, 见图 5.4.1, 其期望等于自由度, 方差等于 2 倍自由度, 即 $E \\chi^{2}=n, \\operatorname{Var}\\left(\\chi^{2}\\right)=2 n$.  \n!  \n图 5.4.1: $\\chi^{2}(n)$ 分布的密度函数  \n当随机变量 $\\chi^{2} \\sim \\chi^{2}(n)$ 时, 对给定 $\\alpha(0<\\alpha<1)$, 称满足 $P\\left(\\chi^{2} \\leqslant \\chi_{1-\\alpha}^{2}(n)\\right)=1-\\alpha$ 的 $\\chi_{1-\\alpha}^{2}$是自由度为 $n$ 的卡方分布的 $1-\\alpha$ 分位数. 分位数 $\\chi_{1-\\alpha}^{2}(n)$ 可以从附表 3 中查到. 譬如 $n=10, \\alpha=$ 0.05 , 那么从附表 3 上查得  \n$$\n\\chi_{1-0.05}^{2}(10)=\\chi_{0.95}^{2}(10)=18.31\n$$",
        "metadata": {
            "Header 2": "5.4 三大抽样分布",
            "Header 3": "5.4.1 $\\chi^{2}$ 分布 (卡方分布)"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 5.4.2. 设 $X_{1} \\sim \\chi^{2}(m), X_{2} \\sim \\chi^{2}(n), X_{1}$ 与 $X_{2}$ 独立, 则称 $F+\\frac{X_{1} / m}{X_{2} / n}$ 的分布是自由度为 $m$ 与 $n$的 $F$ 分布, 记为 $F \\sim F(m, n)$, 其中 $m$ 称为分子自由度, $n$ 称为分母自由度.  \n下面分两步来导出 $F$ 分布的密度函数.  \n首先我们导出 $Z=\\frac{X_{1}}{X_{2}}$ 的密度函数, 若记 $p_{1}(x)$ 和 $p_{2}(x)$ 分别为 $\\chi^{2}(m)$ 和 $\\chi^{2}(n)$ 的密度函数,根据独立随机变量商的分布的密度函数公式 (3.3.22). $Z$ 的密度函数为  \n$$\n\\begin{aligned}\np_{Z}(z) & =\\int_{0}^{=\\infty} x_{2} p_{1}\\left(z x_{2}\\right) p_{2}\\left(x_{2}\\right) \\mathrm{d} x_{2} \\\\\n& =\\frac{z^{\\frac{m}{2}-1}}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right) 2^{\\frac{m+n}{2}}} \\int_{0}^{+\\infty} x_{2}^{\\frac{m+n}{2}-1} \\mathrm{e}^{-\\frac{x_{2}}{2}(1+z)} \\mathrm{d} x_{2} .\n\\end{aligned}\n$$  \n运用变换 $u=\\frac{x_{2}}{2}(1+z)$, 可得  \n$$\np_{Z}(z)=\\frac{z^{\\frac{m}{2}-1}(1+z)^{\\frac{m+n}{2}}}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)} \\int_{0}^{+\\infty} u^{\\frac{m+n}{2}-1} \\mathrm{e}^{-u} \\mathrm{~d} u\n$$  \n!  \n图 5.4.2: $F$ 分布的密度函数",
        "metadata": {
            "Header 2": "5.4 三大抽样分布",
            "Header 3": "5.4.2 F 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{z^{\\frac{m}{2}-1}}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right) 2^{\\frac{m+n}{2}}} \\int_{0}^{+\\infty} x_{2}^{\\frac{m+n}{2}-1} \\mathrm{e}^{-\\frac{x_{2}}{2}(1+z)} \\mathrm{d} x_{2} .\n\\end{aligned}\n$$  \n运用变换 $u=\\frac{x_{2}}{2}(1+z)$, 可得  \n$$\np_{Z}(z)=\\frac{z^{\\frac{m}{2}-1}(1+z)^{\\frac{m+n}{2}}}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)} \\int_{0}^{+\\infty} u^{\\frac{m+n}{2}-1} \\mathrm{e}^{-u} \\mathrm{~d} u\n$$  \n!  \n图 5.4.2: $F$ 分布的密度函数  \n最后的定积分为伽马函数 $\\Gamma\\left(\\frac{m+n}{2}\\right)$, 从而  \n$$\np_{Z}(z)=\\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)} z^{\\frac{m}{2}-1}(1+z)^{-\\frac{m+n}{2}}, \\quad z>0\n$$  \n第二步, 我们导出 $F=\\frac{n}{m} Z$ 的密度函数, 对 $y>0$, 有  \n$$\n\\begin{aligned}\np_{F}(y) & =p_{Z}\\left(\\frac{m}{n} y\\right) \\cdot \\frac{m}{n} \\\\",
        "metadata": {
            "Header 2": "5.4 三大抽样分布",
            "Header 3": "5.4.2 F 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n!  \n图 5.4.2: $F$ 分布的密度函数  \n最后的定积分为伽马函数 $\\Gamma\\left(\\frac{m+n}{2}\\right)$, 从而  \n$$\np_{Z}(z)=\\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)} z^{\\frac{m}{2}-1}(1+z)^{-\\frac{m+n}{2}}, \\quad z>0\n$$  \n第二步, 我们导出 $F=\\frac{n}{m} Z$ 的密度函数, 对 $y>0$, 有  \n$$\n\\begin{aligned}\np_{F}(y) & =p_{Z}\\left(\\frac{m}{n} y\\right) \\cdot \\frac{m}{n} \\\\\n& =\\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)}\\left(\\frac{m}{n} y\\right)^{\\frac{m}{2}-1}\\left(1+\\frac{m}{n} y\\right)^{-\\frac{m+n}{2}} \\cdot \\frac{m}{n} \\\\\n& =\\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)\\left(\\frac{m}{n}\\right)^{\\frac{m}{2}}}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)} y^{\\frac{m}{2}-1}\\left(1+\\frac{m}{n} y\\right)^{-\\frac{m+n}{2}} .\n\\end{aligned}\n$$  \n这就是自由度为 $m$ 与 $n$ 的 $F$ 分布的密度函数. 该密度函数的图像是一个只取非负值的偏态分布 (见图 5.4.2)",
        "metadata": {
            "Header 2": "5.4 三大抽样分布",
            "Header 3": "5.4.2 F 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{\\Gamma\\left(\\frac{m+n}{2}\\right)\\left(\\frac{m}{n}\\right)^{\\frac{m}{2}}}{\\Gamma\\left(\\frac{m}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)} y^{\\frac{m}{2}-1}\\left(1+\\frac{m}{n} y\\right)^{-\\frac{m+n}{2}} .\n\\end{aligned}\n$$  \n这就是自由度为 $m$ 与 $n$ 的 $F$ 分布的密度函数. 该密度函数的图像是一个只取非负值的偏态分布 (见图 5.4.2)  \n当随机变量 $F \\sim F(n, m)$ 时, 对给定 $\\alpha(0<\\alpha<1)$, 称满足 $P\\left(F \\leqslant F_{1-\\alpha}(m, n)\\right)=1-\\alpha$ 的 $F_{1-\\alpha}(m, n)$ 是自由度为 $m$ 与 $n$ 的 $F$ 分布的 $1-\\alpha$ 分位数.  \n由 $F$ 分布的构造知, 若 $F \\sim F(m, n)$, 则有 $1 / F \\sim F(n, m)$, 故对给定 $\\alpha(0<\\alpha<1)$,  \n$$\n\\alpha=P\\left(\\frac{1}{F}<F_{\\alpha}(n, m)\\right)=P\\left(F \\geqslant \\frac{1}{F_{\\alpha}(n, m)}\\right) .\n$$  \n从而  \n$$\nP\\left(F \\leqslant \\frac{1}{F_{\\alpha}(n, m)}\\right)=1-\\alpha\n$$  \n这说明  \n$$\n\\begin{equation*}\nF_{\\alpha}(n, m)=\\frac{1}{F_{1-\\alpha}(m, n)} \\tag{5.4.1}\n\\end{equation*}\n$$  \n对小的 $\\alpha$, 分位数 $F_{1-\\alpha}(m, n)$ 可以从附表 5 中查到, 而分位数 $F_{\\alpha}(m, n)$ 则可通过 (5.4.1) 得到.",
        "metadata": {
            "Header 2": "5.4 三大抽样分布",
            "Header 3": "5.4.2 F 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "由 $F$ 分布的构造知, 若 $F \\sim F(m, n)$, 则有 $1 / F \\sim F(n, m)$, 故对给定 $\\alpha(0<\\alpha<1)$,  \n$$\n\\alpha=P\\left(\\frac{1}{F}<F_{\\alpha}(n, m)\\right)=P\\left(F \\geqslant \\frac{1}{F_{\\alpha}(n, m)}\\right) .\n$$  \n从而  \n$$\nP\\left(F \\leqslant \\frac{1}{F_{\\alpha}(n, m)}\\right)=1-\\alpha\n$$  \n这说明  \n$$\n\\begin{equation*}\nF_{\\alpha}(n, m)=\\frac{1}{F_{1-\\alpha}(m, n)} \\tag{5.4.1}\n\\end{equation*}\n$$  \n对小的 $\\alpha$, 分位数 $F_{1-\\alpha}(m, n)$ 可以从附表 5 中查到, 而分位数 $F_{\\alpha}(m, n)$ 则可通过 (5.4.1) 得到.  \n例 5.4.1: 若取 $m=10, n=5, \\alpha=0.05$, 那么从附表 4 上查得  \n$$\nF_{1-0.05}(10,5)=F_{0.95}(10,5)=4.74\n$$  \n利用 (5.4.1) 可得到  \n$$\nF_{0.05}(10,5)=\\frac{1}{F_{0.95}(5,10)}=\\frac{1}{3.33}=0.3 .\n$$",
        "metadata": {
            "Header 2": "5.4 三大抽样分布",
            "Header 3": "5.4.2 F 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 5.4.3. 设随机变量 $X_{1}$ 与 $X_{2}$ 独立且 $X_{1} \\sim N(0,1), X_{2} \\sim \\chi^{2}(n)$, 则称 $t=\\frac{X_{1}}{\\sqrt{X_{2} / n}}$ 的分布为自由度为 $n$ 的 $t$ 分布, 记为 $t \\sim t(n)$.  \n下面导出 $t$ 分布的密度函数. 由标准正态密度函数的对称性知, $X_{1}$ 与 $-X_{1}$ 有相同分布, 从而 $t$  \n!  \n图 5.4.3: $t$ 分布与 $N(0,1)$ 的密度函数  \n与 $-t$ 有相同分布. 这意味着: 对任意实数 $y$ 有  \n$$\nP(0<t<y)=P(-y<-t<y)=P(-y<-t<0) \\text {. }\n$$  \n于是  \n$$\nP(0<t<y)=\\frac{1}{2} P\\left(t^{2}<y^{2}\\right) .\n$$  \n由 $F$ 变量构造可知, $t^{2}=\\frac{X_{1}^{2}}{X_{2}^{2} / n} \\sim F(1, n)$, 将上式两边关于 $y$ 求导可微 $t$ 分布的密度函数为  \n$$\n\\begin{aligned}\np_{t}(y) & =y p_{F}\\left(y^{2}\\right)=\\frac{\\Gamma\\left(\\frac{1+n}{2}\\right)\\left(\\frac{1}{n}\\right)^{\\frac{1}{n}}}{\\Gamma\\left(\\frac{1}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)}\\left(y^{2}\\right)^{\\frac{1}{2}-1}\\left(1+\\frac{1}{n} y^{2}\\right)^{-\\frac{1+n}{2}} y \\\\\n& =\\frac{\\Gamma\\left(\\frac{n+1}{2}\\right)}{\\sqrt{n \\pi} \\Gamma\\left(\\frac{n}{2}\\right)}\\left(1+\\frac{y^{2}}{n}\\right)^{-\\frac{n+1}{2}}, \\quad-\\infty<y<+\\infty .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\np_{t}(y) & =y p_{F}\\left(y^{2}\\right)=\\frac{\\Gamma\\left(\\frac{1+n}{2}\\right)\\left(\\frac{1}{n}\\right)^{\\frac{1}{n}}}{\\Gamma\\left(\\frac{1}{2}\\right) \\Gamma\\left(\\frac{n}{2}\\right)}\\left(y^{2}\\right)^{\\frac{1}{2}-1}\\left(1+\\frac{1}{n} y^{2}\\right)^{-\\frac{1+n}{2}} y \\\\\n& =\\frac{\\Gamma\\left(\\frac{n+1}{2}\\right)}{\\sqrt{n \\pi} \\Gamma\\left(\\frac{n}{2}\\right)}\\left(1+\\frac{y^{2}}{n}\\right)^{-\\frac{n+1}{2}}, \\quad-\\infty<y<+\\infty .\n\\end{aligned}\n$$  \n这就是自由度为 $n$ 的 $t$ 分布的密度函数.  \n$t$ 分布的密度函数的图像是一个关于纵轴对称的分布 (图 5.4.3), 与标准正态分布的密度函数形状类似, 只是峰比标准正态分布低一些, 尾部的概率比标准正态分布的大一些.  \n- 自由度为 1 的 $t$ 分布就是标准柯西分布, 它的均值不存在;\n- $n>1$ 时, $t$ 分布的数学期望存在切尾 0 ;\n- $n>2$ 时, $t$ 分布的方程存在, 且为 $n /(n-2)$;\n- 当自由度较大 (如 $n \\geqslant 30$ 时), $t$ 分布可以用 $N(0,1)$ 分布近似.",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{\\Gamma\\left(\\frac{n+1}{2}\\right)}{\\sqrt{n \\pi} \\Gamma\\left(\\frac{n}{2}\\right)}\\left(1+\\frac{y^{2}}{n}\\right)^{-\\frac{n+1}{2}}, \\quad-\\infty<y<+\\infty .\n\\end{aligned}\n$$  \n这就是自由度为 $n$ 的 $t$ 分布的密度函数.  \n$t$ 分布的密度函数的图像是一个关于纵轴对称的分布 (图 5.4.3), 与标准正态分布的密度函数形状类似, 只是峰比标准正态分布低一些, 尾部的概率比标准正态分布的大一些.  \n- 自由度为 1 的 $t$ 分布就是标准柯西分布, 它的均值不存在;\n- $n>1$ 时, $t$ 分布的数学期望存在切尾 0 ;\n- $n>2$ 时, $t$ 分布的方程存在, 且为 $n /(n-2)$;\n- 当自由度较大 (如 $n \\geqslant 30$ 时), $t$ 分布可以用 $N(0,1)$ 分布近似.  \n$t$ 分布是统计学中的一类重要分布, 它与标准正态分布的微小差别是由英国统计学家哥塞特 (Gosset) 发现的. 哥塞特年轻时在牛津大学学习数学和化学, 1899 年开始在一家酿酒厂担任酿酒化学技师, 从事试验和数据分析工作. 由于哥塞特接触的样本容量都较小, 只有 4,5 过大量实验数据的积累, 哥塞特发现 $t=\\sqrt{n-1}(\\bar{x}-\\mu) / s$ 的分布与传统认为的 $N(0,1)$ 分布并不同, 特别是尾部概率相差较大, 表 5.4.2 列出了标准正态分布 $N(0,1)$ 和自由度为 4 的 $t$ 分布的一些尾部概率.  \n| 表 5.4.2: $N(0,1)$ 和 $t(4)$ 的尾部概率 $P(\\|X\\| \\geqslant c)$ |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $c=2$ | $c=2.5$ | $c=3$ | $c=3.5$ |  |\n| $X \\sim N(0,1)$ | 0.0455 | 0.0124 | 0.0027 | 0.000465 |",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "$t$ 分布是统计学中的一类重要分布, 它与标准正态分布的微小差别是由英国统计学家哥塞特 (Gosset) 发现的. 哥塞特年轻时在牛津大学学习数学和化学, 1899 年开始在一家酿酒厂担任酿酒化学技师, 从事试验和数据分析工作. 由于哥塞特接触的样本容量都较小, 只有 4,5 过大量实验数据的积累, 哥塞特发现 $t=\\sqrt{n-1}(\\bar{x}-\\mu) / s$ 的分布与传统认为的 $N(0,1)$ 分布并不同, 特别是尾部概率相差较大, 表 5.4.2 列出了标准正态分布 $N(0,1)$ 和自由度为 4 的 $t$ 分布的一些尾部概率.  \n| 表 5.4.2: $N(0,1)$ 和 $t(4)$ 的尾部概率 $P(\\|X\\| \\geqslant c)$ |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: |\n| $c=2$ | $c=2.5$ | $c=3$ | $c=3.5$ |  |\n| $X \\sim N(0,1)$ | 0.0455 | 0.0124 | 0.0027 | 0.000465 |\n| $X \\sim t(4)$ | 0.1161 | 0.0668 | 0.0399 | 0.0249 |  \n由此, 哥塞特怀疑是否有另一个分布族存在, 通过深人研究, 哥塞特于 1908 年 “Studen” 的笔名发表了此项研究结果, 故后人也称 $t$ 分布为学生氏分布. $t$ 分布的发现在统计学史上具有划时代的意义, 打破了正态分布一统天下的局面, 开创了小样本统计推断的新纪元.\n当随机变量 $t \\sim t(n)$, 称满足 $P\\left(t \\leqslant t_{1-\\alpha}(n)\\right)=1-\\alpha$ 的 $t_{1-\\alpha}(n)$ 是自由度为 $n$ 的 $t$ 分布的 $1-\\alpha$ 分位数. 分位数 $t_{1-\\alpha}(n)$ 可以从附表 3 中查到. 譬如 $n=10, \\alpha=0.05$, 那么从附表 4 上查得 $t_{1-0.05}(10)=t_{0.95}(10)=1.812$.  \n由于 $t$ 分布的密度函数关于 0 对称, 故其分位数间有如下关系  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "| $X \\sim t(4)$ | 0.1161 | 0.0668 | 0.0399 | 0.0249 |  \n由此, 哥塞特怀疑是否有另一个分布族存在, 通过深人研究, 哥塞特于 1908 年 “Studen” 的笔名发表了此项研究结果, 故后人也称 $t$ 分布为学生氏分布. $t$ 分布的发现在统计学史上具有划时代的意义, 打破了正态分布一统天下的局面, 开创了小样本统计推断的新纪元.\n当随机变量 $t \\sim t(n)$, 称满足 $P\\left(t \\leqslant t_{1-\\alpha}(n)\\right)=1-\\alpha$ 的 $t_{1-\\alpha}(n)$ 是自由度为 $n$ 的 $t$ 分布的 $1-\\alpha$ 分位数. 分位数 $t_{1-\\alpha}(n)$ 可以从附表 3 中查到. 譬如 $n=10, \\alpha=0.05$, 那么从附表 4 上查得 $t_{1-0.05}(10)=t_{0.95}(10)=1.812$.  \n由于 $t$ 分布的密度函数关于 0 对称, 故其分位数间有如下关系  \n$$\n\\begin{equation*}\nt_{\\alpha}(n)=-t_{1-\\alpha}(n) \\tag{5.4.2}\n\\end{equation*}\n$$  \n譬如, $t_{0.05}(10)=-t_{0.95}(10)=-1.812$.",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布"
        },
        "type": "Document"
    },
    {
        "page_content": "来自一般正态总体的样本均值 $x$ 和样本方差 $s_{2}$ 的抽样分布是应用最广的抽样分布, 下面我们加以介绍.  \n定理 5.4.1. 设 $x_{1}, \\cdots, x_{n}$ 是来自正态总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 其样本均值和样本方差分别为  \n$$\n\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i} \\text { 和 } s^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2} \\text {, }\n$$  \n则有  \n(1) $\\bar{x}$ 相互独立;  \n(2) $\\bar{x} \\sim N\\left(\\mu, \\sigma^{2} / n\\right)$;  \n(3) $\\frac{(n-1) \\cdot s^{2}}{\\sigma^{2}}=\\chi^{2}(n-1)$.  \n证明: 记 $\\boldsymbol{X}=\\left(x_{1}, \\cdots, x_{n}\\right)^{\\mathrm{T}}$, 则有  \n$$\nE \\boldsymbol{X}=(\\mu: \\mu), \\boldsymbol{X}=\\sigma^{2} \\boldsymbol{I}\n$$  \n取一个 $n$ 维正交矩阵 $\\boldsymbol{A}$, 其第一行的每一个元素均为 $1 / \\sqrt{n}$, 如  \n$$\nA=\\left(\\begin{array}{ccccc}\n\\frac{1}{\\sqrt{n}} & \\frac{1}{\\sqrt{n}} & \\frac{1}{\\sqrt{n}} & \\cdots & \\frac{1}{\\sqrt{n}} \\\\\n\\frac{1}{\\sqrt{2 \\cdot 1}} & -\\frac{1}{\\sqrt{2 \\cdot 1}} & 0 & \\cdots & 0 \\\\\n\\frac{1}{\\sqrt{3 \\cdot 2}} & \\frac{1}{\\sqrt{3 \\cdot 2}} & -\\frac{2}{\\sqrt{3 \\cdot 2}} & \\cdots & 0 \\\\",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nE \\boldsymbol{X}=(\\mu: \\mu), \\boldsymbol{X}=\\sigma^{2} \\boldsymbol{I}\n$$  \n取一个 $n$ 维正交矩阵 $\\boldsymbol{A}$, 其第一行的每一个元素均为 $1 / \\sqrt{n}$, 如  \n$$\nA=\\left(\\begin{array}{ccccc}\n\\frac{1}{\\sqrt{n}} & \\frac{1}{\\sqrt{n}} & \\frac{1}{\\sqrt{n}} & \\cdots & \\frac{1}{\\sqrt{n}} \\\\\n\\frac{1}{\\sqrt{2 \\cdot 1}} & -\\frac{1}{\\sqrt{2 \\cdot 1}} & 0 & \\cdots & 0 \\\\\n\\frac{1}{\\sqrt{3 \\cdot 2}} & \\frac{1}{\\sqrt{3 \\cdot 2}} & -\\frac{2}{\\sqrt{3 \\cdot 2}} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{1}{\\sqrt{n(n-1)}} & \\frac{1}{\\sqrt{n(n-1)}} & \\frac{1}{\\sqrt{n(n-1)}} & \\cdots & -\\frac{1}{\\sqrt{n(n-1)}}\n\\end{array}\\right)\n$$  \n令 $\\boldsymbol{Y}=\\boldsymbol{A X}$, 则由多维正态分布的性质知 $\\boldsymbol{Y}$ 仍服从 $n$ 维正态分布, 其均值和方差为  \n$$\n\\begin{aligned}\n& E \\boldsymbol{Y} \\boldsymbol{A} \\cdot E \\boldsymbol{X}=\\left(\\begin{array}{c}\n\\sqrt{n} \\mu \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{array}\\right) \\\\\n& \\begin{aligned}",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{1}{\\sqrt{n(n-1)}} & \\frac{1}{\\sqrt{n(n-1)}} & \\frac{1}{\\sqrt{n(n-1)}} & \\cdots & -\\frac{1}{\\sqrt{n(n-1)}}\n\\end{array}\\right)\n$$  \n令 $\\boldsymbol{Y}=\\boldsymbol{A X}$, 则由多维正态分布的性质知 $\\boldsymbol{Y}$ 仍服从 $n$ 维正态分布, 其均值和方差为  \n$$\n\\begin{aligned}\n& E \\boldsymbol{Y} \\boldsymbol{A} \\cdot E \\boldsymbol{X}=\\left(\\begin{array}{c}\n\\sqrt{n} \\mu \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{array}\\right) \\\\\n& \\begin{aligned}\n\\operatorname{Var}(\\boldsymbol{Y}) & =\\boldsymbol{A} \\cdot\\left(\\boldsymbol{X} \\cdot \\boldsymbol{A}^{\\mathrm{T}}=\\boldsymbol{A} \\cdot \\sigma^{2} \\boldsymbol{I} \\cdot \\boldsymbol{A}^{\\mathrm{T}}\\right. \\\\\n& =\\sigma^{2} \\boldsymbol{A} \\boldsymbol{A}^{\\mathrm{T}}=\\sigma^{2} \\boldsymbol{I},\n\\end{aligned}\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n& E \\boldsymbol{Y} \\boldsymbol{A} \\cdot E \\boldsymbol{X}=\\left(\\begin{array}{c}\n\\sqrt{n} \\mu \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{array}\\right) \\\\\n& \\begin{aligned}\n\\operatorname{Var}(\\boldsymbol{Y}) & =\\boldsymbol{A} \\cdot\\left(\\boldsymbol{X} \\cdot \\boldsymbol{A}^{\\mathrm{T}}=\\boldsymbol{A} \\cdot \\sigma^{2} \\boldsymbol{I} \\cdot \\boldsymbol{A}^{\\mathrm{T}}\\right. \\\\\n& =\\sigma^{2} \\boldsymbol{A} \\boldsymbol{A}^{\\mathrm{T}}=\\sigma^{2} \\boldsymbol{I},\n\\end{aligned}\n\\end{aligned}\n$$  \n由此, $\\boldsymbol{Y}=\\left(y_{1}, \\cdots, y_{n}\\right)^{\\mathrm{T}}$ 的各个分量相互独立, 且都服从正态分布, 其方差均为 $\\sigma^{2}$, 而均值并不完全相同, $y_{1}$ 的均值为 $\\sqrt{n} \\mu, y_{2}, \\cdots, y_{n}$ 的均值为 0 . 注意到 $\\bar{x}=\\frac{1}{\\sqrt{n}} y_{1}$, 这就证明了结论 (2); 由于 $\\sum_{i=1}^{n} y_{i}^{2}=\\boldsymbol{Y}^{\\mathrm{T}} \\boldsymbol{Y}=\\boldsymbol{X}^{\\mathrm{T}} \\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A} \\boldsymbol{X}=\\sum_{i=1}^{n} x_{i}^{2}$, 故而  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n\\end{aligned}\n$$  \n由此, $\\boldsymbol{Y}=\\left(y_{1}, \\cdots, y_{n}\\right)^{\\mathrm{T}}$ 的各个分量相互独立, 且都服从正态分布, 其方差均为 $\\sigma^{2}$, 而均值并不完全相同, $y_{1}$ 的均值为 $\\sqrt{n} \\mu, y_{2}, \\cdots, y_{n}$ 的均值为 0 . 注意到 $\\bar{x}=\\frac{1}{\\sqrt{n}} y_{1}$, 这就证明了结论 (2); 由于 $\\sum_{i=1}^{n} y_{i}^{2}=\\boldsymbol{Y}^{\\mathrm{T}} \\boldsymbol{Y}=\\boldsymbol{X}^{\\mathrm{T}} \\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A} \\boldsymbol{X}=\\sum_{i=1}^{n} x_{i}^{2}$, 故而  \n$$\n\\begin{aligned}\n(n-1) \\cdot s^{2} & =\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}=\\sum_{i=1}^{n} x_{i}^{2}-(\\sqrt{n} \\bar{x})^{2} \\\\\n& =\\sum_{i=1}^{n} y_{i}^{2}-y_{1}^{2}=\\sum_{i=2}^{n} y_{i}^{2}\n\\end{aligned}\n$$  \n这证明结论 (1); 由于 $y_{2}, \\cdots, y_{n}$ 独立同分布于 $N\\left(0, \\sigma^{2}\\right)$, 于是  \n$$\n\\begin{equation*}\n\\frac{(n-1) \\cdot s^{2}}{\\sigma^{2}}=\\sum_{i=2}^{n}\\left(\\frac{y_{i}}{\\sigma}\\right)^{2} \\sim \\chi^{2}(n-1), \\tag{5.4.3}\n\\end{equation*}\n$$  \n定理证明完成.  \n推论 5.4.1. 在定理 5.4.1 的记号下, 有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\sum_{i=1}^{n} y_{i}^{2}-y_{1}^{2}=\\sum_{i=2}^{n} y_{i}^{2}\n\\end{aligned}\n$$  \n这证明结论 (1); 由于 $y_{2}, \\cdots, y_{n}$ 独立同分布于 $N\\left(0, \\sigma^{2}\\right)$, 于是  \n$$\n\\begin{equation*}\n\\frac{(n-1) \\cdot s^{2}}{\\sigma^{2}}=\\sum_{i=2}^{n}\\left(\\frac{y_{i}}{\\sigma}\\right)^{2} \\sim \\chi^{2}(n-1), \\tag{5.4.3}\n\\end{equation*}\n$$  \n定理证明完成.  \n推论 5.4.1. 在定理 5.4.1 的记号下, 有  \n$$\n\\begin{equation*}\nt=\\frac{\\sqrt{n}(\\bar{x}-\\mu)}{s} \\sim t(n-1) . \\tag{5.4.4}\n\\end{equation*}\n$$  \n证明: 由定理 5.4.1(2) 可以推出  \n$$\n\\begin{equation*}\n\\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}} \\sim N(0,1) \\tag{5.4.5}\n\\end{equation*}\n$$  \n将 5.4.4 左端改写为  \n$$\n\\begin{equation*}\n\\frac{\\sqrt{n}(\\bar{x}-\\mu)}{\\sigma / \\sqrt{n}}=\\frac{\\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}}}{\\sqrt{\\frac{(n-1) \\cdot s^{2} / \\sigma^{2}}{n-1}}} \\tag{5.4.6}\n\\end{equation*}\n$$  \n由于分子是标准正态变量, 分母的根号里是自由度为 $n-1$ 的 $t$ 变量除以它的自由度, 且分子与分母相互独立, 由 $t$ 分布定义可知 $t \\sim t(n-1)$, 推论证完.",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n证明: 由定理 5.4.1(2) 可以推出  \n$$\n\\begin{equation*}\n\\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}} \\sim N(0,1) \\tag{5.4.5}\n\\end{equation*}\n$$  \n将 5.4.4 左端改写为  \n$$\n\\begin{equation*}\n\\frac{\\sqrt{n}(\\bar{x}-\\mu)}{\\sigma / \\sqrt{n}}=\\frac{\\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}}}{\\sqrt{\\frac{(n-1) \\cdot s^{2} / \\sigma^{2}}{n-1}}} \\tag{5.4.6}\n\\end{equation*}\n$$  \n由于分子是标准正态变量, 分母的根号里是自由度为 $n-1$ 的 $t$ 变量除以它的自由度, 且分子与分母相互独立, 由 $t$ 分布定义可知 $t \\sim t(n-1)$, 推论证完.  \n推论 5.4.2. 设 $x_{1}, \\cdots, x_{m}$ 是来自 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 的样本, $y_{1}, \\cdots, y_{n}$ 是来自 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$ 的样本, 且此两样本相互独立, 记  \n$$\ns_{x}^{2}=\\frac{1}{m-1} \\sum_{i=1}^{m}\\left(x_{i}-\\bar{x}\\right)^{2}, \\quad s_{y}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}\n$$  \n其中  \n$$\n\\bar{x}=\\frac{1}{m} \\sum_{i=1}^{m} x_{i}, \\quad \\bar{y}=\\frac{1}{n} \\sum_{i=1}^{n} y_{i}\n$$  \n则有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "推论 5.4.2. 设 $x_{1}, \\cdots, x_{m}$ 是来自 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 的样本, $y_{1}, \\cdots, y_{n}$ 是来自 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$ 的样本, 且此两样本相互独立, 记  \n$$\ns_{x}^{2}=\\frac{1}{m-1} \\sum_{i=1}^{m}\\left(x_{i}-\\bar{x}\\right)^{2}, \\quad s_{y}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}\n$$  \n其中  \n$$\n\\bar{x}=\\frac{1}{m} \\sum_{i=1}^{m} x_{i}, \\quad \\bar{y}=\\frac{1}{n} \\sum_{i=1}^{n} y_{i}\n$$  \n则有  \n$$\n\\begin{equation*}\nF=\\frac{s_{x}^{2} / \\sigma_{1}^{2}}{s_{y}^{2} / \\sigma_{2}^{2}} \\sim F(m-1, n-1) \\tag{5.4.7}\n\\end{equation*}\n$$  \n特别, 若 $\\sigma_{1}^{2}=\\sigma_{2}^{2}$, 则 $F=s_{x}^{2} / s_{y}^{2} \\sim F(m-1, n-1)$.  \n证明: 由两样本独立可知, $s_{x}^{2}$ 与 $s_{y}^{2}$ 相互独立, 且  \n$$\n\\frac{(m-1) s_{x}^{2}}{\\sigma_{1}^{2}} \\sim \\chi^{2}(m-1), \\quad \\frac{(n-1) s_{y}^{2}}{\\sigma_{1}^{2}} \\sim \\chi^{2}(n-1)\n$$  \n由 $F$ 分布定义可知 $F \\sim F(m-1, n-1)$.  \n推论 5.4.3. 在推论 5.4.2的记号下, 设 $\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\sigma^{2}$, 并记  \n$$",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "F=\\frac{s_{x}^{2} / \\sigma_{1}^{2}}{s_{y}^{2} / \\sigma_{2}^{2}} \\sim F(m-1, n-1) \\tag{5.4.7}\n\\end{equation*}\n$$  \n特别, 若 $\\sigma_{1}^{2}=\\sigma_{2}^{2}$, 则 $F=s_{x}^{2} / s_{y}^{2} \\sim F(m-1, n-1)$.  \n证明: 由两样本独立可知, $s_{x}^{2}$ 与 $s_{y}^{2}$ 相互独立, 且  \n$$\n\\frac{(m-1) s_{x}^{2}}{\\sigma_{1}^{2}} \\sim \\chi^{2}(m-1), \\quad \\frac{(n-1) s_{y}^{2}}{\\sigma_{1}^{2}} \\sim \\chi^{2}(n-1)\n$$  \n由 $F$ 分布定义可知 $F \\sim F(m-1, n-1)$.  \n推论 5.4.3. 在推论 5.4.2的记号下, 设 $\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\sigma^{2}$, 并记  \n$$\ns_{w}^{2}=\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{m+n-2}=\\frac{\\sum_{i=1}^{m}\\left(x_{i}-\\bar{x}\\right)^{2}+\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}{m+n-2},\n$$  \n则  \n$$\n\\begin{equation*}\n\\frac{(\\bar{x}-\\bar{y})-\\left(\\mu_{1}-\\mu_{2}\\right)}{s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}} \\sim t(m+n-2) . \\tag{5.4.8}\n\\end{equation*}\n$$  \n证明: 由 $\\bar{x} \\sim N\\left(\\mu_{1}, \\sigma^{2} / m\\right), \\bar{y} \\sim N\\left(\\mu_{2}, \\sigma^{2} / n\\right), \\bar{x}$ 与 $\\bar{y}$ 独立, 故有  \n$$",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\ns_{w}^{2}=\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{m+n-2}=\\frac{\\sum_{i=1}^{m}\\left(x_{i}-\\bar{x}\\right)^{2}+\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}{m+n-2},\n$$  \n则  \n$$\n\\begin{equation*}\n\\frac{(\\bar{x}-\\bar{y})-\\left(\\mu_{1}-\\mu_{2}\\right)}{s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}} \\sim t(m+n-2) . \\tag{5.4.8}\n\\end{equation*}\n$$  \n证明: 由 $\\bar{x} \\sim N\\left(\\mu_{1}, \\sigma^{2} / m\\right), \\bar{y} \\sim N\\left(\\mu_{2}, \\sigma^{2} / n\\right), \\bar{x}$ 与 $\\bar{y}$ 独立, 故有  \n$$\n\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2},\\left(\\frac{1}{m}+\\frac{1}{n}\\right) \\sigma^{2}\\right),\n$$  \n所以  \n$$\n\\begin{equation*}\n\\frac{(\\bar{x}-\\bar{y})-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sigma \\sqrt{\\frac{1}{m}+\\frac{1}{n}}} \\sim N((, 1)) . \\tag{5.4.9}\n\\end{equation*}\n$$  \n由定理 5.4.1 知, $\\frac{(m-1) s_{x}^{2}}{\\sigma^{2}} \\sim \\chi^{2}(m-1), \\frac{(n-1) s_{y}^{2}}{\\sigma^{2}} \\sim \\chi^{2}(n-1)$, 且它们相互独立, 则由可加性知  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2},\\left(\\frac{1}{m}+\\frac{1}{n}\\right) \\sigma^{2}\\right),\n$$  \n所以  \n$$\n\\begin{equation*}\n\\frac{(\\bar{x}-\\bar{y})-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sigma \\sqrt{\\frac{1}{m}+\\frac{1}{n}}} \\sim N((, 1)) . \\tag{5.4.9}\n\\end{equation*}\n$$  \n由定理 5.4.1 知, $\\frac{(m-1) s_{x}^{2}}{\\sigma^{2}} \\sim \\chi^{2}(m-1), \\frac{(n-1) s_{y}^{2}}{\\sigma^{2}} \\sim \\chi^{2}(n-1)$, 且它们相互独立, 则由可加性知  \n$$\n\\begin{equation*}\n\\frac{(m+n-2) s_{w}^{2}}{\\sigma^{2}}=\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{\\sigma^{2}} \\sim \\chi^{2}(m+n-2) . \\tag{5.4.10}\n\\end{equation*}\n$$  \n由于 $\\bar{x}-\\bar{y}$ 与 $s_{w}^{2}$ 相互独立, 根据 $t$ 分布的定义即可得到 (5.4.8).",
        "metadata": {
            "Header 2": "$5.4 .3 t$ 分布",
            "Header 3": "5.4.4 一些重要结论"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 在总体 $N(7.6 .4)$ 中抽取样本容量为 $n$ 的样本, 如果要求样本均值落在 $(5.6,9.6)$ 内的概率不小于 0.95 , 则 $n$ 至少为多少?\n2. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N(\\mu, 25)$ 的样本, 问 $n$ 多大时才能使得 $P(|\\bar{x}-\\mu|<1) \\geqslant 10.95$ 成立?\n3. 由正态总体 $N(100,4)$ 抽取二个独立样本, 样本均值分别为 $\\bar{x}, \\bar{y}$, 样本容量分别为 15,20 , 试求 $P(|\\bar{x}-\\bar{y}|>0.2)$.\n4. 由正态总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 抽取容量为 20 的样本, 试求 $P\\left(10 \\sigma^{2} \\leqslant \\sum_{i=1}^{20}\\left(x_{i}-\\mu\\right)^{2} \\leqslant 30 \\sigma^{2}\\right)$.\n5. 设 $x_{1}, \\cdots, x_{16}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 经计算 $\\bar{x}=9, s^{2}=5.32$, 试求 $P(|\\bar{x}-\\mu|<0.6)$.\n6. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N(\\mu, 1)$ 的样本, 试确定最小的常数 $c$, 使得对任意的 $\\mu \\geqslant 0$, 有 $P(|\\bar{x}|<$ c) $\\leqslant \\alpha$.\n7. 设随机变量 $X \\sim F(n, n)$, 证明 $P(X<1)=0.5$.\n8. 设 $x_{1}, x_{2}$ 是来自 $N\\left(0, \\sigma^{2}\\right)$ 的样本, 试求 $Y=\\left(\\frac{x_{1}+x_{2}}{x_{1}-x_{2}}\\right)^{2}$ 的分布.\n9. 设总体为 $N(0,1), x_{1}, x_{2}$ 为样本, 试求常数 $k$, 使得  \n$$",
        "metadata": {
            "Header 2": "习习题 5.4"
        },
        "type": "Document"
    },
    {
        "page_content": "5. 设 $x_{1}, \\cdots, x_{16}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 经计算 $\\bar{x}=9, s^{2}=5.32$, 试求 $P(|\\bar{x}-\\mu|<0.6)$.\n6. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N(\\mu, 1)$ 的样本, 试确定最小的常数 $c$, 使得对任意的 $\\mu \\geqslant 0$, 有 $P(|\\bar{x}|<$ c) $\\leqslant \\alpha$.\n7. 设随机变量 $X \\sim F(n, n)$, 证明 $P(X<1)=0.5$.\n8. 设 $x_{1}, x_{2}$ 是来自 $N\\left(0, \\sigma^{2}\\right)$ 的样本, 试求 $Y=\\left(\\frac{x_{1}+x_{2}}{x_{1}-x_{2}}\\right)^{2}$ 的分布.\n9. 设总体为 $N(0,1), x_{1}, x_{2}$ 为样本, 试求常数 $k$, 使得  \n$$\nP\\left(\\frac{\\left(x_{1}+x_{2}\\right)^{2}}{\\left(x_{1}-x_{2}\\right)^{2}+\\left(x_{1}+x_{2}\\right)^{2}}>k\\right)=0.05 \\text {. }\n$$  \n10. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N\\left(\\mu_{1}, \\sigma^{2}\\right)$ 的样本, $y, \\cdots, y_{m}$ 是来自 $N\\left(\\mu_{2}, \\sigma^{2}\\right)$ 的样本, $c, d$ 是任意两个不为 0 的常数, 证明:  \n$$\nt=\\frac{c\\left(\\bar{x}-\\mu_{1}\\right)+d\\left(\\bar{y}-\\mu_{2}\\right)}{s_{w} \\sqrt{\\frac{c^{2}}{n}+\\frac{d^{2}}{m}}} \\sim t(n+m-2)\n$$  \n其中 $s_{w}^{2}=\\frac{(n-1) s_{x}^{2}+(m-1) s_{y}^{2}}{n+m-2}$.",
        "metadata": {
            "Header 2": "习习题 5.4"
        },
        "type": "Document"
    },
    {
        "page_content": "P\\left(\\frac{\\left(x_{1}+x_{2}\\right)^{2}}{\\left(x_{1}-x_{2}\\right)^{2}+\\left(x_{1}+x_{2}\\right)^{2}}>k\\right)=0.05 \\text {. }\n$$  \n10. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N\\left(\\mu_{1}, \\sigma^{2}\\right)$ 的样本, $y, \\cdots, y_{m}$ 是来自 $N\\left(\\mu_{2}, \\sigma^{2}\\right)$ 的样本, $c, d$ 是任意两个不为 0 的常数, 证明:  \n$$\nt=\\frac{c\\left(\\bar{x}-\\mu_{1}\\right)+d\\left(\\bar{y}-\\mu_{2}\\right)}{s_{w} \\sqrt{\\frac{c^{2}}{n}+\\frac{d^{2}}{m}}} \\sim t(n+m-2)\n$$  \n其中 $s_{w}^{2}=\\frac{(n-1) s_{x}^{2}+(m-1) s_{y}^{2}}{n+m-2}$.  \n11. 设 $x_{1}, \\cdots, x_{n}, x_{n+1}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, $\\bar{x}_{n}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}, s_{n}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}_{n}\\right)^{2}$, 试求常数 $c$ 使得 $t_{c}=c \\frac{x_{n+1}-\\bar{x}_{n}}{s_{n}}$ 服从 $t$ 分布, 并指出分布的自由度.\n12. 设从两个方差相等的正态总体中分别抽取容量为 15,20 的样本, 其样本方差分别为 $s_{1}^{2}, s_{2}^{2}$, 试求 $P\\left(s_{1}^{2} / s_{2}^{2}>2\\right)$.",
        "metadata": {
            "Header 2": "习习题 5.4"
        },
        "type": "Document"
    },
    {
        "page_content": "统计量是把样本中的信息进行加工处理的结果, 它可简化数据, 便于统计推断. 人们自然希望这种加工处理不损失原样本中的信息. 不损失信息的统计量就是充分统计量. 下面 “不损失信息”给出明确的数学含义.  \n例 5.5.1: 为研究某个运动员的打靶命中率 $\\theta$, 我们对该运动员进行测试, 观测其 10 次, 发现除第三、六次未命中外, 其余 8 次都命中, 这样的观测结果包含了两种信息:  \n(1) 打靶 10 次命中 8 次;  \n(2) 2 次不命中分别出现在第 3 次和第 6 次打靶上.  \n第二种信息对了解该运动员的命中率是没有什么帮助的: 设想我们对该运动员的观测结果是第一、二次未命中, 其余都命中, 虽然样本观测值是不一样的, 但它们提供的关于命中率 $\\theta$ 的信息是一样的. 因此, 在绝大多数实际问题中, 试验编号信息常常对了解总体或其参数是无关紧要的, 所以人们通常在试验前对样品进行随机编号.\n一般地, 设我们对该运动员进行 $n$ 次观测, 得到 $x_{1}, \\cdots, x_{n}$ 每个 $x_{j}$ 取值非 0 即 1 , 命中为 1 , 不命中为 0 , 令 $T=x_{1}+\\cdots+x_{n}, T$ 为观测到的命中次数, 在这种场合仅仅记录使用 $T$ 不会丢失任何与命中率 $\\theta$ 有关的信息, 统计上将这种 “样本加工不损失信” 称为 “充分性”.",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.1 充分性的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 打靶 10 次命中 8 次;  \n(2) 2 次不命中分别出现在第 3 次和第 6 次打靶上.  \n第二种信息对了解该运动员的命中率是没有什么帮助的: 设想我们对该运动员的观测结果是第一、二次未命中, 其余都命中, 虽然样本观测值是不一样的, 但它们提供的关于命中率 $\\theta$ 的信息是一样的. 因此, 在绝大多数实际问题中, 试验编号信息常常对了解总体或其参数是无关紧要的, 所以人们通常在试验前对样品进行随机编号.\n一般地, 设我们对该运动员进行 $n$ 次观测, 得到 $x_{1}, \\cdots, x_{n}$ 每个 $x_{j}$ 取值非 0 即 1 , 命中为 1 , 不命中为 0 , 令 $T=x_{1}+\\cdots+x_{n}, T$ 为观测到的命中次数, 在这种场合仅仅记录使用 $T$ 不会丢失任何与命中率 $\\theta$ 有关的信息, 统计上将这种 “样本加工不损失信” 称为 “充分性”.  \n上面我们直观地给出了关于 “充分性” 的概念, 接下来我们从概率层面对之进行分析. 我们知道, 样本 $X=\\left(x_{1}, \\cdots, x_{n}\\right)$ 有一个样本分布 $F_{\\theta}(X)$, 这个分布包含了样本中一切有关 $\\theta$ 的信息. 统计量 $T=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 也有一个抽样分布 $F_{\\theta}^{T}(t)$, 当我们期望用统计量 $T$ 代替原始样本 $X$ 并且不损失任何有关 $\\theta$ 的信息时, 也就是期望抽样分布 $F_{\\theta}^{T}(t)$ 像 $F_{\\theta}(X)$ 一样概括了有关 $\\theta$ 的一切信息. 换言之, 我们考察在统计量 $T$ 的取值为 $t$ 的情况下样本 $X$ 的条件分布 $F_{\\theta}(X \\mid T=t)$, 可能有两种情况:  \n- $F_{\\theta}(X \\mid T=t)$ 依赖于参数 $\\theta$, 此条件分布仍含有 $\\theta$ 的信息;\n- $F_{\\theta}(X \\mid T=t)$ 不依赖于参数 $\\theta$, 此条件分布已不含有 $\\theta$ 的信息.",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.1 充分性的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "- $F_{\\theta}(X \\mid T=t)$ 依赖于参数 $\\theta$, 此条件分布仍含有 $\\theta$ 的信息;\n- $F_{\\theta}(X \\mid T=t)$ 不依赖于参数 $\\theta$, 此条件分布已不含有 $\\theta$ 的信息.  \n后者表明, 条件 “ $T=t$ ” 的出现使得从样本分布 $F_{\\theta}(X)$ 到条件分布 $F_{\\theta}(X \\mid T=t)$, 有关 $\\theta$ 的信息消失了, 这说明有关 $\\theta$ 的信息都含在统计量 $T$ 之中. 当已知统计量 $T$ 的取值之后, 也就知道了样本中关于 $\\theta$ 的所有信息, 这正是统计量具有充分性的含义.  \n例 5.5.2: 设总体为二点分布 $b(1, \\theta), X_{1}, \\cdots, X_{n}$ 为样本, 令 $T=X_{1}+\\cdots+X_{n}$, 则在给定 $T$ 的取值后, 对任意一组 $x_{1}, \\cdots, x_{n}\\left(\\sum_{i=1}^{n} x_{i}=t\\right)$, 有  \n$$\n\\begin{aligned}\nP\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid T=t\\right) & =\\frac{P\\left(X_{1}=x_{1}, \\cdots, X_{n-1}=x_{n-1}, X_{n}=t-\\sum_{i=1}^{n-1} x_{i}\\right)}{P\\left(\\sum_{i=1}^{n} X_{i}=t\\right)} \\\\\n& =\\frac{\\prod_{i=1}^{n-1} P\\left(X_{i}=x_{i}\\right) \\cdot P\\left(X_{n}=t-\\sum_{i=1}^{n-1} x_{i}\\right)}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right) \\theta^{t}(1-\\theta)^{n-t}} \\\\",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.1 充分性的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nP\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid T=t\\right) & =\\frac{P\\left(X_{1}=x_{1}, \\cdots, X_{n-1}=x_{n-1}, X_{n}=t-\\sum_{i=1}^{n-1} x_{i}\\right)}{P\\left(\\sum_{i=1}^{n} X_{i}=t\\right)} \\\\\n& =\\frac{\\prod_{i=1}^{n-1} P\\left(X_{i}=x_{i}\\right) \\cdot P\\left(X_{n}=t-\\sum_{i=1}^{n-1} x_{i}\\right)}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right) \\theta^{t}(1-\\theta)^{n-t}} \\\\\n& =\\frac{\\prod_{i=1}^{n-1} \\theta^{x_{i}}(1-\\theta)^{1-x_{i}} \\cdot \\theta^{t-\\sum_{i=1}^{n-1} x_{i}}(1-\\theta)^{1-t+\\sum_{i=1}^{n-1} x_{i}}}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right) \\theta^{t}(1-\\theta)^{n-t}} \\\\\n& =\\frac{\\theta^{t}(1-\\theta)^{n-t}}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right) \\theta^{t}(1-\\theta)^{n-t}}=\\frac{1}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right)}\n\\end{aligned}\n$$  \n该条件分布与 $\\theta$ 无关. 若令 $S=X_{1}+X_{2}(n>2)$, 由于 $S$ 只是用了前面两个样品观测值, 显然没有包含样本中所有关于 $\\theta$ 的信息, 在给定 $S$ 的取值 $S=s$ 后, 对任意的一组 $x_{1}, \\cdots, x_{n}\\left(x_{1}+x_{2}=s\\right)$,有  \n$$",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.1 充分性的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "n \\\\\nt\n\\end{array}\\right) \\theta^{t}(1-\\theta)^{n-t}} \\\\\n& =\\frac{\\theta^{t}(1-\\theta)^{n-t}}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right) \\theta^{t}(1-\\theta)^{n-t}}=\\frac{1}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right)}\n\\end{aligned}\n$$  \n该条件分布与 $\\theta$ 无关. 若令 $S=X_{1}+X_{2}(n>2)$, 由于 $S$ 只是用了前面两个样品观测值, 显然没有包含样本中所有关于 $\\theta$ 的信息, 在给定 $S$ 的取值 $S=s$ 后, 对任意的一组 $x_{1}, \\cdots, x_{n}\\left(x_{1}+x_{2}=s\\right)$,有  \n$$\n\\begin{aligned}\nP\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid S=s\\right) & =\\frac{P\\left(X_{1}=x_{1}, X_{2}=s-x_{1}, X_{3}=x_{3}, \\cdots, X_{n}=x_{n}\\right)}{P\\left(X_{1}+X_{2}=s\\right)} \\\\\n& =\\frac{\\theta^{1+\\sum_{i=3}^{n}(1-\\theta)^{n-s-\\sum_{i=3}^{n} x_{i}}}}{\\left(\\begin{array}{l}\n2 \\\\\ns\n\\end{array}\\right) \\theta^{s}(1-\\theta)^{2-s}}=\\frac{\\theta^{\\sum_{i=3}^{n} x_{i}}(1-\\theta)^{n-2-\\sum_{i=3}^{n} x_{i}}}{\\left(\\begin{array}{l}\n2 \\\\\ns\n\\end{array}\\right)}\n\\end{aligned}\n$$  \n这个分布依赖于未知参数 $\\theta$, 这说明样本中有关 0 的信息没有完全包含在统计量 $S$ 中.",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.1 充分性的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{\\theta^{1+\\sum_{i=3}^{n}(1-\\theta)^{n-s-\\sum_{i=3}^{n} x_{i}}}}{\\left(\\begin{array}{l}\n2 \\\\\ns\n\\end{array}\\right) \\theta^{s}(1-\\theta)^{2-s}}=\\frac{\\theta^{\\sum_{i=3}^{n} x_{i}}(1-\\theta)^{n-2-\\sum_{i=3}^{n} x_{i}}}{\\left(\\begin{array}{l}\n2 \\\\\ns\n\\end{array}\\right)}\n\\end{aligned}\n$$  \n这个分布依赖于未知参数 $\\theta$, 这说明样本中有关 0 的信息没有完全包含在统计量 $S$ 中.  \n从上例可以直观地看出, 用条件分布与未知参数无关来表示统计量不损失样本中有价值的信息是妥当的. 由此可给出充分统计量的定义.  \n定义 5.5.1. 设 $x_{1}, \\cdots, x_{n}$ 是来自某个总体的样本, 总体分布函数为 $F(x ; \\theta)$, 统计量 $T=T\\left(x_{1}, \\cdots, x_{n}\\right)$称为 $\\theta$ 的 充分统计量, 如果在给定 $T$ 的取值后, $x_{1}, \\cdots, x_{n}$ 的条件分布与 $\\theta$ 无关.  \n应用中条件分布可用条件分布列或条件密度函数来表示.  \n例 5.5.3: 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N(\\mu, 1)$ 的样本, $T=\\bar{x}$, 则 $T \\sim N(\\mu, 1 / n)$, 易计算  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.1 充分性的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n这个分布依赖于未知参数 $\\theta$, 这说明样本中有关 0 的信息没有完全包含在统计量 $S$ 中.  \n从上例可以直观地看出, 用条件分布与未知参数无关来表示统计量不损失样本中有价值的信息是妥当的. 由此可给出充分统计量的定义.  \n定义 5.5.1. 设 $x_{1}, \\cdots, x_{n}$ 是来自某个总体的样本, 总体分布函数为 $F(x ; \\theta)$, 统计量 $T=T\\left(x_{1}, \\cdots, x_{n}\\right)$称为 $\\theta$ 的 充分统计量, 如果在给定 $T$ 的取值后, $x_{1}, \\cdots, x_{n}$ 的条件分布与 $\\theta$ 无关.  \n应用中条件分布可用条件分布列或条件密度函数来表示.  \n例 5.5.3: 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N(\\mu, 1)$ 的样本, $T=\\bar{x}$, 则 $T \\sim N(\\mu, 1 / n)$, 易计算  \n$$\n\\begin{aligned}\np_{\\mu}\\left(x_{1}, \\cdots, x_{N} \\mid T=t\\right) & =\\frac{p_{\\mu}\\left(x_{1}, \\cdots, x_{n}\\right)}{p_{\\mu}(t)}=\\frac{(2 \\pi)^{-1 / 2} \\exp \\left\\{-\\frac{1}{2} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right\\}}{(2 \\pi / n)^{-1 / 2} \\exp \\left\\{-\\frac{n}{2}(t-\\mu)^{2}\\right\\}} \\\\\n& =\\sqrt{n}(2 \\pi)^{(n-1) / 2} \\exp \\left\\{-\\frac{1}{2} \\sum_{i=1}^{n}\\left(x_{i}-t\\right)^{2}\\right\\},\n\\end{aligned}\n$$  \n该分布与 $\\mu$ 无关, 这说明 $\\bar{x}$ 是 $\\mu$ 的充分统计量. 其中最后一个等式成立是因为有如下的平方和分\n解:  \n$$",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.1 充分性的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\np_{\\mu}\\left(x_{1}, \\cdots, x_{N} \\mid T=t\\right) & =\\frac{p_{\\mu}\\left(x_{1}, \\cdots, x_{n}\\right)}{p_{\\mu}(t)}=\\frac{(2 \\pi)^{-1 / 2} \\exp \\left\\{-\\frac{1}{2} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right\\}}{(2 \\pi / n)^{-1 / 2} \\exp \\left\\{-\\frac{n}{2}(t-\\mu)^{2}\\right\\}} \\\\\n& =\\sqrt{n}(2 \\pi)^{(n-1) / 2} \\exp \\left\\{-\\frac{1}{2} \\sum_{i=1}^{n}\\left(x_{i}-t\\right)^{2}\\right\\},\n\\end{aligned}\n$$  \n该分布与 $\\mu$ 无关, 这说明 $\\bar{x}$ 是 $\\mu$ 的充分统计量. 其中最后一个等式成立是因为有如下的平方和分\n解:  \n$$\n\\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}=\\sum_{i=1}^{n}\\left(x_{i}-t\\right)^{2}+n(t-\\mu)^{2}\n$$",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.1 充分性的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "在统计学中有一个基本原则: 在充分统计量存在场合, 任何统计推断都可以基于充分统计量进行, 这可以简化统计推断的程序, 通常将该原则称为充分性原则. 然而在一般场合直接由定义?? 出发验证一个统计量是充分的是困难的, 因为条件分布的计算通常不那么容易. 幸运的是, 我们有一个简单的办法判断一个统计量是否充分, 这就是下面的因子分解定理, 它由统计学家奈曼 (Neyman) 给出. 为简便起见, 我们引人一个在两种分布类型通用的概念一概率函数. $f(x)$ 称为随机变量 $X$ 的概率函数: 在连续型场合, $f(x)$ 表示 $X$ 的概率密度函数; 在离散型场合, $f(x)$ 表示 $X$的概率分布列.  \n定理 5.5.1. 设总体概率函数为 $f(x ; \\theta), X_{1}, \\cdots, X_{n}$ 为样本, 则 $T=T\\left(X_{1}, \\cdots, X_{n}\\right)$ 为充分统计量的充分必要条件是: 存在两个函数 $g(t, \\theta)$ 和 $h\\left(x_{1}, \\cdots, x_{n}\\right)$ 使得对任意的 $\\theta$ 和任一组观测值 $x_{1}, \\cdots, x_{n}$, 有  \n$$\n\\begin{equation*}\nf\\left(x_{1}, \\cdots, x_{n} ; \\theta\\right)=g\\left(T\\left(x_{1}, \\cdots, x_{n}\\right)\\right) h\\left(x_{1}, \\cdots, x_{n}\\right), \\tag{5.5.1}\n\\end{equation*}\n$$  \n其中 $g(t, \\theta)$ 是通过统计量 $T$ 的取值而依赖于样本的.  \n证明: 一般性结果的证明超出本课程范围, 此处我们将给出离散型随机变量下的证明, 此时, $f\\left(x_{1}, \\cdots, x_{n}\\right)=$ $P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right)$.",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nf\\left(x_{1}, \\cdots, x_{n} ; \\theta\\right)=g\\left(T\\left(x_{1}, \\cdots, x_{n}\\right)\\right) h\\left(x_{1}, \\cdots, x_{n}\\right), \\tag{5.5.1}\n\\end{equation*}\n$$  \n其中 $g(t, \\theta)$ 是通过统计量 $T$ 的取值而依赖于样本的.  \n证明: 一般性结果的证明超出本课程范围, 此处我们将给出离散型随机变量下的证明, 此时, $f\\left(x_{1}, \\cdots, x_{n}\\right)=$ $P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right)$.  \n先证必要性. 设 $T$ 是充分统计量, 则在 $T=t$ 下, $P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid T=t\\right)$ 与 $\\theta$ 无关, 记为 $h\\left(x_{1}, \\cdots, x_{n}\\right)$ 或 $h(\\boldsymbol{X})$, 令 $A(t)=\\{\\boldsymbol{X}: T(\\boldsymbol{X})=t\\}$, 当 $\\boldsymbol{X} \\in A(t)$ 时有  \n$$\n\\{T=t\\} \\supset\\left\\{X_{1}=x_{1}, \\cdots, X_{n}=x_{n}\\right\\}\n$$  \n故  \n$$\n\\begin{aligned}\n& \\quad P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right)=P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n}, T=t ; \\theta\\right) \\\\\n& =P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid T=t\\right) P(T=t ; \\theta) \\\\\n& =h\\left(x_{1}, \\cdots, x_{n}\\right) g(t, \\theta),\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\{T=t\\} \\supset\\left\\{X_{1}=x_{1}, \\cdots, X_{n}=x_{n}\\right\\}\n$$  \n故  \n$$\n\\begin{aligned}\n& \\quad P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right)=P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n}, T=t ; \\theta\\right) \\\\\n& =P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid T=t\\right) P(T=t ; \\theta) \\\\\n& =h\\left(x_{1}, \\cdots, x_{n}\\right) g(t, \\theta),\n\\end{aligned}\n$$  \n其中 $g(t, \\theta)=P(T=t ; \\theta)$, 而 $h(\\boldsymbol{X})=P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid T=t\\right)$ 与 $\\theta$ 无关, 必要性得证.  \n对充分性, 由于  \n$$\n\\begin{aligned}\nP(T=t ; \\theta) & =\\sum_{\\left\\{\\left(x_{1}, \\cdots, x_{n}\\right): T\\left(x_{1}, \\cdots, x_{n}\\right)=t\\right\\}} P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right) \\\\\n& =\\sum_{\\left\\{\\left(x_{1}, \\cdots, x_{n}\\right): T\\left(x_{1}, \\cdots, x_{n}\\right)=t\\right\\}} g(t, \\theta) h\\left(x_{1}, \\cdots, x_{n}\\right),\n\\end{aligned}\n$$  \n对任给 $\\boldsymbol{X}=\\left(x_{1}, \\cdots, x_{n}\\right)$ 和 $t$, 满足 $\\boldsymbol{X} \\in A(t)$, 有  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "对充分性, 由于  \n$$\n\\begin{aligned}\nP(T=t ; \\theta) & =\\sum_{\\left\\{\\left(x_{1}, \\cdots, x_{n}\\right): T\\left(x_{1}, \\cdots, x_{n}\\right)=t\\right\\}} P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right) \\\\\n& =\\sum_{\\left\\{\\left(x_{1}, \\cdots, x_{n}\\right): T\\left(x_{1}, \\cdots, x_{n}\\right)=t\\right\\}} g(t, \\theta) h\\left(x_{1}, \\cdots, x_{n}\\right),\n\\end{aligned}\n$$  \n对任给 $\\boldsymbol{X}=\\left(x_{1}, \\cdots, x_{n}\\right)$ 和 $t$, 满足 $\\boldsymbol{X} \\in A(t)$, 有  \n$$\n\\begin{aligned}\nP\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid T=t\\right) & =\\frac{P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n}, T=t ; \\theta\\right)}{P(T=t ; \\theta)} \\\\\n& =\\frac{P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right)}{P(T=t ; \\theta)} \\\\\n& =\\frac{g(t, \\theta) h\\left(x_{1}, \\cdots, x_{n}\\right)}{g(t, \\theta) \\sum_{\\left\\{\\left(y_{1}, \\cdots, y_{n}\\right): T\\left(y_{1}, \\cdots, y_{n}\\right)=t\\right\\}} h\\left(y_{1}, \\cdots, y_{n}\\right)} \\\\",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nP\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} \\mid T=t\\right) & =\\frac{P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n}, T=t ; \\theta\\right)}{P(T=t ; \\theta)} \\\\\n& =\\frac{P\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right)}{P(T=t ; \\theta)} \\\\\n& =\\frac{g(t, \\theta) h\\left(x_{1}, \\cdots, x_{n}\\right)}{g(t, \\theta) \\sum_{\\left\\{\\left(y_{1}, \\cdots, y_{n}\\right): T\\left(y_{1}, \\cdots, y_{n}\\right)=t\\right\\}} h\\left(y_{1}, \\cdots, y_{n}\\right)} \\\\\n& =\\frac{h\\left(x_{1}, \\cdots, x_{n}\\right)}{\\sum_{\\left\\{\\left(y_{1}, \\cdots, y_{n}\\right): T\\left(y_{1}, \\cdots, y_{n}\\right)=t\\right\\}} h\\left(y_{1}, \\cdots, y_{n}\\right)},\n\\end{aligned}\n$$  \n该分布与 $\\theta$ 无关, 这证明了充分性.\n例 5.5.4: 设 $x_{1}, \\cdots, x_{n}$ 是取自总体 $U(0, \\theta)$ 的样本, 即总体的密度函数为  \n$$\np(x ; \\theta)= \\begin{cases}1 / \\theta, * 0<x<\\theta \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n于是样本的联合密度函数为  \n$$",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{h\\left(x_{1}, \\cdots, x_{n}\\right)}{\\sum_{\\left\\{\\left(y_{1}, \\cdots, y_{n}\\right): T\\left(y_{1}, \\cdots, y_{n}\\right)=t\\right\\}} h\\left(y_{1}, \\cdots, y_{n}\\right)},\n\\end{aligned}\n$$  \n该分布与 $\\theta$ 无关, 这证明了充分性.\n例 5.5.4: 设 $x_{1}, \\cdots, x_{n}$ 是取自总体 $U(0, \\theta)$ 的样本, 即总体的密度函数为  \n$$\np(x ; \\theta)= \\begin{cases}1 / \\theta, * 0<x<\\theta \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n于是样本的联合密度函数为  \n$$\np\\left(x_{1} ; \\theta\\right) \\cdots p\\left(x_{n} ; \\theta\\right)= \\begin{cases}(1 / \\theta)^{n}, & 0<\\min \\left\\{x_{i}\\right\\} \\leqslant \\max \\left\\{x_{i}\\right\\}<\\theta, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n由于诸 $x_{i}>0$, 所以我们将上式改写为  \n$$\np\\left(x_{1} ; \\theta\\right) \\cdots p\\left(x_{n} ; \\theta\\right)=(1 / \\theta)^{n} I_{\\left\\{x_{(n)}<\\theta\\right\\}},\n$$  \n取 $T=x_{(n)}$, 并令 $g(t, \\theta)=(1 / \\theta)^{n} I_{t<\\theta}, h(\\boldsymbol{X})=1$, 由因子分解定理知 $T=x_{(n)}$ 是 $\\theta$ 的充分统计量.",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np\\left(x_{1} ; \\theta\\right) \\cdots p\\left(x_{n} ; \\theta\\right)= \\begin{cases}(1 / \\theta)^{n}, & 0<\\min \\left\\{x_{i}\\right\\} \\leqslant \\max \\left\\{x_{i}\\right\\}<\\theta, \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n由于诸 $x_{i}>0$, 所以我们将上式改写为  \n$$\np\\left(x_{1} ; \\theta\\right) \\cdots p\\left(x_{n} ; \\theta\\right)=(1 / \\theta)^{n} I_{\\left\\{x_{(n)}<\\theta\\right\\}},\n$$  \n取 $T=x_{(n)}$, 并令 $g(t, \\theta)=(1 / \\theta)^{n} I_{t<\\theta}, h(\\boldsymbol{X})=1$, 由因子分解定理知 $T=x_{(n)}$ 是 $\\theta$ 的充分统计量.  \n例 5.5.5: 设 $x_{1}, \\cdots, x_{n}$ 是取自总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, $\\theta=\\left(\\mu, \\sigma^{2}\\right)$ 是未知的, 则联合密度函数为  \n$$\n\\begin{aligned}\nP\\left(x_{1}, \\cdots, x_{n} ; \\theta\\right) & =\\left(2 \\pi \\sigma^{2}\\right)^{-n / 2} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right\\} \\\\",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n取 $T=x_{(n)}$, 并令 $g(t, \\theta)=(1 / \\theta)^{n} I_{t<\\theta}, h(\\boldsymbol{X})=1$, 由因子分解定理知 $T=x_{(n)}$ 是 $\\theta$ 的充分统计量.  \n例 5.5.5: 设 $x_{1}, \\cdots, x_{n}$ 是取自总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, $\\theta=\\left(\\mu, \\sigma^{2}\\right)$ 是未知的, 则联合密度函数为  \n$$\n\\begin{aligned}\nP\\left(x_{1}, \\cdots, x_{n} ; \\theta\\right) & =\\left(2 \\pi \\sigma^{2}\\right)^{-n / 2} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right\\} \\\\\n& =\\left(2 \\pi \\sigma^{2}\\right)^{n / 2} \\exp \\left\\{-\\frac{n \\mu^{2}}{2 \\sigma^{2}}\\right\\} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}}\\left(\\sum_{i=1}^{n} x_{i}^{2}-2 \\mu \\sim_{i=1}^{n} x_{i}\\right)\\right\\},\n\\end{aligned}\n$$  \n取 $t_{1}=\\sum_{i=1}^{n} x_{i}, t_{2}=\\sum_{i=1}^{n} x_{i}^{2}$, 并令  \n$$\ng\\left(t_{1}, t_{2}, \\theta\\right)=\\left(2 \\pi \\sigma^{2}\\right)^{-n / 2} \\exp \\left\\{-\\frac{n \\mu^{2}}{2 \\sigma^{2}}\\right\\} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}}\\left(t_{2}-2 \\mu t_{1}\\right)\\right\\}, h(\\boldsymbol{X})=1\n$$",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n取 $t_{1}=\\sum_{i=1}^{n} x_{i}, t_{2}=\\sum_{i=1}^{n} x_{i}^{2}$, 并令  \n$$\ng\\left(t_{1}, t_{2}, \\theta\\right)=\\left(2 \\pi \\sigma^{2}\\right)^{-n / 2} \\exp \\left\\{-\\frac{n \\mu^{2}}{2 \\sigma^{2}}\\right\\} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}}\\left(t_{2}-2 \\mu t_{1}\\right)\\right\\}, h(\\boldsymbol{X})=1\n$$  \n则由因子分解定理, $T=\\left(t_{1}, t_{2}\\right)=\\left(\\sum_{i=1}^{n} x_{i}, \\sum_{i=1}^{n} x_{i}^{2}\\right)$ 是充分统计量. 进一步, 我们指出这个统计量与 $\\left(\\bar{x}, s^{2}\\right)$ 是一一对应的, 这说明在正态总体场合常用的 $\\left(\\bar{x}, s^{2}\\right)$ 是充分统计量.",
        "metadata": {
            "Header 2": "5.5 充分统计量",
            "Header 3": "5.5.2 因子分解定理"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设 $x_{1}, \\cdots, x_{n}$ 来自几何分布  \n$$\nP(X=x)=\\theta(1-\\theta)^{x} m \\quad x=0,1,2, \\cdots\n$$  \n的样本, 证明 $T=\\sum_{i=1}^{n} x_{i}$ 是充分统计量.  \n2. 设 $x_{1}, \\cdots, x_{n}$ 是来自泊松分布 $P(\\lambda)$ 的样本, 证明 $T=\\sum_{i=1}^{n} x_{i}$ 是充分统计量.\n3. 设总体为如下离散型分布,  \n| $x$ | $a_{1}$ | $a_{2}$ | $\\cdots$ | $a_{k}$ |\n| :--- | :--- | :--- | :--- | :--- |\n| $p$ | $p_{1}$ | $p_{2}$ | $\\cdots$ | $p_{k}$ |  \n$x_{1}, \\cdots, x_{n}$ 是来自该总体的样本,  \n(1) 证明次序统计量 $\\left(x_{(1)}, \\cdots, x_{(n)}\\right)$ 是充分统计量.  \n(2) 以 $n_{j}$ 表示 $x_{1}, \\cdots, x_{n}$ 中等于 $a_{j}$ 的个数, 证明 $\\left(n_{1}, \\cdots, x_{n}\\right)$ 是充分统计量.  \n4. 设 $x_{1}, \\cdots, x_{n}$ 是来自正态分布 $N(\\mu, 1)$ 的样本, 证明 $T=\\sum_{i=1}^{n} x_{i}$ 是充分统计量.\n5. 设 $x_{1}, \\cdots, x_{n}$ 是来自  \n$$\np(x ; \\theta)=\\theta \\cdot x^{\\theta-1}, 0<x<1, \\theta>0\n$$  \n的样本, 试给出一个充分统计量.  \n6. 设 $x_{1}, \\cdots, x_{n}$ 是来自威布尔分布  \n$$\np(x ; \\theta)=m x^{m-1} \\theta^{-m} \\mathrm{e}^{-(x / \\theta)^{m}}, \\quad x>0, \\theta>0\n$$  \n的样本 ( $m>0$ 已知), 试给出一个充分统计量.",
        "metadata": {
            "Header 2": "习题 5.5"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) 以 $n_{j}$ 表示 $x_{1}, \\cdots, x_{n}$ 中等于 $a_{j}$ 的个数, 证明 $\\left(n_{1}, \\cdots, x_{n}\\right)$ 是充分统计量.  \n4. 设 $x_{1}, \\cdots, x_{n}$ 是来自正态分布 $N(\\mu, 1)$ 的样本, 证明 $T=\\sum_{i=1}^{n} x_{i}$ 是充分统计量.\n5. 设 $x_{1}, \\cdots, x_{n}$ 是来自  \n$$\np(x ; \\theta)=\\theta \\cdot x^{\\theta-1}, 0<x<1, \\theta>0\n$$  \n的样本, 试给出一个充分统计量.  \n6. 设 $x_{1}, \\cdots, x_{n}$ 是来自威布尔分布  \n$$\np(x ; \\theta)=m x^{m-1} \\theta^{-m} \\mathrm{e}^{-(x / \\theta)^{m}}, \\quad x>0, \\theta>0\n$$  \n的样本 ( $m>0$ 已知), 试给出一个充分统计量.  \n7. 设 $x_{1}, \\cdots, x_{n}$ 是来自 Pareto 分布  \n$$\np(x ; \\theta)=\\theta \\cdot a^{\\theta} x^{-(\\theta+1)}, \\quad x>a, \\theta>0\n$$  \n的样本 ( $a>0$ 已知), 试给出一个充分统计量.  \n8. 设 $x_{1}, \\cdots, x_{n}$ 是来自 Laplace 分布  \n$$\np(x ; \\theta)=\\frac{1}{2 \\theta} \\mathrm{e}^{-|x| \\theta}, \\quad \\theta>0\n$$  \n的样本, 试给出一个充分统计量.  \n9. 设 $x_{1}, \\cdots, x_{n}$ 是辣子正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本.  \n(1) 在 $\\mu$ 已知时给出 $\\sigma^{2}$ 的一个充分统计量;  \n(2) 在 $\\sigma^{2}$ 已知时给出 $\\mu$ 的一个充分统计量.",
        "metadata": {
            "Header 2": "习题 5.5"
        },
        "type": "Document"
    },
    {
        "page_content": "的样本 ( $m>0$ 已知), 试给出一个充分统计量.  \n7. 设 $x_{1}, \\cdots, x_{n}$ 是来自 Pareto 分布  \n$$\np(x ; \\theta)=\\theta \\cdot a^{\\theta} x^{-(\\theta+1)}, \\quad x>a, \\theta>0\n$$  \n的样本 ( $a>0$ 已知), 试给出一个充分统计量.  \n8. 设 $x_{1}, \\cdots, x_{n}$ 是来自 Laplace 分布  \n$$\np(x ; \\theta)=\\frac{1}{2 \\theta} \\mathrm{e}^{-|x| \\theta}, \\quad \\theta>0\n$$  \n的样本, 试给出一个充分统计量.  \n9. 设 $x_{1}, \\cdots, x_{n}$ 是辣子正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本.  \n(1) 在 $\\mu$ 已知时给出 $\\sigma^{2}$ 的一个充分统计量;  \n(2) 在 $\\sigma^{2}$ 已知时给出 $\\mu$ 的一个充分统计量.  \n10. 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀分布 $U\\left(\\theta_{1}, \\theta_{2}\\right)$ 的样本, 试给出一个充分统计量.\n11. 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀分布 $U(\\theta, 2 \\theta), \\theta>0$ 的样本, 试给出充分统计量.",
        "metadata": {
            "Header 2": "习题 5.5"
        },
        "type": "Document"
    },
    {
        "page_content": "这里所指的参数是指如下三类未知参数:  \n- 分布中所含有未知参数 $\\theta$. 如: 二点分布 $b(1, p)$ 中的 $p$; 正态分布 $N(\\mu, \\sigma)$ 中的 $\\mu$ 和 $\\sigma^{2}$.\n- 分布中所含的未知参数 $\\theta$ 的函数. 如: 服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$ 的变量 $X$ 不超过某给定值 $a$的概率 $P(X \\leqslant a)=\\Phi\\left(\\frac{a-\\mu}{\\sigma}\\right)$ 是未知参数 $\\mu, \\sigma$ 的函数; 单位产品的缺陷数 $X$ 通常服从泊松分布 $P(\\lambda)$, 则单位产品合格 (无缺陷) 的概率 $P(X=0)=\\mathrm{e}^{-\\lambda}$ 是未知参数 $\\lambda$ 的函数.\n- 分布的各种特征数也都是未知参数, 如: 均值 $E(X)$, 方差 $\\operatorname{Var}(X)$, 分布中位数等.  \n一般场合, 常用日表示参数, 参数 $\\theta$ 所有可能取值组成的集合称为参数空间, 常用 $\\theta$ 表示. 参数估计问题就是根据样本对上述各种未知参数作出估计.  \n参数估计的形式有两种: 点估计与区间估计. 这里我们从点估计开始.  \n设 $x_{1}, x_{2}, \\cdots, x_{n}$ 是来自总体的一个样本, 我们用一个统计量 $\\bar{\\theta}=\\bar{\\theta}\\left(x_{1}, \\cdots, x_{n}\\right)$ 的取值作为 $\\theta$的估计值, $\\bar{\\theta}$ 称为 $\\theta$ 的点估计 (量), 简称估计. 在这里如何构造统计量并没有明确的规定, 只要它满足一定的合理性即可, 这就涉及两个问题:  \n- 其一是如何给出估计, 即估计的方法问题:\n- 其二是如何对不同的估计进行评价, 即估计的好坏判断标准.  \n接下来我们先介绍一些估计的方法, 接着讨论估计的好坏标准, 然后对几个有用的专题给介绍,最后讲述区间估计.",
        "metadata": {
            "Header 2": "第 6 章 参数估计"
        },
        "type": "Document"
    },
    {
        "page_content": "人们可以运用各种方法构造出很多 $\\theta$ 的估计, 本节介绍两种最常用的点估计方法, 它们是: 矩法和最大似然法.",
        "metadata": {
            "Header 2": "6.1 点估计的几种方法"
        },
        "type": "Document"
    },
    {
        "page_content": "1900 年英国统计学家 K.Pearson 提出了一个替换原则, 后来人们称此方法为矩法.",
        "metadata": {
            "Header 2": "6.1 点估计的几种方法",
            "Header 3": "6.1.1 替换原理和矩法估计"
        },
        "type": "Document"
    },
    {
        "page_content": "替换原理常指如下两句话:  \n- 用样本矩去替换总体矩, 这里的矩可以是原点矩也可以是中心矩;\n- 用样本矩的函数去替换相应的总体矩的函数.  \n根据这个替换原理, 在总体分布形式未知场合也可对各种参数作出估计, 譬如:  \n- 用样本均值 $\\bar{x}$ 估计总体均值 $E(X)$, 即 $\\hat{E}(X)=\\bar{x}$;\n- 用样本方差 $s_{n}^{2}$ 品估计总体方差 $\\operatorname{Var}(x)$, 即 $\\hat{\\operatorname{Var}}(x)=s_{n}^{2}$;\n- 用事件 $A$ 出现的频率估计事件 $A$ 发生的概率;\n- 用样本的 $p$ 分位数估计总体的 $p$ 分位数, 特别, 用样本中位数估计总体中位数.  \n例 6.1.1: 对某型号的 20 辆汽车记录其每 $5 L$ 汽油的行驶里程 (公里), 观测数据如下:  \n| 29.8 | 27.6 | 28.3 | 27.9 | 30.1 | 28.7 | 29.9 | 28.0 | 27.9 | 28.7 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 28.4 | 27.2 | 29.5 | 28.5 | 28.0 | 30.0 | 29.1 | 29.8 | 29.6 | 26.9 |  \n这是一个容量为 20 的样本观测值, 对应总体是该型号汽车每 $5 L$ 汽油的行驶里程, 其分布形\n式尚不清楚, 可用矩法估计其均值、方差和中位数等. 本例中经计算有  \n$$\n\\bar{x}=28.695, \\quad s_{n}^{2}=0.9185, \\quad m_{0.5}=28.6,\n$$  \n由此给出总体均值、方差和中位数的估计分别为 $28.695,0.9185$ 和 28.6 .  \n矩法估计的统计思想 (替换原理) 十分简单明确, 众人都能接受, 使用场合甚广它的实质是用经验分布函数去替换总体分布, 其理论基础是格里纹科定理.",
        "metadata": {
            "Header 2": "一、矩法估计"
        },
        "type": "Document"
    },
    {
        "page_content": "设总体具有已知的概率函数 $p\\left(x ; \\theta_{1}, \\cdots, \\theta_{k}\\right),\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right) \\in \\Theta$ 未知参数或参数向量, $x_{1}, \\cdots, x_{n}$是样本, 假定总体的 $k$ 阶原点矩 $\\mu_{k}$ 存在, 则对所有的 $j, 0<j<k, A$ 内都存在, 若假设 $\\theta_{1}, \\cdots, \\theta_{k}$.能够表示成 $u_{1}, \\cdots, u_{k}$ 的函数 $\\theta_{j}=\\theta_{j}\\left(u_{1}, \\cdots, u_{k}\\right)$, 则可给出诸 $\\theta_{j}$ 的矩法估计:  \n$$\n\\begin{equation*}\n\\hat{\\theta}_{j}=\\theta_{j}\\left(a_{1}, \\cdots, a_{k}\\right), \\quad j=1, \\cdots, k, \\tag{6.1.1}\n\\end{equation*}\n$$  \n其中 $a_{1}, \\cdots, a_{k}$. 是前个样本原点矩: $a_{j}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}^{j}$. 进一步, 如果我们要估计 $\\theta_{1}, \\cdots, \\theta_{k}$ 的函数 $\\eta=g\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)$, 则可直接得到 $\\eta$ 的矩法估计  \n$$\n\\begin{equation*}\n\\hat{\\eta}=g\\left(\\hat{\\theta}_{1}, \\cdots, \\hat{\\theta}_{k}\\right), \\tag{6.1.2}\n\\end{equation*}\n$$  \n当 $k=1$ 时, 我们通常可以由样本均值出发对未知参数进行估计; 如果 $k=2$, 我们可以由一阶、二阶原点矩 (或二阶中心矩) 出发估计未知参数.  \n例 6.1.2: 设总体为指数分布, 其密度函数为  \n$$",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n其中 $a_{1}, \\cdots, a_{k}$. 是前个样本原点矩: $a_{j}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}^{j}$. 进一步, 如果我们要估计 $\\theta_{1}, \\cdots, \\theta_{k}$ 的函数 $\\eta=g\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)$, 则可直接得到 $\\eta$ 的矩法估计  \n$$\n\\begin{equation*}\n\\hat{\\eta}=g\\left(\\hat{\\theta}_{1}, \\cdots, \\hat{\\theta}_{k}\\right), \\tag{6.1.2}\n\\end{equation*}\n$$  \n当 $k=1$ 时, 我们通常可以由样本均值出发对未知参数进行估计; 如果 $k=2$, 我们可以由一阶、二阶原点矩 (或二阶中心矩) 出发估计未知参数.  \n例 6.1.2: 设总体为指数分布, 其密度函数为  \n$$\np(x ; \\lambda)=\\lambda \\cdot \\mathrm{e}^{-\\lambda x}, \\quad x>0,\n$$  \n$x_{1}, \\cdots, x_{n}$ 是样本, 此处 $k=1$, 由于 $E X=1 / \\lambda$, 亦即 $\\lambda=1 / E X$, 故 $\\lambda$ 的矩法估计为  \n$$\n\\hat{\\lambda}=1 / \\bar{x}\n$$  \n另外, 由于 $\\operatorname{Var}(X)=1 / \\lambda^{2}$, 其反函数为 $\\lambda=1 / \\sqrt{\\operatorname{Var}(X)}$, 因此, 从替换原理来看, $\\lambda$ 的矩法估计也可取为  \n$$\n\\hat{\\lambda}_{1}=1 / s \\text {. }\n$$  \n$s$ 为样本标准差. 这说明矩估计可能是不唯一的, 这是矩法估计的一个缺点, 此时通常应该尽量采用低阶矩给出未知参数的估计.",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计"
        },
        "type": "Document"
    },
    {
        "page_content": "例 6.1.2: 设总体为指数分布, 其密度函数为  \n$$\np(x ; \\lambda)=\\lambda \\cdot \\mathrm{e}^{-\\lambda x}, \\quad x>0,\n$$  \n$x_{1}, \\cdots, x_{n}$ 是样本, 此处 $k=1$, 由于 $E X=1 / \\lambda$, 亦即 $\\lambda=1 / E X$, 故 $\\lambda$ 的矩法估计为  \n$$\n\\hat{\\lambda}=1 / \\bar{x}\n$$  \n另外, 由于 $\\operatorname{Var}(X)=1 / \\lambda^{2}$, 其反函数为 $\\lambda=1 / \\sqrt{\\operatorname{Var}(X)}$, 因此, 从替换原理来看, $\\lambda$ 的矩法估计也可取为  \n$$\n\\hat{\\lambda}_{1}=1 / s \\text {. }\n$$  \n$s$ 为样本标准差. 这说明矩估计可能是不唯一的, 这是矩法估计的一个缺点, 此时通常应该尽量采用低阶矩给出未知参数的估计.  \n例 6.1.3: $x_{1}, \\cdots, x_{n}$ 是来自 $(a, b)$ 上的均匀分布 $U(a, b)$ 的样本, $a$ 与 $b$ 均是未知参数, 这里 $k=2$,由于  \n$$\nE X=\\frac{a+b}{2}, \\quad \\operatorname{Var}(X)=\\frac{(b-a)^{2}}{12}\n$$  \n不难推出  \n$$\na=E X-\\sqrt{3 \\operatorname{Var}(X)}, \\quad b=E X+\\sqrt{3 \\operatorname{Var}(X)}\n$$  \n由此即可得到 $a, b$ 的矩估计:  \n$$\n\\hat{a}=\\bar{x}-\\sqrt{3} s, \\quad \\hat{b}=\\bar{x}+\\sqrt{3} s\n$$  \n若从均匀总体 $U(a, b)$ 获得如下一个容量为 5 的样本: 4.5 $5.0 \\quad 4.7$ 4.0 $\\quad 4$.2, 经计算, 有 $\\bar{x}=$ $4.48, s_{n}=0.3962$, 于是可得 $a, b$ 的矩估计为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nE X=\\frac{a+b}{2}, \\quad \\operatorname{Var}(X)=\\frac{(b-a)^{2}}{12}\n$$  \n不难推出  \n$$\na=E X-\\sqrt{3 \\operatorname{Var}(X)}, \\quad b=E X+\\sqrt{3 \\operatorname{Var}(X)}\n$$  \n由此即可得到 $a, b$ 的矩估计:  \n$$\n\\hat{a}=\\bar{x}-\\sqrt{3} s, \\quad \\hat{b}=\\bar{x}+\\sqrt{3} s\n$$  \n若从均匀总体 $U(a, b)$ 获得如下一个容量为 5 的样本: 4.5 $5.0 \\quad 4.7$ 4.0 $\\quad 4$.2, 经计算, 有 $\\bar{x}=$ $4.48, s_{n}=0.3962$, 于是可得 $a, b$ 的矩估计为  \n$$\n\\begin{aligned}\n& \\hat{a}=4.48-0.3962 \\sqrt{3}=3.7938, \\\\\n& \\hat{b}=4.48+0.3962 \\sqrt{3}=5.1662 .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计"
        },
        "type": "Document"
    },
    {
        "page_content": "最大似然估计法是求估计用得最多的方法, 它最早是由高斯在 1821 年提出, 但一般将之归功于费希尔 (R.A.Fisher), 因为费希尔在 1922 年再次提出了这种想法并证明了它的一些性质而使得最大似然法得到了广泛的应用.  \n为了叙述最大似然原理的直观想法, 先看两个例子.  \n例 6.1.4: 设有外形完全相同的两个箱子, 甲箱中有 99 个白球和 1 个黑球, 乙箱中有 99 个黑球和 1 个白球, 今随机地抽取一箱, 并从中随机抽取一球, 结果取得白球, 间这球是从哪一个箱子中取出?解: 不管是哪一个箱子, 从箱子中任取一球都有两个可能的结果: $A$ 表示取出白球, $B$ 表示取出黑球. 如果我们取出的是甲箱, 则 $A$ 发生的概率为 0.99 , 而如果取出的是乙箱, 则 $A$ 发生的概率为 0.01. 现在一次试验中结果 $A$ 发生了, 人们的第一印象就是: “此白球 $(A)$ 最像从甲箱取出的”, 或者说, 应该认为试验条件对结果 $A$ 出现有利, 从而可以推断这球是从甲箱中取出的. 这个推断很符合人们的经验事实, 这里“最像”就是“最大似然”之意.  \n本例中假设的数据很极端. 一般地, 我们可以这样设想: 有两个箱子中各有 100 只球, 甲箱中白球的比例是 $p_{1}$, 乙箱中白球的比例是 $p_{2}$, 已知 $p_{1}>p_{2}$, 现随即地抽取一个箱子并从中抽取一球, 假定取到的是白球, 如果我们要在两个箱子中进行选择, 由子甲箱中白球的比例高于乙箱, 根据最大似然原理, 我们应该推断该球来自甲箱.  \n例 6.1.5: 设产品分为合格品与不合格品两类, 我们用一个随即变量 $X$ 来表示某个产品是否合格, $X=0$ 表示合格品, $X=1$ 表示不合格品, 则 $X$ 服从二点分布 $b(1, p)$, 其中 $p$ 是未知的不合格品率. 现抽取 $n$ 个产品看其是否合格, 得到样本 $x_{1}, \\cdots, x_{n}$, 这批观测值发生的概率为:  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "本例中假设的数据很极端. 一般地, 我们可以这样设想: 有两个箱子中各有 100 只球, 甲箱中白球的比例是 $p_{1}$, 乙箱中白球的比例是 $p_{2}$, 已知 $p_{1}>p_{2}$, 现随即地抽取一个箱子并从中抽取一球, 假定取到的是白球, 如果我们要在两个箱子中进行选择, 由子甲箱中白球的比例高于乙箱, 根据最大似然原理, 我们应该推断该球来自甲箱.  \n例 6.1.5: 设产品分为合格品与不合格品两类, 我们用一个随即变量 $X$ 来表示某个产品是否合格, $X=0$ 表示合格品, $X=1$ 表示不合格品, 则 $X$ 服从二点分布 $b(1, p)$, 其中 $p$ 是未知的不合格品率. 现抽取 $n$ 个产品看其是否合格, 得到样本 $x_{1}, \\cdots, x_{n}$, 这批观测值发生的概率为:  \n$$\n\\begin{equation*}\nP\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; p\\right)=\\prod_{i=1}^{n} p^{x_{i}}(1-p)^{1-x_{i}}=p^{\\sum x_{i}}(1-p)^{n-\\sum x_{i}} \\tag{6.1.3}\n\\end{equation*}\n$$  \n由子 $p$ 是未知的, 根据最大似然原理, 我们应选择 $p$ 使得 (6.1.3) 表示的概率尽可能大. 将(6.1.3)看作未知参数 $p$ 的函数, 用 $L(p)$ 表示, 称作似然函数, 亦即  \n$$\n\\begin{equation*}\nL(p)=p^{\\sum x_{i}}(1-p)^{n-\\sum x_{i}}, \\tag{6.1.4}\n\\end{equation*}\n$$  \n要求 (6.1.4) 的最大值点不是难事, 将 (6.1.4) 两端取对数并关子 $p$ 求导令其为 $\\Theta$, 即得如下方程:  \n$$\n\\begin{equation*}\n\\frac{\\partial \\ln L(p)}{\\partial p}=\\frac{\\sum x_{i}}{p}-\\frac{n-\\sum x_{i}}{1-p}=0 \\tag{6.1.5}\n\\end{equation*}\n$$  \n解之即得 $p$ 的最大似然估计, 为  \n$$",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n由子 $p$ 是未知的, 根据最大似然原理, 我们应选择 $p$ 使得 (6.1.3) 表示的概率尽可能大. 将(6.1.3)看作未知参数 $p$ 的函数, 用 $L(p)$ 表示, 称作似然函数, 亦即  \n$$\n\\begin{equation*}\nL(p)=p^{\\sum x_{i}}(1-p)^{n-\\sum x_{i}}, \\tag{6.1.4}\n\\end{equation*}\n$$  \n要求 (6.1.4) 的最大值点不是难事, 将 (6.1.4) 两端取对数并关子 $p$ 求导令其为 $\\Theta$, 即得如下方程:  \n$$\n\\begin{equation*}\n\\frac{\\partial \\ln L(p)}{\\partial p}=\\frac{\\sum x_{i}}{p}-\\frac{n-\\sum x_{i}}{1-p}=0 \\tag{6.1.5}\n\\end{equation*}\n$$  \n解之即得 $p$ 的最大似然估计, 为  \n$$\n\\hat{p}=\\hat{p}\\left(x_{1}, \\cdots, x_{n}\\right)=\\sum x_{i} / n=\\bar{x} .\n$$  \n由例6.1.5 我们可以看到求最大似然估计的基本思路, 对离散型总体, 设有样本观测值 $x_{1}, \\cdots, x_{n}$,我们写出该观测值出现的概率, 它一般依赖子某个或某些参数, 用 $\\theta$ 表示, 将该概率看成 $\\theta$ 的函数,用 $L(\\theta)$ 表示, 即  \n$$\nL(\\theta)=L\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right),\n$$  \n求最大似然估计就是找 $\\theta$ 的估计值 $\\hat{\\theta}=\\hat{\\theta}\\left(x_{1}, \\cdots, x_{n}\\right)$ 使得上式的 $L(\\theta)$ 达到最大.  \n对连续型总体, 样本观测值 $x_{1}, \\cdots, x_{n}$ 出现的概率总是为 0 的, 但我们可用联合概率密度函数来表示随机变量在观测值附近出现的可能性大小, 也将之称为似然函数, 由此, 我们给出如下正规的定义.",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由例6.1.5 我们可以看到求最大似然估计的基本思路, 对离散型总体, 设有样本观测值 $x_{1}, \\cdots, x_{n}$,我们写出该观测值出现的概率, 它一般依赖子某个或某些参数, 用 $\\theta$ 表示, 将该概率看成 $\\theta$ 的函数,用 $L(\\theta)$ 表示, 即  \n$$\nL(\\theta)=L\\left(X_{1}=x_{1}, \\cdots, X_{n}=x_{n} ; \\theta\\right),\n$$  \n求最大似然估计就是找 $\\theta$ 的估计值 $\\hat{\\theta}=\\hat{\\theta}\\left(x_{1}, \\cdots, x_{n}\\right)$ 使得上式的 $L(\\theta)$ 达到最大.  \n对连续型总体, 样本观测值 $x_{1}, \\cdots, x_{n}$ 出现的概率总是为 0 的, 但我们可用联合概率密度函数来表示随机变量在观测值附近出现的可能性大小, 也将之称为似然函数, 由此, 我们给出如下正规的定义.  \n定义 6.1.1. 设总体的概率函数为 $p(x ; \\theta), \\theta \\in \\Theta$, 日, 其中 $\\theta$ 是一个未知参数或几个未知参数组成的参数向量, 是参数 $\\theta$ 可能取值的参数空间, $x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, 将样本的联合概率函数看成 8 的函数, 用 $L\\left(\\theta ; x_{1}, \\cdots, x_{n}\\right)$ 表示, 简记为 $L(\\theta)$,  \n$$\n\\begin{equation*}\nL(\\theta)=L\\left(\\theta ; x_{1}, \\cdots, x_{n}\\right)=p\\left(x_{1} ; \\theta\\right) \\cdot p\\left(x_{2} ; \\theta\\right) \\cdots \\cdots p\\left(x_{n} ; \\theta\\right) \\tag{6.1.6}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 6.1.1. 设总体的概率函数为 $p(x ; \\theta), \\theta \\in \\Theta$, 日, 其中 $\\theta$ 是一个未知参数或几个未知参数组成的参数向量, 是参数 $\\theta$ 可能取值的参数空间, $x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, 将样本的联合概率函数看成 8 的函数, 用 $L\\left(\\theta ; x_{1}, \\cdots, x_{n}\\right)$ 表示, 简记为 $L(\\theta)$,  \n$$\n\\begin{equation*}\nL(\\theta)=L\\left(\\theta ; x_{1}, \\cdots, x_{n}\\right)=p\\left(x_{1} ; \\theta\\right) \\cdot p\\left(x_{2} ; \\theta\\right) \\cdots \\cdots p\\left(x_{n} ; \\theta\\right) \\tag{6.1.6}\n\\end{equation*}\n$$  \n$L(\\theta)$ 称为样本的似然函数. 如果某统计量 $\\hat{\\theta}=\\hat{\\theta}\\left(x_{1}, \\cdots, x_{n}\\right)$ 满足  \n$$\n\\begin{equation*}\nL(\\hat{\\theta})=\\max _{\\theta \\in \\Theta} L(\\theta) \\tag{6.1.7}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}$ 是 $\\theta$ 的最大似然估计, 简记为 MLE(Maximum Likelihood Estimate).  \n由于 $\\ln x$ 是 $x$ 的单调增函数, 因此, 使对数似然函数 $\\ln L(\\theta)$ 达到最大与使 $L(\\theta)$ 达到最大是等价的. 人们通常更习惯于由 $\\ln L(\\theta)$ 出发寻找日的最大似然估计. 当 $L(\\theta)$ 是可微函数时, 求导是求最大似然估计最常用的方法, 此时对对数似然函数求导更加简单些.  \n例 6.1.6: 设一个试验有三种可能结果, 其发生概率分别为  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nL(\\hat{\\theta})=\\max _{\\theta \\in \\Theta} L(\\theta) \\tag{6.1.7}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}$ 是 $\\theta$ 的最大似然估计, 简记为 MLE(Maximum Likelihood Estimate).  \n由于 $\\ln x$ 是 $x$ 的单调增函数, 因此, 使对数似然函数 $\\ln L(\\theta)$ 达到最大与使 $L(\\theta)$ 达到最大是等价的. 人们通常更习惯于由 $\\ln L(\\theta)$ 出发寻找日的最大似然估计. 当 $L(\\theta)$ 是可微函数时, 求导是求最大似然估计最常用的方法, 此时对对数似然函数求导更加简单些.  \n例 6.1.6: 设一个试验有三种可能结果, 其发生概率分别为  \n$$\n\\begin{equation*}\np_{1}=\\theta^{2}, \\quad p_{2}=2 \\theta(1-\\theta), \\quad p_{3}=(1-\\theta)^{2} \\tag{6.1.8}\n\\end{equation*}\n$$  \n现做了 $n$ 次试验, 观测到三种结果发生的次数分别为 $n_{1}, n_{2}, n_{3}\\left(n_{1}+n_{2}+n_{3}=n\\right)$. 则似然函数为  \n$$\n\\begin{aligned}\nL(\\theta) & =\\left(\\theta^{2}\\right)^{n_{1}}[2 \\theta(1-\\theta)]^{n_{2}}\\left[(1-\\theta)^{2}\\right]^{n_{3}} \\\\\n& =2^{n_{2}} \\theta^{2 n_{1}+n_{2}}(1-\\theta)^{2 n_{3}+n_{2}}\n\\end{aligned}\n$$  \n其对数似然函数为  \n$$\n\\ln L(\\theta)=\\left(2 n_{1}+n_{2}\\right) \\ln \\theta+\\left(2 n_{3}+n_{2}\\right) \\ln (1-\\theta)+n_{2} \\ln 2\n$$  \n将之关于 $\\theta$ 求导并令其为 0 得到似然方程  \n$$",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n现做了 $n$ 次试验, 观测到三种结果发生的次数分别为 $n_{1}, n_{2}, n_{3}\\left(n_{1}+n_{2}+n_{3}=n\\right)$. 则似然函数为  \n$$\n\\begin{aligned}\nL(\\theta) & =\\left(\\theta^{2}\\right)^{n_{1}}[2 \\theta(1-\\theta)]^{n_{2}}\\left[(1-\\theta)^{2}\\right]^{n_{3}} \\\\\n& =2^{n_{2}} \\theta^{2 n_{1}+n_{2}}(1-\\theta)^{2 n_{3}+n_{2}}\n\\end{aligned}\n$$  \n其对数似然函数为  \n$$\n\\ln L(\\theta)=\\left(2 n_{1}+n_{2}\\right) \\ln \\theta+\\left(2 n_{3}+n_{2}\\right) \\ln (1-\\theta)+n_{2} \\ln 2\n$$  \n将之关于 $\\theta$ 求导并令其为 0 得到似然方程  \n$$\n\\frac{2 n_{1}+n_{2}}{\\theta}-\\frac{2 n_{3}+n_{2}}{1-\\theta}=0\n$$  \n解之, 得  \n$$\n\\hat{\\theta}=\\frac{2 n_{1}+n_{2}}{2\\left(n_{1}+n_{2}+n_{3}\\right)}=\\frac{2 n_{1}+n_{2}}{2 n},\n$$  \n由于  \n$$\n\\frac{\\partial^{2} \\ln L(\\theta)}{\\partial \\theta^{2}}=-\\frac{2 n_{1}+n_{2}}{\\theta^{2}}-\\frac{2 n_{3}+n_{2}}{(1-\\theta)^{2}}<0\n$$  \n所以 $\\hat{\\theta}$ 是极大值点.  \n例 6.1.7: 对正态总体 $N\\left(u, \\delta^{2}\\right), \\theta=\\left(u, \\delta^{2}\\right)$ 是二维参数, 设有样本 $x_{1}, \\cdots, x_{n}$, 则似然函数及其对数分别为  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\frac{2 n_{1}+n_{2}}{\\theta}-\\frac{2 n_{3}+n_{2}}{1-\\theta}=0\n$$  \n解之, 得  \n$$\n\\hat{\\theta}=\\frac{2 n_{1}+n_{2}}{2\\left(n_{1}+n_{2}+n_{3}\\right)}=\\frac{2 n_{1}+n_{2}}{2 n},\n$$  \n由于  \n$$\n\\frac{\\partial^{2} \\ln L(\\theta)}{\\partial \\theta^{2}}=-\\frac{2 n_{1}+n_{2}}{\\theta^{2}}-\\frac{2 n_{3}+n_{2}}{(1-\\theta)^{2}}<0\n$$  \n所以 $\\hat{\\theta}$ 是极大值点.  \n例 6.1.7: 对正态总体 $N\\left(u, \\delta^{2}\\right), \\theta=\\left(u, \\delta^{2}\\right)$ 是二维参数, 设有样本 $x_{1}, \\cdots, x_{n}$, 则似然函数及其对数分别为  \n$$\n\\begin{aligned}\nL\\left(\\mu, \\sigma^{2}\\right) & =\\prod_{i=1}^{n}\\left\\{\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{\\left(x_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}}\\right\\}\\right\\} \\\\\n& =\\left(2 \\pi \\sigma^{2}\\right)^{-n / 2} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right\\} \\\\\n\\ln L\\left(\\mu, \\sigma^{2}\\right) & =-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}-\\frac{n}{2} \\ln \\sigma^{2}-\\frac{n}{2} \\ln (2 \\pi)\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\nL\\left(\\mu, \\sigma^{2}\\right) & =\\prod_{i=1}^{n}\\left\\{\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left\\{-\\frac{\\left(x_{i}-\\mu\\right)^{2}}{2 \\sigma^{2}}\\right\\}\\right\\} \\\\\n& =\\left(2 \\pi \\sigma^{2}\\right)^{-n / 2} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right\\} \\\\\n\\ln L\\left(\\mu, \\sigma^{2}\\right) & =-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}-\\frac{n}{2} \\ln \\sigma^{2}-\\frac{n}{2} \\ln (2 \\pi)\n\\end{aligned}\n$$  \n将 $\\ln L\\left(\\mu, \\delta^{2}\\right)$ 分别关于两个分量求偏导并令其为 0 即得到似然方程组将 $\\ln L\\left(u, \\delta^{2}\\right)$ 分别关于两个分量求偏导并令其为 0 即得到似然方程组  \n$$\n\\begin{gather*}\n\\frac{\\partial \\ln L\\left(\\mu, \\sigma^{2}\\right)}{\\partial \\mu}=\\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)=0  \\tag{6.1.9}\\\\\n\\frac{\\partial \\ln L\\left(\\mu, \\sigma^{2}\\right)}{\\partial \\sigma^{2}}=\\frac{1}{2 \\sigma^{4}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}-\\frac{n}{2 \\sigma^{2}}=0 \\tag{6.1.10}\n\\end{gather*}\n$$",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n将 $\\ln L\\left(\\mu, \\delta^{2}\\right)$ 分别关于两个分量求偏导并令其为 0 即得到似然方程组将 $\\ln L\\left(u, \\delta^{2}\\right)$ 分别关于两个分量求偏导并令其为 0 即得到似然方程组  \n$$\n\\begin{gather*}\n\\frac{\\partial \\ln L\\left(\\mu, \\sigma^{2}\\right)}{\\partial \\mu}=\\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)=0  \\tag{6.1.9}\\\\\n\\frac{\\partial \\ln L\\left(\\mu, \\sigma^{2}\\right)}{\\partial \\sigma^{2}}=\\frac{1}{2 \\sigma^{4}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}-\\frac{n}{2 \\sigma^{2}}=0 \\tag{6.1.10}\n\\end{gather*}\n$$  \n解此方程组, 由 (6.1.9) 可得 $\\mu$ 的最大似然估计为  \n$$\n\\hat{\\mu}=\\frac{1}{n} \\sum_{z=1}^{n} x_{i}=\\bar{x}\n$$  \n将之代人 (6.1.10) 给出 $\\delta^{2}$ 的最大似然估计  \n$$\n\\vec{\\sigma}^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}=s^{* 2}\n$$  \n利用二阶导函数矩阵的非正定性可以说明上述估计使得似然函数取极大值.  \n虽然求导函数是求最大似然估计最常用的方法, 但并不是在所有场合求导都是有效的, 下面的例子说明了这个问题.  \n例 6.1.8: 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(0, \\theta)$ 的样本, 试求 $\\theta$ 的最大似然估计.  \n解: 似然函数  \n$$",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{gather*}\n$$  \n解此方程组, 由 (6.1.9) 可得 $\\mu$ 的最大似然估计为  \n$$\n\\hat{\\mu}=\\frac{1}{n} \\sum_{z=1}^{n} x_{i}=\\bar{x}\n$$  \n将之代人 (6.1.10) 给出 $\\delta^{2}$ 的最大似然估计  \n$$\n\\vec{\\sigma}^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}=s^{* 2}\n$$  \n利用二阶导函数矩阵的非正定性可以说明上述估计使得似然函数取极大值.  \n虽然求导函数是求最大似然估计最常用的方法, 但并不是在所有场合求导都是有效的, 下面的例子说明了这个问题.  \n例 6.1.8: 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(0, \\theta)$ 的样本, 试求 $\\theta$ 的最大似然估计.  \n解: 似然函数  \n$$\nL(\\theta)=\\frac{1}{\\theta^{n}} \\prod_{i=1}^{n} I_{\\left\\{0<X_{i} \\leqslant \\theta\\right\\}}=\\frac{1}{\\theta^{n}} I_{\\left\\{X_{(n)} \\leqslant \\theta\\right\\}}\n$$  \n要使 $L(\\theta)$ 达到最大, 首先一点是示性函数取值应该为 1 , 其次是 $1 / \\theta^{n}$ 尽可能大. 由于 $1 / \\theta^{n}$ 是 $\\theta$ 的单调减函数, 所以 $\\theta$ 的取值应尽可能小, 但示性函数为 1 决定了 $\\theta$ 不能小于 $\\mathrm{x}(\\mathrm{a})$, 由此给出 $\\theta$ 的最大似然估计: $\\hat{\\theta}=x_{(n)}$.  \n最大似然估计有一个简单面有用的性质: 如果是 $\\theta$ 的最大似然估计, 则对任一函数 $g(\\theta)$, 其最大似然估计为 $g(\\hat{\\theta})$. 该性质称为最大似然估计的不变性, 从而使一些复杂结构的参数的最大似然估计的获得变得容易了.",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n要使 $L(\\theta)$ 达到最大, 首先一点是示性函数取值应该为 1 , 其次是 $1 / \\theta^{n}$ 尽可能大. 由于 $1 / \\theta^{n}$ 是 $\\theta$ 的单调减函数, 所以 $\\theta$ 的取值应尽可能小, 但示性函数为 1 决定了 $\\theta$ 不能小于 $\\mathrm{x}(\\mathrm{a})$, 由此给出 $\\theta$ 的最大似然估计: $\\hat{\\theta}=x_{(n)}$.  \n最大似然估计有一个简单面有用的性质: 如果是 $\\theta$ 的最大似然估计, 则对任一函数 $g(\\theta)$, 其最大似然估计为 $g(\\hat{\\theta})$. 该性质称为最大似然估计的不变性, 从而使一些复杂结构的参数的最大似然估计的获得变得容易了.  \n例 6.1.9: 设 $x_{1}, \\cdots, x_{n}$ 是来自正态总体 $N\\left(\\mu, \\delta^{2}\\right)$ 的样本, 在例6.1.7中已求得 $\\mu$ 和 $\\delta^{2}$ 的最大似然估计为  \n$$\n\\hat{\\mu}=\\bar{x}, \\quad \\hat{\\sigma}^{2}=s^{* 2}\n$$  \n于是由最大似然估计的不变性可得如下参数的最大似然估计, 它们是  \n- 标准差 $\\delta$ 的 MLE 是 $\\delta=\\sigma^{*}$;\n- 概率 $P(X<3)=\\Phi\\left(\\frac{3-u}{\\delta}\\right)$ 的 MLE 是 $\\Phi\\left(\\frac{3-\\bar{x}}{s^{*}}\\right)$;\n- 总体 0.90 分位数 $x_{0.90}=\\mu+\\sigma \\cdot \\mu_{0.90}$ 的 MLE 是 $\\bar{x}+s^{*} \\cdot u_{0.90}$, 其中 $u_{0.90}$ 为标准正态分布的 0.90 分位数.",
        "metadata": {
            "Header 2": "二、概率函数 $p(x ; \\theta)$ 已知时未知参数的矩法估计",
            "Header 3": "6.1.2 最大似然估计"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 从一批电子元件中抽取 8 个进行寿命测试, 得到如下数据 (单位:h):  \n!  \n试对这批元件的平均寿命以及寿命分布的标准差给出矩估计.  \n2. 设总体 $X \\sim U(0, \\theta)$, 现从该总体中抽取容量为 10 的样本, 样本值为:  \n$$\n0.5, \\quad 1.3, \\quad 0.6, \\quad 1.7, \\quad 2.2, \\quad 1.2, \\quad 0.8, \\quad 1.5, \\quad 2.0, \\quad 1.6\n$$  \n试对参数 $\\theta$ 给出矩估计.  \n3. 设总体分布列如下, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的矩估计.  \n(1) $P(X=k)=\\frac{1}{N}, k=0,1,2, \\cdots, N-1, N$, (正整数) 是未知参数;  \n(2) $P(X=k)=(k-1) \\theta^{2}(1-\\theta)^{k-2}, k=2,3, \\cdots, 0<\\theta<1$.  \n4. 设总体密度函数如下, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的矩估计.  \n(1) $p(x ; \\theta)=\\frac{2}{\\theta^{2}}(\\theta-x), 0<x<\\theta, \\theta>0$,  \n(2) $p(x ; \\theta)=(\\theta+1) x^{8}, 0<x<1, \\theta>0$,  \n(3) $p(x ; \\theta)=\\sqrt{\\theta} x^{\\sqrt{8}-t}, 0<x<1, \\theta>0$,  \n(4) $p(x ; \\theta, \\mu)=\\frac{1}{\\theta} \\mathrm{e}^{-\\frac{x-\\mu}{\\theta}}, x>\\mu, \\theta>0$.  \n5. 设总体为 $N(\\mu, 1)$, 现对该总体观测 $n$ 次, 发现有 $k$ 次观测值为正, 使用频率替换方法求 $A$ 的估计.",
        "metadata": {
            "Header 2": "奴题 6.1"
        },
        "type": "Document"
    },
    {
        "page_content": "4. 设总体密度函数如下, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的矩估计.  \n(1) $p(x ; \\theta)=\\frac{2}{\\theta^{2}}(\\theta-x), 0<x<\\theta, \\theta>0$,  \n(2) $p(x ; \\theta)=(\\theta+1) x^{8}, 0<x<1, \\theta>0$,  \n(3) $p(x ; \\theta)=\\sqrt{\\theta} x^{\\sqrt{8}-t}, 0<x<1, \\theta>0$,  \n(4) $p(x ; \\theta, \\mu)=\\frac{1}{\\theta} \\mathrm{e}^{-\\frac{x-\\mu}{\\theta}}, x>\\mu, \\theta>0$.  \n5. 设总体为 $N(\\mu, 1)$, 现对该总体观测 $n$ 次, 发现有 $k$ 次观测值为正, 使用频率替换方法求 $A$ 的估计.\n6. 甲、乙两个校对员被此独立对同一本书的样稿进行校对, 校完后, 甲发现 $a$ 个错字, 乙发现 $b$ 个错字, 其中共同发现的错字有 $c$ 个, 试用矩法给出如下两个未知参数的估计:  \n(1) 该书样稿的总错字个数;  \n(2) 未被发现的错字数.  \n7. 设总体概率函数如, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的最大似然估计.  \n(1) $p(x ; \\theta)=\\sqrt{\\theta} x^{\\sqrt{\\theta}-1}, 0<x<1, \\theta>0$,  \n(2) $p(x ; \\theta)=\\theta c^{\\theta} x^{-(\\theta+1)}, x>c, c>0$, 已知, $\\theta>1$.  \n8. 设总体概率函数如下, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的最大似然估计.  \n(1) $p(x ; \\theta)=c \\theta^{c} x^{-(c+1)}, x>\\theta, \\theta>0, c>0$ 已知,",
        "metadata": {
            "Header 2": "奴题 6.1"
        },
        "type": "Document"
    },
    {
        "page_content": "6. 甲、乙两个校对员被此独立对同一本书的样稿进行校对, 校完后, 甲发现 $a$ 个错字, 乙发现 $b$ 个错字, 其中共同发现的错字有 $c$ 个, 试用矩法给出如下两个未知参数的估计:  \n(1) 该书样稿的总错字个数;  \n(2) 未被发现的错字数.  \n7. 设总体概率函数如, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的最大似然估计.  \n(1) $p(x ; \\theta)=\\sqrt{\\theta} x^{\\sqrt{\\theta}-1}, 0<x<1, \\theta>0$,  \n(2) $p(x ; \\theta)=\\theta c^{\\theta} x^{-(\\theta+1)}, x>c, c>0$, 已知, $\\theta>1$.  \n8. 设总体概率函数如下, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的最大似然估计.  \n(1) $p(x ; \\theta)=c \\theta^{c} x^{-(c+1)}, x>\\theta, \\theta>0, c>0$ 已知,  \n(2) $p(x ; \\theta, \\mu)=\\frac{1}{\\theta} e^{-\\frac{x-\\mu}{\\theta}}, x>\\mu, \\theta>0$,  \n(3) $p(x ; \\theta)=(k \\theta)^{-1}, \\theta<x<(k+1) \\theta, \\theta>0$.  \n9. 设总体概率函数如下, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的最大似然估计.  \n(1) $p(x ; \\theta)=\\frac{1}{2 \\theta} \\mathrm{e}^{-|x| / \\theta}, \\theta>0$,  \n(2) $p(x ; \\theta)=1, \\theta-1 / 2<x<\\theta+1 / 2$,  \n(3) $p\\left(x ; \\theta_{1}, \\theta_{2}\\right)=\\frac{1}{\\theta_{2}-\\theta_{1}}, \\theta_{1}<x<\\theta_{2}$.",
        "metadata": {
            "Header 2": "奴题 6.1"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) $p(x ; \\theta, \\mu)=\\frac{1}{\\theta} e^{-\\frac{x-\\mu}{\\theta}}, x>\\mu, \\theta>0$,  \n(3) $p(x ; \\theta)=(k \\theta)^{-1}, \\theta<x<(k+1) \\theta, \\theta>0$.  \n9. 设总体概率函数如下, $x_{1}, x_{2}, \\cdots, x_{n}$ 是样本, 试求未知参数的最大似然估计.  \n(1) $p(x ; \\theta)=\\frac{1}{2 \\theta} \\mathrm{e}^{-|x| / \\theta}, \\theta>0$,  \n(2) $p(x ; \\theta)=1, \\theta-1 / 2<x<\\theta+1 / 2$,  \n(3) $p\\left(x ; \\theta_{1}, \\theta_{2}\\right)=\\frac{1}{\\theta_{2}-\\theta_{1}}, \\theta_{1}<x<\\theta_{2}$.  \n10. 一地质学家为研究密歇根湖的湖滩地区的岩石成分, 随机地自该地区取 100 个样品, 每个样品有 10 块石子, 记录了每个样品中属石灰石的石子数. 假设这 100 次观豪相互独立, 求这地区石子中石灰石的比例 $p$ 的最大似然估计. 该地质学家所得的数据如下:  \n| 样本中的石子数 | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 样品个数 | 0 | 1 | 6 | 7 | 23 | 26 | 21 | 12 | 3 | 1 | 0 |  \n11. 在遗传学研究中经常要从截尾二项分布中抽样, 其总体概率函数为  \n$$\nP(X=k ; p)=\\frac{\\left(\\begin{array}{c}\nm \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{m-k}}{1-(1-p)^{m}}, k=1,2, \\cdots, m\n$$",
        "metadata": {
            "Header 2": "奴题 6.1"
        },
        "type": "Document"
    },
    {
        "page_content": "| 样本中的石子数 | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 样品个数 | 0 | 1 | 6 | 7 | 23 | 26 | 21 | 12 | 3 | 1 | 0 |  \n11. 在遗传学研究中经常要从截尾二项分布中抽样, 其总体概率函数为  \n$$\nP(X=k ; p)=\\frac{\\left(\\begin{array}{c}\nm \\\\\nk\n\\end{array}\\right) p^{k}(1-p)^{m-k}}{1-(1-p)^{m}}, k=1,2, \\cdots, m\n$$  \n若已知 $m=2, x_{1}, x_{2}, \\cdots, x_{n}$ 是样本,试求 $p$ 的最大似然估计.  \n12. 已知在文学家萧伯纳的 “An Intelligent Woman's Guide To Socialism”一书中, 一个句子的单词数 $X$ 近似地服从对数正态分布, 即 $x=\\ln X \\sim N\\left(\\mu, \\sigma^{2}\\right)$. 今从该书中随机地取 20 个句子, 这些句子中的单词数分别为  \n| 52 | 24 | 15 | 67 | 15 | 22 | 63 | 26 | 16 | 32 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 7 | 33 | 28 | 14 | 7 | 29 | 10 | 6 | 59 | 30 |  \n求该书中一个句子单词数均值 $E(X)=\\mathrm{e}^{\\mu+\\sigma^{2} / 2}$ 的最大似然估计.",
        "metadata": {
            "Header 2": "奴题 6.1"
        },
        "type": "Document"
    },
    {
        "page_content": "我们已经看到, 点估计有各种不同的求法, 为了在不同的点估计间进行比较选择, 就必须对各种点估计的好坏给出评价标准.  \n数理统计中给出了众多的估计量评价标准, 对同一估计量使用不同的评价标准可能会得到完全不同的结论, 因此, 在评价某一个估计好坏时首先要说明是在哪一个标准下, 否则所论好坏则毫无意义.  \n但不管怎么说, 有一个基本标准是所有的估计都应该满足的, 它是衡量一个估计是否可行的必要条件, 这就是估计的相合性, 我们就从相合性开始.",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 6.2.1. 设 $\\theta \\in \\Theta$ 为未知参数, $\\hat{\\theta}_{n}=\\hat{\\theta}_{n}\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的一个估计量, $n$ 是样本容量, 若对任何一个 $\\varepsilon>0$, 有  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow \\infty} P\\left(\\left|\\hat{\\theta}_{n}-\\theta\\right|>\\varepsilon\\right)=0 \\tag{6.2.1}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}_{n}$ 为参数 $\\theta$ 的相合估计.  \n相合性被认为是对估计的一个最基本要求, 如果一个估计量, 在样本量不断增大时, 它都不能把被估参数估计到任意指定的精度, 那么这个估计是很值得怀疑的. 通常, 不满足相合性要求的估计一般不予考虑. 证明估计的相合性一般可应用大数定律或直接由定义来证.  \n若把依赖于样本量 $n$ 的估计量 $\\hat{\\theta}_{n}$. 看作一个随机变量序列, 相合性就是 $\\hat{\\theta}_{n}$. 依概率收玫于 $\\theta$,所以证明估计的相合性可应用依概率收敛的性质及各种大数定律.  \n例 6.2.1: 设 $x_{1}, \\cdots, x_{n}$ 是来自正态总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 则由辛钦大数定律及依概率收玫的性质知:  \n- $\\bar{x}$ 是 $\\mu$ 的相合估计;\n- $s^{* 2}$ 是 $\\sigma^{2}$ 的相合估计;\n- $s^{2}$ 也是 $\\sigma^{2}$ 的相合估计.  \n由此可见参数的相合估计不止一个.  \n是理 6.2.1. 设 $\\hat{\\theta}_{n}=\\hat{\\theta}_{n}\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的一个估计量, 若  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "若把依赖于样本量 $n$ 的估计量 $\\hat{\\theta}_{n}$. 看作一个随机变量序列, 相合性就是 $\\hat{\\theta}_{n}$. 依概率收玫于 $\\theta$,所以证明估计的相合性可应用依概率收敛的性质及各种大数定律.  \n例 6.2.1: 设 $x_{1}, \\cdots, x_{n}$ 是来自正态总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 则由辛钦大数定律及依概率收玫的性质知:  \n- $\\bar{x}$ 是 $\\mu$ 的相合估计;\n- $s^{* 2}$ 是 $\\sigma^{2}$ 的相合估计;\n- $s^{2}$ 也是 $\\sigma^{2}$ 的相合估计.  \n由此可见参数的相合估计不止一个.  \n是理 6.2.1. 设 $\\hat{\\theta}_{n}=\\hat{\\theta}_{n}\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的一个估计量, 若  \n$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} E\\left(\\hat{\\theta}_{n}\\right)=\\theta, \\quad \\lim _{n \\rightarrow+\\infty} \\operatorname{Var}\\left(\\hat{\\theta}_{n}\\right)=0 \\tag{6.2.2}\n\\end{equation*}\n$$  \n则 $\\hat{\\theta}_{n}$ 是 $\\theta$ 的相合估计,  \n证明: 对任意的 $\\varepsilon>0$, 由切比雪夫不等式有  \n$$\nP\\left(\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right| \\geqslant \\varepsilon / 2\\right) \\leqslant \\frac{4}{\\varepsilon^{2}} \\operatorname{Var}\\left(\\hat{\\theta}_{n}\\right)\n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n\\lim _{n \\rightarrow+\\infty} E\\left(\\hat{\\theta}_{n}\\right)=\\theta, \\quad \\lim _{n \\rightarrow+\\infty} \\operatorname{Var}\\left(\\hat{\\theta}_{n}\\right)=0 \\tag{6.2.2}\n\\end{equation*}\n$$  \n则 $\\hat{\\theta}_{n}$ 是 $\\theta$ 的相合估计,  \n证明: 对任意的 $\\varepsilon>0$, 由切比雪夫不等式有  \n$$\nP\\left(\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right| \\geqslant \\varepsilon / 2\\right) \\leqslant \\frac{4}{\\varepsilon^{2}} \\operatorname{Var}\\left(\\hat{\\theta}_{n}\\right)\n$$  \n另一方面,由 $\\lim _{n \\rightarrow+\\infty} E\\left(\\hat{\\theta}_{n}\\right)=\\theta$ 可知, 当 $n$ 充分大时有  \n$$\n\\left|E \\hat{\\theta}_{n}-\\theta\\right|<\\varepsilon / 2\n$$  \n注意到此时如果 $\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|<\\varepsilon / 2$, 就有  \n$$\n\\left|\\hat{\\theta}_{n}-\\theta\\right| \\leqslant\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|+\\left|E \\hat{\\theta}_{n}-\\theta\\right|<\\varepsilon\n$$  \n故  \n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n另一方面,由 $\\lim _{n \\rightarrow+\\infty} E\\left(\\hat{\\theta}_{n}\\right)=\\theta$ 可知, 当 $n$ 充分大时有  \n$$\n\\left|E \\hat{\\theta}_{n}-\\theta\\right|<\\varepsilon / 2\n$$  \n注意到此时如果 $\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|<\\varepsilon / 2$, 就有  \n$$\n\\left|\\hat{\\theta}_{n}-\\theta\\right| \\leqslant\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|+\\left|E \\hat{\\theta}_{n}-\\theta\\right|<\\varepsilon\n$$  \n故  \n$$\n\\left.\\left\\{\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|<\\varepsilon / 2\\right\\} \\subset \\| \\hat{\\theta}_{n}-\\theta \\mid<\\varepsilon\\right\\}\n$$  \n等价地  \n$$\n\\left\\{\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|<\\varepsilon / 2\\right\\} \\supset\\left\\{\\left|\\hat{\\theta}_{n}-\\theta\\right|<\\varepsilon\\right\\}\n$$  \n由此即有  \n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\left|\\hat{\\theta}_{n}-\\theta\\right| \\leqslant\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|+\\left|E \\hat{\\theta}_{n}-\\theta\\right|<\\varepsilon\n$$  \n故  \n$$\n\\left.\\left\\{\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|<\\varepsilon / 2\\right\\} \\subset \\| \\hat{\\theta}_{n}-\\theta \\mid<\\varepsilon\\right\\}\n$$  \n等价地  \n$$\n\\left\\{\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right|<\\varepsilon / 2\\right\\} \\supset\\left\\{\\left|\\hat{\\theta}_{n}-\\theta\\right|<\\varepsilon\\right\\}\n$$  \n由此即有  \n$$\nP\\left(\\left|\\hat{\\theta}_{n}-\\theta\\right|>\\epsilon\\right) \\leqslant P\\left(\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right| \\geqslant \\epsilon / 2\\right) \\leqslant \\frac{4}{\\varepsilon^{2}} \\operatorname{Var}\\left(\\hat{\\theta}_{n}\\right) \\rightarrow 0(n \\rightarrow+\\infty)\n$$  \n定理得证.  \n例 6.2.2: 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(0,0)$ 的样本, 证明 $\\theta$ 的最大似然估计是相合估计.  \n证明: 在例6.1.7中我们已经给出 $\\theta$ 的最大似然估计是 $x_{(n)}$. 由次序统计量的分布, 我们知道 $\\hat{\\theta}=x_{(n)}$ 的分布密度函数为  \n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由此即有  \n$$\nP\\left(\\left|\\hat{\\theta}_{n}-\\theta\\right|>\\epsilon\\right) \\leqslant P\\left(\\left|\\hat{\\theta}_{n}-E \\hat{\\theta}_{n}\\right| \\geqslant \\epsilon / 2\\right) \\leqslant \\frac{4}{\\varepsilon^{2}} \\operatorname{Var}\\left(\\hat{\\theta}_{n}\\right) \\rightarrow 0(n \\rightarrow+\\infty)\n$$  \n定理得证.  \n例 6.2.2: 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(0,0)$ 的样本, 证明 $\\theta$ 的最大似然估计是相合估计.  \n证明: 在例6.1.7中我们已经给出 $\\theta$ 的最大似然估计是 $x_{(n)}$. 由次序统计量的分布, 我们知道 $\\hat{\\theta}=x_{(n)}$ 的分布密度函数为  \n$$\np(y)=n y^{n-1} / \\theta^{n}, \\quad y<\\theta\n$$  \n故有  \n$$\n\\begin{gathered}\nE \\hat{\\theta}=\\int_{0}^{\\theta} n y^{n} \\mathrm{~d} y / \\theta^{n}=\\frac{n}{n+1} \\theta \\rightarrow \\theta \\\\\nE \\hat{\\hat{\\theta}^{2}}=\\int_{0}^{\\theta} n y^{n+1} \\mathrm{~d} y / \\theta^{n}=\\frac{n}{n+2} \\theta^{2} \\\\\n\\operatorname{Var}(\\hat{\\theta})=\\frac{n}{n+2} \\theta^{2}-\\left(\\frac{n}{n+1} \\theta\\right)^{2}=\\frac{n}{(n+1)^{2}(n+2)} \\theta^{2} \\rightarrow 0 \\quad(n \\rightarrow+\\infty)\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np(y)=n y^{n-1} / \\theta^{n}, \\quad y<\\theta\n$$  \n故有  \n$$\n\\begin{gathered}\nE \\hat{\\theta}=\\int_{0}^{\\theta} n y^{n} \\mathrm{~d} y / \\theta^{n}=\\frac{n}{n+1} \\theta \\rightarrow \\theta \\\\\nE \\hat{\\hat{\\theta}^{2}}=\\int_{0}^{\\theta} n y^{n+1} \\mathrm{~d} y / \\theta^{n}=\\frac{n}{n+2} \\theta^{2} \\\\\n\\operatorname{Var}(\\hat{\\theta})=\\frac{n}{n+2} \\theta^{2}-\\left(\\frac{n}{n+1} \\theta\\right)^{2}=\\frac{n}{(n+1)^{2}(n+2)} \\theta^{2} \\rightarrow 0 \\quad(n \\rightarrow+\\infty)\n\\end{gathered}\n$$  \n由定理6.2.1可知, $x_{(n)}$ 是 $\\theta$ 的相合估计.  \n定理 6.2.2. 若 $\\hat{\\theta}_{n 1}, \\cdots, \\hat{\\theta}_{n k}$ 分别是 $\\theta_{1}, \\cdots, \\theta_{k}$ 的相合估计, $\\eta=g\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)$ 是 $\\theta_{1}, \\cdots, \\theta_{k}$ 的连续函数, 则 $\\bar{\\eta}_{n}=g\\left(\\hat{\\theta}_{n 1}, \\cdots, \\hat{\\theta}_{n k}\\right)$ 是 $\\eta$ 的相合估计.  \n证明: 由函数 $g$ 的连续性, 对任意给定的 $\\varepsilon>0$, 存在一个 $\\delta>0$, 当 $\\left|\\hat{\\theta}_{j}-\\theta_{j}\\right|<\\delta, j=1, \\cdots, k$, 有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由定理6.2.1可知, $x_{(n)}$ 是 $\\theta$ 的相合估计.  \n定理 6.2.2. 若 $\\hat{\\theta}_{n 1}, \\cdots, \\hat{\\theta}_{n k}$ 分别是 $\\theta_{1}, \\cdots, \\theta_{k}$ 的相合估计, $\\eta=g\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)$ 是 $\\theta_{1}, \\cdots, \\theta_{k}$ 的连续函数, 则 $\\bar{\\eta}_{n}=g\\left(\\hat{\\theta}_{n 1}, \\cdots, \\hat{\\theta}_{n k}\\right)$ 是 $\\eta$ 的相合估计.  \n证明: 由函数 $g$ 的连续性, 对任意给定的 $\\varepsilon>0$, 存在一个 $\\delta>0$, 当 $\\left|\\hat{\\theta}_{j}-\\theta_{j}\\right|<\\delta, j=1, \\cdots, k$, 有  \n$$\n\\begin{equation*}\n\\left|g\\left(\\hat{\\theta}_{1}, \\cdots, \\hat{\\theta}_{k}\\right)-g\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)\\right|<\\varepsilon \\tag{6.2.3}\n\\end{equation*}\n$$  \n又由 $\\hat{\\theta}_{n 1}, \\cdots, \\hat{\\theta}_{n k}$ 是的相合性, 对给定的 $\\delta$, 对任意给定的 $v>0$, 存在正整数 $N$, 使得 $n \\geqslant N$ 时,  \n$$\nP\\left(\\left|\\hat{\\theta}_{n j}-\\theta_{j}\\right| \\geqslant \\delta\\right)<v / k, \\quad j=1, \\cdots, k\n$$  \n从而有  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n\\left|g\\left(\\hat{\\theta}_{1}, \\cdots, \\hat{\\theta}_{k}\\right)-g\\left(\\theta_{1}, \\cdots, \\theta_{k}\\right)\\right|<\\varepsilon \\tag{6.2.3}\n\\end{equation*}\n$$  \n又由 $\\hat{\\theta}_{n 1}, \\cdots, \\hat{\\theta}_{n k}$ 是的相合性, 对给定的 $\\delta$, 对任意给定的 $v>0$, 存在正整数 $N$, 使得 $n \\geqslant N$ 时,  \n$$\nP\\left(\\left|\\hat{\\theta}_{n j}-\\theta_{j}\\right| \\geqslant \\delta\\right)<v / k, \\quad j=1, \\cdots, k\n$$  \n从而有  \n$$\n\\begin{aligned}\nP\\left(\\bigcap_{i=1}^{k}\\left\\{\\left|\\hat{\\theta}_{n j}-\\theta_{j}\\right|<\\delta\\right\\}\\right) & =1-P\\left(\\bigcup_{j=1}^{k}\\left\\{\\left|\\vec{\\theta}_{n j}-\\theta_{j}\\right| \\geqslant \\delta\\right\\}\\right) \\\\\n& \\geqslant 1-\\sum_{j=1}^{k} P\\left(\\left|\\hat{\\theta}_{n j}-\\theta_{j}\\right| \\geqslant \\delta\\right) \\\\\n& >1-k \\cdot v / k=1-v\n\\end{aligned}\n$$  \n根据(6.2.3), $\\bigcap_{j=1}^{k}\\left\\{\\left|\\hat{\\theta}_{n j}-\\theta_{j}\\right|<\\delta\\right\\} \\subset\\left\\{\\left|\\hat{\\eta}_{n}-\\eta\\right|<\\varepsilon\\right\\}$ 故有  \n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "& \\geqslant 1-\\sum_{j=1}^{k} P\\left(\\left|\\hat{\\theta}_{n j}-\\theta_{j}\\right| \\geqslant \\delta\\right) \\\\\n& >1-k \\cdot v / k=1-v\n\\end{aligned}\n$$  \n根据(6.2.3), $\\bigcap_{j=1}^{k}\\left\\{\\left|\\hat{\\theta}_{n j}-\\theta_{j}\\right|<\\delta\\right\\} \\subset\\left\\{\\left|\\hat{\\eta}_{n}-\\eta\\right|<\\varepsilon\\right\\}$ 故有  \n$$\nP\\left(\\left|\\hat{\\eta}_{n}-\\eta\\right|<\\epsilon\\right)>1-v\n$$  \n由 $\\mathrm{v}$ 的任意性,定理得证.  \n由大数定律及定理6.2.2, 我们可以看到, 矩估计一般都具有相合性. 比如:  \n- 样本均值是总体均值的相合估计;\n- 样本标准差是总体标准差的相合估计;\n- 样本变异系数 $s / \\bar{x}$ 是总体变异系数的相合估计.  \n例 6.2.3: 设一个试验有三种可能结果, 其发生概率分别为  \n$$\np_{1}=\\theta^{2}, \\quad p_{2}=2 \\theta(1-\\theta), p_{3}=(1-\\theta)^{2}\n$$  \n现做了 $n$ 次试验, 观测到三种结果发生的次数分别为 $n_{1}, n_{2}, n_{3}$ 可以采用频率替换方法估计 $\\theta$. 由于可以有三个不同的日的表达式:  \n$$\n\\theta=\\sqrt{p_{1}}, \\quad \\theta=1-\\sqrt{p_{3}}, \\quad \\theta=p_{1}+p_{2} / 2\n$$  \n从而可以给出 $\\theta$ 三种不同的频率替换估计,它们分别是:  \n$$\n\\hat{\\theta}_{1}=\\sqrt{n_{1} / n}, \\quad \\hat{\\theta}_{2}=1-\\sqrt{n_{3} / n}, \\quad \\hat{\\theta}_{3}=\\left(n_{1}+n_{2} / 2\\right) / n",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "例 6.2.3: 设一个试验有三种可能结果, 其发生概率分别为  \n$$\np_{1}=\\theta^{2}, \\quad p_{2}=2 \\theta(1-\\theta), p_{3}=(1-\\theta)^{2}\n$$  \n现做了 $n$ 次试验, 观测到三种结果发生的次数分别为 $n_{1}, n_{2}, n_{3}$ 可以采用频率替换方法估计 $\\theta$. 由于可以有三个不同的日的表达式:  \n$$\n\\theta=\\sqrt{p_{1}}, \\quad \\theta=1-\\sqrt{p_{3}}, \\quad \\theta=p_{1}+p_{2} / 2\n$$  \n从而可以给出 $\\theta$ 三种不同的频率替换估计,它们分别是:  \n$$\n\\hat{\\theta}_{1}=\\sqrt{n_{1} / n}, \\quad \\hat{\\theta}_{2}=1-\\sqrt{n_{3} / n}, \\quad \\hat{\\theta}_{3}=\\left(n_{1}+n_{2} / 2\\right) / n\n$$  \n由大数定律, $n_{1} / n, n_{2} / n, n_{3} / n$ 分别是 $p_{1}, p_{2}, p_{3}$ 的相合估计, 由定理6.2.2知, 上述三个估计都是 $\\theta$的相合估计.",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.1 相关性"
        },
        "type": "Document"
    },
    {
        "page_content": "相合性是大样本下估计量的评价标准, 对小样本而言, 需要一些其他的评价标准, 无偏性便是一个常用的评价标准.  \n定义 6.2.2. 设 $\\hat{\\theta}_{n}=\\hat{\\theta}_{n}\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的一个估计, $\\theta$ 的参数空间为 $\\Theta$, 若对任意的 $\\theta \\in \\Theta$, 有  \n$$\n\\begin{equation*}\nE(\\hat{\\theta})=\\theta \\tag{6.2.4}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}$ 是 $\\theta$ 的无偏估计, 否则称为有偏估计.  \n无偏性要求可以改写为 $E(\\hat{\\theta}-\\theta)=0$, 这表示无偏估计没有系统偏差, 当我们使用 $\\hat{\\theta}$ 估计 $\\theta$时, 由于样本的随机性, $\\hat{\\theta}$ 与 $\\theta$ 总是有偏差的, 这种偏差时而 (对某些样本观测值) 为正, 时而 (对另一些样本观测值) 为负, 时而大, 时而小. 无偏性表示, 把这些偏差平均起来其值为 0 , 这就是无偏估计的含义. 而若估计不具有无偏性, 则无论使用多少次, 其平均也会与参数真值有一定的距离,这个距离就是系统误差.  \n例 6.2.4: 对任一总体而言, 样本均值是总体均值的无偏估计. 当总体 $k$ 阶矩存在时, 样本 $k$ 阶原点矩 $a_{k}$ 是总体息 $k$ 阶原点矩 $\\mu_{k}$ 么的无偏估计. 但对 $k$ 阶中心矩则不一样, 譬如, 样本方差 $s^{* 2}$ 就不是总体方差 $\\sigma^{2}$ 的无偏估计, 因在定理5.2.1 中已经指出:  \n对此, 有如下两点说明:  \n$$\nE\\left(s^{* 2}\\right)=\\frac{n-1}{n} \\sigma^{2}\n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.2 无偏性"
        },
        "type": "Document"
    },
    {
        "page_content": "例 6.2.4: 对任一总体而言, 样本均值是总体均值的无偏估计. 当总体 $k$ 阶矩存在时, 样本 $k$ 阶原点矩 $a_{k}$ 是总体息 $k$ 阶原点矩 $\\mu_{k}$ 么的无偏估计. 但对 $k$ 阶中心矩则不一样, 譬如, 样本方差 $s^{* 2}$ 就不是总体方差 $\\sigma^{2}$ 的无偏估计, 因在定理5.2.1 中已经指出:  \n对此, 有如下两点说明:  \n$$\nE\\left(s^{* 2}\\right)=\\frac{n-1}{n} \\sigma^{2}\n$$  \n1. 当样本量趋于无穷时, 有 $E\\left(s^{* 2}\\right) \\rightarrow \\sigma^{2}$, 我们称 $s^{* 2}$ 为 $\\sigma^{2}$ 的渐近无偏估计, 这表明当样本量较大时, $s^{* 2}$ 可近似看作 $\\sigma^{2}$ 的无偏估计.\n2. 若对 $s^{* 2}$ 作如下修正:  \n$$\n\\begin{equation*}\ns^{2}=\\frac{n s^{* 2}}{n-1}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2} \\tag{6.2.5}\n\\end{equation*}\n$$  \n则 $s^{2}$ 是总体方差的无偏估计. 这种简单的修正方法在一些场合常被采用.(6.2.5)定义的 $s^{2}$ 也称为样本方差, 它比 $s^{* 2}$ 更常用. 这是因为在 $n \\geqslant 2$ 时, $s^{* 2}<s^{2}$, 因此用 $s^{* 2}$ 估计 $\\sigma^{2}$ 有偏小的倾向, 特别在小样本场合要使用 $s^{2}$ 估计 $\\sigma^{2}$.  \n无偏性不具有不变性. 即若 $\\hat{\\theta}$ 是 $\\theta$ 的无偏估计,一般而言, $g(\\hat{\\theta})$ 不是 $g(\\theta)$ 的无偏估计, 除非 $g(\\theta)$ 是 $\\theta$ 的线性函数. 譬如, $s^{2}$ 是 $\\sigma^{2}$ 的无偏估计, 但 $s$ 不是 $\\sigma$ 的无偏估计. 下而我们以正态分布为例加以说明.",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.2 无偏性"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n则 $s^{2}$ 是总体方差的无偏估计. 这种简单的修正方法在一些场合常被采用.(6.2.5)定义的 $s^{2}$ 也称为样本方差, 它比 $s^{* 2}$ 更常用. 这是因为在 $n \\geqslant 2$ 时, $s^{* 2}<s^{2}$, 因此用 $s^{* 2}$ 估计 $\\sigma^{2}$ 有偏小的倾向, 特别在小样本场合要使用 $s^{2}$ 估计 $\\sigma^{2}$.  \n无偏性不具有不变性. 即若 $\\hat{\\theta}$ 是 $\\theta$ 的无偏估计,一般而言, $g(\\hat{\\theta})$ 不是 $g(\\theta)$ 的无偏估计, 除非 $g(\\theta)$ 是 $\\theta$ 的线性函数. 譬如, $s^{2}$ 是 $\\sigma^{2}$ 的无偏估计, 但 $s$ 不是 $\\sigma$ 的无偏估计. 下而我们以正态分布为例加以说明.  \n例 6.2.5: 设总体为 $N\\left(\\mu, \\sigma^{2}\\right), x_{1}, \\cdots, x_{n}$ 是样本, 我们已经指出 $s^{2}$ 是 $\\sigma^{2}$ 的无偏估计. 由定理5.3.1, $Y=\\frac{(n-1) s^{2}}{\\sigma^{2}} \\sim \\chi^{2}(n-1)$, 其密度函数为  \n$$\np(y)=\\frac{1}{2^{\\frac{n-1}{2}} \\Gamma\\left(\\frac{n-1}{2}\\right)} y^{\\frac{n-1}{2}} \\mathrm{e}^{-\\frac{y}{2}}, \\quad y>0\n$$  \n从而  \n$$\n\\begin{aligned}\nE\\left(Y^{1 / 2}\\right) & =\\int_{0}^{+\\infty} y^{1 / 2} p(y) \\mathrm{d} y \\\\\n& =\\frac{1}{2^{\\frac{n-1}{2}} \\Gamma\\left(\\frac{n-1}{2}\\right)} \\int_{0}^{\\infty} y^{\\frac{n}{2}-1} \\mathrm{e}^{-\\frac{y}{2}} \\mathrm{~d} y \\\\",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.2 无偏性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np(y)=\\frac{1}{2^{\\frac{n-1}{2}} \\Gamma\\left(\\frac{n-1}{2}\\right)} y^{\\frac{n-1}{2}} \\mathrm{e}^{-\\frac{y}{2}}, \\quad y>0\n$$  \n从而  \n$$\n\\begin{aligned}\nE\\left(Y^{1 / 2}\\right) & =\\int_{0}^{+\\infty} y^{1 / 2} p(y) \\mathrm{d} y \\\\\n& =\\frac{1}{2^{\\frac{n-1}{2}} \\Gamma\\left(\\frac{n-1}{2}\\right)} \\int_{0}^{\\infty} y^{\\frac{n}{2}-1} \\mathrm{e}^{-\\frac{y}{2}} \\mathrm{~d} y \\\\\n& =\\frac{2^{\\frac{n}{2}} \\Gamma\\left(\\frac{n}{2}\\right)}{2^{\\frac{n-1}{2}} \\Gamma\\left(\\frac{n-1}{2}\\right)}=\\sqrt{2} \\frac{\\Gamma\\left(\\frac{n}{2}\\right)}{\\Gamma\\left(\\frac{n-1}{2}\\right)}\n\\end{aligned}\n$$  \n由此, 我们有  \n$$\nE s=\\frac{\\sigma}{\\sqrt{n-1}} E\\left(Y^{1 / 2}\\right)=\\sqrt{\\frac{2}{n-1}} \\cdot \\frac{\\Gamma(n / 2)}{\\Gamma((n-1) / 2)} \\cdot \\sigma \\equiv \\frac{\\sigma}{c_{n}}\n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.2 无偏性"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{2^{\\frac{n}{2}} \\Gamma\\left(\\frac{n}{2}\\right)}{2^{\\frac{n-1}{2}} \\Gamma\\left(\\frac{n-1}{2}\\right)}=\\sqrt{2} \\frac{\\Gamma\\left(\\frac{n}{2}\\right)}{\\Gamma\\left(\\frac{n-1}{2}\\right)}\n\\end{aligned}\n$$  \n由此, 我们有  \n$$\nE s=\\frac{\\sigma}{\\sqrt{n-1}} E\\left(Y^{1 / 2}\\right)=\\sqrt{\\frac{2}{n-1}} \\cdot \\frac{\\Gamma(n / 2)}{\\Gamma((n-1) / 2)} \\cdot \\sigma \\equiv \\frac{\\sigma}{c_{n}}\n$$  \n这说明 $s$ 不是 $\\sigma$ 的无偏估计, 利用修正技术可得 $c_{n} \\cdot s$ 是 $\\sigma$ 的无偏估计, 其中 $c_{n}=\\sqrt{\\frac{n-1}{2}} \\cdot \\frac{\\Gamma((n-1) / 2)}{\\Gamma(n / 2)}$是修偏系数, 表 6.2.1 给出了 $c_{n}$ 的部分取值. 可以证明, 当 $n \\rightarrow+\\infty$ 时有 $c_{n} \\rightarrow 1$, 这说明 $s$ 是 $\\sigma$ 的渐近无偏估计, 从而在样本容量较大时, 不经修正的 $s$ 也是 $\\sigma$ 的一个很好的估计.  \n表 6.2.1: 正态标准差的修信系数表  \n| $n$ | $c_{n}$ | $n$ | $c_{n}$ | $n$ | $c_{n}$ | $n$ | $c_{n}$ | $n$ | $c_{n}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n|  |  | 7 | 1.0424 | 13 | 1.0210 | 19 | 1.0140 | 25 | 1.0105 |",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.2 无偏性"
        },
        "type": "Document"
    },
    {
        "page_content": "表 6.2.1: 正态标准差的修信系数表  \n| $n$ | $c_{n}$ | $n$ | $c_{n}$ | $n$ | $c_{n}$ | $n$ | $c_{n}$ | $n$ | $c_{n}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n|  |  | 7 | 1.0424 | 13 | 1.0210 | 19 | 1.0140 | 25 | 1.0105 |\n| 2 | 1.2533 | 8 | 1.0362 | 14 | 1.0194 | 20 | 1.0132 | 26 | 1.0100 |\n| 3 | 1.1284 | 9 | 1.0317 | 15 | 1.0180 | 21 | 1.0126 | 27 | 1.0097 |\n| 4 | 1.0854 | 10 | 1.0281 | 16 | 1.0168 | 22 | 1.0120 | 28 | 1.0093 |\n| 5 | 1.0638 | 11 | 1.0253 | 17 | 1.0157 | 23 | 1.0114 | 29 | 1.0090 |\n| 6 | 1.0509 | 12 | 1.0230 | 18 | 1.0148 | 24 | 1.0109 | 30 | 1.0087 |",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.2 无偏性"
        },
        "type": "Document"
    },
    {
        "page_content": "参数的无偏估计可以有很多, 如何在无偏估计中进行选择? 直观的想法是希望该估计围绕参数真值的波动越小越好, 波动大小可以用方差来衡量, 因此人们常用无偏估计的方差的大小作为度量无偏估计优劣的标准,这就是有效性.  \n定义 6.2.3. 设 $\\hat{\\theta}_{1}, \\hat{\\theta}_{2}$ 是 $\\theta$ 的两个无偏估计, 如果对任意的 $\\theta \\in \\Theta$ 有  \n$$\n\\operatorname{Var}\\left(\\hat{\\theta}_{1}\\right) \\leqslant \\operatorname{Var}\\left(\\hat{\\theta}_{2}\\right)\n$$  \n且至少有一个 $\\theta \\in \\Theta$ 使得上述不等号严格成立, 则称 $\\hat{\\theta}_{1}$ 比 $\\hat{\\theta}_{2}$ 有效.  \n例 6.2.6: 设 $x_{1}, \\cdots, x_{n}$ 是取自某总体的样本, 记总体均值为 $\\mu$, 总体方差为 $\\sigma^{2}$, 则 $\\hat{\\mu}_{1}=x_{1}, \\hat{\\mu}_{2}=\\bar{x}$都是 $\\mu$ 的无偏估计,但  \n$$\n\\operatorname{Var}\\left(\\hat{\\mu}_{1}\\right)=\\sigma^{2}, \\quad \\operatorname{Var}\\left(\\hat{\\mu}_{2}\\right)=\\sigma^{2} / n\n$$  \n显然, 只要 $n>1, \\hat{\\mu}_{2}$ 比 $\\hat{\\mu}_{1}$ 有效. 这表明, 用全部数据的平均估计总体均值要比只使用部分数据更有效.",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.3 有效性"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n且至少有一个 $\\theta \\in \\Theta$ 使得上述不等号严格成立, 则称 $\\hat{\\theta}_{1}$ 比 $\\hat{\\theta}_{2}$ 有效.  \n例 6.2.6: 设 $x_{1}, \\cdots, x_{n}$ 是取自某总体的样本, 记总体均值为 $\\mu$, 总体方差为 $\\sigma^{2}$, 则 $\\hat{\\mu}_{1}=x_{1}, \\hat{\\mu}_{2}=\\bar{x}$都是 $\\mu$ 的无偏估计,但  \n$$\n\\operatorname{Var}\\left(\\hat{\\mu}_{1}\\right)=\\sigma^{2}, \\quad \\operatorname{Var}\\left(\\hat{\\mu}_{2}\\right)=\\sigma^{2} / n\n$$  \n显然, 只要 $n>1, \\hat{\\mu}_{2}$ 比 $\\hat{\\mu}_{1}$ 有效. 这表明, 用全部数据的平均估计总体均值要比只使用部分数据更有效.  \n例 6.2.7: 在例 6.2.2 中, 我们指出均匀总体 $U(0, \\theta)$ 中日的极大似然估计是 $x_{(n)}$, 由于 $E x_{(n)}=$ $\\frac{n}{n+1} \\theta$, 所以 $x_{(n)}$ 不是 $\\theta$ 的无偏估计, 但是 $\\theta$ 的渐近无偏估计. 经过修偏后可以得到 $\\theta$ 的一个无偏估计: $\\hat{\\theta}_{1}=\\frac{n+1}{n} x_{(n)}$. 且  \n$$\n\\begin{aligned}\n\\operatorname{Var}\\left(\\hat{\\theta}_{1}\\right) & =\\left(\\frac{n+1}{n}\\right)^{2} \\operatorname{Var}\\left(x_{(n)}\\right) \\\\\n& =\\left(\\frac{n+1}{n}\\right)^{2} \\frac{n}{(n+1)^{2}(n+2)} \\theta^{2}=\\frac{\\theta^{2}}{n(n+2)} .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.3 有效性"
        },
        "type": "Document"
    },
    {
        "page_content": "例 6.2.7: 在例 6.2.2 中, 我们指出均匀总体 $U(0, \\theta)$ 中日的极大似然估计是 $x_{(n)}$, 由于 $E x_{(n)}=$ $\\frac{n}{n+1} \\theta$, 所以 $x_{(n)}$ 不是 $\\theta$ 的无偏估计, 但是 $\\theta$ 的渐近无偏估计. 经过修偏后可以得到 $\\theta$ 的一个无偏估计: $\\hat{\\theta}_{1}=\\frac{n+1}{n} x_{(n)}$. 且  \n$$\n\\begin{aligned}\n\\operatorname{Var}\\left(\\hat{\\theta}_{1}\\right) & =\\left(\\frac{n+1}{n}\\right)^{2} \\operatorname{Var}\\left(x_{(n)}\\right) \\\\\n& =\\left(\\frac{n+1}{n}\\right)^{2} \\frac{n}{(n+1)^{2}(n+2)} \\theta^{2}=\\frac{\\theta^{2}}{n(n+2)} .\n\\end{aligned}\n$$  \n另一方面, 由矩法, 我们可以得到 $\\theta$ 的另一个无偏估计 $\\hat{\\theta}_{2}=2 \\bar{x}$, 且  \n$$\n\\operatorname{Var}\\left(\\hat{\\theta}_{2}\\right)=4 \\operatorname{Var}(\\bar{x})=\\frac{4}{n} \\operatorname{Var}(X)=\\frac{4}{n} \\cdot \\frac{\\theta^{2}}{12}=\\frac{\\theta^{2}}{3 n}\n$$  \n由此, 当 $n>1$ 时, $\\hat{\\theta}_{1}$ 比 $\\hat{\\theta}_{2}$ 有效.",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.3 有效性"
        },
        "type": "Document"
    },
    {
        "page_content": "无偏性是估计的一个优良性质, 对无偏估计我们还可以通过其方差进行有效性比较. 然而不能由此认为:有偏估计一定是不好的估计.  \n在有些场合, 有偏估计比无偏估计更优, 这就涉及如何对有偏估计进行评价. 一般而言, 在样本量一定时, 评价一个点估计的好坏使用的度最指标总是点估计值与参数真值 8 的距离的函数,\n最常用的函数是距离的平方. 由于具有随机性, 可以对该函数求期望, 这就是下式给出的均方误差  \n$$\n\\begin{equation*}\n\\operatorname{MSE}(\\hat{\\theta})=E(\\hat{\\theta}-\\theta)^{2} \\tag{6.2.6}\n\\end{equation*}\n$$  \n均方误差是评价点估计的最一般的标准. 自然, 我们希望估计的均方误差越小越好.  \n注意到  \n$$\n\\begin{aligned}\n\\operatorname{MSE}(\\hat{\\theta}) & =\\left[E(\\hat{\\theta}-E \\hat{\\theta})+(E \\hat{\\theta}-\\theta)^{2}\\right] \\\\\n& =E(\\hat{\\theta}-E \\hat{\\theta})^{2}+(E \\hat{\\theta}-\\theta)^{2}+2 E[(\\hat{\\theta}-E \\hat{\\theta})(E \\hat{\\theta}-\\theta)] \\\\\n& =\\operatorname{Var}(\\hat{\\theta})+(E \\hat{\\theta}-\\theta)^{2}\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.4 均方误差"
        },
        "type": "Document"
    },
    {
        "page_content": "\\begin{equation*}\n\\operatorname{MSE}(\\hat{\\theta})=E(\\hat{\\theta}-\\theta)^{2} \\tag{6.2.6}\n\\end{equation*}\n$$  \n均方误差是评价点估计的最一般的标准. 自然, 我们希望估计的均方误差越小越好.  \n注意到  \n$$\n\\begin{aligned}\n\\operatorname{MSE}(\\hat{\\theta}) & =\\left[E(\\hat{\\theta}-E \\hat{\\theta})+(E \\hat{\\theta}-\\theta)^{2}\\right] \\\\\n& =E(\\hat{\\theta}-E \\hat{\\theta})^{2}+(E \\hat{\\theta}-\\theta)^{2}+2 E[(\\hat{\\theta}-E \\hat{\\theta})(E \\hat{\\theta}-\\theta)] \\\\\n& =\\operatorname{Var}(\\hat{\\theta})+(E \\hat{\\theta}-\\theta)^{2}\n\\end{aligned}\n$$  \n因此, 均方误差由点估计的方差与偏差的平方两部分组成. 如果 $\\hat{\\theta}$ 是 $\\theta$ 的无偏估计, 则 $\\operatorname{MSE}(\\hat{\\theta})=$ $\\operatorname{Var}(\\hat{\\theta})$, 此时用均方误差评价点估计与用方差是完全一样的, 这也说明了用方差考察无偏估计有效性是合理的. 当 $\\hat{\\theta}$ 不是 $\\theta$ 的无偏估计时, 就要看其均方误差 $\\operatorname{MSE}(\\hat{\\theta})$, 即不仅要看其方差大小, 还要看其偏差大小. 下面的例子说明在均方误差的含义下有些有偏估计优于无偏估计.  \n例 6.2.8: 在例 6.2.7 中我们指出对均匀总体 $U(0, \\theta)$, 由 $\\theta$ 的最大似然估计得到的无偏估计是 $\\hat{\\theta}=(n+1) x_{(n)} / n$, 它的均方误差  \n$$",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.4 均方误差"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n因此, 均方误差由点估计的方差与偏差的平方两部分组成. 如果 $\\hat{\\theta}$ 是 $\\theta$ 的无偏估计, 则 $\\operatorname{MSE}(\\hat{\\theta})=$ $\\operatorname{Var}(\\hat{\\theta})$, 此时用均方误差评价点估计与用方差是完全一样的, 这也说明了用方差考察无偏估计有效性是合理的. 当 $\\hat{\\theta}$ 不是 $\\theta$ 的无偏估计时, 就要看其均方误差 $\\operatorname{MSE}(\\hat{\\theta})$, 即不仅要看其方差大小, 还要看其偏差大小. 下面的例子说明在均方误差的含义下有些有偏估计优于无偏估计.  \n例 6.2.8: 在例 6.2.7 中我们指出对均匀总体 $U(0, \\theta)$, 由 $\\theta$ 的最大似然估计得到的无偏估计是 $\\hat{\\theta}=(n+1) x_{(n)} / n$, 它的均方误差  \n$$\n\\operatorname{MSE}(\\hat{\\theta})=\\operatorname{Var}(\\hat{\\theta})=\\frac{\\theta^{2}}{n(n+2)}\n$$  \n现在我们考虑 $\\theta$ 的形如 $\\hat{\\theta}_{\\alpha}=\\alpha \\cdot x_{(n)}$ 的估计,其均方误差为  \n$$\n\\begin{aligned}\n\\operatorname{MSE}\\left(\\hat{\\theta}_{\\alpha}\\right) & =\\operatorname{Var}\\left(\\alpha \\cdot x_{(n)}\\right)+\\left(\\alpha E x_{(n)}-\\theta\\right)^{2} \\\\\n& =\\alpha^{2} \\operatorname{Var}\\left(x_{(n)}\\right)+\\left(\\alpha \\frac{n}{n+1} \\theta-\\theta\\right)^{2} \\\\",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.4 均方误差"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\operatorname{MSE}(\\hat{\\theta})=\\operatorname{Var}(\\hat{\\theta})=\\frac{\\theta^{2}}{n(n+2)}\n$$  \n现在我们考虑 $\\theta$ 的形如 $\\hat{\\theta}_{\\alpha}=\\alpha \\cdot x_{(n)}$ 的估计,其均方误差为  \n$$\n\\begin{aligned}\n\\operatorname{MSE}\\left(\\hat{\\theta}_{\\alpha}\\right) & =\\operatorname{Var}\\left(\\alpha \\cdot x_{(n)}\\right)+\\left(\\alpha E x_{(n)}-\\theta\\right)^{2} \\\\\n& =\\alpha^{2} \\operatorname{Var}\\left(x_{(n)}\\right)+\\left(\\alpha \\frac{n}{n+1} \\theta-\\theta\\right)^{2} \\\\\n& =\\alpha^{2} \\frac{n}{(n+1)^{2}(n+2)}+\\left(\\frac{n \\cdot \\alpha}{n+1}-1\\right)^{2} \\theta^{2}\n\\end{aligned}\n$$  \n用求导的方法不难求出当 $\\alpha_{0}=(n+2) /(n+1)$ 时上述均方误差达到最小, 且 $\\operatorname{MSE}\\left(\\frac{n+2}{n+1} x_{(n)}\\right)=$ $\\frac{\\theta^{2}}{(n+1)^{2}}$, 这表明, $\\hat{\\theta}_{0}=\\frac{n+2}{n+1} x_{(n)}$ 虽是 $\\theta$ 的有偏估计, 但其均方误差 $\\operatorname{MSE}\\left(\\hat{\\theta}_{0}\\right)=\\frac{\\theta^{2}}{(n+1)^{2}}<\\frac{\\theta^{2}}{n(n+2)}=$ $\\operatorname{MSE}(\\hat{\\theta})$. 所以在均方误差的标准下, 有偏估计 $\\hat{\\theta}_{0}$ 优于无偏估计 $\\hat{\\theta}$.",
        "metadata": {
            "Header 2": "6.2 点估计的评价标准",
            "Header 3": "6.2.4 均方误差"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 总体 $X \\sim U(\\theta, 2 \\theta)$, 其中 $\\theta>0$ 是未知参数, 又 $x_{1}, \\cdots, x_{n}$ 为曲子改总体的样本, $\\bar{x}$ 为样本均值.  \n(1) 证明 $\\hat{\\theta}=\\frac{2}{3} \\bar{x}$ 是参数 $\\theta$ 的无偏估计和相合估计.  \n(2) 求 $\\theta$ 的最大似然估计, 它是无偏估计吗? 是相合估计吗?  \n2. 设 $x_{1}, x_{2}, x_{3}$ 是取自某总体容量为 3 的样本, 试证下列统计量都是该总体均值 $\\mu$ 的无偏估计,在方差存在时指出哪一个估计的有效性最差?  \n(1) $\\hat{\\mu}_{1}=\\frac{1}{2} x_{1}+\\frac{1}{3} x_{2}+\\frac{1}{6} x_{3}$,  \n(2) $\\hat{\\mu}_{2}=\\frac{1}{3} x_{1}+\\frac{1}{3} x_{2}+\\frac{1}{3} x_{3}$,  \n(3) $\\hat{\\mu}_{3}=\\frac{1}{6} x_{1}+\\frac{1}{6} x_{2}+\\frac{2}{3} x_{3}$.  \n3. 设 $\\hat{\\theta}$ 是参数 $\\theta$ 的无偏估计, 且有 $\\operatorname{Var}(\\hat{\\theta})>0$, 试证 $(\\hat{\\theta})^{2}$ 不是 $\\theta^{2}$ 的无偏估计.\n4. 设总体 $X \\sim N\\left(\\mu, \\sigma^{2}\\right), x_{1}, \\cdots, x_{n}$ 是来自该总体的一个样本. 试确定常数 $c$ 使 $c \\sum_{i=1}^{n-1}\\left(x_{i+1}-\\right.$ $\\left.x_{i}\\right)^{2}$ 为 $\\sigma^{2}$ 的无偏估计.",
        "metadata": {
            "Header 2": "好题 6.2"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) $\\hat{\\mu}_{2}=\\frac{1}{3} x_{1}+\\frac{1}{3} x_{2}+\\frac{1}{3} x_{3}$,  \n(3) $\\hat{\\mu}_{3}=\\frac{1}{6} x_{1}+\\frac{1}{6} x_{2}+\\frac{2}{3} x_{3}$.  \n3. 设 $\\hat{\\theta}$ 是参数 $\\theta$ 的无偏估计, 且有 $\\operatorname{Var}(\\hat{\\theta})>0$, 试证 $(\\hat{\\theta})^{2}$ 不是 $\\theta^{2}$ 的无偏估计.\n4. 设总体 $X \\sim N\\left(\\mu, \\sigma^{2}\\right), x_{1}, \\cdots, x_{n}$ 是来自该总体的一个样本. 试确定常数 $c$ 使 $c \\sum_{i=1}^{n-1}\\left(x_{i+1}-\\right.$ $\\left.x_{i}\\right)^{2}$ 为 $\\sigma^{2}$ 的无偏估计.\n5. 设从均值为 $\\mu$, 方差为 $\\sigma^{2}>2$ 的总体中, 分别抽取容量为 $n_{1}$ 和 $n_{2}$ 的两独立样本 $\\bar{x}_{1}$ 和 $\\bar{x}_{2}$ 分别是这两个样本的均值, 试证, 对于任意常数 $a, b(a+b=1), Y=a \\bar{x}_{1}+b \\bar{x}_{2}$ 都是 $\\mu$ 的无偏估计, 并确定常数 $a, b$ 使 $\\operatorname{Var}(Y)$ 达到最小.\n6. 设分别自总体 $N\\left(\\mu_{1}, \\sigma^{2}\\right)$ 和 $N\\left(\\mu_{2}, \\sigma^{2}\\right)$ 中抽取容量为 $n_{1}$ 和 $n_{2}$ 的两独立样本, 其样本方差分别为 $s_{1}^{2}, s_{2}^{2}$. 试证, 对于任意常数 $a, b(a+b=1), Z=a s_{1}^{2}+b s_{2}^{2}$ 都是 $\\sigma^{2}$ 的无偏估计, 并确定常数 $a, b$ 使 $\\operatorname{Var}(Z)$ 达到最小.",
        "metadata": {
            "Header 2": "好题 6.2"
        },
        "type": "Document"
    },
    {
        "page_content": "6. 设分别自总体 $N\\left(\\mu_{1}, \\sigma^{2}\\right)$ 和 $N\\left(\\mu_{2}, \\sigma^{2}\\right)$ 中抽取容量为 $n_{1}$ 和 $n_{2}$ 的两独立样本, 其样本方差分别为 $s_{1}^{2}, s_{2}^{2}$. 试证, 对于任意常数 $a, b(a+b=1), Z=a s_{1}^{2}+b s_{2}^{2}$ 都是 $\\sigma^{2}$ 的无偏估计, 并确定常数 $a, b$ 使 $\\operatorname{Var}(Z)$ 达到最小.\n7. 设有 $k$ 台仪器, 已知用第 $i$ 台仪器测量时, 测定值总体的标准差为 $\\sigma_{i}(i=1, \\cdots, k)$. 用这些仪器独立地对某一物理量日各观家一次, 分别得到 $x_{1}, \\cdots, x_{k}$, 设仪器都没有系统误差. 问 $a_{1}, \\cdots, a_{k}$ 应取何值, 方能使 $\\hat{\\theta}=\\sum_{i=1}^{k} a_{i} x_{i}$ 成为 $\\theta$ 的无偏估计,且方差达到最小?\n8. 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(\\theta, \\theta+1)$ 的一个样本,  \n(1) 验证 $\\hat{\\theta}_{1}=\\bar{x}-\\frac{1}{2}, \\hat{\\theta}_{2}=x_{(1)}-\\frac{1}{n+1}, \\hat{\\theta}_{3}=x_{(n)}-\\frac{n}{n+1}$ 都是 $\\theta$ 的无偏估计;  \n(2) 比较上述三个估计的有效性.  \n9. 设样本 $x_{1}, \\cdots, x_{n_{1}}$ 来着一个正态总体 $N\\left(\\mu_{1}, 1\\right)$, 样本 $y_{1}, \\cdots, y_{n_{2}}$ 来自另一个正态总体 $N\\left(\\mu_{2}, 4\\right)$,且两个样本独立.  \n(1) 求 $\\mu=\\mu_{1}-\\mu_{2}$ 的矩估计 $\\hat{\\mu}$;",
        "metadata": {
            "Header 2": "好题 6.2"
        },
        "type": "Document"
    },
    {
        "page_content": "8. 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(\\theta, \\theta+1)$ 的一个样本,  \n(1) 验证 $\\hat{\\theta}_{1}=\\bar{x}-\\frac{1}{2}, \\hat{\\theta}_{2}=x_{(1)}-\\frac{1}{n+1}, \\hat{\\theta}_{3}=x_{(n)}-\\frac{n}{n+1}$ 都是 $\\theta$ 的无偏估计;  \n(2) 比较上述三个估计的有效性.  \n9. 设样本 $x_{1}, \\cdots, x_{n_{1}}$ 来着一个正态总体 $N\\left(\\mu_{1}, 1\\right)$, 样本 $y_{1}, \\cdots, y_{n_{2}}$ 来自另一个正态总体 $N\\left(\\mu_{2}, 4\\right)$,且两个样本独立.  \n(1) 求 $\\mu=\\mu_{1}-\\mu_{2}$ 的矩估计 $\\hat{\\mu}$;  \n(2) 如果 $n=n_{1}+n_{2}$ 固定,试问如何分配 $n_{1}$ 和 $n_{2}$ 才能使得 $\\mathrm{i}$ 的方差达到最小.  \n10. 设总体 $X \\sim \\operatorname{Exp}(1 / \\theta), x_{1}, \\cdots, x_{n}$ 是样本, 试证 $\\bar{x}$ 和 $n x_{(1)}$ 都是 $\\theta$ 的无偏估计量, 并比较其有效性.\n11. 设总体为 $X \\sim P(\\lambda), x_{1}, \\cdots, x_{n}$ 为样本, 试求 $\\lambda^{2}$ 的无偏估计.\n12. 设总体为 $X \\sim U(\\theta-1 / 2, \\theta+1 / 2), x_{1}, \\cdots, x_{n}$ 为样本, 证明样本均值互和样本中程 $\\frac{1}{2}\\left(x_{(1)}+x_{(n)}\\right)$都是 $\\theta$ 的无偏估计,并比较它们的有效性.\n13. 设 $x_{1}, \\cdots, x_{n}$ 是来自正态总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 的一个样本,对 $\\sigma^{2}$ 考虑如下三个估计  \n$$",
        "metadata": {
            "Header 2": "好题 6.2"
        },
        "type": "Document"
    },
    {
        "page_content": "10. 设总体 $X \\sim \\operatorname{Exp}(1 / \\theta), x_{1}, \\cdots, x_{n}$ 是样本, 试证 $\\bar{x}$ 和 $n x_{(1)}$ 都是 $\\theta$ 的无偏估计量, 并比较其有效性.\n11. 设总体为 $X \\sim P(\\lambda), x_{1}, \\cdots, x_{n}$ 为样本, 试求 $\\lambda^{2}$ 的无偏估计.\n12. 设总体为 $X \\sim U(\\theta-1 / 2, \\theta+1 / 2), x_{1}, \\cdots, x_{n}$ 为样本, 证明样本均值互和样本中程 $\\frac{1}{2}\\left(x_{(1)}+x_{(n)}\\right)$都是 $\\theta$ 的无偏估计,并比较它们的有效性.\n13. 设 $x_{1}, \\cdots, x_{n}$ 是来自正态总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 的一个样本,对 $\\sigma^{2}$ 考虑如下三个估计  \n$$\n\\hat{\\sigma_{1}^{2}}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}, \\hat{\\sigma_{2}^{2}}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}, \\hat{\\sigma_{3}^{2}}=\\frac{1}{n+1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}, \\hat{\\sigma_{2}^{2}}\n$$  \n(1) 哪一个是 $\\sigma^{2}$ 的无偏估计?  \n(2) 哪一个均方误差最小?  \n14. 设 $x_{1}, \\cdots, x_{n}$ 是来自密度函数 $p(x ; \\theta)=\\mathrm{e}^{-(x-\\theta)}, x>\\theta$ 的样本,  \n(1) 求 $\\theta$ 的最大似然估计 $\\hat{\\theta}_{1}$, 它是否是相合估计? 是否是无偏估计?",
        "metadata": {
            "Header 2": "好题 6.2"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\hat{\\sigma_{1}^{2}}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}, \\hat{\\sigma_{2}^{2}}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}, \\hat{\\sigma_{3}^{2}}=\\frac{1}{n+1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}, \\hat{\\sigma_{2}^{2}}\n$$  \n(1) 哪一个是 $\\sigma^{2}$ 的无偏估计?  \n(2) 哪一个均方误差最小?  \n14. 设 $x_{1}, \\cdots, x_{n}$ 是来自密度函数 $p(x ; \\theta)=\\mathrm{e}^{-(x-\\theta)}, x>\\theta$ 的样本,  \n(1) 求 $\\theta$ 的最大似然估计 $\\hat{\\theta}_{1}$, 它是否是相合估计? 是否是无偏估计?  \n(2) 求 $\\theta$ 的矩估计 $\\hat{\\theta}_{2}$, 它是否是相合估计? 是否是无偏估计?  \n(3) 考虑 $\\theta$ 的形如 $\\hat{\\theta}_{c}=x_{(1)}-c$ 的估计, 求使得 $\\hat{\\theta}_{c}$ 的均方误差达到最小的 $c$, 并将之与 $\\hat{\\theta}_{1}, \\hat{\\theta}_{2}$的均方误差进行比较.  \n15. 设总体 $X \\sim \\operatorname{Exp}(1 / \\theta), x_{1}, \\cdots, x_{n}$ 是样本, $\\theta$ 的矩估计和最大似然估计都是 $\\bar{x}$, 它也是 $\\theta$ 的相合估计和无偏估计,试证明在均方误差准则下存在优于 $\\bar{x}$ 的估计 ( 提示: 考虑 $\\hat{\\theta}_{a}=a \\bar{x}$, 找均方误差最小者).",
        "metadata": {
            "Header 2": "好题 6.2"
        },
        "type": "Document"
    },
    {
        "page_content": "我们在例 6.2.6 和例 6.2.7 中分别比较了两个无偏估计的优劣, 在这两个例子中, 好的一个无偏估计都是充分统计量的函数, 这不是偶然的, 下面我们介绍这方面的有关结论. 先从 Rao-Blackwell 定理谈起。  \n定理 6.3 . (Rao-Blackwell 定理). 设 $X$ 和 $Y$ 是两个随机变量, $E X=\\mu$. $\\operatorname{Var}(X)>0$. 我们用条件期望构造一个新的随机变量 $\\varphi(Y)$, 其定义为  \n$$\n\\varphi(y)=E(X \\mid Y=y) \\text {, }\n$$  \n则有  \n$$\nE \\varphi(Y)=\\mu, \\operatorname{Var}(\\varphi(Y)) \\leqslant \\operatorname{Var}(X)\n$$  \n其中等号成立的充分必要条件是 $X$ 和 $\\varphi(Y)$ 几乎处处相等.\n证明: 我们以 $X$ 和 $Y$ 都是连续型随机变量为例加以证明. 设 $p(x, y), P_{Y}(y), h(x \\mid y)$ 分别为 $X$ 和 $Y$ 的联合密度函数、 $Y$ 的边际密度函数和给定 $Y=y$ 下 $X$ 的条件密度函数, 于是条件期望  \n$$\n\\begin{gathered}\n\\varphi(y)=E(X \\mid Y=y)=\\int x h(x \\mid y) \\mathrm{d} x=\\frac{\\int x \\cdot p(x, y) \\mathrm{d} x}{p_{Y}(y)}, \\\\\nE \\varphi(Y)=\\int \\varphi(y) \\cdot p_{Y}(y) \\mathrm{d} y=\\iint c \\cdot p(x, y) \\mathrm{d} x \\mathrm{~d} y=E X=\\mu,\n\\end{gathered}\n$$  \n这证明了第一个结论, 下证第二个结论, 我们将 $\\operatorname{Var}(X)$ 写成如下的形式:  \n$$\n\\begin{align*}\n\\operatorname{Var}(X) & =E[(X-\\varphi(Y))+(\\varphi(Y)-\\mu)]^{2} \\\\",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.1 Rao-Blackwell 定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{gathered}\n\\varphi(y)=E(X \\mid Y=y)=\\int x h(x \\mid y) \\mathrm{d} x=\\frac{\\int x \\cdot p(x, y) \\mathrm{d} x}{p_{Y}(y)}, \\\\\nE \\varphi(Y)=\\int \\varphi(y) \\cdot p_{Y}(y) \\mathrm{d} y=\\iint c \\cdot p(x, y) \\mathrm{d} x \\mathrm{~d} y=E X=\\mu,\n\\end{gathered}\n$$  \n这证明了第一个结论, 下证第二个结论, 我们将 $\\operatorname{Var}(X)$ 写成如下的形式:  \n$$\n\\begin{align*}\n\\operatorname{Var}(X) & =E[(X-\\varphi(Y))+(\\varphi(Y)-\\mu)]^{2} \\\\\n& =E(X-\\varphi(Y))^{2}+E(\\varphi(Y)-\\mu)^{2}+2 E[(x-\\varphi(Y)) \\cdot(\\varphi(Y)-\\mu)] \\tag{6.3.1}\n\\end{align*}\n$$  \n由于 $\\int[x-\\varphi(y)] h(x \\mid y) \\mathrm{d} x=E(X \\mid Y=y)-\\varphi(y)=0$, 故 (6.3.1) 右端第三项为  \n$$\n\\begin{aligned}\nE[(x-\\varphi(Y)) \\cdot(\\varphi(Y)-\\mu)] & =\\iint[x-\\varphi(y)] \\cdot[\\varphi(y)-\\mu] \\cdot p(x, y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\iint[x-\\varphi(y)] \\cdot[\\varphi(y)-\\mu] \\cdot p_{Y}(y) h(x \\mid y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\int[\\varphi(y)-\\mu]\\left(\\int[x-\\varphi(y)] h(x \\mid y) \\mathrm{d} x\\right) p_{Y}(y) \\mathrm{d} y \\\\\n& =0\n\\end{aligned}",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.1 Rao-Blackwell 定理"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{align*}\n$$  \n由于 $\\int[x-\\varphi(y)] h(x \\mid y) \\mathrm{d} x=E(X \\mid Y=y)-\\varphi(y)=0$, 故 (6.3.1) 右端第三项为  \n$$\n\\begin{aligned}\nE[(x-\\varphi(Y)) \\cdot(\\varphi(Y)-\\mu)] & =\\iint[x-\\varphi(y)] \\cdot[\\varphi(y)-\\mu] \\cdot p(x, y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\iint[x-\\varphi(y)] \\cdot[\\varphi(y)-\\mu] \\cdot p_{Y}(y) h(x \\mid y) \\mathrm{d} x \\mathrm{~d} y \\\\\n& =\\int[\\varphi(y)-\\mu]\\left(\\int[x-\\varphi(y)] h(x \\mid y) \\mathrm{d} x\\right) p_{Y}(y) \\mathrm{d} y \\\\\n& =0\n\\end{aligned}\n$$  \n而 (6.3.1) 右端第二项正是 $\\varphi(y)$ 的方差,由此即有  \n$$\n\\begin{equation*}\n\\operatorname{Var}(X)=E(X-\\varphi(y))^{2}+\\operatorname{Var}(\\varphi(Y)) . \\tag{6.3.2}\n\\end{equation*}\n$$  \n由于上式右端第一项非负, 这就证明了第二个结论. 进一步, 等号成立 (即 $\\operatorname{Var}(X)=\\operatorname{Var}(\\varphi(Y)))$ 的充要条件为  \n$$\n\\begin{equation*}\nP(X-\\varphi(Y)=0)=1 \\tag{6.3.3}\n\\end{equation*}\n$$  \n即 $X$ 和 $\\varphi(Y)$ 几乎处处相等.  \n将定理 6.3 .1 应用到参数估计问题中可得到如下重要结论:",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.1 Rao-Blackwell 定理"
        },
        "type": "Document"
    },
    {
        "page_content": "& =0\n\\end{aligned}\n$$  \n而 (6.3.1) 右端第二项正是 $\\varphi(y)$ 的方差,由此即有  \n$$\n\\begin{equation*}\n\\operatorname{Var}(X)=E(X-\\varphi(y))^{2}+\\operatorname{Var}(\\varphi(Y)) . \\tag{6.3.2}\n\\end{equation*}\n$$  \n由于上式右端第一项非负, 这就证明了第二个结论. 进一步, 等号成立 (即 $\\operatorname{Var}(X)=\\operatorname{Var}(\\varphi(Y)))$ 的充要条件为  \n$$\n\\begin{equation*}\nP(X-\\varphi(Y)=0)=1 \\tag{6.3.3}\n\\end{equation*}\n$$  \n即 $X$ 和 $\\varphi(Y)$ 几乎处处相等.  \n将定理 6.3 .1 应用到参数估计问题中可得到如下重要结论:  \n定理 6.3.2. 设总体概率密度函数是 $p(x ; \\theta), x_{1}, x_{2}, \\cdots, x_{n}$ 是其样本, $T=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的充分统计量, 则对 $\\theta$ 的任一无偏估计 $\\hat{\\theta}=\\hat{\\theta}\\left(x_{1}, \\cdots, x_{n}\\right)$, 令 $\\tilde{\\theta}=E(\\hat{\\theta} \\mid T)$, 则 $\\tilde{\\theta}$ 也是 $\\theta$ 的无偏估计, 且  \n$$\n\\begin{equation*}\n\\operatorname{Var}(\\tilde{\\theta}) \\leqslant \\operatorname{Var}(\\hat{\\theta}) \\tag{6.3.4}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.1 Rao-Blackwell 定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n即 $X$ 和 $\\varphi(Y)$ 几乎处处相等.  \n将定理 6.3 .1 应用到参数估计问题中可得到如下重要结论:  \n定理 6.3.2. 设总体概率密度函数是 $p(x ; \\theta), x_{1}, x_{2}, \\cdots, x_{n}$ 是其样本, $T=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的充分统计量, 则对 $\\theta$ 的任一无偏估计 $\\hat{\\theta}=\\hat{\\theta}\\left(x_{1}, \\cdots, x_{n}\\right)$, 令 $\\tilde{\\theta}=E(\\hat{\\theta} \\mid T)$, 则 $\\tilde{\\theta}$ 也是 $\\theta$ 的无偏估计, 且  \n$$\n\\begin{equation*}\n\\operatorname{Var}(\\tilde{\\theta}) \\leqslant \\operatorname{Var}(\\hat{\\theta}) \\tag{6.3.4}\n\\end{equation*}\n$$  \n证明：由于 $T=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是充分统计量, 故而 $\\tilde{\\theta}=E(\\hat{\\theta} \\mid T)$ 与 $\\theta$ 无关, 因此它也是一个估计 ( 统计量),只要在定理 6.3.1 中取 $X=\\hat{\\theta}, Y=T$ 即可完成本定理的证明.  \n定理 6.3.2 说明, 如果无偏估计不是充分统计量的函数, 则将之对充分统计量求条件期望可以得到一个新的无偏估计, 该估计的方差比原来的估计的方差要小, 从而降低了无偏估计的方差. 换言之, 考虑日的估计问题只需要在基于充分统计量的函数中进行即可, 该说法对所有的统计推断问题都是正确的,这便是所谓的充分性原则.  \n例 6.3.1: 设 $x_{1}, \\cdots, x_{n}$ 是来自总体 $b(1 . p)$ 的样本, 则 $\\bar{x}$ (或 $\\left.T=n \\bar{x}\\right)$ 是 $p$ 的充分统计量. 为估计 $\\theta=p^{2}$, 可令  \n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.1 Rao-Blackwell 定理"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n证明：由于 $T=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是充分统计量, 故而 $\\tilde{\\theta}=E(\\hat{\\theta} \\mid T)$ 与 $\\theta$ 无关, 因此它也是一个估计 ( 统计量),只要在定理 6.3.1 中取 $X=\\hat{\\theta}, Y=T$ 即可完成本定理的证明.  \n定理 6.3.2 说明, 如果无偏估计不是充分统计量的函数, 则将之对充分统计量求条件期望可以得到一个新的无偏估计, 该估计的方差比原来的估计的方差要小, 从而降低了无偏估计的方差. 换言之, 考虑日的估计问题只需要在基于充分统计量的函数中进行即可, 该说法对所有的统计推断问题都是正确的,这便是所谓的充分性原则.  \n例 6.3.1: 设 $x_{1}, \\cdots, x_{n}$ 是来自总体 $b(1 . p)$ 的样本, 则 $\\bar{x}$ (或 $\\left.T=n \\bar{x}\\right)$ 是 $p$ 的充分统计量. 为估计 $\\theta=p^{2}$, 可令  \n$$\n\\hat{\\theta}_{1}= \\begin{cases}1, & x_{1}=1, x_{2}=1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n由于  \n$$\nE\\left(\\hat{\\theta}_{1}\\right)=P\\left(x_{1}=1, x_{2}=1\\right)=p \\cdot p=\\theta\n$$  \n所以, $\\hat{\\theta}_{1}$ 是 $\\theta$ 的无偏估计, 这个估计并不好, 它只使用了两个观测值, 下面我们用 Rao-Blackwel 定\n理对之加以改进:求 $\\hat{\\theta}_{1}$ 关于充分统计量 $T=\\sum_{i=1}^{n} x_{i}$ 的条件期望, 过程如下.  \n$$\n\\begin{aligned}\n\\hat{\\theta} & =E\\left(\\hat{\\theta}_{1} \\mid T=t\\right) \\\\\n& =P\\left(\\hat{\\theta}_{1}=1 \\mid T=t\\right) \\\\",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.1 Rao-Blackwell 定理"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\hat{\\theta}_{1}= \\begin{cases}1, & x_{1}=1, x_{2}=1 \\\\ 0, & \\text { 其他. }\\end{cases}\n$$  \n由于  \n$$\nE\\left(\\hat{\\theta}_{1}\\right)=P\\left(x_{1}=1, x_{2}=1\\right)=p \\cdot p=\\theta\n$$  \n所以, $\\hat{\\theta}_{1}$ 是 $\\theta$ 的无偏估计, 这个估计并不好, 它只使用了两个观测值, 下面我们用 Rao-Blackwel 定\n理对之加以改进:求 $\\hat{\\theta}_{1}$ 关于充分统计量 $T=\\sum_{i=1}^{n} x_{i}$ 的条件期望, 过程如下.  \n$$\n\\begin{aligned}\n\\hat{\\theta} & =E\\left(\\hat{\\theta}_{1} \\mid T=t\\right) \\\\\n& =P\\left(\\hat{\\theta}_{1}=1 \\mid T=t\\right) \\\\\n& =\\frac{P\\left(X_{1}=1, X_{2}=1, T=t\\right)}{P(=t)} \\\\\n& =\\frac{P\\left(X_{1}=1, X_{2}=1, \\sum_{i=3}^{n} X_{i}=t-2\\right)}{P(T=t)} \\\\\n& =\\frac{p \\cdot p \\cdot\\left(\\begin{array}{c}\nn-2 \\\\\nt-2\n\\end{array}\\right) p^{t-2}(1-p)^{n-t}}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right) p^{t}(1-p)^{n-t}} \\\\\n& =\\left(\\begin{array}{c}\nn-2 \\\\\nt-2\n\\end{array}\\right) /\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right)=\\frac{t(t-1)}{n(n-1)},\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.1 Rao-Blackwell 定理"
        },
        "type": "Document"
    },
    {
        "page_content": "& =P\\left(\\hat{\\theta}_{1}=1 \\mid T=t\\right) \\\\\n& =\\frac{P\\left(X_{1}=1, X_{2}=1, T=t\\right)}{P(=t)} \\\\\n& =\\frac{P\\left(X_{1}=1, X_{2}=1, \\sum_{i=3}^{n} X_{i}=t-2\\right)}{P(T=t)} \\\\\n& =\\frac{p \\cdot p \\cdot\\left(\\begin{array}{c}\nn-2 \\\\\nt-2\n\\end{array}\\right) p^{t-2}(1-p)^{n-t}}{\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right) p^{t}(1-p)^{n-t}} \\\\\n& =\\left(\\begin{array}{c}\nn-2 \\\\\nt-2\n\\end{array}\\right) /\\left(\\begin{array}{c}\nn \\\\\nt\n\\end{array}\\right)=\\frac{t(t-1)}{n(n-1)},\n\\end{aligned}\n$$  \n其中 $t=\\sum_{i=1}^{n} x_{i}$. 可以验证, $\\hat{\\theta}$ 是 $\\theta$ 的无偏估计, 且 $\\operatorname{Var}(\\hat{\\theta})<\\operatorname{Var}\\left(\\hat{\\theta}_{1}\\right)$.",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.1 Rao-Blackwell 定理"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 6.3.1. 对参数估计问题, 设 $\\hat{\\theta}$ 是 $\\theta$ 的一个无偏估计, 如果对另外任意一个日的无偏估计 $\\tilde{\\theta}$, 在参数空间 $\\Theta$ 上都有  \n$$\n\\begin{equation*}\n\\operatorname{Var}_{\\theta}(\\hat{\\theta}) \\leqslant \\operatorname{Var}_{\\theta}(\\tilde{\\theta}) \\tag{6.3.5}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}$ 是 $\\theta$ 的一致最小方程无偏估计, 简记为 UMVUE.  \n定理 6.3.2 表明,如果 UMVUE 存在,则它一定是充分统计量的函数.一般而言,如果依赖充分统计量的无偏估计只有一个,则它就是 UMVUE.  \n关于 UMVUE, 有如下一个判断准则.  \n定理 6.3.3. 设 $\\boldsymbol{X}=\\left(x_{1}, \\cdots, x_{n}\\right)$ 是来自某总体的一个样本, $\\hat{\\theta}=\\hat{\\theta}(\\boldsymbol{X})$ 是 $\\theta$ 的一个无偏估计, $\\operatorname{Var}(\\hat{\\theta})<+\\infty$. 如果对任意一个满足 $E(\\varphi(\\triangleleft)=0$ 的 $\\varphi(\\boldsymbol{X})$, 都有  \n$$\n\\begin{equation*}\n\\operatorname{Cov}_{\\theta}(\\hat{\\theta}, \\varphi)=0, \\quad \\forall \\theta \\in \\Theta \\tag{6.3.6}\n\\end{equation*}\n$$  \n则 $\\hat{\\theta}$ 是 $\\theta$ 的 UMVUE.  \n证明: 对 $\\theta$ 的任意一个无偏估计 $\\tilde{\\theta}$, 令 $\\varphi=\\tilde{\\theta}-\\hat{\\theta}$,则  \n$$\nE(\\varphi)=E(\\tilde{\\theta})-E(\\hat{\\theta})=0 \\text {. }",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.2 最小方差无偏估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n\\operatorname{Cov}_{\\theta}(\\hat{\\theta}, \\varphi)=0, \\quad \\forall \\theta \\in \\Theta \\tag{6.3.6}\n\\end{equation*}\n$$  \n则 $\\hat{\\theta}$ 是 $\\theta$ 的 UMVUE.  \n证明: 对 $\\theta$ 的任意一个无偏估计 $\\tilde{\\theta}$, 令 $\\varphi=\\tilde{\\theta}-\\hat{\\theta}$,则  \n$$\nE(\\varphi)=E(\\tilde{\\theta})-E(\\hat{\\theta})=0 \\text {. }\n$$  \n于是  \n$$\n\\begin{aligned}\n\\operatorname{Var}(\\tilde{\\theta}) & E(\\tilde{\\theta}-\\theta)^{2} \\\\\n& =E[(\\tilde{\\theta}-\\theta)+(\\hat{\\theta}-\\theta)] \\\\\n& =E\\left(\\varphi^{2}\\right)+\\operatorname{Var}(\\hat{\\theta})+\\operatorname{Var}(\\hat{\\theta})+2 \\operatorname{Cov}(\\varphi, \\hat{\\theta}) \\\\\n& \\geqslant \\operatorname{Var}(\\hat{\\theta}) .\n\\end{aligned}\n$$  \n定理得证.  \n例 6.3.2: 设 $x_{1}, \\cdots, x_{n}$ 是来自指数分布 $\\exp (1 / \\theta)$ 的样本, 则根据因子分解定理可知, $T=x_{1}+\\cdots+$ $x_{n}$ 的充分统计量, 由于 $E T=n \\theta$, 所以 $\\bar{x}=T / n$ 是 $\\theta$ 的无偏估计. 设 $\\varphi=\\varphi\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的任一无偏估计, 则  \n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.2 最小方差无偏估计"
        },
        "type": "Document"
    },
    {
        "page_content": "& =E\\left(\\varphi^{2}\\right)+\\operatorname{Var}(\\hat{\\theta})+\\operatorname{Var}(\\hat{\\theta})+2 \\operatorname{Cov}(\\varphi, \\hat{\\theta}) \\\\\n& \\geqslant \\operatorname{Var}(\\hat{\\theta}) .\n\\end{aligned}\n$$  \n定理得证.  \n例 6.3.2: 设 $x_{1}, \\cdots, x_{n}$ 是来自指数分布 $\\exp (1 / \\theta)$ 的样本, 则根据因子分解定理可知, $T=x_{1}+\\cdots+$ $x_{n}$ 的充分统计量, 由于 $E T=n \\theta$, 所以 $\\bar{x}=T / n$ 是 $\\theta$ 的无偏估计. 设 $\\varphi=\\varphi\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的任一无偏估计, 则  \n$$\nE \\varphi(T)=\\int_{0}^{+\\infty} \\cdots \\int_{0}^{+\\infty} \\varphi\\left(x_{1}, \\cdots, x_{n}\\right) \\cdot \\prod_{i=1}^{n}\\left\\{\\frac{1}{\\theta} \\cdot e^{-x_{i} / \\theta}\\right\\} \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n}=0\n$$  \n即  \n$$\n\\int_{0}^{+\\infty} \\cdots \\int_{0}^{+\\infty} \\varphi\\left(x_{1}, \\cdots, x_{n}\\right) \\cdot \\mathrm{e}^{-\\left(x_{1}+\\cdots+x_{n}\\right) / \\theta} \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n}=0\n$$  \n两端对 $\\theta$ 求导, 得  \n这说明 $E(\\bar{x} \\cdot \\varphi)=0$, 从而  \n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.2 最小方差无偏估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nE \\varphi(T)=\\int_{0}^{+\\infty} \\cdots \\int_{0}^{+\\infty} \\varphi\\left(x_{1}, \\cdots, x_{n}\\right) \\cdot \\prod_{i=1}^{n}\\left\\{\\frac{1}{\\theta} \\cdot e^{-x_{i} / \\theta}\\right\\} \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n}=0\n$$  \n即  \n$$\n\\int_{0}^{+\\infty} \\cdots \\int_{0}^{+\\infty} \\varphi\\left(x_{1}, \\cdots, x_{n}\\right) \\cdot \\mathrm{e}^{-\\left(x_{1}+\\cdots+x_{n}\\right) / \\theta} \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n}=0\n$$  \n两端对 $\\theta$ 求导, 得  \n这说明 $E(\\bar{x} \\cdot \\varphi)=0$, 从而  \n$$\n\\int_{0}^{+\\infty} \\cdots \\int_{0}^{+\\infty} \\frac{n \\bar{x}}{\\theta^{2}} \\varphi\\left(x_{1}, \\cdots, x_{n}\\right) \\cdot e^{\\left(x_{1}+\\cdots+x_{k}\\right) / \\theta} \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n}=0\n$$  \n$$\n\\operatorname{Cov}(\\bar{x}, \\varphi)=E(\\bar{x} \\cdot \\varphi)-E(\\bar{x}) \\cdot E(\\varphi)=0\n$$  \n由定理 6.3.3, $\\bar{x}$ 是 $\\theta$ 的 UMVUE.",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.2 最小方差无偏估计"
        },
        "type": "Document"
    },
    {
        "page_content": "我们在定理6.3.5中将指出, 最大似然估计的渐近方差主要由费希尔信息量 $I(\\theta)$ 决定, 本节先介绍 $I(\\theta)$, 然后讲述 Cramer-Rao 不等式, 有时它可用来判断 UMVUE.  \n定义 6.3.2. 设总体的概率函数 $p(x ; \\theta), \\theta \\in \\Theta$ 满  \n1. 参数空间 $\\Theta$ 是直线上的一个开区间;\n2. 支撑 $S=\\{x: p(x ; \\theta)>0\\}$ 与 $\\Theta$ 无关;\n3. 导数 $\\frac{\\partial}{\\partial \\theta} p(x ; \\theta)$ 对一切 $\\theta \\in \\Theta$ 都存在;\n4. 对 $p(x ; \\theta)$, 积分与微分运算可交换次序, 即  \n$$\n\\frac{\\partial}{\\partial \\theta} \\int_{-\\infty}^{+\\infty} p(x ; \\theta) \\mathrm{d} x=\\int_{-\\infty}^{+\\infty} \\frac{\\partial}{\\partial \\theta} p(x ; \\theta) \\mathrm{d} x\n$$  \n5. 期望 $E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p(x ; \\theta)\\right]^{2}$ 存在, 则称  \n为总体分布的费希尔 (Fisher) 信息量.  \n$$\n\\begin{equation*}\nI(\\theta)=E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p(x ; \\theta)\\right]^{2} \\tag{6.3.7}\n\\end{equation*}\n$$  \n费希尔信息量是数理统计学中一个基本概念, 很多的统计结果都与费希尔信息量有关. 如最大似然估计的渐近方差, 无偏估计的方差的下界等都与费希尔信息量 $I(\\theta)$ 有关. $I(\\theta)$ 的种种性质显示, “ $I(\\theta)$ 越大”可被解释为总体分布中包含未知参数日的信息越多.  \n例 6.3.3: 设总体为泊松分布 $p(\\lambda)$ 分布, 其分布列为  \n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n5. 期望 $E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p(x ; \\theta)\\right]^{2}$ 存在, 则称  \n为总体分布的费希尔 (Fisher) 信息量.  \n$$\n\\begin{equation*}\nI(\\theta)=E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p(x ; \\theta)\\right]^{2} \\tag{6.3.7}\n\\end{equation*}\n$$  \n费希尔信息量是数理统计学中一个基本概念, 很多的统计结果都与费希尔信息量有关. 如最大似然估计的渐近方差, 无偏估计的方差的下界等都与费希尔信息量 $I(\\theta)$ 有关. $I(\\theta)$ 的种种性质显示, “ $I(\\theta)$ 越大”可被解释为总体分布中包含未知参数日的信息越多.  \n例 6.3.3: 设总体为泊松分布 $p(\\lambda)$ 分布, 其分布列为  \n$$\np(x ; \\lambda)=\\frac{\\lambda^{x}}{x !} \\mathrm{e}^{-\\lambda}, \\quad x=0,1, \\cdots\n$$  \n可以看出定义6.3.2的条件满足, 且  \n$$\n\\begin{gathered}\n\\ln p(x ; \\lambda)=x \\ln \\lambda-\\lambda-\\ln (x !) \\\\\n\\frac{\\partial}{\\partial \\lambda} \\ln p(x ; \\lambda)=\\frac{x}{\\lambda}-1\n\\end{gathered}\n$$  \n于是  \n$$\nI(\\lambda)=E\\left(\\frac{X-\\lambda}{\\lambda}\\right)^{2}=\\frac{1}{\\lambda}\n$$  \n例 6.3.4: 设总体为指数分布, 其密度函数为  \n可以验证定义6.3.2 的条件满足, 且  \n$$\np(x ; \\theta)=\\frac{1}{\\theta} \\exp \\left\\{-\\frac{x}{\\theta}\\right\\}, x>0, \\theta>0\n$$  \n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n可以看出定义6.3.2的条件满足, 且  \n$$\n\\begin{gathered}\n\\ln p(x ; \\lambda)=x \\ln \\lambda-\\lambda-\\ln (x !) \\\\\n\\frac{\\partial}{\\partial \\lambda} \\ln p(x ; \\lambda)=\\frac{x}{\\lambda}-1\n\\end{gathered}\n$$  \n于是  \n$$\nI(\\lambda)=E\\left(\\frac{X-\\lambda}{\\lambda}\\right)^{2}=\\frac{1}{\\lambda}\n$$  \n例 6.3.4: 设总体为指数分布, 其密度函数为  \n可以验证定义6.3.2 的条件满足, 且  \n$$\np(x ; \\theta)=\\frac{1}{\\theta} \\exp \\left\\{-\\frac{x}{\\theta}\\right\\}, x>0, \\theta>0\n$$  \n$$\n\\frac{\\partial}{\\partial \\theta} \\ln p(x ; \\theta)=\\frac{1}{\\theta}-\\frac{x}{\\theta^{2}}=-\\frac{x-\\theta}{\\theta^{2}}\n$$  \n于是  \n$$\nI(\\theta)=E\\left(\\frac{x-\\theta}{\\theta^{2}}\\right)^{2}=\\frac{\\operatorname{Var}(x)}{\\theta^{4}}=\\frac{1}{\\theta^{2}}\n$$  \n定理 6.3 . 4 (Cramer-Rao 不等式). 设定义6.3.2的条件满足, $x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, $T=$\n$T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $g(\\theta)$ 的任一个无偏估计, $g^{\\prime}(\\theta)=\\frac{\\partial g(\\theta)}{\\partial \\theta}$ 存在, 且对 $\\Theta$ 中一切 $\\theta$, 对  \n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\frac{\\partial}{\\partial \\theta} \\ln p(x ; \\theta)=\\frac{1}{\\theta}-\\frac{x}{\\theta^{2}}=-\\frac{x-\\theta}{\\theta^{2}}\n$$  \n于是  \n$$\nI(\\theta)=E\\left(\\frac{x-\\theta}{\\theta^{2}}\\right)^{2}=\\frac{\\operatorname{Var}(x)}{\\theta^{4}}=\\frac{1}{\\theta^{2}}\n$$  \n定理 6.3 . 4 (Cramer-Rao 不等式). 设定义6.3.2的条件满足, $x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, $T=$\n$T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $g(\\theta)$ 的任一个无偏估计, $g^{\\prime}(\\theta)=\\frac{\\partial g(\\theta)}{\\partial \\theta}$ 存在, 且对 $\\Theta$ 中一切 $\\theta$, 对  \n$$\ng(\\theta)=\\int_{-\\infty}^{+\\infty} \\cdots \\int_{-\\infty}^{+\\infty} T\\left(x_{1}, \\cdots, x_{n}\\right) \\prod_{i=1}^{n} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n}\n$$  \n的微分可在积分号下进行, 即  \n$$\n\\begin{align*}\ng^{\\prime}(\\theta) & =\\int_{-\\infty}^{+\\infty} \\cdots \\int_{-\\infty}^{+\\infty} T\\left(x_{1}, \\cdots, x_{n}\\right) \\frac{\\partial}{\\partial \\theta}\\left(\\prod_{i=1}^{n} p\\left(x_{i} ; \\theta\\right)\\right) \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n} \\\\",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\ng(\\theta)=\\int_{-\\infty}^{+\\infty} \\cdots \\int_{-\\infty}^{+\\infty} T\\left(x_{1}, \\cdots, x_{n}\\right) \\prod_{i=1}^{n} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n}\n$$  \n的微分可在积分号下进行, 即  \n$$\n\\begin{align*}\ng^{\\prime}(\\theta) & =\\int_{-\\infty}^{+\\infty} \\cdots \\int_{-\\infty}^{+\\infty} T\\left(x_{1}, \\cdots, x_{n}\\right) \\frac{\\partial}{\\partial \\theta}\\left(\\prod_{i=1}^{n} p\\left(x_{i} ; \\theta\\right)\\right) \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n} \\\\\n& =\\int_{-\\infty}^{+\\infty} \\cdots \\int_{-\\infty}^{+\\infty} T\\left(x_{1}, \\cdots, x_{n}\\right)\\left[\\frac{\\partial}{\\partial \\theta} \\ln \\prod_{i=1}^{n} p\\left(x_{i} ; \\theta\\right)\\right] \\prod_{i=1}^{n} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n} \\tag{6.3.8}\n\\end{align*}\n$$  \n对离散总体, 则将上述积分改为求和符号后, 等式仍然成立. 则有  \n$$\n\\begin{equation*}\n\\operatorname{Var}(T) \\geqslant\\left[g^{\\prime}(\\theta)\\right]^{2} /(n I(\\theta)) \\tag{6.3.9}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\int_{-\\infty}^{+\\infty} \\cdots \\int_{-\\infty}^{+\\infty} T\\left(x_{1}, \\cdots, x_{n}\\right)\\left[\\frac{\\partial}{\\partial \\theta} \\ln \\prod_{i=1}^{n} p\\left(x_{i} ; \\theta\\right)\\right] \\prod_{i=1}^{n} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{1} \\cdots \\mathrm{d} x_{n} \\tag{6.3.8}\n\\end{align*}\n$$  \n对离散总体, 则将上述积分改为求和符号后, 等式仍然成立. 则有  \n$$\n\\begin{equation*}\n\\operatorname{Var}(T) \\geqslant\\left[g^{\\prime}(\\theta)\\right]^{2} /(n I(\\theta)) \\tag{6.3.9}\n\\end{equation*}\n$$  \n(6.3.9) 称为克拉美-罗 (C-R) 不等式, $\\left[g^{\\prime}(\\theta)\\right]^{2} /(n I(\\theta))$ 称为 $g(\\theta)$ 的无偏估计的方差的 C-R 下界, 简称 $g(\\theta)$ 的 CR 下界. 特别, 对 $\\theta$ 的无偏估计 $\\hat{\\theta}$, 有 $\\operatorname{Var}(\\hat{\\theta}) \\geqslant(n I(\\theta))^{-1}$  \n证明: 以连续总体为例加以证明. 由 $\\int_{-\\infty}^{+\\infty} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{i}=1, i=1, \\cdots, n$, 两边对 $\\theta$ 求导, 由于积分与微分可交换次序, 于是有  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n(6.3.9) 称为克拉美-罗 (C-R) 不等式, $\\left[g^{\\prime}(\\theta)\\right]^{2} /(n I(\\theta))$ 称为 $g(\\theta)$ 的无偏估计的方差的 C-R 下界, 简称 $g(\\theta)$ 的 CR 下界. 特别, 对 $\\theta$ 的无偏估计 $\\hat{\\theta}$, 有 $\\operatorname{Var}(\\hat{\\theta}) \\geqslant(n I(\\theta))^{-1}$  \n证明: 以连续总体为例加以证明. 由 $\\int_{-\\infty}^{+\\infty} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{i}=1, i=1, \\cdots, n$, 两边对 $\\theta$ 求导, 由于积分与微分可交换次序, 于是有  \n$$\n\\begin{aligned}\n0 & =\\int_{-\\infty}^{+\\infty} \\frac{\\partial}{\\partial \\theta p} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{i}=\\int_{-\\infty}^{+\\infty}\\left[\\frac{\\partial}{\\partial \\theta} \\ln p(x ; \\theta)\\right] p(x ; \\theta) \\mathrm{d} x \\\\\n& =E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)\\right]\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "证明: 以连续总体为例加以证明. 由 $\\int_{-\\infty}^{+\\infty} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{i}=1, i=1, \\cdots, n$, 两边对 $\\theta$ 求导, 由于积分与微分可交换次序, 于是有  \n$$\n\\begin{aligned}\n0 & =\\int_{-\\infty}^{+\\infty} \\frac{\\partial}{\\partial \\theta p} p\\left(x_{i} ; \\theta\\right) \\mathrm{d} x_{i}=\\int_{-\\infty}^{+\\infty}\\left[\\frac{\\partial}{\\partial \\theta} \\ln p(x ; \\theta)\\right] p(x ; \\theta) \\mathrm{d} x \\\\\n& =E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)\\right]\n\\end{aligned}\n$$  \n记 $Z=\\frac{\\partial}{\\partial \\theta} \\ln \\prod_{i=1}^{\\pi} p\\left(x_{i} ; \\theta\\right)=\\sum_{i=1}^{n} \\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)$, 则 $E Z=\\sum_{i=1}^{n} E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)\\right]=0$, 从而  \n$$\n\\begin{align*}\nE\\left(Z^{2}\\right) & =\\operatorname{Var}(Z)=\\sum_{i=1}^{n} \\operatorname{Var}\\left(\\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)\\right) \\\\",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n记 $Z=\\frac{\\partial}{\\partial \\theta} \\ln \\prod_{i=1}^{\\pi} p\\left(x_{i} ; \\theta\\right)=\\sum_{i=1}^{n} \\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)$, 则 $E Z=\\sum_{i=1}^{n} E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)\\right]=0$, 从而  \n$$\n\\begin{align*}\nE\\left(Z^{2}\\right) & =\\operatorname{Var}(Z)=\\sum_{i=1}^{n} \\operatorname{Var}\\left(\\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)\\right) \\\\\n& =\\sum_{i=1}^{n} E\\left[\\frac{\\partial}{\\partial \\theta} \\ln p\\left(x_{i} ; \\theta\\right)\\right]^{2}=n I(\\theta) \\tag{6.3.10}\n\\end{align*}\n$$  \n又由 6.3.8, $g^{\\prime}(\\theta)=E(T \\cdot Z)=E((T-g(\\theta)) \\cdot Z)$, 据施瓦茨不等式, 有  \n$$\n\\left[g^{\\prime}(\\theta)\\right]^{2} \\leqslant E\\left[(T-g(\\theta))^{2}\\right] \\cdot E\\left(Z^{2}\\right)=\\operatorname{Var}(T) \\operatorname{Var}(Z)\n$$  \n由此, 6.3.9, 得证. 关于离散总体可类似证明.  \n注: 如果6.3.9中等号成立, 则称 $\\mathrm{T}=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $g(\\theta)$ 的有效估计, 有效估计一定是 UMVUE.",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{align*}\n$$  \n又由 6.3.8, $g^{\\prime}(\\theta)=E(T \\cdot Z)=E((T-g(\\theta)) \\cdot Z)$, 据施瓦茨不等式, 有  \n$$\n\\left[g^{\\prime}(\\theta)\\right]^{2} \\leqslant E\\left[(T-g(\\theta))^{2}\\right] \\cdot E\\left(Z^{2}\\right)=\\operatorname{Var}(T) \\operatorname{Var}(Z)\n$$  \n由此, 6.3.9, 得证. 关于离散总体可类似证明.  \n注: 如果6.3.9中等号成立, 则称 $\\mathrm{T}=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $g(\\theta)$ 的有效估计, 有效估计一定是 UMVUE.  \n例 6.3.5: 设总体分布列为 $p(x ; \\theta)=\\theta^{x}(1-\\theta)^{1-x}, x=0,1$, 它满足定义6.3.2的所有条件, 可以算得该分布的费希尔信息量为 $I(\\theta)=\\frac{1}{\\theta(1-\\theta)}$, 若 $x_{1}, \\cdots, x_{n}$ 是该总体的样本, 则 $\\theta$ 的 CR 下界为 $(n I(\\theta))^{-1}=\\theta(1-\\theta) / n$. 大家知道 $\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}$; 是 $\\theta$ 的无偏估计, 且其方差等于 $\\theta(1-\\theta) / n$, 达到了 C-R 下界, 所以, $\\bar{x}$ 是 $\\theta$ 的有效估计, 它也是的 UMVUE.",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "注: 如果6.3.9中等号成立, 则称 $\\mathrm{T}=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $g(\\theta)$ 的有效估计, 有效估计一定是 UMVUE.  \n例 6.3.5: 设总体分布列为 $p(x ; \\theta)=\\theta^{x}(1-\\theta)^{1-x}, x=0,1$, 它满足定义6.3.2的所有条件, 可以算得该分布的费希尔信息量为 $I(\\theta)=\\frac{1}{\\theta(1-\\theta)}$, 若 $x_{1}, \\cdots, x_{n}$ 是该总体的样本, 则 $\\theta$ 的 CR 下界为 $(n I(\\theta))^{-1}=\\theta(1-\\theta) / n$. 大家知道 $\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}$; 是 $\\theta$ 的无偏估计, 且其方差等于 $\\theta(1-\\theta) / n$, 达到了 C-R 下界, 所以, $\\bar{x}$ 是 $\\theta$ 的有效估计, 它也是的 UMVUE.  \n例 6.3.6: 设总体为指数分布 $\\exp (1 / \\theta)$, 它满足定义6.3.2的所有条件, 例 6.3.4中已经算出该分布的费希尔信息量为 $I(\\theta)=\\theta^{-2}$, 若 $x_{1}, \\cdots, x_{n}$ 是样本, 则 $\\theta$ 的 CR 下界为 $(n I(\\theta))^{-1}=\\theta^{2} / n$. 而 $\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}$ 是 $\\theta$ 的无偏估计, 且其方差等于 $\\theta^{2} / n$, 达到了 CR 下界, 所以, $\\bar{x}$ 是 $\\theta$ 的有效估计,它也是 $\\theta$ 的 UMVUE.  \n应该指出, 能达到 C-R 下界的无偏估计 (如上两例) 并不多. 大多数场合无偏估计都达不到其 C-R 下界, 下面是一个这样的例子.  \n例 6.3.7: 设总体为正态分布 $N\\left(0, \\sigma^{2}\\right)$, 它满足定义6.3.2的所有条件, 下面计算它的费希尔信息量.",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "例 6.3.6: 设总体为指数分布 $\\exp (1 / \\theta)$, 它满足定义6.3.2的所有条件, 例 6.3.4中已经算出该分布的费希尔信息量为 $I(\\theta)=\\theta^{-2}$, 若 $x_{1}, \\cdots, x_{n}$ 是样本, 则 $\\theta$ 的 CR 下界为 $(n I(\\theta))^{-1}=\\theta^{2} / n$. 而 $\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}$ 是 $\\theta$ 的无偏估计, 且其方差等于 $\\theta^{2} / n$, 达到了 CR 下界, 所以, $\\bar{x}$ 是 $\\theta$ 的有效估计,它也是 $\\theta$ 的 UMVUE.  \n应该指出, 能达到 C-R 下界的无偏估计 (如上两例) 并不多. 大多数场合无偏估计都达不到其 C-R 下界, 下面是一个这样的例子.  \n例 6.3.7: 设总体为正态分布 $N\\left(0, \\sigma^{2}\\right)$, 它满足定义6.3.2的所有条件, 下面计算它的费希尔信息量.\n由于 $p\\left(x ; \\sigma^{2}\\right)=\\left(2 \\pi \\sigma^{2}\\right)^{-1 / 2} \\exp \\left\\{-\\frac{x^{2}}{2 \\sigma^{2}}\\right\\}$, 注意到 $x^{2} / \\sigma^{2} \\sim \\chi^{2}(1)$, 故  \n$$\n\\begin{aligned}\nI\\left(\\sigma^{2}\\right) & =E\\left[\\frac{\\partial}{\\partial \\sigma^{2}} \\ln p\\left(x ; \\sigma^{2}\\right)\\right]^{2} \\\\\n& =E\\left[\\frac{x^{2}}{2 \\sigma^{4}}-\\frac{1}{2 \\sigma^{2}}\\right]^{2} \\\\\n& =\\frac{1}{4 \\sigma^{4}} \\operatorname{Var}\\left(x^{2} / \\sigma^{2}\\right) \\\\\n& =\\frac{1}{2 \\sigma^{4}}\n\\end{aligned}",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "由于 $p\\left(x ; \\sigma^{2}\\right)=\\left(2 \\pi \\sigma^{2}\\right)^{-1 / 2} \\exp \\left\\{-\\frac{x^{2}}{2 \\sigma^{2}}\\right\\}$, 注意到 $x^{2} / \\sigma^{2} \\sim \\chi^{2}(1)$, 故  \n$$\n\\begin{aligned}\nI\\left(\\sigma^{2}\\right) & =E\\left[\\frac{\\partial}{\\partial \\sigma^{2}} \\ln p\\left(x ; \\sigma^{2}\\right)\\right]^{2} \\\\\n& =E\\left[\\frac{x^{2}}{2 \\sigma^{4}}-\\frac{1}{2 \\sigma^{2}}\\right]^{2} \\\\\n& =\\frac{1}{4 \\sigma^{4}} \\operatorname{Var}\\left(x^{2} / \\sigma^{2}\\right) \\\\\n& =\\frac{1}{2 \\sigma^{4}}\n\\end{aligned}\n$$  \n令 $\\sigma=g\\left(\\sigma^{2}\\right)=\\sqrt{\\sigma^{2}}$, 则 $\\sigma$ 的 CR 下界为  \n$\\sigma$ 的无偏估计 (参见例6.2.8) 为  \n$$\n\\frac{\\left[g^{\\prime}\\left(\\sigma^{2}\\right)\\right]^{2}}{n I\\left(\\sigma^{2}\\right)}=\\frac{[1 /(2 \\sigma)]^{2}}{n /\\left(2 \\sigma^{4}\\right)}=\\frac{\\sigma^{2}}{2 n}\n$$  \n$$\n\\tilde{\\sigma}=\\sqrt{\\frac{n}{2}} \\cdot \\frac{\\Gamma(n / 2)}{\\Gamma((n+1) / 2)} \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} x_{i}^{2}}\n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\frac{1}{2 \\sigma^{4}}\n\\end{aligned}\n$$  \n令 $\\sigma=g\\left(\\sigma^{2}\\right)=\\sqrt{\\sigma^{2}}$, 则 $\\sigma$ 的 CR 下界为  \n$\\sigma$ 的无偏估计 (参见例6.2.8) 为  \n$$\n\\frac{\\left[g^{\\prime}\\left(\\sigma^{2}\\right)\\right]^{2}}{n I\\left(\\sigma^{2}\\right)}=\\frac{[1 /(2 \\sigma)]^{2}}{n /\\left(2 \\sigma^{4}\\right)}=\\frac{\\sigma^{2}}{2 n}\n$$  \n$$\n\\tilde{\\sigma}=\\sqrt{\\frac{n}{2}} \\cdot \\frac{\\Gamma(n / 2)}{\\Gamma((n+1) / 2)} \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} x_{i}^{2}}\n$$  \n可以证明, 这是 $\\sigma$ 的 UMVUE, 且其方差大于 C-R 下界. 这表明所有 $\\sigma$ 的无偏估计的方差都大于其 C-R 下界. 费希尔信息量的另一个主要作用体现在最大似然估计. 下面我们不加证明地给出关于最大似然估计的渐近正态性的结论.  \n定理 6.3.5. 设总体 $X$ 有密度函数 $p(x ; \\theta), \\theta \\in \\Theta, \\Theta$ 为非退化区间, 假定  \n1. 对任意的 $x$, 偏导数 $\\frac{\\partial \\ln p}{\\partial \\theta}, \\frac{\\partial^{2} \\ln p}{\\partial \\theta^{2}}$ 和 $\\frac{\\partial^{3} \\ln p}{\\partial \\theta^{3}}$ 对所有 $\\theta \\in \\Theta$ 都存在;\n2. $\\forall \\theta \\in \\Theta$, 有  \n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n可以证明, 这是 $\\sigma$ 的 UMVUE, 且其方差大于 C-R 下界. 这表明所有 $\\sigma$ 的无偏估计的方差都大于其 C-R 下界. 费希尔信息量的另一个主要作用体现在最大似然估计. 下面我们不加证明地给出关于最大似然估计的渐近正态性的结论.  \n定理 6.3.5. 设总体 $X$ 有密度函数 $p(x ; \\theta), \\theta \\in \\Theta, \\Theta$ 为非退化区间, 假定  \n1. 对任意的 $x$, 偏导数 $\\frac{\\partial \\ln p}{\\partial \\theta}, \\frac{\\partial^{2} \\ln p}{\\partial \\theta^{2}}$ 和 $\\frac{\\partial^{3} \\ln p}{\\partial \\theta^{3}}$ 对所有 $\\theta \\in \\Theta$ 都存在;\n2. $\\forall \\theta \\in \\Theta$, 有  \n$$\n\\left|\\frac{\\partial p}{\\partial \\theta}\\right|<F_{1}(x), \\quad\\left|\\frac{\\partial^{2} p}{\\partial \\theta^{2}}\\right|<F_{2}(x), \\quad\\left|\\frac{\\partial^{3} \\ln p}{\\partial \\theta^{3}}\\right|<F_{3}(x)\n$$  \n其中函数 $F_{1}(x), F_{2}(x), F_{3}(x)$ 满足  \n$$\n\\begin{gathered}\n\\int_{-\\infty}^{+\\infty} F_{1}(x) \\mathrm{d} x<+\\infty, \\quad \\int_{\\infty}^{+\\infty} F_{2}(x) \\mathrm{d} x<+\\infty \\\\\n\\sup _{\\theta \\in \\theta} \\int_{-\\infty}^{+\\infty} F_{3}(x) p(x ; \\theta) \\mathrm{d} x<+\\infty\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其中函数 $F_{1}(x), F_{2}(x), F_{3}(x)$ 满足  \n$$\n\\begin{gathered}\n\\int_{-\\infty}^{+\\infty} F_{1}(x) \\mathrm{d} x<+\\infty, \\quad \\int_{\\infty}^{+\\infty} F_{2}(x) \\mathrm{d} x<+\\infty \\\\\n\\sup _{\\theta \\in \\theta} \\int_{-\\infty}^{+\\infty} F_{3}(x) p(x ; \\theta) \\mathrm{d} x<+\\infty\n\\end{gathered}\n$$  \n3. $\\forall \\theta \\in \\Theta, 0<I(\\theta)=\\int_{-\\infty}^{+\\infty}\\left(\\frac{\\partial \\ln p}{\\partial \\theta}\\right)^{2} p(x ; \\theta) \\mathrm{d} x<+\\infty$.  \n若 $x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, 则存在未知参数 $\\theta$ 的最大似然估计 $\\hat{\\theta}_{n}=\\hat{\\theta}_{n}\\left(x_{1}, \\cdots, x_{n}\\right)$,  \n且 $\\hat{\\theta}_{n}$. 具有相合性和渐近正态性 $\\tilde{\\theta}_{n} \\sim N\\left(\\theta, \\frac{1}{n I(\\theta)}\\right)$.  \n定理6.3.5表明, 最大似然估计通常是渐近正态的, 且其渐近方差号 $\\sigma_{n}^{2}(\\theta)=(n I(\\theta))^{-1}$ 有一个统一的形式, 主要依赖于费希尔信息量.  \n例 6.3.8: 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 可以验证该总体分布在 $\\sigma^{2}$ 已知或 $\\mu$, 已知时均满足定理 6.3.5 的三个条件.",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "若 $x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, 则存在未知参数 $\\theta$ 的最大似然估计 $\\hat{\\theta}_{n}=\\hat{\\theta}_{n}\\left(x_{1}, \\cdots, x_{n}\\right)$,  \n且 $\\hat{\\theta}_{n}$. 具有相合性和渐近正态性 $\\tilde{\\theta}_{n} \\sim N\\left(\\theta, \\frac{1}{n I(\\theta)}\\right)$.  \n定理6.3.5表明, 最大似然估计通常是渐近正态的, 且其渐近方差号 $\\sigma_{n}^{2}(\\theta)=(n I(\\theta))^{-1}$ 有一个统一的形式, 主要依赖于费希尔信息量.  \n例 6.3.8: 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 可以验证该总体分布在 $\\sigma^{2}$ 已知或 $\\mu$, 已知时均满足定理 6.3.5 的三个条件.  \n1. 在 $\\sigma^{2}$ 已知时, $\\mu$ 的 MLE 为 $\\hat{\\mu}=\\bar{x}$, 由定理 6.3.5 知, $\\hat{\\mu}$ 服从渐近正态分布, 下面求 $I(\\mu)$,  \n$$\n\\begin{gathered}\n\\ln p(x)=-\\ln \\sqrt{2 \\pi}-\\frac{1}{2} \\ln \\sigma^{2}-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}} \\\\\n\\frac{\\partial \\ln p}{\\partial \\mu}=\\frac{x-\\mu}{a^{2}} \\\\\nI(\\mu)=E\\left(\\frac{x-\\mu}{\\sigma^{2}}\\right)^{2}=\\frac{1}{\\sigma^{2}}\n\\end{gathered}\n$$  \n从而有 $\\dot{\\mu} \\sim N\\left(\\mu, \\sigma^{2} / n\\right)$, 该近似分布与 $\\mu$ 的精确分布相同.",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 在 $\\sigma^{2}$ 已知时, $\\mu$ 的 MLE 为 $\\hat{\\mu}=\\bar{x}$, 由定理 6.3.5 知, $\\hat{\\mu}$ 服从渐近正态分布, 下面求 $I(\\mu)$,  \n$$\n\\begin{gathered}\n\\ln p(x)=-\\ln \\sqrt{2 \\pi}-\\frac{1}{2} \\ln \\sigma^{2}-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}} \\\\\n\\frac{\\partial \\ln p}{\\partial \\mu}=\\frac{x-\\mu}{a^{2}} \\\\\nI(\\mu)=E\\left(\\frac{x-\\mu}{\\sigma^{2}}\\right)^{2}=\\frac{1}{\\sigma^{2}}\n\\end{gathered}\n$$  \n从而有 $\\dot{\\mu} \\sim N\\left(\\mu, \\sigma^{2} / n\\right)$, 该近似分布与 $\\mu$ 的精确分布相同.  \n2. 在 $\\mu$ 已知时, $\\sigma^{2}$ 的 MLE 为 $\\sigma^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}$, 下求 $I\\left(\\sigma^{2}\\right)$,  \n$$\n\\begin{aligned}\n\\frac{\\partial \\ln p}{\\partial \\sigma^{2}} & =-\\frac{1}{2 \\sigma^{2}}+\\frac{1}{2 \\sigma^{4}}(x-\\mu)^{2}=\\frac{(x-\\mu)^{2}-\\sigma^{2}}{2 \\sigma^{4}} \\\\\nI\\left(\\sigma^{2}\\right) & =\\frac{E\\left[(X-\\mu)^{2}-\\sigma^{2}\\right]^{2}}{4 \\sigma^{8}} \\\\\n& =\\frac{\\operatorname{Var}\\left((X-\\mu)^{2}\\right)}{4 \\sigma^{8}}=\\frac{1}{2 \\sigma^{4}}\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n\\frac{\\partial \\ln p}{\\partial \\sigma^{2}} & =-\\frac{1}{2 \\sigma^{2}}+\\frac{1}{2 \\sigma^{4}}(x-\\mu)^{2}=\\frac{(x-\\mu)^{2}-\\sigma^{2}}{2 \\sigma^{4}} \\\\\nI\\left(\\sigma^{2}\\right) & =\\frac{E\\left[(X-\\mu)^{2}-\\sigma^{2}\\right]^{2}}{4 \\sigma^{8}} \\\\\n& =\\frac{\\operatorname{Var}\\left((X-\\mu)^{2}\\right)}{4 \\sigma^{8}}=\\frac{1}{2 \\sigma^{4}}\n\\end{aligned}\n$$  \n从而有 $\\hat{\\sigma}^{2} \\sim N\\left(\\sigma^{2}, 2 \\sigma^{4} / n\\right)$.",
        "metadata": {
            "Header 2": "6.3 最小方差无偏估计",
            "Header 3": "6.3.3 Cramer-Rao 不等式"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设总体概率函数是 $p(x ; \\theta), x_{1}, \\cdots, x_{n}$, 是其样本, $T=T\\left(x_{1}, \\cdots, x_{n}\\right)$ 是 $\\theta$ 的充分统计量, 则对 $g(\\theta)$ 的任一估计 $\\hat{g}$, 令 $\\tilde{g}=E(\\hat{g} \\mid T)$, 证明: $\\operatorname{MSE}(\\tilde{g}) \\leqslant \\operatorname{MSE}(\\hat{g})$. 这说明, 在均方误差准则下, 人们只需要考虑基于充分统计量的估计.\n2. 设 $T_{1}, T_{2}$ 分别是 $\\theta_{1}, \\theta_{2}$ 的 UMVUE, 证明: 对任意的 (非零) 常数 $a, b, a T_{1}+b T_{2}$ 是 $a \\theta_{1}+b \\theta_{2}$ 的 UMVUE.\n3. 设 $T$ 是 $g(\\theta)$ 的 UMVUE, $\\hat{g}$ 是 $g(\\theta)$ 的无偏估计, 证明, 若 $\\operatorname{Var}(\\hat{g})<+\\infty$, 则 $\\operatorname{Cov}(T, \\hat{g}) \\geqslant 0$.\n4. 设总体 $X \\sim N\\left(\\mu, \\sigma^{2}\\right), x_{1}, \\cdots, x_{n}$ 为样本, 证明, $\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{*} x_{i}, s^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}$ 分别为 $\\mu, \\sigma^{2}$ 的 UMVUE.\n5. 设总体的概率函数为 $p(x ; \\theta)$, 满足定义 6.3 .1 的条件, 若二阶导数 $\\frac{\\partial^{2}}{\\partial \\theta^{2}} p(x ; \\theta)$ 对一切的 $\\theta \\in \\Theta$存在, 证明  \n$$",
        "metadata": {
            "Header 2": "如题 6.3"
        },
        "type": "Document"
    },
    {
        "page_content": "4. 设总体 $X \\sim N\\left(\\mu, \\sigma^{2}\\right), x_{1}, \\cdots, x_{n}$ 为样本, 证明, $\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{*} x_{i}, s^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}$ 分别为 $\\mu, \\sigma^{2}$ 的 UMVUE.\n5. 设总体的概率函数为 $p(x ; \\theta)$, 满足定义 6.3 .1 的条件, 若二阶导数 $\\frac{\\partial^{2}}{\\partial \\theta^{2}} p(x ; \\theta)$ 对一切的 $\\theta \\in \\Theta$存在, 证明  \n$$\nI(\\theta)=-E\\left(\\frac{\\partial^{2}}{\\partial \\theta^{2}} \\ln p(x ; \\theta)\\right)\n$$  \n6. 设总体密度函数为 $p(x ; \\theta)=\\theta x^{\\theta-1}, 0<x<1, \\theta>0, x_{1}, \\cdots, x_{n}$, 是样本  \n(1) 求 $g(\\theta)=1 / \\theta$ 的最大似然估计;  \n(2) 求 $g(\\theta)$ 的有效估计.  \n7. 设总体密度函数为 $p(x ; \\theta)=\\frac{2 \\theta}{x^{3}} e^{-\\theta / x^{2}}, x>0, \\theta>0$, 求 $\\theta$ 的费希尔信息量 $I(\\theta)$.\n8. 设总体分布列为 $p(x ; \\theta)=\\theta c^{\\theta} x^{-(\\theta+1)}, x>c, c>0$, 已知 $\\theta>0$, 求 $\\theta$ 的费希尔信息量 $I(\\theta)$.\n9. 设总体密度函数为 $P(X=k)=(k-1) \\theta^{2}(1-\\theta)^{k-2}, k=2,3, \\cdots, 0<\\theta<1$, 求 $\\theta$ 的费希尔信息量 $I(\\theta)$.",
        "metadata": {
            "Header 2": "如题 6.3"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 求 $g(\\theta)=1 / \\theta$ 的最大似然估计;  \n(2) 求 $g(\\theta)$ 的有效估计.  \n7. 设总体密度函数为 $p(x ; \\theta)=\\frac{2 \\theta}{x^{3}} e^{-\\theta / x^{2}}, x>0, \\theta>0$, 求 $\\theta$ 的费希尔信息量 $I(\\theta)$.\n8. 设总体分布列为 $p(x ; \\theta)=\\theta c^{\\theta} x^{-(\\theta+1)}, x>c, c>0$, 已知 $\\theta>0$, 求 $\\theta$ 的费希尔信息量 $I(\\theta)$.\n9. 设总体密度函数为 $P(X=k)=(k-1) \\theta^{2}(1-\\theta)^{k-2}, k=2,3, \\cdots, 0<\\theta<1$, 求 $\\theta$ 的费希尔信息量 $I(\\theta)$.\n10. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $G a(\\alpha, \\lambda)$ 的样本, $\\alpha>0$ 已知, 试证明, $\\bar{x} / \\alpha$ 是 $g(\\lambda)=1 / \\lambda$ 的有效估计, 从而也是 UMVUE.",
        "metadata": {
            "Header 2": "如题 6.3"
        },
        "type": "Document"
    },
    {
        "page_content": "在统计学中有两个大的学派: 频率学派 (也称经典学派) 和贝叶斯学派. 本书主要介绍频率学派的理论和方法, 此一小节将对贝叶斯学派做些介绍.",
        "metadata": {
            "Header 2": "6.4 贝叶斯统计"
        },
        "type": "Document"
    },
    {
        "page_content": "我们在前面已经讲过, 统计推断是根据样本信息对总体分布或总体的特征数进行推断, 事实上, 这是经典学派对统计推断的规定, 这里的统计推断使用到两种信息: 总体信息和样本信息; 面贝叶斯学派认为, 除了上述两种信息以外, 统计推断还应该使用第三种信息: 先验信息. 下面我们先把三种信息加以说明.  \n( 1 ) 总体信息\n总体信息即总体分布或总体所属分布族提供的信息. 譬如, 若已知 “总体是正态分布”,则我们就知道很多信息. 譬如: 总体的一切阶矩都存在; 总体密度函数关于均值对称; 总体的所有性质由其一、二阶矩决定; 有许多成熟的统计推断方法可供我们选用等. 总体信息是很重要的信息, 为了获取此种信息往往耗资巨大. 比如, 我国为确认国产轴承寿命分布为韦布尔分布前后花了五年时间,处理了几千个数据后才定下的.  \n(2) 样本信息  \n样本信息即抽取样本所得观测值提供的信息. 譬如, 在有了样本观测值后, 我们可以根据它大概知道总体的一些特征数, 如总体均值、总体方差等等在一个什么范围内. 这是最 “新鲜” 的信息,并且越多越好, 希望通过样本对总体分布或总体的某些特征作出较精确的统计推断. 没有样本就没有统计学可言.  \n(3) 先验信息  \n如果我们把抽取样本看作做一次试验, 则样本信息就是试验中得到的信息. 实际中, 人们在试验之前对要做的问题在经验上和资料上总是有所了解的, 这些信息对统计推断是有益的. 先验信息即是抽样 (试验) 之前有关统计问题的一些信息.一般说来, 先验信息来源于经验和历史资料.先验信息在日常生活和工作中是很重要的. 先看一个例子.  \n例 6.4.1: 在某工厂的产品中每天要抽检 $n$ 件以确定该厂产品的质量是否满足要求. 产品质量可用不合格品率 $p$ 来度量, 也可以用 $n$ 件抽查产品中的不合格品件数 $\\theta$ 表示. 由于生产过程有连续性,可以认为每天的产品质量是有关联的, 即是说, 在估计现在的 $p$ 时, 以前所积累的资料应该是可供使用的, 这些积累的历史资料就是先验信息. 为了能使用这些先验信息, 需要对它进行加工. 譬如,在经过一段时间后, 就可根据历史资料对过去 $n$ 件产品中的不合格品件数 $\\theta$ 构造一个分布  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "6.4 贝叶斯统计",
            "Header 3": "6.4.1 统计推断的基础"
        },
        "type": "Document"
    },
    {
        "page_content": "(3) 先验信息  \n如果我们把抽取样本看作做一次试验, 则样本信息就是试验中得到的信息. 实际中, 人们在试验之前对要做的问题在经验上和资料上总是有所了解的, 这些信息对统计推断是有益的. 先验信息即是抽样 (试验) 之前有关统计问题的一些信息.一般说来, 先验信息来源于经验和历史资料.先验信息在日常生活和工作中是很重要的. 先看一个例子.  \n例 6.4.1: 在某工厂的产品中每天要抽检 $n$ 件以确定该厂产品的质量是否满足要求. 产品质量可用不合格品率 $p$ 来度量, 也可以用 $n$ 件抽查产品中的不合格品件数 $\\theta$ 表示. 由于生产过程有连续性,可以认为每天的产品质量是有关联的, 即是说, 在估计现在的 $p$ 时, 以前所积累的资料应该是可供使用的, 这些积累的历史资料就是先验信息. 为了能使用这些先验信息, 需要对它进行加工. 譬如,在经过一段时间后, 就可根据历史资料对过去 $n$ 件产品中的不合格品件数 $\\theta$ 构造一个分布  \n$$\n\\begin{equation*}\nP(\\theta=i)=\\pi_{i}, \\quad i=1,2, \\cdots, n \\tag{6.4.1}\n\\end{equation*}\n$$  \n这种对先验信息进行加工获得的分布今后称为先验分布. 这种先验分布是对该厂过去产品的不合格品率的一个全面看法.  \n基于上述三种信息进行统计推断的统计学称为贝叶斯统计学. 它与经典统计学的差别就在于是否利用先验信息. 贝叶斯统计在重视使用总体信息和样本信息的同时, 还注意先验信息的收集、挖掘和加工, 使它数量化, 形成先验分布, 参加到统计推断中来, 以提高统计推断的质量. 忽视先验信息的利用, 有时是一种浪费, 有时还会导出不合理的结论.  \n贝叶斯学派的基本观点是: 任一未知量 $\\theta$ 都可看作随机变量, 可用一个概率分布去描述, 这个分布称为先验分布; 在获得样本之后, 总体分布、样本与先验分布通过贝叶斯公式结合起来得到-一个关于未知量 $\\theta$ 新的分布一一后验分布; 任何关于 $\\theta$ 的统计推断都应该基于 8 的后验分布进行。",
        "metadata": {
            "Header 2": "6.4 贝叶斯统计",
            "Header 3": "6.4.1 统计推断的基础"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nP(\\theta=i)=\\pi_{i}, \\quad i=1,2, \\cdots, n \\tag{6.4.1}\n\\end{equation*}\n$$  \n这种对先验信息进行加工获得的分布今后称为先验分布. 这种先验分布是对该厂过去产品的不合格品率的一个全面看法.  \n基于上述三种信息进行统计推断的统计学称为贝叶斯统计学. 它与经典统计学的差别就在于是否利用先验信息. 贝叶斯统计在重视使用总体信息和样本信息的同时, 还注意先验信息的收集、挖掘和加工, 使它数量化, 形成先验分布, 参加到统计推断中来, 以提高统计推断的质量. 忽视先验信息的利用, 有时是一种浪费, 有时还会导出不合理的结论.  \n贝叶斯学派的基本观点是: 任一未知量 $\\theta$ 都可看作随机变量, 可用一个概率分布去描述, 这个分布称为先验分布; 在获得样本之后, 总体分布、样本与先验分布通过贝叶斯公式结合起来得到-一个关于未知量 $\\theta$ 新的分布一一后验分布; 任何关于 $\\theta$ 的统计推断都应该基于 8 的后验分布进行。  \n关于未知量是否可看作随机变量在经典学派与贝叶斯学派间争论了很长时间. 因为任一未知量都有不确定性, 而在表述不确定性的程度时, 概率与概率分布是最好的语言, 因此把它看成随机变量是合理的. 如今经典学派已不反对这一观点: 著名的美国经典统计学家奈曼 (Lehmann, E.L.)在他的《点估计理论》一书中写道: “把统计问题中的参数看作随机变量的实现要比看作未知参数更合理一些” 如今两派的争论焦点是: 如何利用各种先验信息合理地确定先验分布. 这在有些场合是容易解决的, 但在很多场合是相当困难的, 关于这方面问题的讨论可参阅文献 [11].",
        "metadata": {
            "Header 2": "6.4 贝叶斯统计",
            "Header 3": "6.4.1 统计推断的基础"
        },
        "type": "Document"
    },
    {
        "page_content": "贝叶斯公式的事件形式已在??节中叙述. 这里用随机变量的概率函数再一次叙述贝叶斯公式,并从中介绍贝叶斯学派的一些具体想法.  \n(1) 总体依赖于参数 $\\theta$ 的概率函数在经典统计中记为 $p(x ; \\theta)$, 它表示参数空间 $\\Theta$ 中不同的 $\\theta$对应不同的分布. 在贝叶斯统计中应记为 $p(x \\mid \\theta)$, 它表示在随机变量 $\\theta$ 取某个给定值时总体的条",
        "metadata": {
            "Header 2": "6.4 贝叶斯统计",
            "Header 3": "6.4.2 贝叶斯公式的密度函数形式"
        },
        "type": "Document"
    },
    {
        "page_content": "( 2 ) 根据参数 $\\theta$ 的先验信息确定先验分布 $\\pi(\\theta)$.  \n(3) 从贝叶斯观点看, 样本 $\\boldsymbol{X}=\\left(x_{1}, \\cdots, x_{n}\\right)$ 的产生要分两步进行. 首先设想从先验分布 $\\pi(\\theta)$ 产生一个样本 $\\theta_{0}$. 这一步是 “老天爷” 做的, 人们是看不到的, 故用 “设想”二字. 第二步从 $p\\left(\\boldsymbol{X} \\mid \\theta_{0}\\right)$ 中产生一组样本. 这时样本 $\\boldsymbol{X}=\\left(x_{1}, \\cdots, x_{n}\\right)$ 的联合条件概率函数为  \n$$\np\\left(\\boldsymbol{X} \\mid \\theta_{0}\\right)=p\\left(x_{1}, \\cdots, x_{n} \\mid \\theta_{0}\\right)=\\prod_{i=1}^{n} p\\left(x_{i} \\mid \\theta_{0}\\right)\n$$  \n这个分布综合了总体信息和样本信息.  \n(4) 由于 $\\theta_{0}$ 是设想出来的, 仍然是未知的, 它是按先验分布 $\\pi(\\theta)$ 产生的. 为把先验信息综合进去, 不能只考虑 $\\theta$, 对 $\\theta$ 的其他值发生的可能性也要加以考虑, 故要用 $\\pi(\\theta)$ 进行综合. 这样一来,样本 $\\boldsymbol{X}$ 和参数 $\\theta$ 的联合分布为  \n$$\nh(\\boldsymbol{X}, \\theta)=p(\\boldsymbol{X} \\mid \\theta) \\pi(\\theta)\n$$  \n这个联合分布把总体信息、样本信息和先验信息三种可用信息都综合进去了.",
        "metadata": {
            "Header 2": "件概率函数."
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np\\left(\\boldsymbol{X} \\mid \\theta_{0}\\right)=p\\left(x_{1}, \\cdots, x_{n} \\mid \\theta_{0}\\right)=\\prod_{i=1}^{n} p\\left(x_{i} \\mid \\theta_{0}\\right)\n$$  \n这个分布综合了总体信息和样本信息.  \n(4) 由于 $\\theta_{0}$ 是设想出来的, 仍然是未知的, 它是按先验分布 $\\pi(\\theta)$ 产生的. 为把先验信息综合进去, 不能只考虑 $\\theta$, 对 $\\theta$ 的其他值发生的可能性也要加以考虑, 故要用 $\\pi(\\theta)$ 进行综合. 这样一来,样本 $\\boldsymbol{X}$ 和参数 $\\theta$ 的联合分布为  \n$$\nh(\\boldsymbol{X}, \\theta)=p(\\boldsymbol{X} \\mid \\theta) \\pi(\\theta)\n$$  \n这个联合分布把总体信息、样本信息和先验信息三种可用信息都综合进去了.  \n( 5 ) 我们的目的是要对未知参数 $\\theta$ 作统计推断. 在没有样本信息时, 我们只能依据先验分布对 $\\theta$ 作出推断. 在有了样本观察值 $\\boldsymbol{X}=\\left(x_{1}, \\cdots, x_{n}\\right)$ 之后, 我们应依据 $h(\\boldsymbol{X}, \\theta)$ 对 $\\theta$ 作出推断. 若把 $h(\\mathbf{X}, \\theta)$ 作如下分解:  \n$$\nh(\\boldsymbol{X}, \\theta)=\\pi(\\theta \\mid \\boldsymbol{X}) m(\\boldsymbol{X})\n$$  \n其中 $m(\\boldsymbol{X})$ 是 $X$ 的边际概率函数:  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "件概率函数."
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nh(\\boldsymbol{X}, \\theta)=p(\\boldsymbol{X} \\mid \\theta) \\pi(\\theta)\n$$  \n这个联合分布把总体信息、样本信息和先验信息三种可用信息都综合进去了.  \n( 5 ) 我们的目的是要对未知参数 $\\theta$ 作统计推断. 在没有样本信息时, 我们只能依据先验分布对 $\\theta$ 作出推断. 在有了样本观察值 $\\boldsymbol{X}=\\left(x_{1}, \\cdots, x_{n}\\right)$ 之后, 我们应依据 $h(\\boldsymbol{X}, \\theta)$ 对 $\\theta$ 作出推断. 若把 $h(\\mathbf{X}, \\theta)$ 作如下分解:  \n$$\nh(\\boldsymbol{X}, \\theta)=\\pi(\\theta \\mid \\boldsymbol{X}) m(\\boldsymbol{X})\n$$  \n其中 $m(\\boldsymbol{X})$ 是 $X$ 的边际概率函数:  \n$$\n\\begin{equation*}\nm(\\boldsymbol{X})=\\int_{\\boldsymbol{\\theta}} h(\\boldsymbol{X}, \\theta) \\mathrm{d} \\theta=\\int_{\\boldsymbol{\\theta}} p(\\boldsymbol{X} \\mid \\theta) \\pi(\\theta) \\mathrm{d} \\theta \\tag{6.4.2}\n\\end{equation*}\n$$  \n它与 $\\theta$ 无关, 或者说 $m(\\boldsymbol{X})$ 中不含 $\\theta$ 的任何信息. 因此能用来对 $\\theta$ 作出推断的仅是条件分布 $\\pi(\\theta \\mid \\mathbf{X})$, 它的计算公式是  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "件概率函数."
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其中 $m(\\boldsymbol{X})$ 是 $X$ 的边际概率函数:  \n$$\n\\begin{equation*}\nm(\\boldsymbol{X})=\\int_{\\boldsymbol{\\theta}} h(\\boldsymbol{X}, \\theta) \\mathrm{d} \\theta=\\int_{\\boldsymbol{\\theta}} p(\\boldsymbol{X} \\mid \\theta) \\pi(\\theta) \\mathrm{d} \\theta \\tag{6.4.2}\n\\end{equation*}\n$$  \n它与 $\\theta$ 无关, 或者说 $m(\\boldsymbol{X})$ 中不含 $\\theta$ 的任何信息. 因此能用来对 $\\theta$ 作出推断的仅是条件分布 $\\pi(\\theta \\mid \\mathbf{X})$, 它的计算公式是  \n$$\n\\begin{equation*}\n\\pi(\\theta \\mid \\boldsymbol{X})=\\frac{h(\\boldsymbol{X}, \\theta)}{m(\\boldsymbol{X})}=\\frac{p(\\boldsymbol{X} \\mid \\theta) \\pi(\\theta)}{\\int_{\\boldsymbol{\\theta}} p(\\boldsymbol{X} \\mid \\theta) \\pi(\\theta) \\mathrm{d} \\theta} \\tag{6.4.3}\n\\end{equation*}\n$$  \n这个条件分布称为 $\\theta$ 的后验分布, 它集中了总体、样本和先验中有关 $\\theta$ 的一切信息. (6.4.3)就是用密度函数表示的贝叶斯公式, 它也是用总体和样本对先验分布 $\\pi(\\theta)$ 作调整的结果, 它要比 $\\pi(\\theta)$ 更接近 $\\theta$ 的实际情况.",
        "metadata": {
            "Header 2": "件概率函数."
        },
        "type": "Document"
    },
    {
        "page_content": "由后验分布 $\\pi(\\theta \\mid \\boldsymbol{X})$ 估计 $\\theta$ 有三种常用的方法：  \n- 使用后验分布的密度函数最大值点作为 $\\theta$ 的点估计的最大后验估计;  \n。使用后验分布的中位数作为 $\\theta$ 的点估计的后验中位数估计;  \n- 使用后验分布的均值作为 $\\theta$ 的点估计的后验期望估计.  \n用得最多的是后验期望估计, 它一般也简称为贝叶斯估计, 记为的 $\\hat{\\theta}_{\\theta}$.  \n例 6.4.2: 设某事件 $A$ 在一次试验中发生的概率为 $\\theta$, 为估计 $\\theta$, 对试验进行了 $n$ 次独立观测, 其中事件 $A$ 发生了 $X$ 次, 显然 $X \\mid \\theta \\sim b(n, \\theta)$, 即  \n$$\nP(X=x \\mid \\theta)=\\left(\\begin{array}{l}\nn \\\\\nx\n\\end{array}\\right) \\theta^{x}(1-\\theta)^{n-x}, \\quad x=0,1, \\cdots, n\n$$  \n假若我们在试验前对事件 $A$ 没有什么了解, 从而对其发生的概率日也没有任何信息. 在这种场合,贝叶斯本人建议采用 “同等无知” 的原则使用区间 $(0,1)$ 上的均匀分布 $U(0,1)$ 作为 $\\theta$ 的先验分布,因为它取 $(0,1)$ 上的每一点的机会均等. 贝叶斯的这个建议被后人称为贝叶斯假设, 由此即可利用\n贝叶斯公式求出 $\\theta$ 的后验分布. 具体如下: 先写出 $X$ 和 $\\theta$ 的联合分布  \n$$\nh(x, \\theta)=\\left(\\begin{array}{l}\nn \\\\\nx\n\\end{array}\\right) \\theta^{x}(1-\\theta)^{n-x}, \\quad x=0,1, \\cdots, n, \\quad 0<\\theta<1\n$$  \n然后求 $X$ 的边际分布  \n$$\nm(x)=\\left(\\begin{array}{l}\nn \\\\\nx",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.3 贝叶斯估计"
        },
        "type": "Document"
    },
    {
        "page_content": "n \\\\\nx\n\\end{array}\\right) \\theta^{x}(1-\\theta)^{n-x}, \\quad x=0,1, \\cdots, n\n$$  \n假若我们在试验前对事件 $A$ 没有什么了解, 从而对其发生的概率日也没有任何信息. 在这种场合,贝叶斯本人建议采用 “同等无知” 的原则使用区间 $(0,1)$ 上的均匀分布 $U(0,1)$ 作为 $\\theta$ 的先验分布,因为它取 $(0,1)$ 上的每一点的机会均等. 贝叶斯的这个建议被后人称为贝叶斯假设, 由此即可利用\n贝叶斯公式求出 $\\theta$ 的后验分布. 具体如下: 先写出 $X$ 和 $\\theta$ 的联合分布  \n$$\nh(x, \\theta)=\\left(\\begin{array}{l}\nn \\\\\nx\n\\end{array}\\right) \\theta^{x}(1-\\theta)^{n-x}, \\quad x=0,1, \\cdots, n, \\quad 0<\\theta<1\n$$  \n然后求 $X$ 的边际分布  \n$$\nm(x)=\\left(\\begin{array}{l}\nn \\\\\nx\n\\end{array}\\right) \\int_{0}^{1} \\theta^{x}(1-\\theta)^{n \\cdot x} \\mathrm{~d} \\theta=\\left(\\begin{array}{l}\nn \\\\\nx\n\\end{array}\\right) \\frac{\\Gamma(x+1) \\Gamma(n-x+1)}{\\Gamma(n+2)}\n$$  \n最后求出 $\\theta$ 的后验分布  \n$$\n\\begin{aligned}\n\\pi(\\theta \\mid x) & =\\frac{h(x, \\theta)}{m(x)} \\\\\n& =\\frac{\\Gamma(n+2)}{\\Gamma(x+1) \\Gamma(n-x+1)} \\theta^{(x+1)-1}(1-\\theta)^{(n-x+1)-1}, \\quad 0<\\theta<1\n\\end{aligned}\n$$  \n最后的结果说明 $\\theta \\mid x \\sim B e(x+1, n-x+1)$, 其后验期望估计为  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.3 贝叶斯估计"
        },
        "type": "Document"
    },
    {
        "page_content": "n \\\\\nx\n\\end{array}\\right) \\int_{0}^{1} \\theta^{x}(1-\\theta)^{n \\cdot x} \\mathrm{~d} \\theta=\\left(\\begin{array}{l}\nn \\\\\nx\n\\end{array}\\right) \\frac{\\Gamma(x+1) \\Gamma(n-x+1)}{\\Gamma(n+2)}\n$$  \n最后求出 $\\theta$ 的后验分布  \n$$\n\\begin{aligned}\n\\pi(\\theta \\mid x) & =\\frac{h(x, \\theta)}{m(x)} \\\\\n& =\\frac{\\Gamma(n+2)}{\\Gamma(x+1) \\Gamma(n-x+1)} \\theta^{(x+1)-1}(1-\\theta)^{(n-x+1)-1}, \\quad 0<\\theta<1\n\\end{aligned}\n$$  \n最后的结果说明 $\\theta \\mid x \\sim B e(x+1, n-x+1)$, 其后验期望估计为  \n$$\n\\begin{equation*}\n\\hat{\\theta}_{\\mathrm{B}}=E(\\theta \\mid x)=\\frac{x+1}{n+2} \\tag{6.4.4}\n\\end{equation*}\n$$  \n假如不用先验信息, 只用总体信息与样本信息, 那么事件 $\\mathrm{A}$ 发生的概率的最大似然估计为  \n$$\n\\hat{\\theta}_{M}=\\frac{x}{n}\n$$",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.3 贝叶斯估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\pi(\\theta \\mid x) & =\\frac{h(x, \\theta)}{m(x)} \\\\\n& =\\frac{\\Gamma(n+2)}{\\Gamma(x+1) \\Gamma(n-x+1)} \\theta^{(x+1)-1}(1-\\theta)^{(n-x+1)-1}, \\quad 0<\\theta<1\n\\end{aligned}\n$$  \n最后的结果说明 $\\theta \\mid x \\sim B e(x+1, n-x+1)$, 其后验期望估计为  \n$$\n\\begin{equation*}\n\\hat{\\theta}_{\\mathrm{B}}=E(\\theta \\mid x)=\\frac{x+1}{n+2} \\tag{6.4.4}\n\\end{equation*}\n$$  \n假如不用先验信息, 只用总体信息与样本信息, 那么事件 $\\mathrm{A}$ 发生的概率的最大似然估计为  \n$$\n\\hat{\\theta}_{M}=\\frac{x}{n}\n$$  \n它与贝叶斯估计是不同的两个估计. 某些场合, 贝叶斯估计要比最大似然估计更合理一点. 比如,在产品抽样检验中只区分合格品和不合格品, 对质量好的产品批, 抽检的产品常为合格品, 但 “抽检 3 个全是合格品” 与 “抽检 10 个全是合格品” 这两个事件在人们心目中留下的印象是不同的, 后者的质量比前者更信得过. 这种差别在不合格品率 $\\theta$ 最大似然估计 $\\hat{\\theta}_{M}$ 中反映不出来 (两者都为 $\\theta)$, 而用贝叶斯估计 $\\hat{\\theta}_{B}$ 则有所反映, 两者分别是 $1 /(3+2)=0.20$ 和 $1 /(10+2)=0.083$. 类似地,对质量差的产品批, 抽检的产品常为不合格品, 这时 “抽检 3 个全是不合格品” 与 “抽检 10 个全是不合格品” 也是有差别的两个事件, 前者质量很差, 后者则不可救药. 这种差别用 $\\hat{\\theta}_{M}$ 也反映不出 (两者都是 1 ), 而 $\\hat{\\theta}_{B}$ 则分别是 $(3+1) /(3+2)=0.80$ 和 $(10+1) /(10+2)=0.917$. 由此可以看到,在这些极端情况下, 贝叶斯估计比最大似然估计更符合人们的理念",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.3 贝叶斯估计"
        },
        "type": "Document"
    },
    {
        "page_content": "例 6.4.3: 设 $x_{1}, \\cdots, x_{n}$ 是来自正态分布 $N\\left(\\mu, \\sigma_{0}^{2}\\right)$ 的一个样本, 其中品已知, $\\mu$ 未知, 假设 $\\mu$ 的先验分布亦为正态分布 $N\\left(\\theta, \\tau^{2}\\right)$, 其中先验均值 8 和先验方差 $\\tau^{2}$ 均已知, 试求 $\\mu$ 的贝叶斯估计.  \n解: 样本 $\\boldsymbol{X}$ 的分布和 $\\mu$ 的先验分布分别为  \n$$\n\\begin{gathered}\np(\\boldsymbol{X} \\mid \\mu)=\\left(2 \\pi \\sigma_{0}^{2}\\right)^{-n / 2} \\exp \\left\\{-\\frac{1}{2 \\sigma_{0}^{2}} \\sum_{i=1}^{n}\\left(x_{i}-\\mu\\right)^{2}\\right\\} \\\\\n\\pi(\\mu)=\\left(2 \\pi \\tau^{2}\\right)^{-1 / 2} \\exp \\left\\{-\\frac{1}{2 \\tau^{2}}(\\mu-\\theta)^{2}\\right\\}\n\\end{gathered}\n$$  \n由此可以写出 $X$ 与 $\\mu$ 的联合分布  \n$$\nh(\\boldsymbol{X}, \\mu)=k_{1} \\cdot \\exp \\left\\{-\\frac{1}{2}\\left[\\frac{n_{\\mu}^{2}-2 n \\mu \\bar{x}+\\sum_{i=1}^{n} x_{i}^{2}}{\\sigma_{0}^{2}}+\\frac{\\mu^{2}-2 \\theta_{\\mu}+\\theta^{2}}{\\tau^{2}}\\right]\\right\\}\n$$  \n其中 $\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}, k_{1}=(2 \\pi)^{-(n+1) / 2} \\tau^{-1} \\sigma_{0}^{-n}$, 若记  \n则有  \n$$",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.3 贝叶斯估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\pi(\\mu)=\\left(2 \\pi \\tau^{2}\\right)^{-1 / 2} \\exp \\left\\{-\\frac{1}{2 \\tau^{2}}(\\mu-\\theta)^{2}\\right\\}\n\\end{gathered}\n$$  \n由此可以写出 $X$ 与 $\\mu$ 的联合分布  \n$$\nh(\\boldsymbol{X}, \\mu)=k_{1} \\cdot \\exp \\left\\{-\\frac{1}{2}\\left[\\frac{n_{\\mu}^{2}-2 n \\mu \\bar{x}+\\sum_{i=1}^{n} x_{i}^{2}}{\\sigma_{0}^{2}}+\\frac{\\mu^{2}-2 \\theta_{\\mu}+\\theta^{2}}{\\tau^{2}}\\right]\\right\\}\n$$  \n其中 $\\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}, k_{1}=(2 \\pi)^{-(n+1) / 2} \\tau^{-1} \\sigma_{0}^{-n}$, 若记  \n则有  \n$$\nA=\\frac{n}{\\sigma_{0}^{2}}+\\frac{1}{\\tau^{2}}, \\quad B=\\frac{n \\bar{x}}{\\sigma_{0}^{2}}+\\frac{\\theta}{\\tau^{2}}, \\quad C=\\frac{\\sum_{i=1}^{n} x_{i}^{2}}{\\sigma_{0}^{2}}+\\frac{\\theta^{2}}{\\tau^{2}}\n$$  \n$$\n\\begin{aligned}\nh(\\boldsymbol{X}, \\mu) & =k_{1} \\exp \\left\\{-\\frac{1}{2}\\left[A \\mu^{2}-2 B \\mu+C\\right]\\right\\} \\\\\n& =k_{1} \\exp \\left\\{-\\frac{(\\mu-B / A)^{2}}{2 / A}-\\frac{1}{2}\\left(C-B^{2} / A\\right)\\right\\}\n\\end{aligned}\n$$  \n注意到 $A, B, C$ 均与 $\\mu$ 无关, 由此容易算得样本的边际密度函数  \n$$",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.3 贝叶斯估计"
        },
        "type": "Document"
    },
    {
        "page_content": "则有  \n$$\nA=\\frac{n}{\\sigma_{0}^{2}}+\\frac{1}{\\tau^{2}}, \\quad B=\\frac{n \\bar{x}}{\\sigma_{0}^{2}}+\\frac{\\theta}{\\tau^{2}}, \\quad C=\\frac{\\sum_{i=1}^{n} x_{i}^{2}}{\\sigma_{0}^{2}}+\\frac{\\theta^{2}}{\\tau^{2}}\n$$  \n$$\n\\begin{aligned}\nh(\\boldsymbol{X}, \\mu) & =k_{1} \\exp \\left\\{-\\frac{1}{2}\\left[A \\mu^{2}-2 B \\mu+C\\right]\\right\\} \\\\\n& =k_{1} \\exp \\left\\{-\\frac{(\\mu-B / A)^{2}}{2 / A}-\\frac{1}{2}\\left(C-B^{2} / A\\right)\\right\\}\n\\end{aligned}\n$$  \n注意到 $A, B, C$ 均与 $\\mu$ 无关, 由此容易算得样本的边际密度函数  \n$$\nm(\\boldsymbol{X})=\\int_{-\\infty}^{+\\infty} h(\\boldsymbol{X}, \\mu) \\mathrm{d} \\mu=k_{1} \\exp \\left\\{-\\frac{1}{2}\\left(C-B^{2} / A\\right)\\right\\}(2 \\pi / A)^{1 / 2}\n$$  \n应用贝叶斯公式即可得到后验分布  \n$$\n\\pi(\\mu \\mid \\boldsymbol{X})=\\frac{h(\\boldsymbol{X}, \\underline{\\mu})}{m(\\boldsymbol{X})}=(2 \\pi / A)^{1 / 2} \\exp \\left\\{-\\frac{1}{2 / A}\\left(\\mu-B(A)^{2}\\right)\\right\\}\n$$  \n这说明在样本给定后, $\\mu$ 的后验分布为 $N(B / A, 1 / A)$, 即  \n$$",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.3 贝叶斯估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n注意到 $A, B, C$ 均与 $\\mu$ 无关, 由此容易算得样本的边际密度函数  \n$$\nm(\\boldsymbol{X})=\\int_{-\\infty}^{+\\infty} h(\\boldsymbol{X}, \\mu) \\mathrm{d} \\mu=k_{1} \\exp \\left\\{-\\frac{1}{2}\\left(C-B^{2} / A\\right)\\right\\}(2 \\pi / A)^{1 / 2}\n$$  \n应用贝叶斯公式即可得到后验分布  \n$$\n\\pi(\\mu \\mid \\boldsymbol{X})=\\frac{h(\\boldsymbol{X}, \\underline{\\mu})}{m(\\boldsymbol{X})}=(2 \\pi / A)^{1 / 2} \\exp \\left\\{-\\frac{1}{2 / A}\\left(\\mu-B(A)^{2}\\right)\\right\\}\n$$  \n这说明在样本给定后, $\\mu$ 的后验分布为 $N(B / A, 1 / A)$, 即  \n$$\n\\mu \\left\\lvert\\, \\mathbf{X} \\sim N\\left(\\frac{n \\bar{x} \\sigma_{0}^{-2}+\\theta_{\\tau}^{-2}}{n \\sigma_{0}^{-2}+r^{-2}}, \\frac{1}{n \\sigma_{0}^{-2}+\\tau^{-2}}\\right)\\right.\n$$  \n后验均值即为其贝叶斯估计：  \n$$\n\\dot{\\mu}=\\frac{n / \\sigma_{0}^{2}}{n / \\sigma_{0}^{2}+1 / \\tau^{2}} \\bar{x}+\\frac{1 / \\tau^{2}}{n / \\sigma_{0}^{2}+1 / r^{2}} \\theta\n$$  \n它是样本均值 $\\bar{x}$ 与先验均值 $\\theta$ 的加权平均. 当总体方差 $\\sigma_{0}^{2}$ 较小或样本量 $n$ 较大时, 样本均值 $\\bar{x}$ 的权重较大; 当先验方差 $\\tau^{2}$ 较小时, 先验均值 $\\theta$ 的权重较大, 这一综合很符合人们的经验, 也是可以接收的.",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.3 贝叶斯估计"
        },
        "type": "Document"
    },
    {
        "page_content": "从贝叶斯公式可以看出, 整个贝叶斯统计推断只要先验分布确定后就没有理论上的困难. 关于先验分布的确定有多种途径, 此处我们介绍一类最常用的先 “验分布类——共扼先验分布.  \n定义 6.4.1. 设日是总体参数, $\\pi(\\theta)$ 是其先验分布, 若对任意的样本观测值得到的后验分布 $\\pi(\\theta \\mid \\boldsymbol{X})$与 $\\pi(\\theta)$ 属于同一个分布族, 则称该分布族是 $\\theta$ 的共扼先验分布 (族).  \n例 6.4.4: 在例 6.4.2中, 我们知道 $(0,1)$ 上的均匀分布就是贝塔分布的一个特例 $B e(1,1)$, 其对应的后验分布则是贝塔分布 $B e(x+1, n-x+1)$. 更一般地, 设 $\\theta$ 的先验分布是 $B e(a, b), a>0, b>$ $0, a, b$ 均已知, 则由贝叶斯公式可以求出后验分布为 $B e(x+a, n-x+b)$, 这说明贝塔分布是伯努利试验中成功概率的共扼先验分布.  \n类似地, 由例6.4.3可以看出, 在方差已知时正态总体均值的共扼先验分布是正态分布.",
        "metadata": {
            "Header 2": "件概率函数.",
            "Header 3": "6.4.4 共轭先验分部"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设一页书上的错别字个数服从泊松分布 $P(\\lambda), \\lambda$ 有两个可能取值: 1.5 和 1.8 , 且先验分布为  \n$$\nP(\\lambda=1.5)=0.45, P(\\lambda=1.8)=0.55\n$$  \n现检查了一页, 发现有 3 个错别字, 试求 $\\lambda$ 的后验分布。  \n2. 设总体为均匀分布 $U(\\theta, \\theta+1), \\theta$ 的先验分布是均匀分布 $U(10,16)$. 现有三个观测值: 11.7, 12.1, 12.0.求 $\\theta$ 的后验分布.\n3. 设 $x_{1}, \\cdots, x_{n}$ 是来自几何分布的样本, 总体分布列为  \n$$\nP(X=k \\mid \\theta)=\\theta(1-\\theta)^{k}, k=0,1,2, \\cdots\n$$  \n$\\theta$ 的先验分布是均匀分布 $U(0,1)$.  \n(1) 求 $\\theta$ 的后验分布;  \n(2) 若 4 次观测值为 $4,3,1,6$, 求 $\\theta$ 的贝叶斯估计.  \n4. 验证: 泊松分布的均值 $\\lambda$ 的共轭先验分布是伽玛分布.\n5. 验证: 正态总体方差 (均值已知) 的共斩先验分布是倒伽玛分布.\n6. 设 $x_{1}, \\cdots, x_{n}$ 是来自如下总体的一个样本  \n$$\np(x \\mid \\theta)=\\frac{2 x}{\\theta^{2}}, \\quad 0<x<\\theta\n$$  \n(1) 若 $\\theta$ 的先验分布为均匀分布 $U(0,1)$, 求 $\\theta$ 的后验分布;  \n(2) 若 $\\theta$ 的先验分布为 $\\pi(\\theta)=3 \\theta^{2}, 0<\\theta<1$, 求 $\\theta$ 的后验分布.  \n7. 设 $x_{1}, \\cdots, x_{n}$ 是来自如下总体的一个样本  \n$$\np(x \\mid \\theta)=\\theta x^{\\theta-1}, \\quad 0<x<1\n$$  \n若取 $\\theta$ 的先验分布为伽玛分布, 即 $\\theta \\sim G a(\\alpha, \\lambda)$, 求 $\\theta$ 的后验期望估计.",
        "metadata": {
            "Header 2": "如 题 6.4"
        },
        "type": "Document"
    },
    {
        "page_content": "5. 验证: 正态总体方差 (均值已知) 的共斩先验分布是倒伽玛分布.\n6. 设 $x_{1}, \\cdots, x_{n}$ 是来自如下总体的一个样本  \n$$\np(x \\mid \\theta)=\\frac{2 x}{\\theta^{2}}, \\quad 0<x<\\theta\n$$  \n(1) 若 $\\theta$ 的先验分布为均匀分布 $U(0,1)$, 求 $\\theta$ 的后验分布;  \n(2) 若 $\\theta$ 的先验分布为 $\\pi(\\theta)=3 \\theta^{2}, 0<\\theta<1$, 求 $\\theta$ 的后验分布.  \n7. 设 $x_{1}, \\cdots, x_{n}$ 是来自如下总体的一个样本  \n$$\np(x \\mid \\theta)=\\theta x^{\\theta-1}, \\quad 0<x<1\n$$  \n若取 $\\theta$ 的先验分布为伽玛分布, 即 $\\theta \\sim G a(\\alpha, \\lambda)$, 求 $\\theta$ 的后验期望估计.  \n8. 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀分布 $U(0, \\theta)$ 的样本, $\\theta$ 的先验分布是 Pareto 分布, 其密度函数为 $\\pi(\\theta)=\\frac{\\beta \\theta_{0}^{\\beta}}{\\theta^{\\theta+1}}, \\theta>\\theta_{0}$, 其中 $\\beta, \\theta_{0}$ 是两个已知的常数.  \n(1) 验证: Pareto 分布是 $\\theta$ 的共扼先验分布;  \n(2) 求 $\\theta$ 的贝叶斯估计.  \n9. 设指数分布 $\\operatorname{Exp}(\\theta)$ 中未知参数 $\\theta$ 的先验分布为伽玛分布 $G a(\\alpha, \\lambda)$, 现从先验信息得知: 先验均值为 0.0002 , 先验标准差为 0.0001 , 试确定先验分布.",
        "metadata": {
            "Header 2": "如 题 6.4"
        },
        "type": "Document"
    },
    {
        "page_content": "参数的点估计给出了一个具体的数值, 便于计算和使用, 但其精度如何点估计本身不能回答,需要由其分布来反映. 实际中, 度一个点估计的精度的最直观的方法就是给出未知参数的一个区间, 这便产生区间估计的概念.",
        "metadata": {
            "Header 2": "6.5 区间估计"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $\\theta$ 是总体的一个参数, $x_{1}, \\cdots, x_{n}$ 是样本, 所谓区间估计就是要找两个统计量元 $\\hat{\\theta}_{L}=$ $\\hat{\\theta}_{L}\\left(x_{1}, \\cdots, x_{n}\\right)$ 和 $\\hat{\\theta}_{\\mathrm{U}}=\\hat{\\theta}_{U}\\left\\langle x_{1}, \\cdots, x_{n}\\right)$, 使得 $\\hat{\\theta}_{L}<\\hat{\\theta}_{U}$, 在得到样本观测值之后, 就把 $\\theta$ 估计在区间 $\\left[\\hat{\\theta}_{L}, \\hat{\\theta}_{U}\\right]$ 内. 显然, 作为区间估计通常要求区间 $\\left[\\hat{\\theta}_{L}, \\hat{\\theta}_{U}\\right]$ 盖住 $\\theta$ 的概率 $P\\left(\\hat{\\theta}_{L} \\leqslant \\theta \\leqslant \\hat{\\theta}_{U}\\right)$ 尽可能大, 但这必然导致区间长度增大, 为平衡此矛盾, 把区间 $\\left[\\hat{\\theta}_{L}, \\hat{\\theta}_{U}\\right]$ 盖住 $\\theta$ 的概率 (以后称为置信水平) 事先给定, 这就引人如下置信区间的概念.  \n定义 6.5.1. 设 $\\theta$ 是总体的一个参数, 其参数空间为 $\\Theta, x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, 对给定的一个 $\\alpha(0<\\alpha<1)$, 若有两个统计量 $\\hat{\\theta}_{2}=\\hat{\\theta}_{2}\\left(x_{1}, \\cdots, x_{n}\\right)$ 和 $\\hat{\\theta}_{U}=\\hat{\\theta}_{U}\\left(x_{1}, \\cdots, x_{n}\\right)$, 若对任意的 $\\theta \\in \\Theta$,有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "6.5 区间估计",
            "Header 3": "6.5.1 区间估计的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 6.5.1. 设 $\\theta$ 是总体的一个参数, 其参数空间为 $\\Theta, x_{1}, \\cdots, x_{n}$ 是来自该总体的样本, 对给定的一个 $\\alpha(0<\\alpha<1)$, 若有两个统计量 $\\hat{\\theta}_{2}=\\hat{\\theta}_{2}\\left(x_{1}, \\cdots, x_{n}\\right)$ 和 $\\hat{\\theta}_{U}=\\hat{\\theta}_{U}\\left(x_{1}, \\cdots, x_{n}\\right)$, 若对任意的 $\\theta \\in \\Theta$,有  \n$$\n\\begin{equation*}\nP_{\\theta}\\left(\\hat{\\theta}_{L} \\leqslant \\theta \\leqslant \\hat{\\theta}_{U}\\right) \\geqslant 1-\\alpha \\tag{6.5.1}\n\\end{equation*}\n$$  \n则称随机区间 $\\left[\\hat{\\theta}_{\\mathrm{L}}, \\hat{\\theta}_{\\mathrm{U}}\\right]$ 为 $\\theta$ 的置信水平为 $1-\\alpha$ 的置信区间, 或简称 $\\left[\\hat{\\theta}_{\\mathrm{L}}, \\hat{\\theta}_{\\mathrm{U}}\\right]$ 是 $\\theta$ 的 $1-\\alpha$ 置信区间, $\\hat{\\theta}_{\\mathrm{L}}$ 和 $\\hat{\\theta}_{\\mathrm{U}}$ 分别称为 $\\theta$ 的 (双侧) 量信下限和量信上限.",
        "metadata": {
            "Header 2": "6.5 区间估计",
            "Header 3": "6.5.1 区间估计的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nP_{\\theta}\\left(\\hat{\\theta}_{L} \\leqslant \\theta \\leqslant \\hat{\\theta}_{U}\\right) \\geqslant 1-\\alpha \\tag{6.5.1}\n\\end{equation*}\n$$  \n则称随机区间 $\\left[\\hat{\\theta}_{\\mathrm{L}}, \\hat{\\theta}_{\\mathrm{U}}\\right]$ 为 $\\theta$ 的置信水平为 $1-\\alpha$ 的置信区间, 或简称 $\\left[\\hat{\\theta}_{\\mathrm{L}}, \\hat{\\theta}_{\\mathrm{U}}\\right]$ 是 $\\theta$ 的 $1-\\alpha$ 置信区间, $\\hat{\\theta}_{\\mathrm{L}}$ 和 $\\hat{\\theta}_{\\mathrm{U}}$ 分别称为 $\\theta$ 的 (双侧) 量信下限和量信上限.  \n置信水平 $1-\\alpha$ 有一个频率解释: 在大量重复使用 $\\theta$ 的置信区间 $\\left[\\hat{\\theta}_{\\mathrm{L}}, \\hat{\\theta}_{\\mathrm{U}}\\right]$ 时, 每次得到的样本观测值是不同的, 从而每次得到的区间估计值也是不一样的. 对一次具体的观测值而言, $\\theta$ 可能在 $\\left[\\hat{\\theta}_{\\mathrm{L}}, \\hat{\\theta}_{\\mathrm{U}}\\right]$ 内, 也可能不在. 平均而言, 在这大量的区间估计观测值中, 至少有 $100(1-\\alpha) \\%$ 包含 $\\theta$. 下例中的图6.5.1和图6.5.2直观地显示了该种频率意义.  \n例 6.5.1: 设 $x_{1}, \\cdots, x_{10}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 则 $\\mu$ 的置信水平为 $1-\\alpha$ 的置信区间为  \n$$",
        "metadata": {
            "Header 2": "6.5 区间估计",
            "Header 3": "6.5.1 区间估计的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "置信水平 $1-\\alpha$ 有一个频率解释: 在大量重复使用 $\\theta$ 的置信区间 $\\left[\\hat{\\theta}_{\\mathrm{L}}, \\hat{\\theta}_{\\mathrm{U}}\\right]$ 时, 每次得到的样本观测值是不同的, 从而每次得到的区间估计值也是不一样的. 对一次具体的观测值而言, $\\theta$ 可能在 $\\left[\\hat{\\theta}_{\\mathrm{L}}, \\hat{\\theta}_{\\mathrm{U}}\\right]$ 内, 也可能不在. 平均而言, 在这大量的区间估计观测值中, 至少有 $100(1-\\alpha) \\%$ 包含 $\\theta$. 下例中的图6.5.1和图6.5.2直观地显示了该种频率意义.  \n例 6.5.1: 设 $x_{1}, \\cdots, x_{10}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 则 $\\mu$ 的置信水平为 $1-\\alpha$ 的置信区间为  \n$$\n\\left[\\bar{x}-t_{1-a / 2}(9) s / \\sqrt{10}, \\bar{x}+t_{1-a / 2}(9) s / \\sqrt{10}\\right]\n$$  \n其中, $\\vec{x}, s$ 分别为样本均值和样本标准差. 这个置信区间的由来将在??节中说明, 这里用它来说明置信区间与置信水平的含义. 若取 $\\alpha=0.10$, 则 $t_{0.95}(9)=1.8331$, 上式化为  \n$$\n[\\bar{x}-0.5797 s, \\bar{x}+0.5797 s]\n$$  \n现假定 $\\mu=15, \\sigma^{2}=4$, 则我们可以用随机模拟方法由 $N(15,4)$ 产生一个容量为 10 的样本, 如下\n即是这样一个样本:  \n$\\begin{array}{llllllllll}14.85 & 13.01 & 13.50 & 14.93 & 16.97 & 13.80 & 17.95 & 13.37 & 16.29 & 12.38\\end{array}$  \n由该样本可以算得  \n$$\n\\bar{x}=14.705, s=1.843\n$$  \n从而得到 $\\mu$ 的一个区间估计为  \n$$",
        "metadata": {
            "Header 2": "6.5 区间估计",
            "Header 3": "6.5.1 区间估计的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其中, $\\vec{x}, s$ 分别为样本均值和样本标准差. 这个置信区间的由来将在??节中说明, 这里用它来说明置信区间与置信水平的含义. 若取 $\\alpha=0.10$, 则 $t_{0.95}(9)=1.8331$, 上式化为  \n$$\n[\\bar{x}-0.5797 s, \\bar{x}+0.5797 s]\n$$  \n现假定 $\\mu=15, \\sigma^{2}=4$, 则我们可以用随机模拟方法由 $N(15,4)$ 产生一个容量为 10 的样本, 如下\n即是这样一个样本:  \n$\\begin{array}{llllllllll}14.85 & 13.01 & 13.50 & 14.93 & 16.97 & 13.80 & 17.95 & 13.37 & 16.29 & 12.38\\end{array}$  \n由该样本可以算得  \n$$\n\\bar{x}=14.705, s=1.843\n$$  \n从而得到 $\\mu$ 的一个区间估计为  \n$$\n14.705 \\mp 0.5797 \\times 1.843=[13.637,15.773]\n$$  \n该区间包含 $\\mu$ 的真值一 15. 现重复这样的方法 100 次, 可以得到 100 个样本, 也就得到 100 个区间, 我们将这 100 个区间画在图6.5.1上. 由图6.5.1可以看出, 这 100 个区间中有 91 个包含参数真值 15 , 另外 9 个不包含参数真值. 若取 $\\alpha=0.50$, 则 $t_{0.75}(9)=0.7027$, 于是 $\\mu$ 的置信水平为 0.50 的置信区间为  \n$$\n[\\bar{x}-0.2222 s, \\bar{x}+0.2222 s]\n$$  \n对上述样本, $\\mu$ 的区间估计为  \n$$\n14.705 \\mp 0.2222 \\times 1.843=[14.295,15.116]\n$$  \n该区间也包含了参数真值, 类似地, 我们也可以给出 100 个这样的区间, 见图6.5.2. 由图6.5.2可以看出, 这 100 个区间中有 50 个包含参数真值 15 , 另外 50 个不包含参数真值. 在定义 6.5 .1 中使用  \n!  \n图 6.5.1: $\\mu$ 的置信水平为 0.90 的置信区间  \n!",
        "metadata": {
            "Header 2": "6.5 区间估计",
            "Header 3": "6.5.1 区间估计的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n[\\bar{x}-0.2222 s, \\bar{x}+0.2222 s]\n$$  \n对上述样本, $\\mu$ 的区间估计为  \n$$\n14.705 \\mp 0.2222 \\times 1.843=[14.295,15.116]\n$$  \n该区间也包含了参数真值, 类似地, 我们也可以给出 100 个这样的区间, 见图6.5.2. 由图6.5.2可以看出, 这 100 个区间中有 50 个包含参数真值 15 , 另外 50 个不包含参数真值. 在定义 6.5 .1 中使用  \n!  \n图 6.5.1: $\\mu$ 的置信水平为 0.90 的置信区间  \n!  \n不等式给出了区间估计的定义, 实际中常用的都是等式,这便给出如下一个定义.\n定义 6.5.2. 沿用定义6.5.1的记号, 如对给定的 $\\alpha(0<\\alpha<1)$ 对任意的 $\\theta \\in \\Theta$, 有  \n$$\n\\begin{equation*}\nP_{\\theta}\\left(\\hat{\\theta}_{L} \\leqslant \\theta \\leqslant \\hat{\\theta}_{\\mathrm{U}}\\right)=1-\\alpha \\tag{6.5.2}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}_{L}$ 为 $\\theta$ 的 $1-\\alpha$ 同等置信区间.  \n在一些实际问题中, 人们感兴趣的有时仅仅是未知参数的一个下限或一个上限. 譬如, 对某种产品的平均寿命来说, 我们希望它越大越好, 因此人们关心的是它的 0.90 置信下限是多少, 此下限标志了该产品的质量, 它的一般定义如下.  \n定义 6.5.3. 设 $\\hat{\\theta}_{L}=\\hat{\\theta}_{L}\\left(x_{1}, \\cdots, x_{n}\\right)$ 是统计量, 对给定的 $\\alpha \\in(0,1)$ 和任意的 $\\theta \\in \\Theta$ 有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "6.5 区间估计",
            "Header 3": "6.5.1 区间估计的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nP_{\\theta}\\left(\\hat{\\theta}_{L} \\leqslant \\theta \\leqslant \\hat{\\theta}_{\\mathrm{U}}\\right)=1-\\alpha \\tag{6.5.2}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}_{L}$ 为 $\\theta$ 的 $1-\\alpha$ 同等置信区间.  \n在一些实际问题中, 人们感兴趣的有时仅仅是未知参数的一个下限或一个上限. 譬如, 对某种产品的平均寿命来说, 我们希望它越大越好, 因此人们关心的是它的 0.90 置信下限是多少, 此下限标志了该产品的质量, 它的一般定义如下.  \n定义 6.5.3. 设 $\\hat{\\theta}_{L}=\\hat{\\theta}_{L}\\left(x_{1}, \\cdots, x_{n}\\right)$ 是统计量, 对给定的 $\\alpha \\in(0,1)$ 和任意的 $\\theta \\in \\Theta$ 有  \n$$\n\\begin{equation*}\nP_{\\theta}\\left(\\tilde{\\theta}_{L} \\leqslant \\theta\\right) \\geqslant 1-\\alpha, \\quad \\forall \\theta \\in \\Theta \\tag{6.5.3}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}_{L}$ 为 $\\theta$ 的置信水平为 $1-\\alpha$ 的 (单侧) 置信下限. 假如等号对一切 $\\theta \\in \\Theta$ 成立, 则称 $\\hat{\\theta}_{L}$ 为 $\\theta$的 $1-\\alpha$ 同等置信下限.  \n类似地, 对某些指标人们希望它越小越好. 比如, 某种药品的毒性, 这引出了置信上限的概念.定义 6.5.4. 设 $\\hat{\\theta}_{U}=\\hat{\\theta}_{U}\\left(x_{1}, \\cdots, x_{n}\\right)$ 是统计量, 对给定的 $\\alpha \\in(0,1)$ 和任意的 $\\theta \\in \\Theta$, 有  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "6.5 区间估计",
            "Header 3": "6.5.1 区间估计的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n则称 $\\hat{\\theta}_{L}$ 为 $\\theta$ 的置信水平为 $1-\\alpha$ 的 (单侧) 置信下限. 假如等号对一切 $\\theta \\in \\Theta$ 成立, 则称 $\\hat{\\theta}_{L}$ 为 $\\theta$的 $1-\\alpha$ 同等置信下限.  \n类似地, 对某些指标人们希望它越小越好. 比如, 某种药品的毒性, 这引出了置信上限的概念.定义 6.5.4. 设 $\\hat{\\theta}_{U}=\\hat{\\theta}_{U}\\left(x_{1}, \\cdots, x_{n}\\right)$ 是统计量, 对给定的 $\\alpha \\in(0,1)$ 和任意的 $\\theta \\in \\Theta$, 有  \n$$\n\\begin{equation*}\nP_{\\theta}\\left(\\hat{\\theta}_{U} \\geqslant \\theta\\right) \\geqslant 1-\\alpha \\tag{6.5.4}\n\\end{equation*}\n$$  \n则称 $\\hat{\\theta}_{U}$ 为 $\\theta$ 的置信水平为 $1-\\alpha$ 的 (单侧) 置信上限. 若等号对一切 $\\theta \\in \\Theta$ 成立, 则称 $\\hat{\\theta}_{U}$ 为 $1-\\alpha$同等置信上限.  \n不难看出, 单侧置信下限和单侧置信上限都是置信区间的特殊情形. 因此, 寻求置信区间的方法可以用来寻找置信限. 接下来我们主要介绍寻找置信区间的方法.",
        "metadata": {
            "Header 2": "6.5 区间估计",
            "Header 3": "6.5.1 区间估计的概念"
        },
        "type": "Document"
    },
    {
        "page_content": "构造未知参数 $\\theta$ 的置信区间的最常用的方法是枢轴置法, 其步骤可以概括为如下三步:  \n1. 设法构造一个样本和 $\\theta$ 的函数 $G=G\\left(x_{1}, \\cdots, x_{n}, \\theta\\right)$ 使得 $G$ 的分布不依赖于未知参数. 一般称具有这种性质的 $G$ 为枢轴量.\n2. 适当地选择两个常数 $c 、 d$, 使对给定的 $\\alpha(0<\\alpha<1)$, 有  \n$$\n\\begin{equation*}\nP(c \\leqslant G \\leqslant d)=1-\\alpha \\tag{6.5.5}\n\\end{equation*}\n$$  \n3. 假如能将 $c \\leqslant G \\leqslant d$ 进行不等式等价变形化为 $\\hat{\\theta}_{L} \\leqslant \\theta \\leqslant \\hat{\\theta}_{\\mathrm{U}}$, 则有  \n$$\n\\begin{equation*}\nP_{\\theta}\\left(\\hat{\\theta}_{L} \\leqslant \\theta \\leqslant \\hat{\\theta}_{U}\\right)=1-\\alpha \\tag{6.5.6}\n\\end{equation*}\n$$  \n这表明 $\\left[\\hat{\\theta}_{L}, \\hat{\\theta}_{v}\\right]$ 是 $\\theta$ 的 $1-\\alpha$ 同等置信区间.  \n上述构造置信区间的关键在于构造枢轴量 $G$, 故把这种方法称为枢轴置法. 枢轴量的寻找一般从 $\\theta$的点估计出发. 而满足6.5.5的 $c 、 d$ 可以有很多, 选择的目的是希望6.5.6中的平均长度 $E_{\\theta}\\left(\\tilde{\\theta}_{U}-\\hat{\\theta}_{L}\\right)$尽可能短. 假如可以找到这样的 $c 、 d$ 使 $E_{\\theta}\\left(\\tilde{\\theta}_{U}-\\hat{\\theta}_{L}\\right)$ 达到最短当然是最好的, 不过在不少场合很难做到这一点. 故常这样选择 $c$ 和 $d$, 使得  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "6.5 .2 枢轴量法"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n这表明 $\\left[\\hat{\\theta}_{L}, \\hat{\\theta}_{v}\\right]$ 是 $\\theta$ 的 $1-\\alpha$ 同等置信区间.  \n上述构造置信区间的关键在于构造枢轴量 $G$, 故把这种方法称为枢轴置法. 枢轴量的寻找一般从 $\\theta$的点估计出发. 而满足6.5.5的 $c 、 d$ 可以有很多, 选择的目的是希望6.5.6中的平均长度 $E_{\\theta}\\left(\\tilde{\\theta}_{U}-\\hat{\\theta}_{L}\\right)$尽可能短. 假如可以找到这样的 $c 、 d$ 使 $E_{\\theta}\\left(\\tilde{\\theta}_{U}-\\hat{\\theta}_{L}\\right)$ 达到最短当然是最好的, 不过在不少场合很难做到这一点. 故常这样选择 $c$ 和 $d$, 使得  \n$$\n\\begin{equation*}\nP_{\\theta}(G<c)=P_{\\theta}(G>d)=\\alpha / 2 \\tag{6.5.7}\n\\end{equation*}\n$$  \n这样得到的置信区间称为等尾置倍区间. 实用的置信区间大都是等尾置信区间.  \n例 6.5.2: 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(0, \\theta)$ 的一个样本, 试对给定的 $\\alpha(0<\\alpha<1)$ 给出 $\\theta$ 的 $1-\\alpha$ 同等置信区间.  \n解: 我们采用枢轴量法分二步进行  \n(1) 我们已知 $\\theta$ 的最大似然估计为样本的最大次序统计量 $x_{(n)}$, 而 $x_{(n)} / \\theta$ 的密度函数为  \n$$\np(y ; \\theta)=n y^{n-1}, \\quad 0<y<1\n$$  \n它与参数 $\\theta$ 无关, 故可取 $x_{(n)} / \\theta$ 作为枢轴量 $G$.",
        "metadata": {
            "Header 2": "6.5 .2 枢轴量法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nP_{\\theta}(G<c)=P_{\\theta}(G>d)=\\alpha / 2 \\tag{6.5.7}\n\\end{equation*}\n$$  \n这样得到的置信区间称为等尾置倍区间. 实用的置信区间大都是等尾置信区间.  \n例 6.5.2: 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(0, \\theta)$ 的一个样本, 试对给定的 $\\alpha(0<\\alpha<1)$ 给出 $\\theta$ 的 $1-\\alpha$ 同等置信区间.  \n解: 我们采用枢轴量法分二步进行  \n(1) 我们已知 $\\theta$ 的最大似然估计为样本的最大次序统计量 $x_{(n)}$, 而 $x_{(n)} / \\theta$ 的密度函数为  \n$$\np(y ; \\theta)=n y^{n-1}, \\quad 0<y<1\n$$  \n它与参数 $\\theta$ 无关, 故可取 $x_{(n)} / \\theta$ 作为枢轴量 $G$.  \n（2）由于 $x_{(n)} / \\theta$ 的分布函数为 $F(y)=y^{n}, 0<y<1$, 故 $P\\left(c \\leqslant x_{(n)} / \\theta \\leqslant d\\right)=d^{n}-c^{n}$, 因此我们可以适当的选择 $c$ 和 $d$ 满足  \n$$\nd^{n}-c^{n}=1-a\n$$",
        "metadata": {
            "Header 2": "6.5 .2 枢轴量法"
        },
        "type": "Document"
    },
    {
        "page_content": "例 6.5.2: 设 $x_{1}, \\cdots, x_{n}$ 是来自均匀总体 $U(0, \\theta)$ 的一个样本, 试对给定的 $\\alpha(0<\\alpha<1)$ 给出 $\\theta$ 的 $1-\\alpha$ 同等置信区间.  \n解: 我们采用枢轴量法分二步进行  \n(1) 我们已知 $\\theta$ 的最大似然估计为样本的最大次序统计量 $x_{(n)}$, 而 $x_{(n)} / \\theta$ 的密度函数为  \n$$\np(y ; \\theta)=n y^{n-1}, \\quad 0<y<1\n$$  \n它与参数 $\\theta$ 无关, 故可取 $x_{(n)} / \\theta$ 作为枢轴量 $G$.  \n（2）由于 $x_{(n)} / \\theta$ 的分布函数为 $F(y)=y^{n}, 0<y<1$, 故 $P\\left(c \\leqslant x_{(n)} / \\theta \\leqslant d\\right)=d^{n}-c^{n}$, 因此我们可以适当的选择 $c$ 和 $d$ 满足  \n$$\nd^{n}-c^{n}=1-a\n$$  \n（3）利用不等式变形可容易地给出 $\\theta$ 的 $1-\\alpha$ 同等置信区间为 $\\left[x_{(n)} / d, x_{(n)} / c\\right]$, 该区间的平均长度为 $\\left(\\frac{1}{\\varepsilon}-\\frac{1}{d}\\right) E x_{(n)}$, 不难看出, 在 $0 \\leqslant c<d \\leqslant 1$ 及 $d^{n}-c^{n}=1-a$ 的条件下, 当 $d=1, c=\\sqrt[n]{a}$ 时, $\\frac{1}{c}-\\frac{1}{d}$ 取得最小值, 这说明 $\\left[x_{(n)}, x_{(n)} / \\sqrt[n]{a}\\right]$ 是 $\\theta$ 的置信水平为 $1-\\alpha$ 最短量信区间.",
        "metadata": {
            "Header 2": "6.5 .2 枢轴量法"
        },
        "type": "Document"
    },
    {
        "page_content": "正态总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 是最常见的分布, 本小节中我们讨论它的两个参数的置信区间.",
        "metadata": {
            "Header 2": "6.5 .2 枢轴量法",
            "Header 3": "6.5.3 単个正态总体参数的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "在这种情况下, 由于 $\\mu$ 的点估计为 $\\bar{x}$, 其分布为 $N\\left(\\mu, \\sigma^{2} / n\\right)$, 因此枢轴量可选为 $G=\\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}} \\sim$ $N(0,1), c$ 和 $d$ 应满足 $P(c \\leqslant G \\leqslant d)=\\Phi(d)-\\Phi(c)=1-\\alpha$, 经过不等式变形可得  \n$$\nP_{\\mu}(\\bar{x}-d \\sigma / \\sqrt{n} \\leqslant \\mu \\leqslant \\bar{x}-c \\sigma \\sqrt{n})=1-a\n$$  \n该区间长度为 $(d-c) \\sigma \\sqrt{n}$. 由于标准正态分布为单峰对称的, 从图 6.5 .3 上不难看出在 $\\Phi(d)-$ $\\Phi(c)=1-\\alpha$ 的条件下, 当 $d=-c=u_{1-\\alpha / 2}$ 时, $d-c$ 达到最小, 由此给出了 $\\mu$ 的 $1-\\alpha$ 同等置信区间为  \n$$\n\\begin{equation*}\n\\left[\\bar{x}-u_{1-\\alpha / 2} \\sigma / \\sqrt{n}, \\quad \\bar{x}+u_{1-\\alpha / 2} \\sigma / \\sqrt{n}\\right] \\tag{6.5.8}\n\\end{equation*}\n$$  \n这是一个以 $\\bar{x}$ 为中心, 半径为 $u_{1-\\alpha / 2} \\sigma / \\sqrt{n}$ 的对称区间, 常将之表示为 $\\bar{x} \\pm u_{1-\\alpha / 2} \\sigma / \\sqrt{n}$.  \n!  \n图 6.5.3: 标准正态分布示意图  \n例 6.5.3: 用天平称量某物体的质量 9 次, 得平均值为 $\\bar{x}=15.4(\\mathrm{~g})$, 已知天平称量结果为正态分布,其标准差为 $0.1 \\mathrm{~g}$. 试求该物体质量的 0.95 置信区间.",
        "metadata": {
            "Header 2": "一。 $\\sigma$ 己知时 $\\mu$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n\\left[\\bar{x}-u_{1-\\alpha / 2} \\sigma / \\sqrt{n}, \\quad \\bar{x}+u_{1-\\alpha / 2} \\sigma / \\sqrt{n}\\right] \\tag{6.5.8}\n\\end{equation*}\n$$  \n这是一个以 $\\bar{x}$ 为中心, 半径为 $u_{1-\\alpha / 2} \\sigma / \\sqrt{n}$ 的对称区间, 常将之表示为 $\\bar{x} \\pm u_{1-\\alpha / 2} \\sigma / \\sqrt{n}$.  \n!  \n图 6.5.3: 标准正态分布示意图  \n例 6.5.3: 用天平称量某物体的质量 9 次, 得平均值为 $\\bar{x}=15.4(\\mathrm{~g})$, 已知天平称量结果为正态分布,其标准差为 $0.1 \\mathrm{~g}$. 试求该物体质量的 0.95 置信区间.  \n解: 此处 $1-\\alpha=0.95, \\alpha=0.05$, 查表知 $u_{0.975}=1.96$, 于是该物体质量 $\\mu$ 的 0.95 置信区间为  \n$$\n\\bar{x} \\pm u_{1-\\alpha / 2} \\sigma / \\sqrt{n}=15.4 \\pm 1.96 \\times 0.1 / \\sqrt{9}=15.4 \\pm 0.0653\n$$",
        "metadata": {
            "Header 2": "一。 $\\sigma$ 己知时 $\\mu$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "例 6.5.4: 设总体为正态分布 $N(\\mu, 1)$, 为得到 $\\mu$ 的置信水平为 0.95 的置信区间长度不超过 1.2 , 样本容量应为多大?  \n解: 由题设条件知 $\\mu$ 的 0.95 置信区间为 $\\left[\\bar{x}-u_{1-\\alpha / 2} / \\sqrt{n}, \\quad \\bar{x}+u_{1-\\alpha / 2} / \\sqrt{n}\\right]$ 其区间长度为 $2 u_{1-\\alpha / 2} / \\sqrt{n}$,它仅依赖于样本容量 $n$ 而与样本具体取值无关. 现要求 $2 u_{1-\\alpha / 2} / \\sqrt{n} \\leqslant 1.2$, 立即有 $n \\geqslant(2 / 1.2)^{2} u_{1-\\alpha / 2}^{2}$.现 $1-\\alpha=0.95$, 故 $u_{1-\\alpha / 2}=1.96$, 从而 $n \\geqslant(5 / 3)^{2} \\times 1.96^{2}=10.67 \\approx 11$. 即样本容量至少为 11 时才能使得 $\\mu$ 的置信水平为 0.95 的置信区间长度不超过 1.2 .",
        "metadata": {
            "Header 2": "从而该物体质量的 0.95 置信区间为 [15.3347, 15.4653]."
        },
        "type": "Document"
    },
    {
        "page_content": "这时可用 $t$ 统计量, 因为 $t=\\frac{\\sqrt{n}(\\bar{x}-\\mu)}{s} \\sim t(n-1)$, 因此 $t$ 可以用来作为枢轴量. 完全类似于上一小节, 可得到 $\\mu$ 的 $1-\\alpha$ 置信区间为  \n$$\n\\begin{equation*}\n\\left[\\bar{x}-t_{1-\\alpha / 2}(n-1) s / \\sqrt{n}, \\bar{x}+t_{1-\\alpha / 2}(n-1) s / \\sqrt{n}\\right] \\tag{6.5.9}\n\\end{equation*}\n$$  \n此处 $s^{2}=\\frac{1}{n-1} \\sum\\left(x_{i}-\\bar{x}\\right)^{2}$ 是 $\\sigma^{2}$ 的无偏估计.  \n例 6.5.5: 假设轮胎的寿命服从正态分布. 为估计某种轮胎的平均寿命, 现随机地抽 12 只轮胎试用,测得它们的寿命 (单位: 万公里) 如下:  \n$$\n\\begin{array}{llllllllllll}\n4.68 & 4.85 & 4.32 & 4.85 & 4.61 & 5.02 & 5.20 & 4.60 & 4.58 & 4.72 & 4.38 & 4.70\n\\end{array}\n$$  \n试求平均寿命的 0.95 置信区间.  \n解: 此处正态总体标准差未知, 可使用 $t$ 分布求均值的置信区间. 本例中经计算有 $\\bar{x}=4.7092, s^{2}=$ 0.0615 . 取 $\\alpha=0.05$, 查表知 $t_{0.975}(11)=2.2010$, 于是平均寿命的 0.95 置信区间为 (单位: 万公里)  \n$$\n4.7092 \\pm 2.2010 \\cdot \\sqrt{0.0615} / \\sqrt{12}=[4.5516,4.8668]\n$$  \n在实际问题中, 由于轮胎的寿命越长越好, 因此可以只求平均寿命的置信下限, 也即构造单边的置信下限. 由于  \n$$\nP\\left(\\frac{\\sqrt{n}(\\bar{x}-\\mu)}{s}<t_{1-\\alpha}(n-1)\\right)=1-\\alpha\n$$",
        "metadata": {
            "Header 2": "二。 $\\sigma$ 未知时 $\\mu$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "4.68 & 4.85 & 4.32 & 4.85 & 4.61 & 5.02 & 5.20 & 4.60 & 4.58 & 4.72 & 4.38 & 4.70\n\\end{array}\n$$  \n试求平均寿命的 0.95 置信区间.  \n解: 此处正态总体标准差未知, 可使用 $t$ 分布求均值的置信区间. 本例中经计算有 $\\bar{x}=4.7092, s^{2}=$ 0.0615 . 取 $\\alpha=0.05$, 查表知 $t_{0.975}(11)=2.2010$, 于是平均寿命的 0.95 置信区间为 (单位: 万公里)  \n$$\n4.7092 \\pm 2.2010 \\cdot \\sqrt{0.0615} / \\sqrt{12}=[4.5516,4.8668]\n$$  \n在实际问题中, 由于轮胎的寿命越长越好, 因此可以只求平均寿命的置信下限, 也即构造单边的置信下限. 由于  \n$$\nP\\left(\\frac{\\sqrt{n}(\\bar{x}-\\mu)}{s}<t_{1-\\alpha}(n-1)\\right)=1-\\alpha\n$$  \n由不等式变形可知 $\\mu$ 的 $1-\\alpha$ 置信下限为 $\\bar{x}-t_{1-\\alpha}(n-1) s / \\sqrt{n}$. 将 $t_{0.95}(11)=1.7959$ 代人计算可得平均寿命 $\\mu$ 的 0.95 置信下限为 4.5806 (万公里).",
        "metadata": {
            "Header 2": "二。 $\\sigma$ 未知时 $\\mu$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "此时虽然也可以就 $\\mu$ 是否已知分两种情况讨论 $\\sigma^{2}$ 的置信区间, 在实际中 $\\sigma^{2}$ 未知时 $\\mu$ 已知的情形是极为罕见的, 所以我们只在 $\\mu$ 未知的条件下讨论 $\\sigma^{2}$ 的置信区间.  \n枢轴量不难给出. 大家知道, $\\sigma^{2}$ 可用样本方差 $s^{2}$ 估计. 在 5.4 中我们已经证明 $\\frac{(n-1) s^{2}}{\\sigma^{2}} \\sim$ $\\chi^{2}(n-1)$, 由于 $\\xi^{2}$ 分布是偏态分布, 寻找平均长度最短区间很难实现, 一般都改为寻找等尾置信区间: 把 $\\alpha$ 平分为两部分, 在 $\\chi^{2}$ 分布两侧各截面积为 $\\alpha / 2$ 的部分, 即采用 $\\chi^{2}$ 的两个分位数 $\\chi_{\\alpha / 2}^{2}(n-1)$ 和 $\\chi_{1-\\alpha / 2}^{2}(n-1)$ (见图 6.5.4), 它们满足  \n$$\nP\\left(\\chi_{\\alpha / 2}^{2} \\leqslant \\frac{(n-1) s^{2}}{\\sigma^{2}} \\leqslant \\chi_{1-\\alpha / 2}^{2}\\right)=1-\\alpha\n$$  \n由此给出 $\\sigma^{2}$ 的 $1-\\alpha$ 置信区间为  \n$$\n\\begin{equation*}\n\\left[(n-1) s^{2} / \\chi_{1-\\alpha / 2}^{2}(n-1),(n-1) s^{2} / \\chi_{\\alpha / 2}^{2}(n-1)\\right] \\tag{6.5.10}\n\\end{equation*}\n$$  \n将(6.5.10)的两端开方即得到标准差 $\\sigma$ 的 $1-\\alpha$ 置信区间.  \n例 6.5.6: 某厂生产的零件重量服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$, 现从该厂生产的零件中抽取 9 个, 测得其  \n!  \n图 6.5.4: $\\chi^{2}$ 分布置信区间示意图  \n质量为 (单位: $g$ )  \n$$\n\\begin{array}{lllllllll}",
        "metadata": {
            "Header 2": "三、 $\\sigma^{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由此给出 $\\sigma^{2}$ 的 $1-\\alpha$ 置信区间为  \n$$\n\\begin{equation*}\n\\left[(n-1) s^{2} / \\chi_{1-\\alpha / 2}^{2}(n-1),(n-1) s^{2} / \\chi_{\\alpha / 2}^{2}(n-1)\\right] \\tag{6.5.10}\n\\end{equation*}\n$$  \n将(6.5.10)的两端开方即得到标准差 $\\sigma$ 的 $1-\\alpha$ 置信区间.  \n例 6.5.6: 某厂生产的零件重量服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$, 现从该厂生产的零件中抽取 9 个, 测得其  \n!  \n图 6.5.4: $\\chi^{2}$ 分布置信区间示意图  \n质量为 (单位: $g$ )  \n$$\n\\begin{array}{lllllllll}\n45.3 & 45.4 & 45.1 & 45.3 & 45.5 & 45.7 & 45.4 & 45.3 & 45.6\n\\end{array}\n$$  \n试求总体标准差 $\\sigma$ 的 0.95 置信区间.  \n解: 由数据可算得 $s^{2}=0.0325,(n-1) s^{2}=8 \\times 0.0325=0.26$, 这里 $\\alpha=0.05$, 查表知 $\\chi_{0.025}^{2}(8)=$ $2.1797, \\chi_{0.975}^{2}(8)=17.5345$, 代人 (6.5.10) 可得 $\\sigma^{2}$ 的 0.95 置信区间为  \n$$\n\\left[\\frac{0.26}{17.5345}, \\frac{0.26}{2.1797}\\right]=[0.0148,0.1193]\n$$  \n从而 $\\sigma$ 的 0.95 置信区间为 $[0.1218,0.3454]$.",
        "metadata": {
            "Header 2": "三、 $\\sigma^{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "在样本容量充分大时, 可以用渐近分布来构造近似的置信区间. 一个典型的例子是关于比例 $p$ 的置信区间.  \n设 $x_{1}, \\cdots, x_{n}$ 是来自二点分布 $b(1, p)$ 的样本, 现要求 $p$ 的 $1-\\alpha$ 置信区间. 由中心极限定理知, 样本均值 $\\bar{x}$ 的渐近分布为 $N\\left(p, \\frac{p(1-p)}{n}\\right)$, 因此有  \n$$\nu=\\frac{\\bar{x}-p}{\\sqrt{p(1-p) / n}} \\dot{\\sim} N(0,1)\n$$  \n这个 $w$ 可作为枢轴量, 对给定 $\\alpha$, 利用标准正态分布的 $1-\\alpha / 2$ 分位数 $u_{1-\\alpha / 2}$ 可得  \n括号里的事件等价于  \n$$\nP\\left(\\left|\\frac{\\bar{x}-p}{\\sqrt{p(1-p) / n}}\\right| \\leqslant u_{1-\\alpha / 2}\\right) \\approx 1-\\alpha\n$$  \n$$\n(\\vec{x}-p)^{2} \\leqslant u_{1-\\alpha / 2}^{2} p(1-p) / n\n$$  \n记 $\\lambda=u_{1-\\alpha / 2}^{2}$, 上述不等式可化为  \n$$\n\\left(1+\\frac{\\lambda}{n}\\right) p^{2}-\\left(2 \\bar{x}+\\frac{\\lambda}{n}\\right) p+\\bar{x}^{2} \\leqslant 0\n$$  \n左侧的二次多项式的判别式  \n$$\n\\left(2 \\bar{x}+\\frac{\\lambda}{n}\\right)^{2}-4\\left(1+\\frac{\\lambda}{n}\\right) \\bar{x}^{2}=\\frac{4 \\bar{x}(1-\\bar{x})}{n}+\\frac{\\lambda^{2}}{n^{2}}>0,\n$$  \n故此二次多项式是开口向上并与 $x$ 轴有两个交点的曲线 (见图6.5.5). 记此两个交点为 $p_{L}$ 和 $p_{U}$,则有  \n$$",
        "metadata": {
            "Header 2": "三、 $\\sigma^{2}$ 的置信区间",
            "Header 3": "6.5.4 大样本置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n$$\n(\\vec{x}-p)^{2} \\leqslant u_{1-\\alpha / 2}^{2} p(1-p) / n\n$$  \n记 $\\lambda=u_{1-\\alpha / 2}^{2}$, 上述不等式可化为  \n$$\n\\left(1+\\frac{\\lambda}{n}\\right) p^{2}-\\left(2 \\bar{x}+\\frac{\\lambda}{n}\\right) p+\\bar{x}^{2} \\leqslant 0\n$$  \n左侧的二次多项式的判别式  \n$$\n\\left(2 \\bar{x}+\\frac{\\lambda}{n}\\right)^{2}-4\\left(1+\\frac{\\lambda}{n}\\right) \\bar{x}^{2}=\\frac{4 \\bar{x}(1-\\bar{x})}{n}+\\frac{\\lambda^{2}}{n^{2}}>0,\n$$  \n故此二次多项式是开口向上并与 $x$ 轴有两个交点的曲线 (见图6.5.5). 记此两个交点为 $p_{L}$ 和 $p_{U}$,则有  \n$$\nP\\left(p_{L} \\leqslant p \\leqslant p_{U}\\right)=1-\\alpha\n$$  \n这里 $p_{L}$ 和 $p_{U}$ 是该二次多项式的两个根, 它们可表示为  \n!  \n$$\np=\\frac{1}{1+\\frac{\\lambda}{n}}\\left(\\bar{x}+\\frac{\\lambda}{2 n} \\pm \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}+\\frac{\\lambda^{2}}{4 n^{2}}}\\right)\n$$  \n由于 $n$ 比较大, 在实用中通常略去 $\\lambda / n$ 项, 于是可将置信区间近似为  \n$$\n\\begin{equation*}\n\\left[\\bar{x}-u_{1-\\alpha / 2} \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}}, \\bar{x}+u_{1-\\alpha / 2} \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}}\\right] \\tag{6.5.11}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "三、 $\\sigma^{2}$ 的置信区间",
            "Header 3": "6.5.4 大样本置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "P\\left(p_{L} \\leqslant p \\leqslant p_{U}\\right)=1-\\alpha\n$$  \n这里 $p_{L}$ 和 $p_{U}$ 是该二次多项式的两个根, 它们可表示为  \n!  \n$$\np=\\frac{1}{1+\\frac{\\lambda}{n}}\\left(\\bar{x}+\\frac{\\lambda}{2 n} \\pm \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}+\\frac{\\lambda^{2}}{4 n^{2}}}\\right)\n$$  \n由于 $n$ 比较大, 在实用中通常略去 $\\lambda / n$ 项, 于是可将置信区间近似为  \n$$\n\\begin{equation*}\n\\left[\\bar{x}-u_{1-\\alpha / 2} \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}}, \\bar{x}+u_{1-\\alpha / 2} \\sqrt{\\frac{\\bar{x}(1-\\bar{x})}{n}}\\right] \\tag{6.5.11}\n\\end{equation*}\n$$  \n例 6.5.7: 对某事件 $A$ 作 120 次观察, $A$ 发生 36 次. 试给出事件 $A$ 发生概率 $p$ 的 0.95 置信区间.解: 此处 $n=120, \\bar{x}=36 / 120=0.3$, 而 $u_{0.975}=1.96$, 于是 $p$ 的 0.95 (双侧) 置信下限和上限分别为  \n$$\n\\begin{aligned}\n& \\hat{p}_{L}=0.3-1.96 \\times \\sqrt{\\frac{0.3 \\times 0.7}{120}}=0.218, \\\\\n& \\hat{p}_{U}=0.3+1.96 \\times \\sqrt{\\frac{0.3 \\times 0.7}{120}}=0.382,\n\\end{aligned}\n$$  \n故所求的置信区间为 $[0.218 \\square 0.382]$.  \n例 6.5.8: 某传媒公司欲调查电视台某综艺节目收视率 $p$, 为使得 $p$ 的 $1-\\alpha$ 置信区间长度不超过 $d_{0}$, 问应调查多少用户?",
        "metadata": {
            "Header 2": "三、 $\\sigma^{2}$ 的置信区间",
            "Header 3": "6.5.4 大样本置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n例 6.5.7: 对某事件 $A$ 作 120 次观察, $A$ 发生 36 次. 试给出事件 $A$ 发生概率 $p$ 的 0.95 置信区间.解: 此处 $n=120, \\bar{x}=36 / 120=0.3$, 而 $u_{0.975}=1.96$, 于是 $p$ 的 0.95 (双侧) 置信下限和上限分别为  \n$$\n\\begin{aligned}\n& \\hat{p}_{L}=0.3-1.96 \\times \\sqrt{\\frac{0.3 \\times 0.7}{120}}=0.218, \\\\\n& \\hat{p}_{U}=0.3+1.96 \\times \\sqrt{\\frac{0.3 \\times 0.7}{120}}=0.382,\n\\end{aligned}\n$$  \n故所求的置信区间为 $[0.218 \\square 0.382]$.  \n例 6.5.8: 某传媒公司欲调查电视台某综艺节目收视率 $p$, 为使得 $p$ 的 $1-\\alpha$ 置信区间长度不超过 $d_{0}$, 问应调查多少用户?  \n解: 这是关于二点分布比例 $p$ 的置信区问问题, 由 (6.5.11) 知, $1-\\alpha$ 的置信区间长度为 $2 u_{1-\\alpha / 2} \\sqrt{\\bar{x}(1-\\bar{x}) / n}$,这是一个随机变量, 但由于 $\\bar{x} \\in(0,1)$, 所以对任意的观测值有 $\\bar{x}(1-\\bar{x}) \\leqslant 0.5^{2}=0.25$. 这也就是说 $p$ 的 $1-\\alpha$ 的置信区间长度不会超过 $u_{1-\\alpha / 2} / \\sqrt{n}$. 现要求 $p$ 的 $1-a$ 的置信区间长度不超过 $d_{0}$, 只需要 $u_{1-\\alpha / 2} / \\sqrt{n} \\leqslant d_{0}$ 即可, 从而  \n$$\n\\begin{equation*}\nn \\geqslant\\left(\\frac{u_{1-\\alpha / 2}}{d_{0}}\\right)^{2} \\tag{6.5.12}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "三、 $\\sigma^{2}$ 的置信区间",
            "Header 3": "6.5.4 大样本置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 这是关于二点分布比例 $p$ 的置信区问问题, 由 (6.5.11) 知, $1-\\alpha$ 的置信区间长度为 $2 u_{1-\\alpha / 2} \\sqrt{\\bar{x}(1-\\bar{x}) / n}$,这是一个随机变量, 但由于 $\\bar{x} \\in(0,1)$, 所以对任意的观测值有 $\\bar{x}(1-\\bar{x}) \\leqslant 0.5^{2}=0.25$. 这也就是说 $p$ 的 $1-\\alpha$ 的置信区间长度不会超过 $u_{1-\\alpha / 2} / \\sqrt{n}$. 现要求 $p$ 的 $1-a$ 的置信区间长度不超过 $d_{0}$, 只需要 $u_{1-\\alpha / 2} / \\sqrt{n} \\leqslant d_{0}$ 即可, 从而  \n$$\n\\begin{equation*}\nn \\geqslant\\left(\\frac{u_{1-\\alpha / 2}}{d_{0}}\\right)^{2} \\tag{6.5.12}\n\\end{equation*}\n$$  \n这是一类常见的寻求样本量的问题. 比如, 若取 $d_{0}=0.04, \\alpha=0.05$, 则  \n$$\nn \\geqslant\\left(\\frac{u_{0.975}}{0.04}\\right)^{2}=\\left(\\frac{1.96}{0.04}\\right)^{2}=2401\n$$  \n这表明, 要使综艺节目收视率 $p$ 的 0.95 置信区间的长度不超过 0.04 , 则需要对 2401 个用户做调查.",
        "metadata": {
            "Header 2": "三、 $\\sigma^{2}$ 的置信区间",
            "Header 3": "6.5.4 大样本置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $x_{1}, \\cdots, x_{m}$ 是来自 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 的样本, $y_{1}, \\cdots, y_{n}$ 是来自 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$ 的样本, 且两个样本相互独立. $\\bar{x}$ 与 $\\bar{y}$ 分别是它们的样本均值, $s_{x}^{2}=\\frac{1}{m-1} \\sum_{i=1}^{m}\\left(x_{i}-\\bar{x}\\right)^{2}$ 和 $s_{y}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}$. 分别是它们的样本方差. 下面讨论两个均值差和两个方差比的置信区间.",
        "metadata": {
            "Header 2": "三、 $\\sigma^{2}$ 的置信区间",
            "Header 3": "6.5.5 两个正态总体下的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "这是历史上著名的 Behrens-Fisher 问题, 它是 Behrens 在 1929 年从实际应用中提出的问题. 它的几种特殊情况已获得圆满的解决, 但其一般情况至今尚有学者在讨论. 下面我们对此问题分几种情况分别叙述, 读者应留意它们之间的差别及其处理方法.  \n1. $\\sigma_{1}^{2}$ 和 $\\sigma_{2}^{2}$ 已知时  \n此时有 $\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2}, \\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}\\right)$, 取枢轴量为  \n$$\nu=\\frac{\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}} \\sim N(0,1),\n$$  \n沿用前面多次用过的方法可以得到 $\\mu_{1}-\\mu_{2}$ 的 $1-\\alpha$ 置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-u_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}, \\bar{x}-\\bar{y}+u_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}\\right],\n$$  \n该区间称为二样本 $u$ 区间.\n2. $\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\sigma^{2}$ 未知时  \n此时有  \n$$\n\\begin{gathered}\n\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2},\\left(\\frac{1}{m}+\\frac{1}{n}\\right) \\sigma^{2}\\right), \\\\\n\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{\\sigma^{2}} \\sim \\chi^{2}(m+n-2)\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\left[\\bar{x}-\\bar{y}-u_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}, \\bar{x}-\\bar{y}+u_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}\\right],\n$$  \n该区间称为二样本 $u$ 区间.\n2. $\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\sigma^{2}$ 未知时  \n此时有  \n$$\n\\begin{gathered}\n\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2},\\left(\\frac{1}{m}+\\frac{1}{n}\\right) \\sigma^{2}\\right), \\\\\n\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{\\sigma^{2}} \\sim \\chi^{2}(m+n-2)\n\\end{gathered}\n$$  \n由于 $\\bar{x}, \\bar{y}, s_{x}^{2}, s_{y}^{2}$ 相互独立, 故可构造如下服从 $t$ 分布 $t(m+n-2)$ 的枢轴量  \n$$\nt=\\sqrt{\\frac{m n(m+n-2)}{m+n}} \\frac{\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sqrt{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}} \\sim t(m+n-2)\n$$  \n记 $s_{w}^{2}=\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{m+n-2}$, 则 $\\mu_{1}-\\mu_{2}$ 的置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-\\sqrt{\\frac{m+n}{m n}} s_{w} t_{1-\\alpha / 2}(m+n-2), \\bar{x}-\\bar{y}+\\sqrt{\\frac{m+n}{m n}} s_{w} t_{1-\\alpha / 2}(m+n-2)\\right] .\n$$",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由于 $\\bar{x}, \\bar{y}, s_{x}^{2}, s_{y}^{2}$ 相互独立, 故可构造如下服从 $t$ 分布 $t(m+n-2)$ 的枢轴量  \n$$\nt=\\sqrt{\\frac{m n(m+n-2)}{m+n}} \\frac{\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sqrt{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}} \\sim t(m+n-2)\n$$  \n记 $s_{w}^{2}=\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{m+n-2}$, 则 $\\mu_{1}-\\mu_{2}$ 的置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-\\sqrt{\\frac{m+n}{m n}} s_{w} t_{1-\\alpha / 2}(m+n-2), \\bar{x}-\\bar{y}+\\sqrt{\\frac{m+n}{m n}} s_{w} t_{1-\\alpha / 2}(m+n-2)\\right] .\n$$  \n3. $\\sigma_{1}^{2} / \\sigma_{2}^{2}=\\theta$ 已知时  \n此时的处理方法与 2 中完全类似, 只须注意到  \n$$\n\\begin{gathered}\n\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2},\\left(\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}\\right) \\sigma^{2}\\right)=N\\left(\\mu_{1}-\\mu_{2}, \\sigma_{1}^{2}\\left(\\frac{1}{m}+\\frac{\\sigma_{2}^{2} \\theta}{n}\\right)\\right), \\\\\n\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2} / \\theta}{\\sigma_{1}^{2}}=\\frac{(m-1) s_{x}^{2}}{\\sigma_{1}^{2}}+\\frac{(n-1) s_{y}^{2}}{\\sigma_{2}^{2}} \\sim \\chi^{2}(m+n-2)\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "此时的处理方法与 2 中完全类似, 只须注意到  \n$$\n\\begin{gathered}\n\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2},\\left(\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}\\right) \\sigma^{2}\\right)=N\\left(\\mu_{1}-\\mu_{2}, \\sigma_{1}^{2}\\left(\\frac{1}{m}+\\frac{\\sigma_{2}^{2} \\theta}{n}\\right)\\right), \\\\\n\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2} / \\theta}{\\sigma_{1}^{2}}=\\frac{(m-1) s_{x}^{2}}{\\sigma_{1}^{2}}+\\frac{(n-1) s_{y}^{2}}{\\sigma_{2}^{2}} \\sim \\chi^{2}(m+n-2)\n\\end{gathered}\n$$  \n由于 $\\bar{x}, \\bar{y}, s_{x}^{2}, s_{y}^{2}$ 相互独立, 仍可构造如下服从 $t$ 分布 $t(m+n-2)$ 的枢轴量  \n$$\nt=\\frac{\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sqrt{(m-1) s_{x}^{2}+(n-1) s_{y}^{2} / \\theta}} \\sqrt{\\frac{m n(m+n-2)}{m \\theta+n}} \\sim t(m+n-2)\n$$  \n记 $s_{t}^{2}=\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2} / \\theta}{m+n-2}$, 则 $\\mu_{1}-\\mu_{2}$ 的 $1-\\alpha$ 置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-\\sqrt{\\frac{m n}{m \\theta+n}} s_{t} t_{1-\\alpha / 2}(m+n-2), \\bar{x}-\\bar{y}+\\sqrt{\\frac{m n}{m \\theta+n}} s_{t} t_{1-\\alpha / 2}(m+n-2)\\right] .\n$$",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nt=\\frac{\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sqrt{(m-1) s_{x}^{2}+(n-1) s_{y}^{2} / \\theta}} \\sqrt{\\frac{m n(m+n-2)}{m \\theta+n}} \\sim t(m+n-2)\n$$  \n记 $s_{t}^{2}=\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2} / \\theta}{m+n-2}$, 则 $\\mu_{1}-\\mu_{2}$ 的 $1-\\alpha$ 置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-\\sqrt{\\frac{m n}{m \\theta+n}} s_{t} t_{1-\\alpha / 2}(m+n-2), \\bar{x}-\\bar{y}+\\sqrt{\\frac{m n}{m \\theta+n}} s_{t} t_{1-\\alpha / 2}(m+n-2)\\right] .\n$$  \n4. 当 $m$ 和 $n$ 都很大时的近似置信区间  \n此时可以证明有  \n$$\n\\frac{\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sqrt{\\frac{s_{x}^{2}}{m}+\\frac{s_{y}^{2}}{n}}} \\sim N(0,1),\n$$  \n由此可给出 $\\mu_{1}-\\mu_{2}$ 的 $1-\\alpha$ 近似置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-u_{1-\\alpha / 2} \\sqrt{\\frac{s_{x}^{2}}{m}+\\frac{s_{y}^{2}}{n}}, \\bar{x}-\\bar{y}+u_{1-\\alpha / 2} \\sqrt{\\frac{s_{x}^{2}}{m}+\\frac{s_{y}^{2}}{n}}\\right]\n$$  \n5. 一般情况下的近似置信区间  \n当 $m, n$ 并不都很大时, 可采用如下的近似方法: 令 $s_{0}^{2}=s_{x}^{2} / m+s_{y}^{2} / n$, 取枢轴量  \n$$",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n4. 当 $m$ 和 $n$ 都很大时的近似置信区间  \n此时可以证明有  \n$$\n\\frac{\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)}{\\sqrt{\\frac{s_{x}^{2}}{m}+\\frac{s_{y}^{2}}{n}}} \\sim N(0,1),\n$$  \n由此可给出 $\\mu_{1}-\\mu_{2}$ 的 $1-\\alpha$ 近似置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-u_{1-\\alpha / 2} \\sqrt{\\frac{s_{x}^{2}}{m}+\\frac{s_{y}^{2}}{n}}, \\bar{x}-\\bar{y}+u_{1-\\alpha / 2} \\sqrt{\\frac{s_{x}^{2}}{m}+\\frac{s_{y}^{2}}{n}}\\right]\n$$  \n5. 一般情况下的近似置信区间  \n当 $m, n$ 并不都很大时, 可采用如下的近似方法: 令 $s_{0}^{2}=s_{x}^{2} / m+s_{y}^{2} / n$, 取枢轴量  \n$$\nT=\\left[\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)\\right] / s_{0},\n$$  \n此时 $T$ 既不服从 $N(0,1)$ 也不服从 $t$ 分布. 但研究表明它与自由度为 $l$ 的 $t$ 分布很接近, 其中 $l$ 由公式  \n$$\nl=\\frac{s_{0}^{4}}{\\frac{s_{x}^{4}}{m^{2}(m-1)}+\\frac{s_{y}^{4}}{n^{2}(n-1)}}\n$$  \n决定, $l$ 一般不为整数, 可以取与 $l$ 最接近的整数代替之. 于是, 近似地有 $T \\sim t(l)$, 从而可得 $\\mu_{1}-\\mu_{2}$的 $1-\\alpha$ 近似置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-s_{0} t_{1-\\alpha / 2}(l), \\bar{x}-\\bar{y}+s_{0} t_{1-\\alpha / 2}(l)\\right] .\n$$",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nT=\\left[\\bar{x}-\\bar{y}-\\left(\\mu_{1}-\\mu_{2}\\right)\\right] / s_{0},\n$$  \n此时 $T$ 既不服从 $N(0,1)$ 也不服从 $t$ 分布. 但研究表明它与自由度为 $l$ 的 $t$ 分布很接近, 其中 $l$ 由公式  \n$$\nl=\\frac{s_{0}^{4}}{\\frac{s_{x}^{4}}{m^{2}(m-1)}+\\frac{s_{y}^{4}}{n^{2}(n-1)}}\n$$  \n决定, $l$ 一般不为整数, 可以取与 $l$ 最接近的整数代替之. 于是, 近似地有 $T \\sim t(l)$, 从而可得 $\\mu_{1}-\\mu_{2}$的 $1-\\alpha$ 近似置信区间为  \n$$\n\\left[\\bar{x}-\\bar{y}-s_{0} t_{1-\\alpha / 2}(l), \\bar{x}-\\bar{y}+s_{0} t_{1-\\alpha / 2}(l)\\right] .\n$$  \n例 6.5.9: 为比较两个小麦品种的产量, 选择 18 块条件相似的试验田, 采用相同的耕作方法做试验,结果播种甲品种的 8 块试验田的单位面积产量和播种乙品种的 10 块试验田的单位面积产量 (单位: $\\mathrm{kg}$ ) 分别为:  \n| 甲品种 | 628 | 583 | 510 | 554 | 612 | 523 | 530 | 615 |  |  |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 乙品种 | 535 | 433 | 398 | 470 | 567 | 480 | 498 | 560 | 503 | 426 |  \n假定每个品种的单位面积产量均服从正态分布, 试求这两个品种平均单位面积产量差的置信区间 (取 $\\alpha=0.05$ ).  \n解: 以 $x_{1}, \\cdots, x_{8}$ 记甲品种的单位面积产量, $y_{1}, \\cdots, y_{10}$ 记乙品种的单位面积产量, 由样本数据可计算得到  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "| 甲品种 | 628 | 583 | 510 | 554 | 612 | 523 | 530 | 615 |  |  |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 乙品种 | 535 | 433 | 398 | 470 | 567 | 480 | 498 | 560 | 503 | 426 |  \n假定每个品种的单位面积产量均服从正态分布, 试求这两个品种平均单位面积产量差的置信区间 (取 $\\alpha=0.05$ ).  \n解: 以 $x_{1}, \\cdots, x_{8}$ 记甲品种的单位面积产量, $y_{1}, \\cdots, y_{10}$ 记乙品种的单位面积产量, 由样本数据可计算得到  \n$$\n\\begin{aligned}\n& \\bar{x}=569.38, s_{x}^{2}=2140.55, m=8 \\\\\n& \\bar{y}=487.00, s_{y}^{2}=3256.22, n=10\n\\end{aligned}\n$$  \n下面分两种情况讨论.  \n( 1 ) 若已知两个品种单位面积产量的标准差相同, 则可采用二样本 $t$ 区间. 此处  \n$$\n\\begin{gathered}\ns_{w}=\\sqrt{\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{m+n-2}}=\\sqrt{\\frac{7 \\times 2110.55+9 \\times 3256.22}{16}}=52.4880, \\\\\nt_{1-\\alpha / 2}(m+n-2)=t_{0.975}(16)=2.1199, \\\\\nt_{1-\\alpha / 2}(m+n-2) s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}=2.1199 \\times 52.4880 \\times \\sqrt{\\frac{1}{8}+\\frac{1}{10}}=52.78,\n\\end{gathered}\n$$  \n故 $\\mu_{1}-\\mu_{2}$ 的 0.95 置信区间为  \n$$\n569.38-487 \\pm 52.78=[29.60,135.16]\n$$",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n下面分两种情况讨论.  \n( 1 ) 若已知两个品种单位面积产量的标准差相同, 则可采用二样本 $t$ 区间. 此处  \n$$\n\\begin{gathered}\ns_{w}=\\sqrt{\\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{m+n-2}}=\\sqrt{\\frac{7 \\times 2110.55+9 \\times 3256.22}{16}}=52.4880, \\\\\nt_{1-\\alpha / 2}(m+n-2)=t_{0.975}(16)=2.1199, \\\\\nt_{1-\\alpha / 2}(m+n-2) s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}=2.1199 \\times 52.4880 \\times \\sqrt{\\frac{1}{8}+\\frac{1}{10}}=52.78,\n\\end{gathered}\n$$  \n故 $\\mu_{1}-\\mu_{2}$ 的 0.95 置信区间为  \n$$\n569.38-487 \\pm 52.78=[29.60,135.16]\n$$  \n(2) 若两个品种单位面积产量的方差不等, 则可采用近似 $t$ 区间. 此处  \n$$\n\\begin{gathered}\ns_{0}^{2}=2110.55 / 8+3256.22 / 10=589.44, s_{0}=24.28, \\\\\nl=\\frac{589.44^{2}}{\\frac{2110.55^{2}}{8^{2} \\times 7}+\\frac{3256.22^{2}}{10^{2} \\times 11}}=17.74 \\approx 18, \\\\\ns_{0} t_{0.975}(l)=24.28 \\times 2.1009=51.01\n\\end{gathered}\n$$  \n于是 $\\mu_{1}-\\mu_{2}$ 的 0.95 近似置信区间为 [31.37, 133.38].",
        "metadata": {
            "Header 2": "一、 $\\mu_{1}-\\mu_{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "由于 $(m-1) s_{x}^{2} / \\sigma_{1}^{2} \\sim \\chi^{2}(m-1),(n-1) s_{y}^{2} / \\sigma_{2}^{2} \\sim \\chi^{2}(n-1)$ 且 $s_{x}^{2}$ 与 $s_{y}^{2}$ 相互独立, 故可仿照 $F$变量构造如下枢轴量:  \n$$\nF=\\frac{s_{x}^{2} / \\sigma_{1}^{2}}{s_{y}^{2} / \\sigma_{2}^{2}} \\sim F(m-1, n-1)\n$$  \n对给定的置信水平 $1-\\alpha$, 由  \n$$\nP\\left(F_{\\alpha / 2}(m-1, n-1) \\leqslant \\frac{s_{x}^{2}}{s_{y}^{2}} \\cdot \\frac{\\sigma_{2}^{2}}{\\sigma_{1}^{2}} \\leqslant F_{1-\\alpha / 2}(m-1, n-1)\\right)=1-\\alpha\n$$  \n经不等式变形即给出 $\\sigma_{1}^{2} / \\sigma_{2}^{2}$ 的如下的 $1-\\alpha$ 置信区间:  \n$$\n\\left[\\frac{s_{x}^{2}}{s_{y}^{2}} \\frac{1}{F_{1-\\alpha / 2}(m-1, n-1)}, \\frac{s_{x}^{2}}{s_{y}^{2}} \\frac{1}{F_{\\alpha / 2}(m-1, n-1)}\\right]\n$$  \n例 6.5.10: 某车间有两台自动机床加工一类套筒, 假设套筒直径服从正态分布. 现在从两个班次的产品中分别检查了 5 个和 6 个套筒, 得其直径数据如下 (单位: $\\mathrm{cm}$ ):  \n$$\n\\begin{array}{lllllll}\n\\text { 甲班 : } & 5.06 & 5.08 & 5.03 & 5.00 & 5.07 & \\\\\n\\text { 乙班 : } & 4.98 & 5.03 & 4.97 & 4.99 & 5.02 & 4.95\n\\end{array}\n$$",
        "metadata": {
            "Header 2": "二, $\\sigma_{1}^{2} / \\sigma_{2}^{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n经不等式变形即给出 $\\sigma_{1}^{2} / \\sigma_{2}^{2}$ 的如下的 $1-\\alpha$ 置信区间:  \n$$\n\\left[\\frac{s_{x}^{2}}{s_{y}^{2}} \\frac{1}{F_{1-\\alpha / 2}(m-1, n-1)}, \\frac{s_{x}^{2}}{s_{y}^{2}} \\frac{1}{F_{\\alpha / 2}(m-1, n-1)}\\right]\n$$  \n例 6.5.10: 某车间有两台自动机床加工一类套筒, 假设套筒直径服从正态分布. 现在从两个班次的产品中分别检查了 5 个和 6 个套筒, 得其直径数据如下 (单位: $\\mathrm{cm}$ ):  \n$$\n\\begin{array}{lllllll}\n\\text { 甲班 : } & 5.06 & 5.08 & 5.03 & 5.00 & 5.07 & \\\\\n\\text { 乙班 : } & 4.98 & 5.03 & 4.97 & 4.99 & 5.02 & 4.95\n\\end{array}\n$$  \n试求两班加工套筒直径的方差比 $\\sigma_{\\text {甲 }}^{2} / \\sigma_{\\text {乙 }}^{2}$ 的 0.95 置信区间.  \n解: 此处, $m=5, n=6$, 若取 $1-\\alpha=0.95$, 则查表知  \n$$\n\\begin{gathered}\nF_{0.025}(4,5)=\\frac{1}{F_{0.975}(5,4)}=\\frac{1}{9.36}=0.1068 \\\\\nF_{0.975}(4,5)=7.39\n\\end{gathered}\n$$  \n由数据算得 $\\sigma_{\\text {甲 }}^{2}=0.00037, \\sigma_{\\text {乙 }}^{2}=0.00092$, 故置信区间的两端分别为  \n$$\n\\begin{aligned}\n& \\frac{s_{\\text {甲 }}^{2}}{s_{\\text {乙 }}^{2}} \\cdot \\frac{1}{F_{0.975}(4,5)}=\\frac{0.00037}{0.00092} \\cdot \\frac{1}{7.39}=0.0544, \\\\",
        "metadata": {
            "Header 2": "二, $\\sigma_{1}^{2} / \\sigma_{2}^{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n试求两班加工套筒直径的方差比 $\\sigma_{\\text {甲 }}^{2} / \\sigma_{\\text {乙 }}^{2}$ 的 0.95 置信区间.  \n解: 此处, $m=5, n=6$, 若取 $1-\\alpha=0.95$, 则查表知  \n$$\n\\begin{gathered}\nF_{0.025}(4,5)=\\frac{1}{F_{0.975}(5,4)}=\\frac{1}{9.36}=0.1068 \\\\\nF_{0.975}(4,5)=7.39\n\\end{gathered}\n$$  \n由数据算得 $\\sigma_{\\text {甲 }}^{2}=0.00037, \\sigma_{\\text {乙 }}^{2}=0.00092$, 故置信区间的两端分别为  \n$$\n\\begin{aligned}\n& \\frac{s_{\\text {甲 }}^{2}}{s_{\\text {乙 }}^{2}} \\cdot \\frac{1}{F_{0.975}(4,5)}=\\frac{0.00037}{0.00092} \\cdot \\frac{1}{7.39}=0.0544, \\\\\n& \\frac{s_{\\text {甲 }}^{2}}{s_{\\text {乙 }}^{2}} \\cdot \\frac{1}{F_{0.075}(4,5)}=\\frac{0.00037}{0.00092} \\cdot \\frac{1}{0.1068}=3.7657,\n\\end{aligned}\n$$  \n由此可知 $\\sigma_{\\text {甲 }}^{2} / \\sigma_{\\text {乙 }}^{2}$ 的 0.95 置信区间为 $[0.0544,3.7657]$.",
        "metadata": {
            "Header 2": "二, $\\sigma_{1}^{2} / \\sigma_{2}^{2}$ 的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 某厂生产的化纤强度服从正态分布, 长期以来其标准差稳定在 $\\sigma=0.85$, 现抽取了一个容量为 $n=25$ 的样本, 测定其强度, 算得样本均值为 $\\bar{x}=2.25$, 试求这批化纤平均强度的置信水平为 0.95 的置信区间.\n2. 总体 $X \\sim N\\left(\\mu, \\sigma^{2}\\right), \\sigma^{2}$ 已知, 问样本容量 $n$ 取多大时才能保证 $\\mu$ 的 $95 \\%$ 的置信区间的长度不大于 $k$.\n3. $0.50,1.25,0.80,2.00$ 是取自总体 $X$ 的样本, 已知 $Y=\\ln X$ 服从正态分布 $N(\\mu, 1)$.  \n(1) 求 $\\mu$ 的置信水平为 $95 \\%$ 的置信区间;  \n(2) 求 $X$ 的数学期望的置信水平为 $95 \\%$ 的置信区.  \n4. 用一个仪表测量某一物理量 9 次, 得样本均值 $\\bar{x}=56.32$, 样本标准差 $\\mathrm{s}=0.22$.  \n(1) 测量标准差. 大小反映了测量仪表的精度, 试求 $\\sigma$ 的 0.95 置信区间;  \n(2) 求该物理量真值的 0.99 置信区间.  \n5. 已知某种材料的抗压强度 $X \\sim N(\\mu, 2)$, 现随机地抽取 10 个试件进行抗压试验, 测得数据如下: $482,493,457,471,510,446,435,418,394,469$.  \n(1) 求平均抗压强度 $\\mu$ 的 $95 \\%$ 的置信区间;  \n(2) 若已知 $\\sigma=30$, 求平均抗压强度 $\\mu$ 的 $95 \\%$ 的置信区间;  \n(3) 求 $\\sigma$ 的 $95 \\%$ 的置信区间.  \n6. 在一批货物中随机抽取 80 件, 发现有 11 件不合格品, 试求这批货物的不合格品率的 0.90 置信区间.\n7. 设 $x_{1}, \\cdots, x_{n}$ 是来自泊松分布 $P(\\lambda)$ 的样本, 证明: $\\lambda$ 的近似 $1-\\alpha$ 置信区间为  \n$$",
        "metadata": {
            "Header 2": "妇题 6.5"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 测量标准差. 大小反映了测量仪表的精度, 试求 $\\sigma$ 的 0.95 置信区间;  \n(2) 求该物理量真值的 0.99 置信区间.  \n5. 已知某种材料的抗压强度 $X \\sim N(\\mu, 2)$, 现随机地抽取 10 个试件进行抗压试验, 测得数据如下: $482,493,457,471,510,446,435,418,394,469$.  \n(1) 求平均抗压强度 $\\mu$ 的 $95 \\%$ 的置信区间;  \n(2) 若已知 $\\sigma=30$, 求平均抗压强度 $\\mu$ 的 $95 \\%$ 的置信区间;  \n(3) 求 $\\sigma$ 的 $95 \\%$ 的置信区间.  \n6. 在一批货物中随机抽取 80 件, 发现有 11 件不合格品, 试求这批货物的不合格品率的 0.90 置信区间.\n7. 设 $x_{1}, \\cdots, x_{n}$ 是来自泊松分布 $P(\\lambda)$ 的样本, 证明: $\\lambda$ 的近似 $1-\\alpha$ 置信区间为  \n$$\n\\left[\\frac{2 \\bar{x}+\\frac{1}{n} u_{1-\\alpha / 2}^{2}-\\sqrt{\\left(2 \\bar{x}+\\frac{1}{n} u_{1-\\alpha / 2}\\right)^{2}-4 \\bar{x}^{2}}}{2}, \\frac{2 \\bar{x}+\\frac{1}{n} u_{1-\\alpha / 2}^{2}+\\sqrt{\\left(2 \\bar{x}+\\frac{1}{n} u_{1-\\alpha / 2}\\right)^{2}-4 \\bar{x}^{2}}}{2}\\right]\n$$  \n8. 某商店某种商品的月销售量服从泊松分布, 为合理进货, 必须了解销售情况. 现记录了该商店过去的一些销售量, 数据如下:  \n| 月销售量 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 月份数 | 1 | 6 | 13 | 12 | 9 | 4 | 2 | 1 |  \n试求平均月销售量的 0.95 置信区间.",
        "metadata": {
            "Header 2": "妇题 6.5"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n8. 某商店某种商品的月销售量服从泊松分布, 为合理进货, 必须了解销售情况. 现记录了该商店过去的一些销售量, 数据如下:  \n| 月销售量 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 月份数 | 1 | 6 | 13 | 12 | 9 | 4 | 2 | 1 |  \n试求平均月销售量的 0.95 置信区间.  \n9. 设从总体 $X \\sim N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 和总体 $Y \\sim N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$ 中分别抽取容量为 $n_{1}=10, n_{2}=15$ 的独立样本, 可计算得 $\\bar{x}=82, s_{x}^{2}=56.5, \\bar{y}=76, s_{y}^{2}=52.4$.  \n(1) 若已知 $\\sigma_{1}^{2}=64, \\sigma_{2}^{2}=49$, 求 $\\mu_{1}-\\mu_{2}$ 的 $95 \\%$ 的置信区间;  \n(2) 若已知 $\\sigma_{1}^{2},=\\sigma_{2}^{2}$, 求 $\\mu_{1}-\\mu_{2}$ 的 $95 \\%$ 的置信区间;  \n(3) 若对 $\\sigma_{1}^{2}, \\sigma_{2}^{2}$ 一无所知, 求 $\\mu_{1}-\\mu_{2}$ 的 $95 \\%$ 的近似置信区间;  \n(4) 求 $\\sigma_{1}^{2} / \\sigma_{2}^{2}$ 的 $95 \\%$ 的置信区间.  \n10. 假设人体身高服从正态分布, 今抽测甲、乙两地区 18 岁 25 岁女青年身高得数据如下: 甲地区抽取 10 名, 样本均值 $1.64 \\mathrm{~m}$, 样本标准差 $0.2 \\mathrm{~m}$; 乙地区抽取 10 名, 样本均值 $1.62 \\mathrm{~m}$, 样本标准差 $0.4 \\mathrm{~m}$. 求：  \n(1) 两正态总体方差比的 $95 \\%$ 的置信区间;",
        "metadata": {
            "Header 2": "妇题 6.5"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) 若已知 $\\sigma_{1}^{2},=\\sigma_{2}^{2}$, 求 $\\mu_{1}-\\mu_{2}$ 的 $95 \\%$ 的置信区间;  \n(3) 若对 $\\sigma_{1}^{2}, \\sigma_{2}^{2}$ 一无所知, 求 $\\mu_{1}-\\mu_{2}$ 的 $95 \\%$ 的近似置信区间;  \n(4) 求 $\\sigma_{1}^{2} / \\sigma_{2}^{2}$ 的 $95 \\%$ 的置信区间.  \n10. 假设人体身高服从正态分布, 今抽测甲、乙两地区 18 岁 25 岁女青年身高得数据如下: 甲地区抽取 10 名, 样本均值 $1.64 \\mathrm{~m}$, 样本标准差 $0.2 \\mathrm{~m}$; 乙地区抽取 10 名, 样本均值 $1.62 \\mathrm{~m}$, 样本标准差 $0.4 \\mathrm{~m}$. 求：  \n(1) 两正态总体方差比的 $95 \\%$ 的置信区间;  \n(2) 两正态总体均值差的 $95 \\%$ 的置信区间.",
        "metadata": {
            "Header 2": "妇题 6.5"
        },
        "type": "Document"
    },
    {
        "page_content": "统计推断的另一个主要内容是统计假设检验. 在这一章里我们将讨论统计假设的设立及其检验问题.",
        "metadata": {
            "Header 2": "第 7 章 假设检验"
        },
        "type": "Document"
    },
    {
        "page_content": "我们从一个例子开始引出假设检验问题.  \n例 7.1.1: 某厂生产的合金强度服从正态分布 $N(\\theta, 16)$, 其中 $\\theta$ 的设计值为不低于 $110(\\mathrm{~Pa})$. 为保证质量, 该厂每天都要对生产情况做例行检查, 以判断生产是否正常进行, 即该合金的平均强度不低于 $110(\\mathrm{~Pa})$. 某天从生产中随机抽取 25 块合金, 测得强度值为 $x_{1}, x_{2}, \\cdots, x_{25}$ 其均值为 $\\bar{x}=108(\\mathrm{~Pa})$ ,间当日生产是否正常?  \n对这个实际问题可作如下分析;  \n1. 这不是一个参数估计问题.\n2. 这是在给定总体与样本下, 要求对命题 “合金平均强度不低于 $110 \\mathrm{~Pa}$ ” 作出回答: “是” 还是 “否”? 这类问题称为统计假设检验问题, 简称假设检验问题.\n3. 命题: “合金平均强度不低于 $110 \\mathrm{~Pa}$ ”正确与否仅涉及参数 0 , 因此该命题是否正确将涉及如下两个参数集合:  \n$$\n\\theta_{0}=|\\theta ; \\theta \\geqslant 110|, \\theta_{1}=|\\theta: \\theta<110|\n$$  \n命题成立对应于 “ $\\theta \\in \\theta_{0}$ ”, 命题不成立则对应 “ $\\theta \\in \\theta_{1}$ ”. 在统计学中这两个非空参数集合都称作统计假设,简称假设.  \n4. 我们的任务是利用所给总体 $N(\\theta, 16)$ 和样本均值 $\\bar{x}=108(\\mathrm{~Pa})$ 去判断假设 (命题) “ $\\theta \\in \\theta_{0}$ ”.是否成立,这里的“判断”在统计学中称为检验或检验法则.  \n检验结果有两种:  \n“假设不正确”一一称为拒绝该假设;  \n“假设正确”一一称为接收该假设.",
        "metadata": {
            "Header 2": "7.1 假设检验的基本思想与概念",
            "Header 3": "7.1.1 假设检验问题"
        },
        "type": "Document"
    },
    {
        "page_content": "3. 命题: “合金平均强度不低于 $110 \\mathrm{~Pa}$ ”正确与否仅涉及参数 0 , 因此该命题是否正确将涉及如下两个参数集合:  \n$$\n\\theta_{0}=|\\theta ; \\theta \\geqslant 110|, \\theta_{1}=|\\theta: \\theta<110|\n$$  \n命题成立对应于 “ $\\theta \\in \\theta_{0}$ ”, 命题不成立则对应 “ $\\theta \\in \\theta_{1}$ ”. 在统计学中这两个非空参数集合都称作统计假设,简称假设.  \n4. 我们的任务是利用所给总体 $N(\\theta, 16)$ 和样本均值 $\\bar{x}=108(\\mathrm{~Pa})$ 去判断假设 (命题) “ $\\theta \\in \\theta_{0}$ ”.是否成立,这里的“判断”在统计学中称为检验或检验法则.  \n检验结果有两种:  \n“假设不正确”一一称为拒绝该假设;  \n“假设正确”一一称为接收该假设.  \n5. 若假设可用一个参数的集合表示, 该假设检验问题称为参数假设检验问题, 否则称为非参数假设检验问题, 例 7.1.1 就是一个参数假设检验问题, 而对假设 “总体为正态分布” 作出检验的问题就是一个非参数假设检验问题. 本章前三节讲述参数假设检验问题, 最后一节 (7.4) 将讨论非参数假设检验问题.",
        "metadata": {
            "Header 2": "7.1 假设检验的基本思想与概念",
            "Header 3": "7.1.1 假设检验问题"
        },
        "type": "Document"
    },
    {
        "page_content": "接下来我们来叙述假设检验的基本步骤.",
        "metadata": {
            "Header 2": "7.1 假设检验的基本思想与概念",
            "Header 3": "7.1.2 假设检验的基本步骤"
        },
        "type": "Document"
    },
    {
        "page_content": "在假设检验中, 常把一个被检验的假设称为原假设, 用 $H_{0}$ 表示, 通常将不应轻易加以否定的假设作为原假设. 当 $H_{0}$ 被拒绝时而接收的假设称为备择假设, 用 $H_{1}$ 表示, 它们常常成对出现. 在\n例 7.1.1 中, 我们可建立如下两个假设:  \n$$\nH_{0}: \\theta \\in \\Theta_{0}=\\left\\{\\theta: \\theta \\geqslant 110 \\mid \\quad \\text { vs } \\quad H_{1} ; \\theta \\in \\Theta_{1}=\\{\\theta: \\theta<110\\}\\right.\n$$  \n或简写为  \n$$\nH_{0}: \\theta \\geqslant 110 \\quad \\text { vs } \\quad H_{1}: \\theta<110\n$$  \n其中 “vs”是 versus 的缩写, 是 “对”的意思, 即表示 $H_{0}$ 对 $H_{1}$ 的假设检验问题.",
        "metadata": {
            "Header 2": "一、建立假设"
        },
        "type": "Document"
    },
    {
        "page_content": "由样本对原假设进行判断总是通过一个统计量完成的, 该统计量称为检验统计量. 比如, 在例 7.1.1中, 样本均值 $\\bar{x}$ 就是一个很好的检验统计量, 因为要检验的假设是正态总体的均值, 在方差已知场合, 样本均值 $x$ 是总体均值的充分统计量、使原假设被拒绝的样本观测值所在区域称为拒绝域,一般它是样本空间的一个子集, 并用 $W$ 表示, 在例 7.1.1中, 样本均值 $\\bar{x}$ 愈大, 意味着总体均值 $\\theta$ 也大, 样本均值 $\\bar{x}$ 愈小, 意味着总体均值 $\\theta$ 也小, 因此, 在样本均值的取值中有一个临界值 $c$ ( 待定),所以拒绝域为  \n$$\n\\left\\{W=\\mid\\left(x_{1}, \\cdots, x_{n}\\right) ; \\bar{x} \\leqslant c\\right\\}=\\{\\bar{x} \\leqslant c\\}\n$$  \n是合理的.  \n当拒绝域确定了,检验的判断准则跟着也确定了:  \n- 如果 $\\left(x_{1}, \\cdots, x_{n}\\right) \\in W$, 则认为 $H_{0}$ 不成立;\n- 如果 $\\left(x_{1}, \\cdots, x_{n}\\right) \\in \\bar{W}$, 认为 $H_{0}$ 成立;  \n一般将 $\\bar{W}$ 称为接收域. 由此可见, 一个拒绝域 $W$ 唯一确定一个检验法则, 反之, 一个检验法则也唯一确定一个拒绝续. 在两个观测值 $n=2$ 场合, 图 7.1.1 给出拒绝域的示意图.  \n通常我们将注意力放在拒绝域上. 正如在数学上我们不能用一个例子去证  \n明一个结论一样, 用一个样本 ( 例子) 不能证明一个命题 (假设 ) 是成立的, 但可以用一个例子 (样本) 推翻一个命题. 因此, 从逻辑上看, 注重拒绝域是适当的. 事实上,在 “拒绝原假设”和“拒绝备择假设 ( 从而接收原假设 )”之间还有一个模糊域, 如今我们把它并人接收域 (参见图 7.1.1),所以接收域是复杂的, 将之称为保留域也许更恰当, 但习惯上已把它称为接收域, 没有必要再进行改变, 只是应注意它的含义.  \n!  \n图 7.1.1: 拒绝域示意图",
        "metadata": {
            "Header 2": "二、选择检验统计量, 给出拒绝域形式"
        },
        "type": "Document"
    },
    {
        "page_content": "检验的结果与真实情况可能吻合也可能不吻合, 因此, 检验是可能犯错误的. 检验可能犯的错误有两类: 其一是 $H_{0}$ 为真但由子随机性使样本观测值落在拒绝域中, 从而拒绝原假设 $H_{0}$, 这种错\n误称为第一类错误, 其发生的概率称为犯第一类错误的概率, 或称拒真概率, 通常记为 $\\alpha$, 即  \n$$\n\\begin{equation*}\n\\alpha=P\\left(\\text { 拒绝 } H_{0} \\mid H_{0} \\text { 为真 }\\right)=P(X \\in W), \\theta \\in \\theta_{0} \\tag{7.1.1}\n\\end{equation*}\n$$  \n其中 $X=\\left(x_{1}, \\cdots, x_{n}\\right)$ 表示样本. 另一种错误是 $H_{0}$ 不真 (即 $H_{1}$ 为真) 但由于随机性使样本观测值落在接受域中, 从而接受原假设 $H_{0}$, 这种错误称为第二类错误, 其发生的概率称为犯第二类错误的概率,或称受伪概率, 通常记为 $\\beta$,即  \n$$\n\\begin{equation*}\n\\alpha=P\\left(\\text { 接受 } H_{0} \\mid H_{0} \\text { 为真 }\\right)=P(X \\in \\bar{W}), \\theta \\in \\Theta_{0} \\tag{7.1.2}\n\\end{equation*}\n$$  \n表7.1.1列出了检验的各种情况及两类错误.  \n表 7.1.1: 检验的两类错误  \n| 观察数据情况 | 总体情况 |  |\n| :--- | :--- | :--- |\n|  | $H_{0}$ 为真 | $H_{1}$ 为真 |\n| $\\left(x_{1}, \\cdots, x_{n}\\right) \\in W$ | 犯第一类错误 | 正确 |\n| $\\left(x_{1}, \\cdots, x_{n}\\right) \\in W^{c}$ | 正确 | 犯第二类错误 |  \n犯第一类错误的概率 $\\alpha$ 和犯第二类错误的概率 $\\beta$ 可以用同一个函数表示, 即所谓的势函数.势函数是假设检验中最重要的概念之一, 它的定义如下:  \n定义 7.1.1. 设检验问题  \n$$",
        "metadata": {
            "Header 2": "三、选择显着性水平"
        },
        "type": "Document"
    },
    {
        "page_content": "\\alpha=P\\left(\\text { 接受 } H_{0} \\mid H_{0} \\text { 为真 }\\right)=P(X \\in \\bar{W}), \\theta \\in \\Theta_{0} \\tag{7.1.2}\n\\end{equation*}\n$$  \n表7.1.1列出了检验的各种情况及两类错误.  \n表 7.1.1: 检验的两类错误  \n| 观察数据情况 | 总体情况 |  |\n| :--- | :--- | :--- |\n|  | $H_{0}$ 为真 | $H_{1}$ 为真 |\n| $\\left(x_{1}, \\cdots, x_{n}\\right) \\in W$ | 犯第一类错误 | 正确 |\n| $\\left(x_{1}, \\cdots, x_{n}\\right) \\in W^{c}$ | 正确 | 犯第二类错误 |  \n犯第一类错误的概率 $\\alpha$ 和犯第二类错误的概率 $\\beta$ 可以用同一个函数表示, 即所谓的势函数.势函数是假设检验中最重要的概念之一, 它的定义如下:  \n定义 7.1.1. 设检验问题  \n$$\nH_{0}: \\theta \\in \\Theta_{0} \\quad \\text { vs } \\quad H_{1}: \\theta \\in \\Theta_{1}\n$$  \n的拒绝域为 $W$, 则样本观测值 $X$ 落在拒绝域 $W$ 内的概率称为该检验的势函数, 记为  \n$$\n\\begin{equation*}\ng(\\theta)=P_{\\theta}(X \\in W), \\quad \\theta \\in \\Theta=\\Theta_{0} \\cup \\Theta_{1} \\tag{7.1.3}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "三、选择显着性水平"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\left(x_{1}, \\cdots, x_{n}\\right) \\in W^{c}$ | 正确 | 犯第二类错误 |  \n犯第一类错误的概率 $\\alpha$ 和犯第二类错误的概率 $\\beta$ 可以用同一个函数表示, 即所谓的势函数.势函数是假设检验中最重要的概念之一, 它的定义如下:  \n定义 7.1.1. 设检验问题  \n$$\nH_{0}: \\theta \\in \\Theta_{0} \\quad \\text { vs } \\quad H_{1}: \\theta \\in \\Theta_{1}\n$$  \n的拒绝域为 $W$, 则样本观测值 $X$ 落在拒绝域 $W$ 内的概率称为该检验的势函数, 记为  \n$$\n\\begin{equation*}\ng(\\theta)=P_{\\theta}(X \\in W), \\quad \\theta \\in \\Theta=\\Theta_{0} \\cup \\Theta_{1} \\tag{7.1.3}\n\\end{equation*}\n$$  \n显然, 势函数 $g(\\theta)$ 是定义在参数空间 $\\Theta$ 上的一个函数. 由 (7.1.1) 和 (7.1.2) 知, 当 $\\theta \\in \\Theta_{0}$ 时, $g(\\theta)=\\alpha=\\alpha(\\theta)$, 当 $\\theta \\in \\Theta_{1}$ 时, $g(\\beta)=1-\\beta=1-\\beta(\\theta)$. 由此可见, 犯两类错误的概率都是参数 $\\theta$ 的函数, 并可由势函数得到, 即:  \n$$\ng(\\theta)=\\left\\{\\begin{array}{cc}\n\\alpha(\\theta), & \\theta \\in \\Theta_{0} \\\\\n1-\\beta(\\theta), & \\theta \\in \\Theta_{1}\n\\end{array}\\right.\n$$  \n对例 7.1.1, 其拒绝域为 $W=|\\bar{x} \\leqslant c|$, 由 (7.1.3) 可以算出该检验的势函数  \n$$",
        "metadata": {
            "Header 2": "三、选择显着性水平"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n显然, 势函数 $g(\\theta)$ 是定义在参数空间 $\\Theta$ 上的一个函数. 由 (7.1.1) 和 (7.1.2) 知, 当 $\\theta \\in \\Theta_{0}$ 时, $g(\\theta)=\\alpha=\\alpha(\\theta)$, 当 $\\theta \\in \\Theta_{1}$ 时, $g(\\beta)=1-\\beta=1-\\beta(\\theta)$. 由此可见, 犯两类错误的概率都是参数 $\\theta$ 的函数, 并可由势函数得到, 即:  \n$$\ng(\\theta)=\\left\\{\\begin{array}{cc}\n\\alpha(\\theta), & \\theta \\in \\Theta_{0} \\\\\n1-\\beta(\\theta), & \\theta \\in \\Theta_{1}\n\\end{array}\\right.\n$$  \n对例 7.1.1, 其拒绝域为 $W=|\\bar{x} \\leqslant c|$, 由 (7.1.3) 可以算出该检验的势函数  \n$$\ng(\\theta)=P_{\\theta}(\\bar{x} \\leqslant c)=P_{\\theta}\\left(\\frac{\\bar{x}-\\theta}{4 / 5} \\leqslant \\frac{c-\\theta}{4 / 5}\\right)=\\Phi\\left(\\frac{c-\\theta}{4 / 5}\\right)\n$$  \n这个势函数是 $\\theta$ 的减函数 (见图7.1.2)  \n!  \n图 7.1.2: 例 7.1.1 的势函数 $g(\\theta)$  \n利用这个势函数容易写出其犯两类错误的概率分别为  \n$$\n\\begin{gather*}\n\\alpha(\\theta)=\\Phi\\left(\\frac{c-\\theta}{4 / 5}\\right), \\quad \\theta \\in \\Theta_{0}  \\tag{7.1.4}\\\\\n\\beta(\\theta)=1-\\Phi\\left(\\frac{c-\\theta}{4 / 5}\\right), \\quad \\theta \\in \\Theta_{1} \\tag{7.1.5}\n\\end{gather*}\n$$",
        "metadata": {
            "Header 2": "三、选择显着性水平"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n这个势函数是 $\\theta$ 的减函数 (见图7.1.2)  \n!  \n图 7.1.2: 例 7.1.1 的势函数 $g(\\theta)$  \n利用这个势函数容易写出其犯两类错误的概率分别为  \n$$\n\\begin{gather*}\n\\alpha(\\theta)=\\Phi\\left(\\frac{c-\\theta}{4 / 5}\\right), \\quad \\theta \\in \\Theta_{0}  \\tag{7.1.4}\\\\\n\\beta(\\theta)=1-\\Phi\\left(\\frac{c-\\theta}{4 / 5}\\right), \\quad \\theta \\in \\Theta_{1} \\tag{7.1.5}\n\\end{gather*}\n$$  \n由上述两个式子可以看出犯两类错误的概率 $\\alpha, \\beta$ 间的关系:  \n- 当 $\\alpha$ 减小时,由 (7.1.4) 知, $c$ 也随之减小,再由 (7.1.5) 知, $c$ 的减小必导致 $\\beta$ 的增大;\n- 当 $\\beta$ 减小时, 由 (7.1.5) 知, $c$ 会增大, 再由 (7.1.4) 知, $c$ 的增大必导致 $\\alpha$ 的增大.  \n这一现象说明:在样本量给定的条件下, $\\alpha$ 与 $\\beta$ 中一个减小必导致另一个增大,这不是偶然的,而具有一般性. 这进一步说明: 在样本量一定的条件下不可能找到一个使 $\\alpha, \\beta$ 都小的检验. 在此背景下, 只能采取折中方案. 英国统计学家 Neyman 和 Pearson 提出水平为 $\\alpha$ 的显著性检验的概念.  \n定义 7.1.2. 对检验问题 $H_{0}: \\theta \\in \\Theta_{0} \\quad$ vs $\\quad H_{1}: \\theta \\in \\Theta_{1}$, 如果一个检验满足对任意的 $\\theta \\in \\Theta_{0}$, 都有  \n$$\ng(\\theta) \\leqslant \\alpha\n$$  \n则称该检验是显着性水平为 $\\alpha$ 的显着性检验,简称水平为 $\\alpha$ 的检验.",
        "metadata": {
            "Header 2": "三、选择显着性水平"
        },
        "type": "Document"
    },
    {
        "page_content": "- 当 $\\beta$ 减小时, 由 (7.1.5) 知, $c$ 会增大, 再由 (7.1.4) 知, $c$ 的增大必导致 $\\alpha$ 的增大.  \n这一现象说明:在样本量给定的条件下, $\\alpha$ 与 $\\beta$ 中一个减小必导致另一个增大,这不是偶然的,而具有一般性. 这进一步说明: 在样本量一定的条件下不可能找到一个使 $\\alpha, \\beta$ 都小的检验. 在此背景下, 只能采取折中方案. 英国统计学家 Neyman 和 Pearson 提出水平为 $\\alpha$ 的显著性检验的概念.  \n定义 7.1.2. 对检验问题 $H_{0}: \\theta \\in \\Theta_{0} \\quad$ vs $\\quad H_{1}: \\theta \\in \\Theta_{1}$, 如果一个检验满足对任意的 $\\theta \\in \\Theta_{0}$, 都有  \n$$\ng(\\theta) \\leqslant \\alpha\n$$  \n则称该检验是显着性水平为 $\\alpha$ 的显着性检验,简称水平为 $\\alpha$ 的检验.  \n提出显著性检验的概念就是要控制犯第一类错误的概率 $\\alpha$, 但也不能使得 $\\alpha$ 过小 ( $\\alpha$ 过小会导致 $\\beta$ 过大), 在适当控制 $\\alpha$ 中制约 $\\beta$. 最常用的选择是 $\\alpha=0.05$, 有时也选择 $\\alpha=0.10$ 或 $\\alpha=0.01$.",
        "metadata": {
            "Header 2": "三、选择显着性水平"
        },
        "type": "Document"
    },
    {
        "page_content": "在确定显著性水平后, 我们可以定出检验的拒绝域 $W$. 在例 7.1.1中, 若取 $\\alpha=0.05$, 则要求对任意的 $\\theta \\geqslant 100$ 有 $g(\\theta)=\\Phi(5(c-\\theta) / 4) \\leqslant 0.05$, 由于 $g(\\theta)$ 是关于 $\\theta$ 的单调减函数 (见图 7.1.2),只需要  \n$$\ng(110)=\\Phi(5(c-110) / 4)=0.05\n$$  \n成立即可. 由此可先确定标准正态分布的 0.05 分位数 $u_{0.05}=-u_{0.95}$, 它使得  \n$$\n\\frac{5(c-110)}{4}=u_{0.05}\n$$  \n从而 $c$ 的值为  \n$$\nc=110+0.8 u_{0.05}=110-0.8 \\times 1.645=108.684\n$$  \n所以,检验的拒绝域为  \n$$\nW=\\{\\bar{x} \\leqslant 108.684\\}\n$$  \n若令 $u=\\frac{\\bar{x}-110}{4 / 5}$, 则拒绝域有另一种表示, 即  \n$$\nW=\\left\\{u \\leqslant u_{0.05}\\right\\}=\\{u \\leqslant-1.645\\}\n$$  \n五、做出判断  \n在有了明确的拒绝域 $W$ 后, 根据样本观测值我们可以做出判断:  \n- 当 $\\bar{x} \\leqslant 108.684$ 或 $u \\leqslant-1.645$ 时, 则拒绝 $H_{0}$, 即接收 $H_{1}$;  \n。当 $\\bar{x}>108.684$ 或 $u>-1.645$ 时,则接收 $H_{0}$.  \n在例7.1.1 中, 由于  \n$$\n\\bar{x}=108<108.684\n$$  \n因此拒绝原假设, 即认为该日生产不正常.",
        "metadata": {
            "Header 2": "四、给出拒绝域"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设 $x_{1}, \\cdots, x_{n}$ 是来自 $N(\\mu, 1)$ 的样本, 考虑如下假设检验问题  \n$$\nH_{0}: \\mu=2 \\quad \\text { vs } \\quad H_{1}, \\mu=3\n$$  \n若检验由拒绝域为 $w=\\{\\bar{x} \\geqslant 2.6\\}$ 确定.  \n(1) 当 $n=20$ 时求检验犯两类错误的概率;  \n(2) 如果要使得检验犯第二类错误的概率 $\\beta \\leqslant 0.01, n$ 最小应取多少?  \n(3) 证明: 当 $n \\rightarrow+\\infty$ 时, $\\alpha \\rightarrow 0, \\beta \\rightarrow 0$.  \n2. 设 $x_{1}, \\cdots, x_{10}$ 是来自 $0-1$ 总体 $b(1, p)$ 的样本, 考虑如下检验问题  \n$$\nH_{0}: p=0.2 \\quad \\text { vs } \\quad H_{1}, p=0.4\n$$  \n取拒绝域为 $W=\\{\\bar{x} \\geqslant 0.5\\}$, 求该检验犯两类错误的概率.  \n3. 设 $x_{1}, \\cdots, x_{16}$ 是来自正态总体 $N(\\mu, 4)$ 的样本, 考虑检验问题  \n$$\nH_{0}: \\mu=6 \\quad \\text { vs } \\quad H_{1}: \\mu \\neq 6\n$$  \n拒绝域取为 $W=\\{|\\bar{x}-6| \\geqslant c\\}$, 试求 $c$ 使得检验的显著性水平为 0.05 , 并求该检验在 $\\mu=6.5$处犯第二类错误的概率.  \n4. 设总体为均匀分布 $U(0, \\theta), x_{1}, \\cdots, x_{n}$ 是样本, 考虑检验问题  \n$$\nH_{0}: \\theta \\geqslant 3 \\quad \\text { vs } \\quad H_{1}: \\theta<3\n$$  \n拒绝域取为 $W=\\left\\{x_{(n)} \\leqslant 2.5\\right\\}$, 求检验犯第一类错误的最大值 $\\alpha$, 若要使得该最大值 $\\alpha$ 不超过 $0.05, n$ 至少应取多大?",
        "metadata": {
            "Header 2": "也习题 7.1"
        },
        "type": "Document"
    },
    {
        "page_content": "3. 设 $x_{1}, \\cdots, x_{16}$ 是来自正态总体 $N(\\mu, 4)$ 的样本, 考虑检验问题  \n$$\nH_{0}: \\mu=6 \\quad \\text { vs } \\quad H_{1}: \\mu \\neq 6\n$$  \n拒绝域取为 $W=\\{|\\bar{x}-6| \\geqslant c\\}$, 试求 $c$ 使得检验的显著性水平为 0.05 , 并求该检验在 $\\mu=6.5$处犯第二类错误的概率.  \n4. 设总体为均匀分布 $U(0, \\theta), x_{1}, \\cdots, x_{n}$ 是样本, 考虑检验问题  \n$$\nH_{0}: \\theta \\geqslant 3 \\quad \\text { vs } \\quad H_{1}: \\theta<3\n$$  \n拒绝域取为 $W=\\left\\{x_{(n)} \\leqslant 2.5\\right\\}$, 求检验犯第一类错误的最大值 $\\alpha$, 若要使得该最大值 $\\alpha$ 不超过 $0.05, n$ 至少应取多大?  \n5. 在假设检验问题中, 若检验结果是接受原假设, 则检验可能犯哪一类错误? 若检验结构是拒绝原假设,则又有可能犯哪一类错误?",
        "metadata": {
            "Header 2": "也习题 7.1"
        },
        "type": "Document"
    },
    {
        "page_content": "参数假设检验常见的有三种基本形式  \n(1) $H_{0}: \\theta \\leqslant \\theta_{0} \\quad$ vs $H_{1}: \\theta>\\theta_{0}$  \n(2) $H_{0}: \\theta \\geqslant \\theta_{0} \\quad$ vs $H_{1} ; \\theta<\\theta_{0}$  \n(3) $H_{0}: \\theta=\\theta_{0} \\quad$ vs $H_{1}: \\theta \\neq \\theta_{0}$  \n一般说来, 对这三种假设所采用的检验统计量是相同的, 差别在拒绝域上. 当备择假设 $H_{1}$ 在原假设 $H_{0}$ 一侧时的检验称为单侧检验, 当备择假设 $H_{1}$ 分散在原假设 $H_{0}$ 两侧时的检验称为双侧检验. 以上 (1), (2) 是单侧检验, (3) 是双侧检验. 识别单侧与双侧检验有益于以后构造其拒绝域.  \n本节对正态总体参数检验分别进行讨论.",
        "metadata": {
            "Header 2": "7.2 正态总体参数假设检验"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $x_{1}, \\cdots, x_{n}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 考虑如下三种关于 $\\mu$ 的检验问题  \n$$\n\\begin{array}{lcl}\nH_{0}: \\mu \\leqslant \\mu_{0} & \\text { vs } & H_{1}: \\mu>\\mu_{0} \\\\\nH_{0}: \\mu \\geqslant \\mu_{0} & \\text { vs } & H_{1}: \\mu<\\mu_{0} \\\\\nH_{0}: \\mu=\\mu_{0} & \\text { vs } & H_{1}: \\mu \\neq \\mu_{0} \\tag{7.2.3}\n\\end{array}\n$$  \n由于正态总体含两个参数, 总体方差 $\\sigma^{2}$ 已知与否对检验有影响. 下面我们分 $\\sigma$ 已知和未知两种情况叙述.",
        "metadata": {
            "Header 2": "7.2 正态总体参数假设检验",
            "Header 3": "7.2.1 单个正态总体均值的检验"
        },
        "type": "Document"
    },
    {
        "page_content": "对于单侧检验问题 (7.2.1), 由于 $\\mu$ 的点估计是, 且 $\\bar{x} \\sim N\\left(\\mu, \\sigma^{2} / n\\right)$, 故选用检验统计量  \n$$\n\\begin{equation*}\nu=\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}} \\tag{7.2.4}\n\\end{equation*}\n$$  \n是恰当的. 直觉告诉我们: 当样本均值 $\\bar{x}$ 不超过设定均值 $\\mu_{0}$ 时, 应接收原假设; 当样本均值 $\\bar{x}$ 超过 $\\mu_{0}$ 时, 应拒绝原假设. 可是, 在有随机性存在的场合, 如果 $\\bar{x}$ 比 $\\mu_{0}$ 大一点就拒绝原假设似乎不当,只有当 $\\bar{x}$ 比 $\\mu_{0}$ 大到一定程度时拒绝原假设才是恰当的, 这就存在一个临界值 $c$, 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{\\left(x_{1}, \\cdots, x_{n}\\right): u \\geqslant c\\right\\} \\tag{7.2.5}\n\\end{equation*}\n$$  \n常简记为 $\\mu \\geqslant c$, 若要求检验的显著性水平为 $\\alpha$, 则 $c$ 满足  \n$$\nP_{\\mu_{0}}(u \\geqslant c)=\\alpha\n$$  \n由于在 $\\mu=\\mu_{0}$ 时 $\\mu \\sim N(0,1)$, 故 $c=\\mu_{1-\\alpha}$ (见图 7.2.1(a)), 最后的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{u \\geqslant u_{1-\\alpha}\\right\\} \\tag{7.2.6}\n\\end{equation*}\n$$  \n!  \n(a) $H_{1}: \\mu>\\mu_{0}$  \n!  \n(b) $H_{1}: \\mu<\\mu_{0}$  \n!  \n(c) $H_{1}: \\mu \\neq \\mu_{0}$  \n图 7.2.1: $\\mu$ 检验的拒绝域",
        "metadata": {
            "Header 2": "一、 $\\sigma$ 已知时的 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n常简记为 $\\mu \\geqslant c$, 若要求检验的显著性水平为 $\\alpha$, 则 $c$ 满足  \n$$\nP_{\\mu_{0}}(u \\geqslant c)=\\alpha\n$$  \n由于在 $\\mu=\\mu_{0}$ 时 $\\mu \\sim N(0,1)$, 故 $c=\\mu_{1-\\alpha}$ (见图 7.2.1(a)), 最后的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{u \\geqslant u_{1-\\alpha}\\right\\} \\tag{7.2.6}\n\\end{equation*}\n$$  \n!  \n(a) $H_{1}: \\mu>\\mu_{0}$  \n!  \n(b) $H_{1}: \\mu<\\mu_{0}$  \n!  \n(c) $H_{1}: \\mu \\neq \\mu_{0}$  \n图 7.2.1: $\\mu$ 检验的拒绝域  \n该检验用的检验统计量是 $\\mu$ 统计量, 故一般称为 $\\mu$ 检验. 该检验的势函数是 $\\mu$ 的函数, 它可用正态分布写出,具体如下:对 $\\mu \\in(\\infty,+\\infty)$,  \n$$\n\\begin{aligned}\ng(\\mu) & =P_{\\mu}(X \\in W)=P_{\\mu}\\left(u \\geqslant u_{1-\\alpha}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}} \\geqslant u_{1-a}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu+\\mu-\\mu_{0}}{\\sigma / \\sqrt{n}} \\geqslant u_{1-\\alpha}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}} \\geqslant \\frac{\\mu_{0}-\\mu}{\\sigma / \\sqrt{n}}+u_{1-\\alpha}\\right) \\\\",
        "metadata": {
            "Header 2": "一、 $\\sigma$ 已知时的 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\ng(\\mu) & =P_{\\mu}(X \\in W)=P_{\\mu}\\left(u \\geqslant u_{1-\\alpha}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}} \\geqslant u_{1-a}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu+\\mu-\\mu_{0}}{\\sigma / \\sqrt{n}} \\geqslant u_{1-\\alpha}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}} \\geqslant \\frac{\\mu_{0}-\\mu}{\\sigma / \\sqrt{n}}+u_{1-\\alpha}\\right) \\\\\n& =1-\\Phi\\left(\\sqrt{n}\\left(\\mu_{0}-\\mu\\right) / \\sigma+u_{1-a}\\right)\n\\end{aligned}\n$$  \n由此可见, 势函数是 $\\mu$ 的增函数, 其图形见图 7.2.2(a), 由增函数性质知, 只要 $g\\left(\\mu_{0}=\\alpha\\right)$ 就可保证在 $\\mu \\leqslant \\mu_{0}$ 时有 $g(\\mu) \\leqslant \\mu_{0}$, 所以上述求出的检验是水平为 $\\alpha$ 的检验.  \n对单侧检验问题 (7.2.1), 可以类似进行讨论. 仍选用 $\\mu$ 作为检验统计量, 考虑到 (7.2.1) 的备择  \n!  \n(a) $H_{1}: \\mu>\\mu_{0}$  \n!  \n(b) $H_{1}: \\mu<\\mu_{0}$  \n!  \n(c) $H_{1}: \\mu \\neq \\mu_{0}$  \n图 7.2.2: $g(\\mu)$ 的图形  \n假设 $H_{1}$ 在左侧,故其拒绝城应有如下形式  \n$$\nW=\\{\\mu \\leqslant c\\}\n$$",
        "metadata": {
            "Header 2": "一、 $\\sigma$ 已知时的 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n由此可见, 势函数是 $\\mu$ 的增函数, 其图形见图 7.2.2(a), 由增函数性质知, 只要 $g\\left(\\mu_{0}=\\alpha\\right)$ 就可保证在 $\\mu \\leqslant \\mu_{0}$ 时有 $g(\\mu) \\leqslant \\mu_{0}$, 所以上述求出的检验是水平为 $\\alpha$ 的检验.  \n对单侧检验问题 (7.2.1), 可以类似进行讨论. 仍选用 $\\mu$ 作为检验统计量, 考虑到 (7.2.1) 的备择  \n!  \n(a) $H_{1}: \\mu>\\mu_{0}$  \n!  \n(b) $H_{1}: \\mu<\\mu_{0}$  \n!  \n(c) $H_{1}: \\mu \\neq \\mu_{0}$  \n图 7.2.2: $g(\\mu)$ 的图形  \n假设 $H_{1}$ 在左侧,故其拒绝城应有如下形式  \n$$\nW=\\{\\mu \\leqslant c\\}\n$$  \n对给定的显著性水平 $\\alpha(0<\\alpha<1)$, 由 $P_{\\mu_{0}}(u \\leqslant c)=\\alpha$ 可定出 $c=\\mu_{\\alpha}$ (图 7.2.1(b)), 最后的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{\\mu \\leqslant \\mu_{\\alpha}\\right\\} \\tag{7.2.7}\n\\end{equation*}\n$$  \n判断准则是类似的: 当 $\\mu \\leqslant \\mu_{\\alpha}$ 时拒绝原假设 $H_{0}$ (接收 $H_{1}$ ), 否则接收 $H_{0}$. 该检验的势函数也是 $\\mu$ 的减函数 (图 7.2.2(b)), 具体如下: 对 $\\mu \\in(-\\infty,+\\infty$ ),  \n$$\n\\begin{aligned}\ng(\\mu) & =P_{\\mu}\\left(u \\leqslant u_{a}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}} \\leqslant u_{\\mathrm{a}}\\right) \\\\",
        "metadata": {
            "Header 2": "一、 $\\sigma$ 已知时的 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nW=\\left\\{\\mu \\leqslant \\mu_{\\alpha}\\right\\} \\tag{7.2.7}\n\\end{equation*}\n$$  \n判断准则是类似的: 当 $\\mu \\leqslant \\mu_{\\alpha}$ 时拒绝原假设 $H_{0}$ (接收 $H_{1}$ ), 否则接收 $H_{0}$. 该检验的势函数也是 $\\mu$ 的减函数 (图 7.2.2(b)), 具体如下: 对 $\\mu \\in(-\\infty,+\\infty$ ),  \n$$\n\\begin{aligned}\ng(\\mu) & =P_{\\mu}\\left(u \\leqslant u_{a}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}} \\leqslant u_{\\mathrm{a}}\\right) \\\\\n& =P_{\\mu}\\left(\\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}} \\leqslant \\frac{\\mu_{0}-\\mu}{\\sigma / \\sqrt{n}}+u_{\\alpha}\\right) \\\\\n& =\\Phi\\left(\\sqrt{n}\\left(\\mu_{0}-\\mu\\right) / \\sigma+u_{a}\\right)\n\\end{aligned}\n$$  \n对双侧检验问题 (7.2.3), 也可类似进行讨论. 仍选用 $\\mu$ 作为检验统计量, 考虑到 (7.2.3) 的备择假设 $H_{1}$ 分散在二侧,故其拒绝域亦应在二侧,即拒绝域应有如下形式  \n$$\nW=\\{|\\mu| \\geqslant c\\}\n$$  \n对给定的显著性水平 $\\alpha(0<\\alpha<1)$, 由 $P_{\\mu_{0}}(|\\mu| \\geqslant c)=\\alpha$ 可定出 $c=\\mu_{1-\\alpha / 2}$ (见图 7.2.1(c)), 最后的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{|\\mu| \\geqslant_{1-\\alpha / 2}\\right\\} \\tag{7.2.8}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "一、 $\\sigma$ 已知时的 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\Phi\\left(\\sqrt{n}\\left(\\mu_{0}-\\mu\\right) / \\sigma+u_{a}\\right)\n\\end{aligned}\n$$  \n对双侧检验问题 (7.2.3), 也可类似进行讨论. 仍选用 $\\mu$ 作为检验统计量, 考虑到 (7.2.3) 的备择假设 $H_{1}$ 分散在二侧,故其拒绝域亦应在二侧,即拒绝域应有如下形式  \n$$\nW=\\{|\\mu| \\geqslant c\\}\n$$  \n对给定的显著性水平 $\\alpha(0<\\alpha<1)$, 由 $P_{\\mu_{0}}(|\\mu| \\geqslant c)=\\alpha$ 可定出 $c=\\mu_{1-\\alpha / 2}$ (见图 7.2.1(c)), 最后的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{|\\mu| \\geqslant_{1-\\alpha / 2}\\right\\} \\tag{7.2.8}\n\\end{equation*}\n$$  \n判断准则仍类似: 当 $\\mu \\geqslant_{1-\\alpha / 2}$ 时拒绝原假设 $H_{0}$ ( 接收 $H_{1}$ ), 否则接收 $H_{0}$. 该检验的势函数仍是 $\\mu$ 的函数 (图7.2.2(c)), 具体如下: 对 $\\mu \\in(-\\infty,+\\infty)$,  \n$$\n\\begin{aligned}\ng(\\mu) & =P_{\\mu}\\left(|u| \\geqslant u_{1-\\alpha / 2}\\right)=P_{\\mu}\\left(\\frac{\\left|\\bar{x}-\\mu_{0}\\right|}{\\sigma / \\sqrt{n}} \\geqslant u_{1-a / 2}\\right) \\\\\n& =1-P_{\\mu}\\left(\\frac{\\mu_{0}-\\mu}{\\sigma / \\sqrt{n}}-u_{1-a / 2} \\leqslant \\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}} \\leqslant \\frac{\\mu_{0}-\\mu}{\\sigma / \\sqrt{n}}+u_{1-a / 2}\\right)\n\\end{aligned}\n$$  \n$$",
        "metadata": {
            "Header 2": "一、 $\\sigma$ 已知时的 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\ng(\\mu) & =P_{\\mu}\\left(|u| \\geqslant u_{1-\\alpha / 2}\\right)=P_{\\mu}\\left(\\frac{\\left|\\bar{x}-\\mu_{0}\\right|}{\\sigma / \\sqrt{n}} \\geqslant u_{1-a / 2}\\right) \\\\\n& =1-P_{\\mu}\\left(\\frac{\\mu_{0}-\\mu}{\\sigma / \\sqrt{n}}-u_{1-a / 2} \\leqslant \\frac{\\bar{x}-\\mu}{\\sigma / \\sqrt{n}} \\leqslant \\frac{\\mu_{0}-\\mu}{\\sigma / \\sqrt{n}}+u_{1-a / 2}\\right)\n\\end{aligned}\n$$  \n$$\n=1-\\Phi\\left(\\sqrt{n}\\left(\\mu_{0}-\\mu\\right) / \\sigma+u_{1-a / 2}\\right)+\\Phi\\left(\\sqrt{n}\\left(\\mu_{0}-\\mu\\right) / \\sigma-u_{1-a / 2}\\right)\n$$  \n由图 7.2.2 可以看出, 对三种假设检验问题, 只要在 $\\mu=\\mu_{0}$ 处控制检验犯第一类错误的概率为 $\\alpha$, 则检验就是水平为 $\\alpha$ 的显著性检验. 这不是偶然的现象, 具有一般性, 这为求显著性检验提供了很大的方便.  \n例 7.2.1: 从甲地发送一个讯号到乙地. 设乙地接受到的讯号值是一个服从正态分布 $N\\left(\\mu, 0.2^{2}\\right)$ 的随机变量, 其中 $\\mu$ 为甲地发送的真实讯号值. 现甲地重复发送同一讯号 5 次, 乙地接收到的讯号值为  \n$$\n\\begin{array}{lllll}\n8.05 & 8.15 & 8.2 & 8.1 & 8.25\n\\end{array}\n$$  \n设接受方有理由猜测甲地发送的讯号值为 8 , 问能否接受这猜测?  \n解: 这是一个假设检验的问题, 总体 $X \\sim N\\left(\\mu, 0.2^{2}\\right)$, 待检验的原假设 $H_{0}$ 与备择假设 $H_{1}$ 分别为",
        "metadata": {
            "Header 2": "一、 $\\sigma$ 已知时的 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由图 7.2.2 可以看出, 对三种假设检验问题, 只要在 $\\mu=\\mu_{0}$ 处控制检验犯第一类错误的概率为 $\\alpha$, 则检验就是水平为 $\\alpha$ 的显著性检验. 这不是偶然的现象, 具有一般性, 这为求显著性检验提供了很大的方便.  \n例 7.2.1: 从甲地发送一个讯号到乙地. 设乙地接受到的讯号值是一个服从正态分布 $N\\left(\\mu, 0.2^{2}\\right)$ 的随机变量, 其中 $\\mu$ 为甲地发送的真实讯号值. 现甲地重复发送同一讯号 5 次, 乙地接收到的讯号值为  \n$$\n\\begin{array}{lllll}\n8.05 & 8.15 & 8.2 & 8.1 & 8.25\n\\end{array}\n$$  \n设接受方有理由猜测甲地发送的讯号值为 8 , 问能否接受这猜测?  \n解: 这是一个假设检验的问题, 总体 $X \\sim N\\left(\\mu, 0.2^{2}\\right)$, 待检验的原假设 $H_{0}$ 与备择假设 $H_{1}$ 分别为  \n$$\nH_{0}: \\mu=8 \\quad \\text { vs } \\quad H_{1}: \\mu \\neq 8\n$$  \n这是一个双侧检验问题, 检验的拒绝域为 $\\left\\{|u| \\geqslant u_{1-\\alpha / 2}\\right\\}$. 取置信水平 $\\alpha=0.05$, 则查表知 $u_{0.975}=$ 1.96. 现该例中观测值可计算得出 $\\bar{x}=8.15, u=\\sqrt{5}(8.15-8) / 0.2=1.68, \\mu$ 值未落人拒绝域内,故不能拒绝原假设,即接受原假设,可认为猜测成立.",
        "metadata": {
            "Header 2": "一、 $\\sigma$ 已知时的 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "对检验问题 (7.2.1), 由于 $\\sigma$ 未知, (7.2.4) 给出的 $\\mu$ 含未知参数 $\\sigma$ 而无法计算, 需要做修改. 一个自然的想法是将 (7.2.4) 中未知的 $\\sigma$ 替换成样本标准差 $s$, 这就形成 $t$ 检验统计量  \n$$\n\\begin{equation*}\nt=\\frac{\\sqrt{n}\\left(\\bar{x}-\\mu_{0}\\right)}{s} \\tag{7.2.9}\n\\end{equation*}\n$$  \n由定理 5.4.1 知, 在 $\\mu=\\mu_{0}$ 时 $t \\sim t(n-1)$, 从而检验问题 (7.2.1) 的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{t \\geqslant t_{1 \\cdot a}(n-1)\\right\\} \\tag{7.2.10}\n\\end{equation*}\n$$  \n对检验问题 (7.2.2), 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{t \\leqslant t_{a}(n-1)\\right\\} \\tag{7.2.11}\n\\end{equation*}\n$$  \n对检验问题 (7.2.3), 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{|t| \\geqslant t_{1-a / 2}(n-1)\\right\\} \\tag{7.2.12}\n\\end{equation*}\n$$  \n同样可证明这三个检验都是水平为 $\\alpha$ 的检验.  \n例 7.2.2: 某厂生产的某种铝材的长度服从正态分布, 其均值设定为 $240 \\mathrm{~cm}$. 现从该厂抽取 5 件产品, 测得其长度为 (单位: $\\mathrm{cm}$ )  \n$\\begin{array}{lllll}239.7 & 239.6 & 239 & 240 & 239.2\\end{array}$  \n试判断该厂此类铝材的长度是否满足设定要求?",
        "metadata": {
            "Header 2": "二、 $\\sigma$ 未知时的 $t$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n对检验问题 (7.2.2), 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{t \\leqslant t_{a}(n-1)\\right\\} \\tag{7.2.11}\n\\end{equation*}\n$$  \n对检验问题 (7.2.3), 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{|t| \\geqslant t_{1-a / 2}(n-1)\\right\\} \\tag{7.2.12}\n\\end{equation*}\n$$  \n同样可证明这三个检验都是水平为 $\\alpha$ 的检验.  \n例 7.2.2: 某厂生产的某种铝材的长度服从正态分布, 其均值设定为 $240 \\mathrm{~cm}$. 现从该厂抽取 5 件产品, 测得其长度为 (单位: $\\mathrm{cm}$ )  \n$\\begin{array}{lllll}239.7 & 239.6 & 239 & 240 & 239.2\\end{array}$  \n试判断该厂此类铝材的长度是否满足设定要求?  \n这是一个关于正态均值的双侧假设检验问题. 原假设是 $H_{0}: \\mu=240$, 备择假设是 $H_{1}: \\mu=$ 240. 由于 $\\sigma$ 未知, 故采用 $t$ 检验, 其拒绝域为 $\\left\\{|t| \\geqslant t_{1-a / 2}(n-1)\\right\\}$, 若取 $\\alpha=0.05$, 则查表得 $t_{0.975}(4)=2.776$. 现由样本计算得到 $\\bar{x}=239.5, s=0.4$, 故  \n$$\nt=\\sqrt{5} \\cdot|239.5-240| / 0.4=2.795\n$$  \n由于 $2.795>2.776$, 故拒绝原假设,认为该厂生产的铝材的长度不满足设定要求.  \n综上,关于单个正态总体的均值的检验问题可汇总成表 7.2.1.\n表 7.2.1: 单个正态总体均值的假设检验  \n| 检验法 | 条件 | 原假设 $H_{0}$ | 备择假设 $H_{1}$ | 检验统计量 | 拒绝域 |\n| :--- | :--- | :--- | :---: | :---: | :--- |",
        "metadata": {
            "Header 2": "二、 $\\sigma$ 未知时的 $t$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "这是一个关于正态均值的双侧假设检验问题. 原假设是 $H_{0}: \\mu=240$, 备择假设是 $H_{1}: \\mu=$ 240. 由于 $\\sigma$ 未知, 故采用 $t$ 检验, 其拒绝域为 $\\left\\{|t| \\geqslant t_{1-a / 2}(n-1)\\right\\}$, 若取 $\\alpha=0.05$, 则查表得 $t_{0.975}(4)=2.776$. 现由样本计算得到 $\\bar{x}=239.5, s=0.4$, 故  \n$$\nt=\\sqrt{5} \\cdot|239.5-240| / 0.4=2.795\n$$  \n由于 $2.795>2.776$, 故拒绝原假设,认为该厂生产的铝材的长度不满足设定要求.  \n综上,关于单个正态总体的均值的检验问题可汇总成表 7.2.1.\n表 7.2.1: 单个正态总体均值的假设检验  \n| 检验法 | 条件 | 原假设 $H_{0}$ | 备择假设 $H_{1}$ | 检验统计量 | 拒绝域 |\n| :--- | :--- | :--- | :---: | :---: | :--- |\n| 检验 | $\\sigma$ 已知 | $\\mu \\leqslant \\mu_{0}$ | $\\mu>\\mu_{0}$ |  | $\\left\\{u \\geqslant u_{1}-\\alpha\\right\\}$ |\n|  |  | $\\mu \\geqslant \\mu_{0}$ | $\\mu<\\mu_{0}$ | $\\mu=\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}}$ | $\\left\\{u \\leqslant u_{\\alpha}\\right\\}$ |\n|  |  | $\\mu=\\mu_{0}$ | $\\mu \\neq \\mu_{0}$ |  | $\\left\\{\\|u\\| \\geqslant u_{1-\\alpha / 2}\\right\\}$ |\n| $t$ 检验 | $\\sigma$ 已知 | $\\mu \\geqslant \\mu_{0}$ | $\\mu>\\mu_{0}$ |  | $\\left\\{t \\geqslant \\mu_{1-\\alpha}(n-1)\\right\\}$ |",
        "metadata": {
            "Header 2": "二、 $\\sigma$ 未知时的 $t$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| 检验 | $\\sigma$ 已知 | $\\mu \\leqslant \\mu_{0}$ | $\\mu>\\mu_{0}$ |  | $\\left\\{u \\geqslant u_{1}-\\alpha\\right\\}$ |\n|  |  | $\\mu \\geqslant \\mu_{0}$ | $\\mu<\\mu_{0}$ | $\\mu=\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}}$ | $\\left\\{u \\leqslant u_{\\alpha}\\right\\}$ |\n|  |  | $\\mu=\\mu_{0}$ | $\\mu \\neq \\mu_{0}$ |  | $\\left\\{\\|u\\| \\geqslant u_{1-\\alpha / 2}\\right\\}$ |\n| $t$ 检验 | $\\sigma$ 已知 | $\\mu \\geqslant \\mu_{0}$ | $\\mu>\\mu_{0}$ |  | $\\left\\{t \\geqslant \\mu_{1-\\alpha}(n-1)\\right\\}$ |\n|  |  | $\\mu=\\mu_{0}$ | $\\mu<\\mu_{0}$ | $t=\\frac{\\bar{x}-\\mu_{0}}{s / \\sqrt{n}}$ | $\\left\\{t \\leqslant t_{\\alpha}(n-1)\\right\\}$ |\n|  |  | $\\mu \\neq \\mu_{0}$ |  | $\\left\\{\\|t\\| \\geqslant t_{1-\\alpha / 2}(n-1)\\right\\}$ |  |",
        "metadata": {
            "Header 2": "二、 $\\sigma$ 未知时的 $t$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "细心的读者可能会发现, 这里用的检验统计量与 6.5 .5 节中置信区间所用的枢轴量是相同的,这不是偶然的,两者之间存在非常密切的关系,现叙述如下.  \n设 $x_{1}, \\cdots, x_{n}$ 是来自正态总体 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 现讨论在 $\\sigma$ 未知场合关于均值 $\\mu$ 的检验问题. 分三种情况:  \n考虑双侧检验问题  \n$$\nH_{0}: \\mu=\\mu_{0} \\quad \\text { vs } \\quad H_{1}: \\mu \\neq \\mu_{0}\n$$  \n则水平为 $\\alpha$ 的检验的接收域为  \n$$\n\\bar{W}=\\left\\{\\left|\\bar{x}-\\mu_{0}\\right| \\leqslant \\frac{s}{\\sqrt{n}} t_{1-\\alpha / 2}(n-1)\\right\\}\n$$  \n它可以改写为  \n$$\n\\bar{W}=\\left\\{\\bar{x}-\\frac{s}{\\sqrt{n}} t_{1-a / 2}(n-1) \\leqslant \\mu_{0} \\leqslant \\bar{x}+\\frac{s}{\\sqrt{n}} t_{1-\\alpha / 2}(n-1)\\right\\}\n$$  \n并且有 $P_{\\mu_{0}}(\\bar{W}=1-\\alpha)$, 这里 $\\mu_{0}$ 并无限制, 若让 $\\mu_{0}$ 在 $(-\\infty,+\\infty)$ 内取值, 就可得到 $\\mu$ 的 $1-\\alpha$ 置信区间: $\\bar{x} \\pm \\frac{s}{\\sqrt{n}} t_{1-a / 2}(n-1)$. 反之, 若有一个如上的 $1-\\alpha$ 置信区间, 也可获得关于 $H_{0}: \\mu=\\mu_{0}$的水平为 $\\alpha$ 的显著性检验. 所以, “正态均值 $\\mu$ 的 $1-\\alpha$ 置信区间” 与 “关于 $H_{0}: \\mu=\\mu_{0}$ 的双侧检验问题的水平为 $\\alpha$ 的检验”是一一对应.  \n考虑单侧检验问题  \n$$",
        "metadata": {
            "Header 2": "三、假设检验与置信区间的关系"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n并且有 $P_{\\mu_{0}}(\\bar{W}=1-\\alpha)$, 这里 $\\mu_{0}$ 并无限制, 若让 $\\mu_{0}$ 在 $(-\\infty,+\\infty)$ 内取值, 就可得到 $\\mu$ 的 $1-\\alpha$ 置信区间: $\\bar{x} \\pm \\frac{s}{\\sqrt{n}} t_{1-a / 2}(n-1)$. 反之, 若有一个如上的 $1-\\alpha$ 置信区间, 也可获得关于 $H_{0}: \\mu=\\mu_{0}$的水平为 $\\alpha$ 的显著性检验. 所以, “正态均值 $\\mu$ 的 $1-\\alpha$ 置信区间” 与 “关于 $H_{0}: \\mu=\\mu_{0}$ 的双侧检验问题的水平为 $\\alpha$ 的检验”是一一对应.  \n考虑单侧检验问题  \n$$\nH_{0}: \\mu \\leqslant \\mu_{0} \\quad \\text { vs } \\quad H_{1}: \\mu>\\mu_{0}\n$$  \n其水平为 $\\alpha$ 的检验的接受域为  \n$$\n\\begin{aligned}\n\\bar{W} & =\\left\\{\\bar{x}-\\mu_{0} \\geqslant \\frac{s}{\\sqrt{n}} t_{1-a}(n-1)\\right\\} \\\\\n& =\\left\\{\\mu_{0} \\leqslant \\bar{x}-\\frac{s}{\\sqrt{n}} t_{1-\\alpha}(n-1)\\right\\}\n\\end{aligned}\n$$  \n这就给出了参数 $\\mu$ 的 $1-\\alpha$ 置信上限. 反之, 对上述给定的 $p$ 的 $1-\\alpha$ 置信上限, 我们也可以得到关于 $H_{0}: u \\leqslant u_{0}$ 的单侧检验问题的水平为 $\\alpha$ 的检验, 它们之间也是一一对应的. 类似地, 对另一个单侧检验问题,其水平为 $\\alpha$ 的检验与参数 $\\mu$ 的 $1-\\alpha$ 置信下限也是一一对应的.",
        "metadata": {
            "Header 2": "三、假设检验与置信区间的关系"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $x_{1}, \\cdots, x_{m}$ 是来自正态总体 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 的样本, $y_{1}, \\cdots, y_{n}$ 是来自另一个正态总体 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$的样本, 两个样本相互独立. 考虑如下三类检验问题:  \n$$\n\\begin{array}{lcl}\nH_{0}: \\mu_{1}-\\mu_{2} \\leqslant 0 & \\text { vs } & H_{1}: \\mu_{1}-\\mu_{2}>0 \\\\\nH_{0}: \\mu_{1}-\\mu_{2} \\geqslant 0 & \\text { vs } & H_{1}: \\mu_{1}-\\mu_{2}<0 \\\\\nH_{0}: \\mu_{1}-\\mu_{2}=0 & \\text { vs } & H_{1}: \\mu_{1}-\\mu_{2} \\neq 0 \\tag{7.2.15}\n\\end{array}\n$$  \n这里主要分两种情形进行讨论.",
        "metadata": {
            "Header 2": "三、假设检验与置信区间的关系",
            "Header 3": "7.2.2 两个正态总体均值差的检验"
        },
        "type": "Document"
    },
    {
        "page_content": "此时 $\\mu_{1}-\\mu_{2}$ 的点估计 $\\bar{x}-\\bar{y}$ 的分布完全已知,  \n$$\n\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2}, \\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}\\right)\n$$  \n由此可采用 $\\mu$ 检验方法, 检验统计量为  \n$$\nu=(\\bar{x}-\\bar{y}) / \\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}\n$$  \n在 $\\mu_{1}=\\mu_{2}$ 时, $\\mu \\sim N(0,1)$. 检验的拒绝域取决于备择假设的具体内容. 对检验问题 (7.2.13), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{u \\geqslant u_{1-\\alpha}\\right\\} \\tag{7.2.16}\n\\end{equation*}\n$$  \n对检验问题 (7.2.14), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{\\mu \\leqslant \\mu_{\\alpha}\\right\\} \\tag{7.2.17}\n\\end{equation*}\n$$  \n对检验问题 (7.2.15), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{|\\mu| \\geqslant \\mu_{1-\\alpha / 2}\\right\\} . \\tag{7.2.18}\n\\end{equation*}\n$$  \n二、 $\\sigma_{1}=\\sigma_{2}=0$ 但未知时的两样本 $t$ 检验  \n在 $\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\sigma^{2}$ 但未知时,首先 $\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2},\\left(\\frac{1}{m}+\\frac{1}{n}\\right) \\sigma^{2}\\right)$, 其次, 由于  \n$$",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n对检验问题 (7.2.14), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{\\mu \\leqslant \\mu_{\\alpha}\\right\\} \\tag{7.2.17}\n\\end{equation*}\n$$  \n对检验问题 (7.2.15), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{|\\mu| \\geqslant \\mu_{1-\\alpha / 2}\\right\\} . \\tag{7.2.18}\n\\end{equation*}\n$$  \n二、 $\\sigma_{1}=\\sigma_{2}=0$ 但未知时的两样本 $t$ 检验  \n在 $\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\sigma^{2}$ 但未知时,首先 $\\bar{x}-\\bar{y} \\sim N\\left(\\mu_{1}-\\mu_{2},\\left(\\frac{1}{m}+\\frac{1}{n}\\right) \\sigma^{2}\\right)$, 其次, 由于  \n$$\n\\frac{1}{\\sigma^{2}} \\sum_{i=1}^{\\infty}\\left(x_{i}-\\bar{x}\\right)^{2} \\sim \\chi^{2}(m-1), \\quad \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2} \\sim \\chi^{2}(n-1)\n$$  \n故 $\\frac{1}{\\sigma^{2}}\\left(\\sum\\left(x_{i}-\\bar{x}\\right)^{2}+\\sum\\left(y_{i}-\\bar{y}\\right)^{2}\\right) \\sim \\chi^{2}(m+n-2)$, 记  \n$$\ns_{w}^{2}=\\frac{1}{m+n-2}\\left[\\sum_{i=1}^{m}\\left(x_{i}-\\bar{x}\\right)^{2}+\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}\\right]\n$$  \n于是有  \n$$",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\frac{1}{\\sigma^{2}} \\sum_{i=1}^{\\infty}\\left(x_{i}-\\bar{x}\\right)^{2} \\sim \\chi^{2}(m-1), \\quad \\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2} \\sim \\chi^{2}(n-1)\n$$  \n故 $\\frac{1}{\\sigma^{2}}\\left(\\sum\\left(x_{i}-\\bar{x}\\right)^{2}+\\sum\\left(y_{i}-\\bar{y}\\right)^{2}\\right) \\sim \\chi^{2}(m+n-2)$, 记  \n$$\ns_{w}^{2}=\\frac{1}{m+n-2}\\left[\\sum_{i=1}^{m}\\left(x_{i}-\\bar{x}\\right)^{2}+\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}\\right]\n$$  \n于是有  \n$$\nt=\\frac{(\\bar{x}-\\bar{y})-\\left(\\mu_{1}-\\mu_{2}\\right)}{s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}} \\sim t(m+n-2)\n$$  \n这就给出了检验统计量为  \n$$\nt=\\frac{(\\bar{x}-\\bar{y})}{s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}}\n$$  \n对检验问题 (7.2.13), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{t \\geqslant t_{1-\\alpha}(m+n-2)\\right\\}, \\tag{7.2.19}\n\\end{equation*}\n$$  \n对检验问题 (7.2.14), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{t \\leqslant t_{\\alpha}(m+n-2)\\right\\}, \\tag{7.2.20}\n\\end{equation*}\n$$  \n对检验问题 (7.2.15), 检验的拒绝域为  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n这就给出了检验统计量为  \n$$\nt=\\frac{(\\bar{x}-\\bar{y})}{s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}}\n$$  \n对检验问题 (7.2.13), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{t \\geqslant t_{1-\\alpha}(m+n-2)\\right\\}, \\tag{7.2.19}\n\\end{equation*}\n$$  \n对检验问题 (7.2.14), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{t \\leqslant t_{\\alpha}(m+n-2)\\right\\}, \\tag{7.2.20}\n\\end{equation*}\n$$  \n对检验问题 (7.2.15), 检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{|t| \\geqslant t_{1-\\alpha / 2}(m+n-2)\\right\\} . \\tag{7.2.21}\n\\end{equation*}\n$$  \n例 7.2.3: 某厂铸造车间为提高铸件的耐磨性而试制了一种镍合金铸件以取代铜合金铸件, 为此,从两种铸件中各抽取一个容量分别为 8 和 9 的样本, 测得其硬度 (一种耐磨性指标) 为  \n!\n铜合金 : 73.66\n64.27\n69.34\n71.37\n69.77\n68.12\n67.27\n68.07\n62.61  \n根据专业经验,硬度服从正态分布,且方差保持不变,试在显著性水平 $\\alpha=0.05$ 下判断镍合金的硬度是否有明显提高.  \n解: 用 $X$ 表示镍合金的硬度, $Y$ 表示钢合金的硬度, 则由假定, $X \\sim N\\left(\\mu_{1}, \\sigma^{2}\\right), Y \\sim N\\left(\\mu_{2}, \\sigma^{2}\\right)$, 要检验的假设是: $H_{0}: \\mu_{1}=\\mu_{2} \\quad$ vs $\\quad H_{1}: \\mu_{1}>\\mu_{2}$. 由于两者方差未知但相等,故采用两样本 $t$ 检验,经计算,  \n$$\n\\begin{gathered}",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n例 7.2.3: 某厂铸造车间为提高铸件的耐磨性而试制了一种镍合金铸件以取代铜合金铸件, 为此,从两种铸件中各抽取一个容量分别为 8 和 9 的样本, 测得其硬度 (一种耐磨性指标) 为  \n!\n铜合金 : 73.66\n64.27\n69.34\n71.37\n69.77\n68.12\n67.27\n68.07\n62.61  \n根据专业经验,硬度服从正态分布,且方差保持不变,试在显著性水平 $\\alpha=0.05$ 下判断镍合金的硬度是否有明显提高.  \n解: 用 $X$ 表示镍合金的硬度, $Y$ 表示钢合金的硬度, 则由假定, $X \\sim N\\left(\\mu_{1}, \\sigma^{2}\\right), Y \\sim N\\left(\\mu_{2}, \\sigma^{2}\\right)$, 要检验的假设是: $H_{0}: \\mu_{1}=\\mu_{2} \\quad$ vs $\\quad H_{1}: \\mu_{1}>\\mu_{2}$. 由于两者方差未知但相等,故采用两样本 $t$ 检验,经计算,  \n$$\n\\begin{gathered}\n\\bar{x}=73.39, \\quad \\bar{y}=68.2756, \\quad \\sum_{i=1}^{8}\\left(x_{i}-\\bar{x}\\right)^{2}=205.7958 \\\\\n\\sum_{i=1}^{9}\\left(y_{i}-\\bar{y}\\right)^{2}=91.1552\n\\end{gathered}\n$$  \n从而 $s_{w}=\\sqrt{\\frac{1}{8+9-2}(205.7958+91.1552)}=4.4494$,  \n$$\nt=\\frac{73.39-68.2756}{4.4494 \\cdot \\sqrt{\\frac{1}{7}+\\frac{1}{8}}}=2.2210\n$$  \n查表知 $t_{0.95}(15)=1.753$, 由于 $t>t_{0.95}(15)$, 故拒绝原假设, 可判断镍合金硬度有显著提高.  \n利用假设检验与置信区间的关系对其他情况下的检验问题可仿 6.5 .5 节中两正态总体均值差  \n| 检验法 | 条件 | 原假设 $H_{0}$ | 备择假设 $H_{1}$ | 检验统计量 | 拒绝域 |",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\bar{x}=73.39, \\quad \\bar{y}=68.2756, \\quad \\sum_{i=1}^{8}\\left(x_{i}-\\bar{x}\\right)^{2}=205.7958 \\\\\n\\sum_{i=1}^{9}\\left(y_{i}-\\bar{y}\\right)^{2}=91.1552\n\\end{gathered}\n$$  \n从而 $s_{w}=\\sqrt{\\frac{1}{8+9-2}(205.7958+91.1552)}=4.4494$,  \n$$\nt=\\frac{73.39-68.2756}{4.4494 \\cdot \\sqrt{\\frac{1}{7}+\\frac{1}{8}}}=2.2210\n$$  \n查表知 $t_{0.95}(15)=1.753$, 由于 $t>t_{0.95}(15)$, 故拒绝原假设, 可判断镍合金硬度有显著提高.  \n利用假设检验与置信区间的关系对其他情况下的检验问题可仿 6.5 .5 节中两正态总体均值差  \n| 检验法 | 条件 | 原假设 $H_{0}$ | 备择假设 $H_{1}$ | 检验统计量 | 拒绝域 |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $u$ 检验 | $\\sigma_{1}, \\sigma_{2}$ 已知 | $\\mu_{1} \\leqslant \\mu_{2}$ <br> $\\mu_{1} \\geqslant \\mu_{2}$ <br> $\\mu_{1}=\\mu_{2}$ | $\\mu_{1}>\\mu_{2}$ <br> $\\mu_{1}<\\mu_{2}$ <br> $\\mu_{1} \\neq \\mu_{2}$ | $u=\\frac{(\\bar{x}-\\bar{y})}{\\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}}$ | $\\left\\{u \\geqslant u_{1-\\alpha}\\right\\}$ <br> $\\left\\{u \\leqslant u_{\\alpha}\\right\\}$ <br> $\\left\\{\\|u\\| \\geqslant u_{1-\\alpha / 2}\\right\\}$ |",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| :---: | :---: | :---: | :---: | :---: | :---: |\n| $u$ 检验 | $\\sigma_{1}, \\sigma_{2}$ 已知 | $\\mu_{1} \\leqslant \\mu_{2}$ <br> $\\mu_{1} \\geqslant \\mu_{2}$ <br> $\\mu_{1}=\\mu_{2}$ | $\\mu_{1}>\\mu_{2}$ <br> $\\mu_{1}<\\mu_{2}$ <br> $\\mu_{1} \\neq \\mu_{2}$ | $u=\\frac{(\\bar{x}-\\bar{y})}{\\sqrt{\\frac{\\sigma_{1}^{2}}{m}+\\frac{\\sigma_{2}^{2}}{n}}}$ | $\\left\\{u \\geqslant u_{1-\\alpha}\\right\\}$ <br> $\\left\\{u \\leqslant u_{\\alpha}\\right\\}$ <br> $\\left\\{\\|u\\| \\geqslant u_{1-\\alpha / 2}\\right\\}$ |\n| $t$ 检验 | $\\sigma_{1}, \\sigma_{2}$ 未知 <br> $\\sigma_{1}=\\sigma_{2}$ | $\\mu_{1} \\leqslant \\mu_{2}$ <br> $\\mu_{2} \\geqslant \\mu_{2}$ <br> $\\mu_{1}=\\mu_{2}$ | $\\mu_{1}>\\mu_{2}$ <br> $\\mu_{1}<\\mu_{2}$ <br> $\\mu_{1} \\neq \\mu_{2}$ | $t=\\frac{(\\bar{x}-\\bar{y})}{s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}}$ | $\\left\\{t \\geqslant t_{1-\\alpha}(m+n-2)\\right\\}$ <br> $\\left\\{t \\leqslant t_{\\alpha}(m+n-2)\\right\\}$ <br> $\\left\\{\\|t\\| \\geqslant t_{1-\\alpha / 2}(m+n-2)\\right\\}$ |",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| $t$ 检验 | $\\sigma_{1}, \\sigma_{2}$ 未知 <br> $\\sigma_{1}=\\sigma_{2}$ | $\\mu_{1} \\leqslant \\mu_{2}$ <br> $\\mu_{2} \\geqslant \\mu_{2}$ <br> $\\mu_{1}=\\mu_{2}$ | $\\mu_{1}>\\mu_{2}$ <br> $\\mu_{1}<\\mu_{2}$ <br> $\\mu_{1} \\neq \\mu_{2}$ | $t=\\frac{(\\bar{x}-\\bar{y})}{s_{w} \\sqrt{\\frac{1}{m}+\\frac{1}{n}}}$ | $\\left\\{t \\geqslant t_{1-\\alpha}(m+n-2)\\right\\}$ <br> $\\left\\{t \\leqslant t_{\\alpha}(m+n-2)\\right\\}$ <br> $\\left\\{\\|t\\| \\geqslant t_{1-\\alpha / 2}(m+n-2)\\right\\}$ |\n| 大样本 <br> 检验 | $\\sigma_{1}, \\sigma_{2}$ 未知 <br> $m, n$ <br> 充分大 | $\\mu_{1} \\leqslant \\mu_{2}$ <br> $\\mu_{1} \\geqslant \\mu_{2}$ <br> $\\mu_{1}=\\mu_{2}$ | $\\mu_{1}>\\mu_{2}$ <br> $\\mu_{1}<\\mu_{2}$ <br> $\\mu_{1} \\neq \\mu_{2}$ | $u=\\frac{(\\bar{x}-\\bar{y})}{\\sqrt{\\frac{s_{x}^{2}}{n}+\\frac{s_{y}^{2}}{m}}}$ | $\\left\\{u \\geqslant u_{1-\\alpha}\\right\\}$ <br> $\\left\\{u \\leqslant u_{\\alpha}\\right\\}$ <br> $\\left\\{\\|u\\| \\geqslant u_{1-\\alpha / 2}\\right\\}$ |",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| 大样本 <br> 检验 | $\\sigma_{1}, \\sigma_{2}$ 未知 <br> $m, n$ <br> 充分大 | $\\mu_{1} \\leqslant \\mu_{2}$ <br> $\\mu_{1} \\geqslant \\mu_{2}$ <br> $\\mu_{1}=\\mu_{2}$ | $\\mu_{1}>\\mu_{2}$ <br> $\\mu_{1}<\\mu_{2}$ <br> $\\mu_{1} \\neq \\mu_{2}$ | $u=\\frac{(\\bar{x}-\\bar{y})}{\\sqrt{\\frac{s_{x}^{2}}{n}+\\frac{s_{y}^{2}}{m}}}$ | $\\left\\{u \\geqslant u_{1-\\alpha}\\right\\}$ <br> $\\left\\{u \\leqslant u_{\\alpha}\\right\\}$ <br> $\\left\\{\\|u\\| \\geqslant u_{1-\\alpha / 2}\\right\\}$ |\n| 近似 <br> $t$ 检验 | $\\sigma_{1}, \\sigma_{2}$ 未知 <br> $m, n$ <br> 不很大 | $\\mu_{1} \\leqslant \\mu_{2}$ <br> $\\mu_{1} \\geqslant \\mu_{2}$ <br> $\\mu_{1}=\\mu_{2}$ | $\\mu_{1}>\\mu_{2}$ <br> $\\mu_{1}<\\mu_{2}$ <br> $\\mu_{1} \\neq \\mu_{2}$ | $t=\\frac{(\\bar{x}-\\bar{y})}{\\sqrt{\\frac{s_{x}^{2}}{n}+\\frac{s_{y}^{2}}{m}}}$ | $\\left\\{t \\geqslant t_{1-\\alpha}(l-1)\\right\\}$ <br> $\\left\\{t \\leqslant t_{\\alpha}(l-1)\\right\\}$ <br> $\\left\\{\\|t\\| \\geqslant t_{1-\\alpha / 2}(l-1)\\right\\}$ |  \n的置信区间类似进行,我们下面以表格形式列出,而不作推导 ( $l$ 的表达式见 6.5 .5 节).  \n表 7.2.2: 两个正态总体均值的假设检验",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "一、单个正态总体方差的 $\\chi^{2}$ 检验  \n设 $x_{1}, \\cdots, x_{n}$ 是来自 $N\\left(\\mu, \\sigma^{2}\\right)$ 的样本, 对方差亦可考虑如下三个检验问题:  \n$$\n\\begin{array}{lll}\nH_{0}: \\sigma^{2} \\leqslant \\sigma_{0}^{2} & \\text { vs } & H_{1}: \\sigma^{2}>\\sigma_{0}^{2} \\\\\nH_{0}: \\sigma^{2} \\geqslant \\sigma_{0}^{2} & \\text { vs } & H_{1}: \\sigma^{2}<\\sigma_{0}^{2} \\\\\nH_{0}: \\sigma^{2}=\\sigma_{0}^{2} & \\text { vs } & H_{1}: \\sigma^{2} \\neq \\sigma_{0}^{2} \\tag{7.2.24}\n\\end{array}\n$$  \n此处通常假定 $\\mu$ 未知,它们采用的检验统计量是相同的,均为  \n$$\n\\begin{equation*}\n\\chi^{2}=(n-1) s^{2} / \\sigma_{0}^{2} \\tag{7.2.25}\n\\end{equation*}\n$$  \n在 $\\sigma^{2}=\\sigma_{0}^{2}$ 时, $\\chi^{2} \\sim \\chi^{2}(n-1)$, 于是, 若取显著性水平为 $\\alpha$, 则对应三个检验问题的拒绝域依次分别为  \n$$\n\\begin{gathered}\nW=\\left\\{x^{2} \\geqslant \\chi_{1-\\alpha}^{2}(n-1)\\right\\} \\\\\nW=\\left\\{\\chi^{2} \\leqslant \\chi_{\\alpha}^{2}(n-1) !\\right\\} \\\\\nW=\\left\\{\\chi^{2} \\leqslant \\chi_{\\alpha / 2}^{2}(n-1) \\text { 或 } \\chi^{2} \\geqslant \\chi_{1-\\alpha / 2}^{2}(n-1)\\right\\}\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验",
            "Header 3": "7.2.3 正态总体方差的检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n\\chi^{2}=(n-1) s^{2} / \\sigma_{0}^{2} \\tag{7.2.25}\n\\end{equation*}\n$$  \n在 $\\sigma^{2}=\\sigma_{0}^{2}$ 时, $\\chi^{2} \\sim \\chi^{2}(n-1)$, 于是, 若取显著性水平为 $\\alpha$, 则对应三个检验问题的拒绝域依次分别为  \n$$\n\\begin{gathered}\nW=\\left\\{x^{2} \\geqslant \\chi_{1-\\alpha}^{2}(n-1)\\right\\} \\\\\nW=\\left\\{\\chi^{2} \\leqslant \\chi_{\\alpha}^{2}(n-1) !\\right\\} \\\\\nW=\\left\\{\\chi^{2} \\leqslant \\chi_{\\alpha / 2}^{2}(n-1) \\text { 或 } \\chi^{2} \\geqslant \\chi_{1-\\alpha / 2}^{2}(n-1)\\right\\}\n\\end{gathered}\n$$  \n$\\chi^{2}$ 分布是偏态分布,三种拒绝域形式见图 7.2.3  \n!  \n(a) $H_{1}: \\sigma^{2}>\\sigma_{0}^{2}$  \n!  \n(b) $H_{1}: \\sigma^{2}<\\sigma_{0}^{2}$  \n!  \n(c) $H_{1}: \\sigma^{2} \\neq \\sigma_{0}^{2}$  \n图 7.2.3: $\\chi^{2}$ 检验的拒绝域 $(n-1=6, \\alpha=0.05)$  \n例 7.2.4: 某类钢板每块的重量 $X$ 服从正态分布, 其一项质量指标是钢板重量的方差不得超过 $0.016 \\mathrm{~kg}^{2}$. 现从某天生产的钢板中随机抽取 25 块, 得其样本方差 $s^{2}=0.025 \\mathrm{~kg}^{2}$, 问该天生产的钢板重量的方差是否满足要求.",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验",
            "Header 3": "7.2.3 正态总体方差的检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{gathered}\n$$  \n$\\chi^{2}$ 分布是偏态分布,三种拒绝域形式见图 7.2.3  \n!  \n(a) $H_{1}: \\sigma^{2}>\\sigma_{0}^{2}$  \n!  \n(b) $H_{1}: \\sigma^{2}<\\sigma_{0}^{2}$  \n!  \n(c) $H_{1}: \\sigma^{2} \\neq \\sigma_{0}^{2}$  \n图 7.2.3: $\\chi^{2}$ 检验的拒绝域 $(n-1=6, \\alpha=0.05)$  \n例 7.2.4: 某类钢板每块的重量 $X$ 服从正态分布, 其一项质量指标是钢板重量的方差不得超过 $0.016 \\mathrm{~kg}^{2}$. 现从某天生产的钢板中随机抽取 25 块, 得其样本方差 $s^{2}=0.025 \\mathrm{~kg}^{2}$, 问该天生产的钢板重量的方差是否满足要求.  \n解：这是一个关于正态总体方差的单侧检验问题. 原假设为 $H_{0}: \\sigma^{2} \\leqslant 0.016$, 备择假设为 $H_{1}$ : $\\sigma^{2}>0.016$, 此处 $n=25$, 若取 $\\alpha=0.05$, 则查表知 $\\chi_{0.95}^{2}(24)=36.415$, 现计算可得  \n$$\n\\chi^{2}=\\frac{(n-1) s^{2}}{\\sigma_{0}^{2}}=\\frac{24 \\times 0.025}{0.016}=37.5>36.415\n$$  \n由此,在显著性水平 0.05 下,我们拒绝原假设,认为该天生产的钢板重量不符合要求.  \n若取 $\\alpha=0.01$, 则 $\\chi_{0.99}^{2}(24)=42.98$, 则不能拒绝原假设. 所以, 显著性水平的大小对检验结果是有影响的. 关于这方面的讨论我们在 7.4 节进行.",
        "metadata": {
            "Header 2": "一、 $\\sigma_{1}, \\sigma_{2}$ 已知时的两样本 $\\mu$ 检验",
            "Header 3": "7.2.3 正态总体方差的检验"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $x_{1}, \\cdots, x_{m}$ 是来自 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right)$ 的样本, $y_{1}, \\cdots, y_{n}$ 是来自 $N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$ 的样本, 考虑如下三个假设检验问题  \n$$\n\\begin{array}{lll}\nH_{0}: \\sigma_{1}^{2} \\leqslant \\sigma_{2}^{2} \\quad \\text { vs } & H_{1}: \\sigma_{1}^{2}>\\sigma_{2}^{2} \\\\\nH_{0}: \\sigma_{1}^{2} \\geqslant \\sigma_{2}^{2} \\quad \\text { vs } & H_{1}: \\sigma_{1}^{2}<\\sigma_{2}^{2} \\tag{7.2.27}\n\\end{array}\n$$  \n$$\n\\begin{equation*}\nH_{0}: \\sigma_{1}^{2}=\\sigma_{2}^{2} \\quad \\text { vs } \\quad H_{1}: \\sigma_{1}^{2} \\neq \\sigma_{2}^{2} \\tag{7.2.28}\n\\end{equation*}\n$$  \n此处 $\\mu_{1}, \\mu_{2}$ 均未知, 记 $s_{x}^{2}, s_{y}^{2}$ 分别是由 $x_{1}, \\cdots, x_{m}$ 算得的 $\\sigma_{1}^{2}$ 的无偏估计和由 $y_{1}, \\cdots, y_{n}$ 算得的 $\\sigma_{2}^{2}$ 的无偏估计 (两个都是样本方差), 则可建立如下的检验统计量  \n$$\n\\begin{equation*}\nF=\\frac{s_{x}^{2}}{s_{y}^{2}} \\tag{7.2.29}\n\\end{equation*}\n$$  \n当 $\\sigma_{1}^{2}=\\sigma_{2}^{2}$ 时, (7.2.29) 的 $F \\sim F(m-1, n-1)$, 由此给出三个检验问题对应的拒绝域依次分别为  \n$$\n\\begin{gathered}",
        "metadata": {
            "Header 2": "二、两个正态总体方差比的 $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n此处 $\\mu_{1}, \\mu_{2}$ 均未知, 记 $s_{x}^{2}, s_{y}^{2}$ 分别是由 $x_{1}, \\cdots, x_{m}$ 算得的 $\\sigma_{1}^{2}$ 的无偏估计和由 $y_{1}, \\cdots, y_{n}$ 算得的 $\\sigma_{2}^{2}$ 的无偏估计 (两个都是样本方差), 则可建立如下的检验统计量  \n$$\n\\begin{equation*}\nF=\\frac{s_{x}^{2}}{s_{y}^{2}} \\tag{7.2.29}\n\\end{equation*}\n$$  \n当 $\\sigma_{1}^{2}=\\sigma_{2}^{2}$ 时, (7.2.29) 的 $F \\sim F(m-1, n-1)$, 由此给出三个检验问题对应的拒绝域依次分别为  \n$$\n\\begin{gathered}\nW=\\left\\{F \\geqslant F_{1-\\alpha}(m-1, n-1)\\right\\} \\\\\nW=\\left\\{F \\leqslant F_{1-\\alpha}(m-1, n-1)\\right\\} \\\\\nW=\\left\\{F \\leqslant F_{\\alpha / 2}(m-1, n-1)\\right\\} \\text { 或 } W=\\left\\{F \\geqslant F_{\\alpha / 2}(m-1, n-1)\\right\\} .\n\\end{gathered}\n$$  \n例 7.2.5: 甲、乙两台机床加工某种零件, 零件的直径服从正态分布, 总体方差反映了加工精度, 为比较两台机床的加工精度有无差别, 现从各自加工的零件中分别抽取 7 件产品和 8 件产品, 测得其直径为  \n| $X$ 机床甲 | 16.2 | 16.4 | 15.8 | 15.5 | 16.7 | 15.6 | 15.8 |  |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| $Y$ 机床乙 | 15.9 | 16.0 | 16.4 | 16.1 | 16.5 | 15.8 | 15.7 | 15.0 |",
        "metadata": {
            "Header 2": "二、两个正态总体方差比的 $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "W=\\left\\{F \\leqslant F_{\\alpha / 2}(m-1, n-1)\\right\\} \\text { 或 } W=\\left\\{F \\geqslant F_{\\alpha / 2}(m-1, n-1)\\right\\} .\n\\end{gathered}\n$$  \n例 7.2.5: 甲、乙两台机床加工某种零件, 零件的直径服从正态分布, 总体方差反映了加工精度, 为比较两台机床的加工精度有无差别, 现从各自加工的零件中分别抽取 7 件产品和 8 件产品, 测得其直径为  \n| $X$ 机床甲 | 16.2 | 16.4 | 15.8 | 15.5 | 16.7 | 15.6 | 15.8 |  |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| $Y$ 机床乙 | 15.9 | 16.0 | 16.4 | 16.1 | 16.5 | 15.8 | 15.7 | 15.0 |  \n这就形成了一个双侧假设检验问题, 原假设是 $H_{0}: \\sigma_{1}^{2}=\\sigma_{2}^{2}$, 备择假设为 $H_{1}: \\sigma_{1}^{2} \\neq \\sigma_{2}^{2}$. 此处 $m=7, n=8$, 经计算, $s_{x}^{2}=0.2729, s_{y}^{2}=0.2164$, 于是 $F=\\frac{0.2729}{0.2164}=1.261$. 若取 $\\alpha=0.05$, 查表知 $F_{0.975}(6,7)=5.12, F_{0.025}=\\frac{1}{F_{0.025}(7,6)}=\\frac{1}{5.70}=0.175$. 其拒绝域为  \n$$\nW=\\{F \\leqslant 0.175 \\text { 或 } F \\geqslant 5.12\\}\n$$  \n由此可见, 样本未落人拒绝域, 即在 0.05 水平下可以认为二台机床的加工精度一致.  \n关于正态总体方差的假设检验汇总列于表 7.2.3中.  \n表 7.2.3: 正态总体方差的假设检验  \n| 检验法 | $H_{0}$ | $H_{1}$ | 检验统计量 | 拒绝域 |",
        "metadata": {
            "Header 2": "二、两个正态总体方差比的 $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nW=\\{F \\leqslant 0.175 \\text { 或 } F \\geqslant 5.12\\}\n$$  \n由此可见, 样本未落人拒绝域, 即在 0.05 水平下可以认为二台机床的加工精度一致.  \n关于正态总体方差的假设检验汇总列于表 7.2.3中.  \n表 7.2.3: 正态总体方差的假设检验  \n| 检验法 | $H_{0}$ | $H_{1}$ | 检验统计量 | 拒绝域 |\n| :---: | :--- | :---: | :---: | :--- |\n|  | $\\sigma^{2} \\leqslant \\sigma_{0}^{2}$ | $\\sigma^{2}>\\sigma_{0}^{2}$ |  | $\\chi^{2} \\geqslant \\chi_{1-\\alpha}^{2}(n-1)$ |\n| $\\chi^{2}$ 检验 | $\\sigma^{2} \\geqslant \\sigma_{0}^{2}$ | $\\sigma^{2}<\\sigma_{0}^{2}$ | $\\chi^{2}=\\frac{(n-1) s^{2}}{\\sigma_{0}^{2}}$ | $\\chi^{2} \\leqslant \\chi_{\\alpha}^{2}(n-1)$ |\n|  | $\\sigma^{2}=\\sigma_{0}^{2}$ | $\\sigma^{2} \\neq \\sigma_{0}^{2}$ |  | $\\chi^{2} \\leqslant \\chi_{\\alpha / 2}^{2}(n-1)$ 或 |\n|  |  |  |  | $\\chi^{2} \\leqslant \\chi_{1-\\alpha}^{2}(n-1)$ |\n|  | $\\sigma^{2} \\leqslant \\sigma_{0}^{2}$ | $\\sigma^{2}>\\sigma_{0}^{2}$ |  | $F \\geqslant F_{1-\\alpha}(m-1, n-1)$ |",
        "metadata": {
            "Header 2": "二、两个正态总体方差比的 $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\chi^{2}$ 检验 | $\\sigma^{2} \\geqslant \\sigma_{0}^{2}$ | $\\sigma^{2}<\\sigma_{0}^{2}$ | $\\chi^{2}=\\frac{(n-1) s^{2}}{\\sigma_{0}^{2}}$ | $\\chi^{2} \\leqslant \\chi_{\\alpha}^{2}(n-1)$ |\n|  | $\\sigma^{2}=\\sigma_{0}^{2}$ | $\\sigma^{2} \\neq \\sigma_{0}^{2}$ |  | $\\chi^{2} \\leqslant \\chi_{\\alpha / 2}^{2}(n-1)$ 或 |\n|  |  |  |  | $\\chi^{2} \\leqslant \\chi_{1-\\alpha}^{2}(n-1)$ |\n|  | $\\sigma^{2} \\leqslant \\sigma_{0}^{2}$ | $\\sigma^{2}>\\sigma_{0}^{2}$ |  | $F \\geqslant F_{1-\\alpha}(m-1, n-1)$ |\n| $F$ 检验 | $\\sigma^{2} \\geqslant \\sigma_{0}^{2}$ | $\\sigma^{2}<\\sigma_{0}^{2}$ | $F=\\frac{s_{x}^{2}}{s_{y}^{2}}$ | $F \\leqslant F_{\\alpha}(m-1, n-1)$ |\n|  | $\\sigma^{2}=\\sigma_{0}^{2}$ | $\\sigma^{2} \\neq \\sigma_{0}^{2}$ |  | $F \\leqslant F_{\\alpha / 2}(m-1, n-1)$ 或 |\n|  |  |  |  | $F \\geqslant F_{1-\\alpha / 2}(m-1, n-1)$ |",
        "metadata": {
            "Header 2": "二、两个正态总体方差比的 $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 有一批枪弹, 出厂时, 其初速 $v \\sim N(950,100)$ (单位: $\\mathrm{m} / \\mathrm{s}$ ). 经过较长时间储存, 取 9 发进行测试, 得样本值 (单位: $\\mathrm{m} / \\mathrm{s}$ ) 如下:  \n$$\n\\begin{array}{lllllllll}\n914 & 920 & 910 & 934 & 953 & 945 & 912 & 924 & 940\n\\end{array}\n$$  \n据经验, 枪弹经储存后其初速仍服从正态分布, 且标准差保持不变, 问是否可认为这批枪弹的初速有显著降低 $(\\alpha=0.05) ?$  \n2. 已知某炼铁厂铁水含碳量服从正态分布 $N\\left(4.55,0.108^{2}\\right)$. 现在测定了 9 炉铁水, 其平均含碳量为 4.484, 如果铁水含碳量的方差没有变化, 可否认为现在生产的铁水平均含碳量仍为 4.55 $(\\alpha=0.05)$ ?\n3. 由经验知某零件质量 $X \\sim N\\left(15,0.05^{2}\\right)$ (单位: $\\mathrm{g}$ ), 技术革新后, 抽出 6 个零件, 测得质量为:",
        "metadata": {
            "Header 2": "如习题 7.2"
        },
        "type": "Document"
    },
    {
        "page_content": "已知方差不变, 问平均质量是否仍为 $15 \\mathrm{~g}$ ? (取 $\\alpha=0.05$ )  \n4. 化肥厂用自动包装机包装化肥, 每包的质量服从正态分布, 其平均质量为 $100 \\mathrm{~kg}$, 标准差为 $1.2 \\mathrm{~kg}$. 某日开工后, 为了确定这天包装机工作是否正常, 随机抽取 9 袋化肥, 称得质量如下:  \n$$\n\\begin{array}{lllllllll}\n99.3 & 98.7 & 100.5 & 101.2 & 98.3 & 99.7 & 99.5 & 102.1 & 100.5\n\\end{array}\n$$  \n设方差稳定不变, 问这一天包装机的工作是否正常? ( 取 $\\alpha=0.05$ )  \n5. 设需要对某正态总体的均值进行假设检验  \n$$\nH_{0}: \\mu=15, \\quad H_{1}: \\mu<15\n$$  \n已知 $\\sigma^{2}=2.5$, 取 $\\alpha=0.05$, 若要求当 $H_{1}$ 中的以 $\\mu \\leqslant 13$ 时犯第二类错误的概率不超过 0.05 ,求所需的样本容量.  \n6. 从一批钢管抽取 10 根, 测得其内径 (单位: $\\mathrm{mm}$ ) 为:  \n| 100.36 | 100.31 | 99.99 | 100.11 | 100.64 |\n| :--- | :--- | :--- | :--- | :--- |\n| 100.85 | 99.42 | 99.91 | 99.35 | 100.10 |  \n设这批钢管内直径服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$, 试分别在下列条件下检验假设 $(\\alpha=0.05)$.  \n$$\nH_{0}: \\mu=100 \\quad \\text { vs } \\quad H_{1}: \\mu>100\n$$  \n(1) 已知 $\\sigma=0.5$.  \n(2) $\\sigma$ 未知.  \n7. 假定考生成绩服从正态分布, 在某地一次数学统考中, 随机抽取了 36 位考生的成绩, 算得平均成绩为 66.5 分, 标准差为 15 分, 问在显著性水平 0.05 下, 是否可以认为这次考试全体考生的平均成绩为 70 分?",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "6. 从一批钢管抽取 10 根, 测得其内径 (单位: $\\mathrm{mm}$ ) 为:  \n| 100.36 | 100.31 | 99.99 | 100.11 | 100.64 |\n| :--- | :--- | :--- | :--- | :--- |\n| 100.85 | 99.42 | 99.91 | 99.35 | 100.10 |  \n设这批钢管内直径服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right)$, 试分别在下列条件下检验假设 $(\\alpha=0.05)$.  \n$$\nH_{0}: \\mu=100 \\quad \\text { vs } \\quad H_{1}: \\mu>100\n$$  \n(1) 已知 $\\sigma=0.5$.  \n(2) $\\sigma$ 未知.  \n7. 假定考生成绩服从正态分布, 在某地一次数学统考中, 随机抽取了 36 位考生的成绩, 算得平均成绩为 66.5 分, 标准差为 15 分, 问在显著性水平 0.05 下, 是否可以认为这次考试全体考生的平均成绩为 70 分?\n8. 一个小学校长在报纸上看到这样的报道: “这一城市的初中学生平均每周着 $8 \\mathrm{~h}$ 电视.”她认为她所在学校的学生看电视的时间明显小于该数字为此她在该校随机调查了 100 个学生, 得知平均每周看电视的时间 bar $x=6.5 \\mathrm{~h}$, 样本标准差为 $s=2 \\mathrm{~h}$. 问是否可以认为这位校长的看法是对的? 取 $\\alpha=0.05$.\n9. 设在木材中抽出 100 根, 测其小头直径, 得到样本平均数为 $\\bar{x}=11.2 \\mathrm{~cm}$, 样本标准差 $s=$ $2.6 \\mathrm{~cm}$, 问该批木材小头的平均直径能否认为不低于 $12 \\mathrm{~cm}(\\alpha=0.05) ?$\n10. 考察一鱼塘中鱼的含永量, 随机地取 10 条鱼测得各条鱼的含录量 (单位: $\\mathrm{mg}$ ) 为:  \n$$\n\\begin{array}{llllllllll}\n0.8 & 1.6 & 0.9 & 0.8 & 1.2 & 0.4 & 0.7 & 1.0 & 1.2 & 1.1\n\\end{array}\n$$",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "9. 设在木材中抽出 100 根, 测其小头直径, 得到样本平均数为 $\\bar{x}=11.2 \\mathrm{~cm}$, 样本标准差 $s=$ $2.6 \\mathrm{~cm}$, 问该批木材小头的平均直径能否认为不低于 $12 \\mathrm{~cm}(\\alpha=0.05) ?$\n10. 考察一鱼塘中鱼的含永量, 随机地取 10 条鱼测得各条鱼的含录量 (单位: $\\mathrm{mg}$ ) 为:  \n$$\n\\begin{array}{llllllllll}\n0.8 & 1.6 & 0.9 & 0.8 & 1.2 & 0.4 & 0.7 & 1.0 & 1.2 & 1.1\n\\end{array}\n$$  \n设鱼的含录量服从正态分布 $N\\left(\\mu, \\sigma^{2}\\right.$ ), 试检验假设 $H_{0}: \\mu \\leqslant 1.2 \\quad$ vs $H_{1} ; \\mu>1.2$ (取 $\\alpha=0.10$ ).  \n11. 如果一个矩形的宽度 $w$ 与长度 $l$ 的比 $\\frac{w}{l}=\\frac{1}{2}(\\sqrt{5}-1) \\approx 0.618$, 这样的矩形称为黄金矩形. 下面列出某工艺品工厂随机取的 20 个矩形宽度与长度的比值.  \n| 0.693 | 0.749 | 0.654 | 0.670 | 0.662 | 0.672 | 0.615 | 0.606 | 0.690 | 0.628 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 0.668 | 0.611 | 0.606 | 0.609 | 0.553 | 0.570 | 0.844 | 0.576 | 0.933 | 0.630 |  \n设这一工厂生产的矩形的宽度与长度的比值总体服从正态分布, 其均值为 $\\mu$, 试检验假设 ( 取 $\\alpha=0.05$ )  \n$$\nH_{0}: \\mu=0.618 \\quad \\text { vs } \\quad H_{1}: \\mu \\neq 0.618\n$$  \n12. 下面给出两种型号的计算器充电以后所能使用的时间 (h) 的观测值",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "| 0.693 | 0.749 | 0.654 | 0.670 | 0.662 | 0.672 | 0.615 | 0.606 | 0.690 | 0.628 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 0.668 | 0.611 | 0.606 | 0.609 | 0.553 | 0.570 | 0.844 | 0.576 | 0.933 | 0.630 |  \n设这一工厂生产的矩形的宽度与长度的比值总体服从正态分布, 其均值为 $\\mu$, 试检验假设 ( 取 $\\alpha=0.05$ )  \n$$\nH_{0}: \\mu=0.618 \\quad \\text { vs } \\quad H_{1}: \\mu \\neq 0.618\n$$  \n12. 下面给出两种型号的计算器充电以后所能使用的时间 (h) 的观测值\n$\\begin{array}{lllllllllllll}\\text { 型号 B } & 3.8 & 4.3 & 4.2 & 4.0 & 4.9 & 4.5 & 5.2 & 4.8 & 4.5 & 3.9 & 3.7 & 4.6\\end{array}$  \n设两样本独立且数据所属的两总体的密度函数至多差一个平移量. 试问能否认为型号 $A$ 的计算器平均使用时间比型号 $B$ 来得长 $((\\alpha=0.01)$ ?  \n13. 从某锌矿的东、西两支矿脉中, 各抽取样本容量分别为 9 与 8 的样本进行测试, 得样本含锌平均数及样本方差如下:  \n$$\n\\begin{aligned}\n& \\text { 东支: } \\bar{x}_{1}=0.230, s_{1}^{2}=0.1337 \\\\\n& \\text { 西支: } \\bar{x}_{2}=0.269, s_{2}^{2}=0.1736\n\\end{aligned}\n$$  \n若东、西两支矿脉的含锌量都服从正杰分布且方差相同, 问东、西两支矿脉含锌量的平均值是否可以看作一样 $(\\alpha=0.05)$ ?",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "$\\begin{array}{lllllllllllll}\\text { 型号 B } & 3.8 & 4.3 & 4.2 & 4.0 & 4.9 & 4.5 & 5.2 & 4.8 & 4.5 & 3.9 & 3.7 & 4.6\\end{array}$  \n设两样本独立且数据所属的两总体的密度函数至多差一个平移量. 试问能否认为型号 $A$ 的计算器平均使用时间比型号 $B$ 来得长 $((\\alpha=0.01)$ ?  \n13. 从某锌矿的东、西两支矿脉中, 各抽取样本容量分别为 9 与 8 的样本进行测试, 得样本含锌平均数及样本方差如下:  \n$$\n\\begin{aligned}\n& \\text { 东支: } \\bar{x}_{1}=0.230, s_{1}^{2}=0.1337 \\\\\n& \\text { 西支: } \\bar{x}_{2}=0.269, s_{2}^{2}=0.1736\n\\end{aligned}\n$$  \n若东、西两支矿脉的含锌量都服从正杰分布且方差相同, 问东、西两支矿脉含锌量的平均值是否可以看作一样 $(\\alpha=0.05)$ ?  \n14. 在针织品漂白工艺过程中, 要考察温度对针织品断裂强力 (主要质量指标) 的影响. 为了比较 $70^{\\circ} \\mathrm{C}$ 与 $80^{\\circ} \\mathrm{C}$ 的影响有无差别, 在这两个温度下, 分别重复做了 8 次试验, 得数据如下 (单位: N ):  \n$70^{\\circ} \\mathrm{C}$ 时的强力 $: 18.5,18.8,19.8,20.9,21.5,19.5,21.0,21.2$  \n$80^{\\circ} \\mathrm{C}$ 时的强力 : $17.7,20.3,20.0, \\quad 18.8, \\quad 19.0, \\quad 20.1 \\quad 20.0, \\quad 19.1$  \n根据经验, 温度对针织品断裂强度的波动没有影响. 问在 $70^{\\circ} \\mathrm{C}$ 时的平均断裂强力与 $80^{\\circ} \\mathrm{C}$ 时的平均断裂强力间是否有显著差别?（假定断裂强力服从正态分布, $\\alpha=0.05$. )",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "14. 在针织品漂白工艺过程中, 要考察温度对针织品断裂强力 (主要质量指标) 的影响. 为了比较 $70^{\\circ} \\mathrm{C}$ 与 $80^{\\circ} \\mathrm{C}$ 的影响有无差别, 在这两个温度下, 分别重复做了 8 次试验, 得数据如下 (单位: N ):  \n$70^{\\circ} \\mathrm{C}$ 时的强力 $: 18.5,18.8,19.8,20.9,21.5,19.5,21.0,21.2$  \n$80^{\\circ} \\mathrm{C}$ 时的强力 : $17.7,20.3,20.0, \\quad 18.8, \\quad 19.0, \\quad 20.1 \\quad 20.0, \\quad 19.1$  \n根据经验, 温度对针织品断裂强度的波动没有影响. 问在 $70^{\\circ} \\mathrm{C}$ 时的平均断裂强力与 $80^{\\circ} \\mathrm{C}$ 时的平均断裂强力间是否有显著差别?（假定断裂强力服从正态分布, $\\alpha=0.05$. )  \n15. 一药厂生产一种新的止痛片, 厂方希望验证服用新药片后至开始起作用的时间间隔较原有止痛片至少缩短一半, 因此厂方提出需检验假设  \n$$\nH_{0}: \\mu_{1}=2 \\mu_{2} \\quad \\text { vs } \\quad H_{1} ; \\dot{\\mu}_{1}>2 \\mu_{2}\n$$  \n此处 $\\mu_{1}, \\mu_{2}$ 分别是服用原有止痛片和服用新止痛片后至开始起作用的时间间隔的总体的均值.设两总体均为正态分布且方差分别为已知值 $\\sigma_{1}^{2}, \\sigma_{2}^{2}$, 现分别在两总体中取一样本 $x_{1}, \\cdots, x_{n}$ 和 $y_{1}, \\cdots, y_{m}$, 设两个样本独立. 试给出上述假设检验问题的检验统计景及拒绝域.  \n16. 已知维尼纶纤度在正常条件下服从正态分布, 且标准差为 0.048 . 从某天产品中抽取 5 根纤维,测得其纤度为  \n$$\n1.32,1.55,1.36,1.40,1.44\n$$  \n问这一天纤度的总体标准差是否正常? (取 $\\alpha=0.05$ )",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nH_{0}: \\mu_{1}=2 \\mu_{2} \\quad \\text { vs } \\quad H_{1} ; \\dot{\\mu}_{1}>2 \\mu_{2}\n$$  \n此处 $\\mu_{1}, \\mu_{2}$ 分别是服用原有止痛片和服用新止痛片后至开始起作用的时间间隔的总体的均值.设两总体均为正态分布且方差分别为已知值 $\\sigma_{1}^{2}, \\sigma_{2}^{2}$, 现分别在两总体中取一样本 $x_{1}, \\cdots, x_{n}$ 和 $y_{1}, \\cdots, y_{m}$, 设两个样本独立. 试给出上述假设检验问题的检验统计景及拒绝域.  \n16. 已知维尼纶纤度在正常条件下服从正态分布, 且标准差为 0.048 . 从某天产品中抽取 5 根纤维,测得其纤度为  \n$$\n1.32,1.55,1.36,1.40,1.44\n$$  \n问这一天纤度的总体标准差是否正常? (取 $\\alpha=0.05$ )  \n17. 某电工器材厂生产一种保险丝. 测量其熔化时间, 依通常情况方差为 400 , 今从某天产品中抽取容量为 25 的样本, 测量其熔化时间并计算得 $\\bar{x}=62.24, s^{2}=52=404.77$, 问这天保险熔化时间分散度与通常有无显著差异? ( 取 $\\alpha=0.05$,假定熔化时间跟从正态分布. )\n18. 某种导线的质量标准要求其电阻的标准差不得超过 $0.005(\\Omega)$. 今在一批导线中随机抽取样品 9 根, 测得样本标准差为 $s=0.007(\\Omega)$, 设总体为正态分布. 问在水平 $\\alpha=0.05$ 下能否认为这批导线的标准差显著地偏大?\n19. 两台车床生产同一种滚珠, 滚珠直径服从正态分布. 从中分别抽取 8 个和 9 个产品, 测得其直径为  \n甲车床: $15.0,14.5,15.2,15.5,14.8,15.1,15.2,14.8$  \n乙车床: $15.2, \\quad 15.0,14.8, \\quad 15.2, \\quad 15.0,15.0,14.8, \\quad 15.1, \\quad 14.8$  \n比较两台车床生产的滚珠直径的方差是否有明显差异 $(\\alpha=0.05)$.",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "18. 某种导线的质量标准要求其电阻的标准差不得超过 $0.005(\\Omega)$. 今在一批导线中随机抽取样品 9 根, 测得样本标准差为 $s=0.007(\\Omega)$, 设总体为正态分布. 问在水平 $\\alpha=0.05$ 下能否认为这批导线的标准差显著地偏大?\n19. 两台车床生产同一种滚珠, 滚珠直径服从正态分布. 从中分别抽取 8 个和 9 个产品, 测得其直径为  \n甲车床: $15.0,14.5,15.2,15.5,14.8,15.1,15.2,14.8$  \n乙车床: $15.2, \\quad 15.0,14.8, \\quad 15.2, \\quad 15.0,15.0,14.8, \\quad 15.1, \\quad 14.8$  \n比较两台车床生产的滚珠直径的方差是否有明显差异 $(\\alpha=0.05)$.  \n20. 有两台机器生产金属部件, 分别在两台机器所生产的部件中各取一容量为 $m=14$ 和 $n=12$的样本, 测得部件重量的样本方差分别为 $s_{1}^{2}=15.46, s_{2}^{2}=9.66$, 设两样本相互独立, 试在水平\n$\\alpha=0.05$ 下检验假设  \n$$\nH_{0}: \\sigma_{1}^{2}=\\sigma_{2}^{2} \\quad \\text { vs } \\quad H_{1} ; \\sigma_{1}^{2}>\\sigma_{2}^{2}\n$$  \n21. 测得两批电子器件的样品的电阻 $(\\Omega)$ 为\n$\\mathrm{A}$ 批 $(x)$\n$0.140 \\quad 0.138$\n0.143\n0.142\n0.144\n0.137\nB 批 $(y)$\n0.135\n0.140\n0.142\n0.136\n0.138\n0.140  \n设这两批器材的电阻值分别服从分布 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right), N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$, 且两样本独立.  \n(1) 试检验两个总体的方差是否相等? $(\\alpha=0.05)$  \n(2) 试检验两个总体的均值是否相等? $(\\alpha=0.05)$",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "$\\alpha=0.05$ 下检验假设  \n$$\nH_{0}: \\sigma_{1}^{2}=\\sigma_{2}^{2} \\quad \\text { vs } \\quad H_{1} ; \\sigma_{1}^{2}>\\sigma_{2}^{2}\n$$  \n21. 测得两批电子器件的样品的电阻 $(\\Omega)$ 为\n$\\mathrm{A}$ 批 $(x)$\n$0.140 \\quad 0.138$\n0.143\n0.142\n0.144\n0.137\nB 批 $(y)$\n0.135\n0.140\n0.142\n0.136\n0.138\n0.140  \n设这两批器材的电阻值分别服从分布 $N\\left(\\mu_{1}, \\sigma_{1}^{2}\\right), N\\left(\\mu_{2}, \\sigma_{2}^{2}\\right)$, 且两样本独立.  \n(1) 试检验两个总体的方差是否相等? $(\\alpha=0.05)$  \n(2) 试检验两个总体的均值是否相等? $(\\alpha=0.05)$  \n22. 某厂使用两种不同的原料生产同一类型产品, 随机选取使用原料 $\\mathrm{A}$ 生产的样品 22 件, 测得平均质量为 $2.36(\\mathrm{~kg})$, 样本标准差为 $0.57(\\mathrm{~kg})$. 取使用原料 $\\mathrm{B}$ 生产的样品 24 件, 测得平均质量为 $2.55(\\mathrm{~kg})$, 样本标准差为 $0.48(\\mathrm{~kg})$. 设产品质量服从正态分布, 两个样本独立. 问能否认为使用原料 $\\mathrm{B}$ 生产的产品平均质量较使用原料 $\\mathrm{A}$ 显著大? ( 取 $\\alpha=0.05$. )",
        "metadata": {
            "Header 2": "$\\begin{array}{llllll}14.7 & 15.1 & 14.8 & 15.0 & 15.2 & 14.6\\end{array}$"
        },
        "type": "Document"
    },
    {
        "page_content": "指数分布是一类重要的分布, 有广泛的应用. 设 $x_{1}, \\cdots, x_{n}$, 是来自指数分布 $\\operatorname{Exp}(1 / \\theta)$ 的样本, $\\theta$ 为其均值, 现考虑关于 $\\theta$ 的如下检验问题:  \n$$\n\\begin{equation*}\nH_{0}: \\theta \\leqslant \\theta_{0} \\quad \\text { vs } \\quad H_{1}: \\theta>\\theta_{0} \\tag{7.3.1}\n\\end{equation*}\n$$  \n拒绝域的自然形式是 $W=\\{\\bar{x} \\geqslant c\\}$, 下面讨论 $\\bar{x}$ 的分布.  \n为寻找检验统计量, 我们考察参数 $\\theta$ 的充分统计量 $\\bar{x}$. 在 $\\theta=\\theta_{0}$ 时, $n \\bar{x}=\\sum_{i=1}^{n} x_{1} \\sim$ $G a\\left(n, 1 / \\theta_{0}\\right)$, 由伽玛分布性质可知  \n$$\n\\begin{equation*}\n\\chi^{2}=\\frac{2 n \\bar{x}}{\\theta_{0}} \\sim \\chi^{2}(2 n) \\tag{7.3.2}\n\\end{equation*}\n$$  \n于是可用 $\\chi^{2}$ 作为检验统计量并利用 $\\chi^{2}(2 n)$ 的分位数建立检验的拒绝域, 对检验问题 7.3.1, 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{\\chi^{2} \\geqslant \\chi_{1-a}^{2}(2 n)\\right\\} \\tag{7.3.3}\n\\end{equation*}\n$$  \n关于 $\\theta$ 的另两种检验问题的处理方法是类似的. 对检验问题  \n$$\n\\begin{array}{lll}\nH_{0}: \\theta \\geqslant \\theta_{0} & \\text { vs } & H_{1}: \\theta<\\theta_{0} \\\\",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.1 指数分布参数的假设检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n\\chi^{2}=\\frac{2 n \\bar{x}}{\\theta_{0}} \\sim \\chi^{2}(2 n) \\tag{7.3.2}\n\\end{equation*}\n$$  \n于是可用 $\\chi^{2}$ 作为检验统计量并利用 $\\chi^{2}(2 n)$ 的分位数建立检验的拒绝域, 对检验问题 7.3.1, 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{\\chi^{2} \\geqslant \\chi_{1-a}^{2}(2 n)\\right\\} \\tag{7.3.3}\n\\end{equation*}\n$$  \n关于 $\\theta$ 的另两种检验问题的处理方法是类似的. 对检验问题  \n$$\n\\begin{array}{lll}\nH_{0}: \\theta \\geqslant \\theta_{0} & \\text { vs } & H_{1}: \\theta<\\theta_{0} \\\\\nH_{0}: \\theta=\\theta_{0} & \\text { vs } & H_{1}: \\theta \\neq \\theta_{0} \\tag{7.3.5}\n\\end{array}\n$$  \n检验统计量仍然是 7.3.2的 $\\chi^{2}$, 拒绝域分别为  \n$$\n\\begin{gather*}\nW=\\left\\{\\chi^{2} \\leqslant \\chi_{a}^{2}(2 n)\\right\\}  \\tag{7.3.6}\\\\\nW=\\left\\{\\chi^{2} \\leqslant \\chi_{\\alpha / 2}^{2}(2 n) \\text { 或 } \\chi^{2} \\geqslant \\chi_{\\alpha / 2}^{2}(2 n)\\right\\} \\tag{7.3.7}\n\\end{gather*}\n$$  \n例 7.3.1: 设我们要检验某种元件的平均寿命不小于 $6000 \\mathrm{~h}$, 假定元件寿命为指敬分布, 现取 5 个元件投人试验, 观测到如下 5 个失效时间 ( h)  \n$\\begin{array}{lllll}395 & 4094 & 119 & 11572 & 6133\\end{array}$",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.1 指数分布参数的假设检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array}\n$$  \n检验统计量仍然是 7.3.2的 $\\chi^{2}$, 拒绝域分别为  \n$$\n\\begin{gather*}\nW=\\left\\{\\chi^{2} \\leqslant \\chi_{a}^{2}(2 n)\\right\\}  \\tag{7.3.6}\\\\\nW=\\left\\{\\chi^{2} \\leqslant \\chi_{\\alpha / 2}^{2}(2 n) \\text { 或 } \\chi^{2} \\geqslant \\chi_{\\alpha / 2}^{2}(2 n)\\right\\} \\tag{7.3.7}\n\\end{gather*}\n$$  \n例 7.3.1: 设我们要检验某种元件的平均寿命不小于 $6000 \\mathrm{~h}$, 假定元件寿命为指敬分布, 现取 5 个元件投人试验, 观测到如下 5 个失效时间 ( h)  \n$\\begin{array}{lllll}395 & 4094 & 119 & 11572 & 6133\\end{array}$\n这是一个假设检验问题, 检验的假设为  \n$$\nH_{0}: \\theta \\geqslant 6000 \\quad \\text { vs } \\quad H_{1}: \\theta<6000\n$$  \n经计算, $\\bar{x}=4462.6$,故检验统计量为  \n$$\n\\chi^{2}=\\frac{10 \\bar{x}}{\\theta_{0}}=\\frac{10 \\times 4462.6}{6000}=7.4377\n$$  \n若取 $\\alpha=0.05$, 则查表知 $\\chi_{0.05}^{2}(10)=3.94$, 由于 $\\chi^{2}>\\chi_{0.05}^{2}(10)$, 故接受原假设可以认为平均寿命不低于 $6000 \\mathrm{~h}$.",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.1 指数分布参数的假设检验"
        },
        "type": "Document"
    },
    {
        "page_content": "比例 $p$ 可看作某事件发生的概率, 即可看作二点分布 $b(1, p)$ 中的参数. 作 $n$ 次独立试验, 以 $x$ 记该事件发生的次数, 则 $x \\sim b(n, p)$. 我们可以根据 $x$ 检验关于 $p$ 的一些假设. 先考虑如下单边假设检验问题.  \n$$\n\\begin{equation*}\nH_{0}: p \\leqslant p_{0} \\quad \\text { vs } \\quad H_{1}: p>p_{0} \\tag{7.3.8}\n\\end{equation*}\n$$  \n直观上看,一个显然的检验方法是取如下的拒绝域 $W=\\{x \\geqslant c\\}$, 由于 $x$ 只取整数值, 故 $c$ 可限制在非负整数中. 然而,一般情况下对给定的 $\\alpha$,不一定能正好取到一个 $c$ 使  \n$$\nP\\left(x \\geqslant c ; p_{0}\\right)=\\sum_{i=c}^{n}\\left(\\begin{array}{c}\nn  \\tag{7.3.9}\\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i}=\\alpha\n$$  \n能恰巧使得7.3.9成立的 $c$ 值是罕见的. 这是在对离散总体作假设检验中普遍会遇到的问题, 在这种情况下, 较常见的是找一个 $c_{0}$, 使得  \n$$\n\\sum_{i=c_{0}}^{n}\\left(\\begin{array}{l}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i}>a>\\sum_{i=c_{0}+1}^{n}\\left(\\begin{array}{l}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{i-1}\n$$",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.2 比例 $p$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nP\\left(x \\geqslant c ; p_{0}\\right)=\\sum_{i=c}^{n}\\left(\\begin{array}{c}\nn  \\tag{7.3.9}\\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i}=\\alpha\n$$  \n能恰巧使得7.3.9成立的 $c$ 值是罕见的. 这是在对离散总体作假设检验中普遍会遇到的问题, 在这种情况下, 较常见的是找一个 $c_{0}$, 使得  \n$$\n\\sum_{i=c_{0}}^{n}\\left(\\begin{array}{l}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i}>a>\\sum_{i=c_{0}+1}^{n}\\left(\\begin{array}{l}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{i-1}\n$$  \n于是, 若取 $c=c_{0}$, 这相当于把检验的显著性水平提高了一些, 由 $\\alpha$ 提高到到 $\\sum_{i=c_{0}}^{n}\\left(\\begin{array}{l}n \\\\ i\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i}$若取 $c=c_{0}+1$, 此时相当于把显著性水平由 $\\alpha$ 降低到 $\\sum_{i=c_{0}+1}^{n}\\left(\\begin{array}{c}n \\\\ i\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{i-1}$, 因为后者可保证 (7.3.9) 的左侧不大于 $\\alpha$,故取 $c=c_{0}+1$ 可得水平为 $\\alpha$ 的检验,  \n对检验问题  \n$$\n\\begin{equation*}\nH_{0}: p \\geqslant p_{0} \\quad \\text { vs } \\quad H_{1}: p<p_{0} \\tag{7.3.10}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.2 比例 $p$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "对检验问题  \n$$\n\\begin{equation*}\nH_{0}: p \\geqslant p_{0} \\quad \\text { vs } \\quad H_{1}: p<p_{0} \\tag{7.3.10}\n\\end{equation*}\n$$  \n处理方法是类似的, 检验的拒绝域为 $W=\\{x \\geqslant c\\}, c$ 为满足  \n$$\n\\sum_{i=0}^{c}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i} \\leqslant a\n$$  \n的最大正整数. 对检验问题  \n$$\n\\begin{equation*}\nH_{0}: p=p_{0} \\quad \\text { vs } \\quad H_{1} ; p \\neq p_{0}, \\tag{7.3.11}\n\\end{equation*}\n$$  \n检验的拒绝域 $W=\\left\\{x \\leqslant c_{1}\\right\\}$ 或 $\\left\\{x \\geqslant c_{2}\\right\\}$, 其中 $c_{1}$ 为满足  \n$$\n\\sum_{i=0}^{c_{1}}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i} \\leqslant \\frac{\\alpha}{2}\n$$  \n的最大整数, $c_{2}$ 为满足  \n$$\n\\sum_{i=c_{2}}^{n_{1}}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i} \\leqslant \\frac{\\alpha}{2}\n$$  \n的最小整数.  \n例 7.3.2: 某厂生产的产品优质品率一直保持在 40\\%, 近期对该厂生产的该类产品抽检 20 件, 其中优质品 7 件, 在 $\\alpha=0.05$ 下能否认为优质品率仍保持在 $40 \\%$ ?",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.2 比例 $p$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\sum_{i=0}^{c_{1}}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i} \\leqslant \\frac{\\alpha}{2}\n$$  \n的最大整数, $c_{2}$ 为满足  \n$$\n\\sum_{i=c_{2}}^{n_{1}}\\left(\\begin{array}{c}\nn \\\\\ni\n\\end{array}\\right) p_{0}^{i}\\left(1-p_{0}\\right)^{n-i} \\leqslant \\frac{\\alpha}{2}\n$$  \n的最小整数.  \n例 7.3.2: 某厂生产的产品优质品率一直保持在 40\\%, 近期对该厂生产的该类产品抽检 20 件, 其中优质品 7 件, 在 $\\alpha=0.05$ 下能否认为优质品率仍保持在 $40 \\%$ ?  \n这是一个假设检验问题, 以 $p$ 表示优质品率, $x$ 表示 20 件产品中的优质品件数, 则 $x \\sim$\n$b \\square(20, p)$, 待检验的原假设为  \n$$\nH_{0}: p=0.4 \\quad \\text { vs } \\quad H_{1}: p \\neq 0.4\n$$  \n拒绝域为 $W=\\left\\{x \\leqslant c_{1}\\right\\}$ 或 $\\left\\{x \\geqslant c_{2}\\right\\}$, 下求 $c_{1}$ 与 $c_{2}$.  \n由于  \n$$\nP(x \\leqslant 3)=0.0160<0.025<P(x \\leqslant 4)=0.0510\n$$  \n故取 $c_{1}=3$, 又因  \n$$\nP(x \\geqslant 11)=0.0565>0.025>P(x \\geqslant 12)=0.0210\n$$  \n从而 $c_{2}=12$, 拒绝域为 $W=\\{x \\leqslant 3\\}$ 或 $\\{x \\geqslant 12\\}$. 附带指出, 该拒绝域的显著水平实际上不是 0.05 , 而是 $0.0160+0.021=0.0370$, 本例中, 由于观测值没有落人拒绝域, 故接受原假设.",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.2 比例 $p$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "前一小节我们介绍了对二点分布参数 $p$ 的检验问题, 我们看到临界值的确定比较繁琐, 使用不太方便. 如果样本量较大, 我们可用近似的检验方法一一大样本检验. 其一般思路如下: 设 $x_{1}, \\cdots, x_{n}$, 是来自某总体的样本, 又设该总体均值为 $\\theta$, 方差为 $\\theta$ 的函数, 记为 $\\sigma^{2}(\\theta)$, 譬如, 对二点分布 $b(1, \\theta)$, 其方差 $\\theta(1-\\theta)$ 是均值 $\\theta$ 的函数, 则对下列三类假设检验问题:  \n(1) $H_{0}: \\theta \\leqslant \\theta_{0} \\quad$ vs $H_{0}: \\theta>\\theta_{0}$;  \n(2) $H_{0}: \\theta \\geqslant \\theta_{0} \\quad$ vs $\\quad H_{0}: \\theta<\\theta_{0}$;  \n(3) $H_{0}: \\theta=\\theta_{0} \\quad$ vs $\\quad H_{0}: \\theta \\neq \\theta_{0}$  \n在样本容量 $n$ 充分大时, 利用中心极限定理, $\\bar{x} \\dot{\\sim} N\\left(\\theta, \\sigma^{2}(\\theta) / n\\right)$, 故在 $\\theta=\\theta_{0}$ 时, 可采用如下检验统计量  \n$$\n\\begin{equation*}\nu=\\frac{\\sqrt{n}\\left(\\bar{x}-\\theta_{0}\\right)}{\\sqrt{\\sigma^{2}\\left(\\theta_{0}\\right)}} \\dot{\\sim} N(0,1) \\tag{7.3.12}\n\\end{equation*}\n$$  \n近似地确定拒绝域. 对应上述三类检验问题的拒绝域依次分别为  \n$$\n\\begin{aligned}\n& W=\\left\\{u \\geqslant u_{1-\\alpha}\\right\\} \\\\\n& W=\\left\\{u \\leqslant u_{a}\\right\\} \\\\\n& W=\\left\\{|u| \\geqslant u_{1-a / 2}\\right\\}",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.3 大样本检验"
        },
        "type": "Document"
    },
    {
        "page_content": "在样本容量 $n$ 充分大时, 利用中心极限定理, $\\bar{x} \\dot{\\sim} N\\left(\\theta, \\sigma^{2}(\\theta) / n\\right)$, 故在 $\\theta=\\theta_{0}$ 时, 可采用如下检验统计量  \n$$\n\\begin{equation*}\nu=\\frac{\\sqrt{n}\\left(\\bar{x}-\\theta_{0}\\right)}{\\sqrt{\\sigma^{2}\\left(\\theta_{0}\\right)}} \\dot{\\sim} N(0,1) \\tag{7.3.12}\n\\end{equation*}\n$$  \n近似地确定拒绝域. 对应上述三类检验问题的拒绝域依次分别为  \n$$\n\\begin{aligned}\n& W=\\left\\{u \\geqslant u_{1-\\alpha}\\right\\} \\\\\n& W=\\left\\{u \\leqslant u_{a}\\right\\} \\\\\n& W=\\left\\{|u| \\geqslant u_{1-a / 2}\\right\\}\n\\end{aligned}\n$$  \n例 7.3.3: 某厂生产的产品不合格率为 $10 \\%$, 在一次例行检查中, 随机抽取 80 件, 发现有 11 件不合格品, 在 $\\alpha=0.05$ 下能否认为不合格品率仍为 $10 \\%$ ?  \n解: 这是关于不合格品率 $\\theta$ 的检验, 假设为  \n$$\nH_{0}: \\theta=0.1 \\quad \\text { vs } \\quad H_{1}: \\theta \\neq 0.1\n$$  \n我们可以仿例 7.3.2 的方法求拒绝域, 但要把此拒绝域找出来是困难的, 如今 $n=80$ 比较大, 因此可采用大样本检验方法. 由 $(7.3 .12), \\theta_{0}=0.1, \\sigma^{2}\\left(\\theta_{0}=0.1 \\times 0.9\\right)$, 检验统计量为  \n$$\nu=\\frac{\\sqrt{80}\\left(\\frac{11}{80}-0.1\\right)}{\\sqrt{0.1 \\times 0.9}}=1.118\n$$",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.3 大样本检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n例 7.3.3: 某厂生产的产品不合格率为 $10 \\%$, 在一次例行检查中, 随机抽取 80 件, 发现有 11 件不合格品, 在 $\\alpha=0.05$ 下能否认为不合格品率仍为 $10 \\%$ ?  \n解: 这是关于不合格品率 $\\theta$ 的检验, 假设为  \n$$\nH_{0}: \\theta=0.1 \\quad \\text { vs } \\quad H_{1}: \\theta \\neq 0.1\n$$  \n我们可以仿例 7.3.2 的方法求拒绝域, 但要把此拒绝域找出来是困难的, 如今 $n=80$ 比较大, 因此可采用大样本检验方法. 由 $(7.3 .12), \\theta_{0}=0.1, \\sigma^{2}\\left(\\theta_{0}=0.1 \\times 0.9\\right)$, 检验统计量为  \n$$\nu=\\frac{\\sqrt{80}\\left(\\frac{11}{80}-0.1\\right)}{\\sqrt{0.1 \\times 0.9}}=1.118\n$$  \n若取 $\\alpha=0.05$, 则 $u_{0.975}=1.96$, 故拒绝域为 $W=\\{|u| \\geqslant 1.96\\}$. 如今 $u=1.118$ 未落人拒绝域, 故不能拒绝原假设, 可以认为不合格品率仍为 $10 \\%$.  \n例 7.3.4: 某建筑公司宣称其磨下建筑工地平均每天发生事故数不超过 0.6 起, 现记录了该公司磨下建筑工地 200 天的安全生产情况, 事故数记录如下:  \n$$\n\\begin{array}{c|cccccccc}\n\\text { 一天发生的事故数 } & 0 & 1 & 2 & 3 & 4 & 5 & \\geqslant 6 & \\text { 合计 } \\\\\n\\hline \\text { 天数 } & 102 & 59 & 30 & 8 & 0 & 1 & 0 & 200\n\\end{array}\n$$  \n试检验该建筑公司的宜称是否成立. (取 $\\alpha=0.05$.)  \n解: 以 $X$ 记该建筑公司麾下建筑工地一天发生的事故数, 可认为 $X \\sim P(\\lambda)$ (见习题 7.4.4), 现要\n检验的假设是:  \n$$",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.3 大样本检验"
        },
        "type": "Document"
    },
    {
        "page_content": "例 7.3.4: 某建筑公司宣称其磨下建筑工地平均每天发生事故数不超过 0.6 起, 现记录了该公司磨下建筑工地 200 天的安全生产情况, 事故数记录如下:  \n$$\n\\begin{array}{c|cccccccc}\n\\text { 一天发生的事故数 } & 0 & 1 & 2 & 3 & 4 & 5 & \\geqslant 6 & \\text { 合计 } \\\\\n\\hline \\text { 天数 } & 102 & 59 & 30 & 8 & 0 & 1 & 0 & 200\n\\end{array}\n$$  \n试检验该建筑公司的宜称是否成立. (取 $\\alpha=0.05$.)  \n解: 以 $X$ 记该建筑公司麾下建筑工地一天发生的事故数, 可认为 $X \\sim P(\\lambda)$ (见习题 7.4.4), 现要\n检验的假设是:  \n$$\nH_{0}: \\lambda \\leqslant 0.6 \\quad \\text { vs } \\quad H_{1}: \\lambda>0.6\n$$  \n由于 $n=200$ 很大,故可以采用大样本检验,泊松分布的均值和方差都是 $\\lambda$,而  \n$$\n\\bar{x}=\\frac{1}{200}(0 \\times 102+1 \\times 59+2 \\times 30+3 \\times 8+4 \\times 0+5 \\times 1)=0.74\n$$  \n由 (7.3.12), 检验统计量为  \n$$\nu=\\frac{\\sqrt{n}(\\bar{x}-\\lambda)}{\\lambda}=\\frac{\\sqrt{200}(0.74-0.6)}{\\sqrt{0.6}}=2.556\n$$  \n若取 $\\alpha=0.05$, 则 $u_{0.95}=1.645$, 拒绝域为 $W=\\{u \\geqslant 1.645\\}$. 如今 $u=2.556$, 已落人拒绝域,故拒绝原假设,认为该建筑公司的宣称明显不成立.",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.3 大样本检验"
        },
        "type": "Document"
    },
    {
        "page_content": "检验的假设是:  \n$$\nH_{0}: \\lambda \\leqslant 0.6 \\quad \\text { vs } \\quad H_{1}: \\lambda>0.6\n$$  \n由于 $n=200$ 很大,故可以采用大样本检验,泊松分布的均值和方差都是 $\\lambda$,而  \n$$\n\\bar{x}=\\frac{1}{200}(0 \\times 102+1 \\times 59+2 \\times 30+3 \\times 8+4 \\times 0+5 \\times 1)=0.74\n$$  \n由 (7.3.12), 检验统计量为  \n$$\nu=\\frac{\\sqrt{n}(\\bar{x}-\\lambda)}{\\lambda}=\\frac{\\sqrt{200}(0.74-0.6)}{\\sqrt{0.6}}=2.556\n$$  \n若取 $\\alpha=0.05$, 则 $u_{0.95}=1.645$, 拒绝域为 $W=\\{u \\geqslant 1.645\\}$. 如今 $u=2.556$, 已落人拒绝域,故拒绝原假设,认为该建筑公司的宣称明显不成立.  \n大样本检验是近似的. 近似的含义是指检验的实际显著性水平与原先设定的显著性水平有差距, 这是由于诸如 (7.3.12) 中 $u$ 的分布与 $N(0,1)$ 有距离. 如果 $n$ 很大, 则这种差异就很小. 实用中我们一般并不清楚对一定的 $n, u$ 的分布与 $N(0,1)$ 的差异有多大, 因而也就不能确定检验的实际水平与设定水平究竞差多少. 在区间估计中也有类似问题. 因此, 大样本方法是一个“不得已而为之”的方法. 只要有基于精确分布的方法一般总是首先要加以考虑的.",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.3 大样本检验"
        },
        "type": "Document"
    },
    {
        "page_content": "假设检验的结论通常是简单的. 在给定的显著水平下, 不是拒绝原假设就是保留原假设. 然而有时也会出现这样的情况: 在一个较大的显著水平 ( 比如 $\\alpha=0.05$ )下得到拒绝原假设的结论, 而在一个较小的显著水平 (比如 $\\alpha=0.01$ ) 下却会得到相反的结论. 这种情况在理论上很容易解释:因为显著水平变小后会导致检验的拒绝域变小, 于是原来落在拒绝域中的观测值就可能落人接受域, 但这种情况在应用中会带来一些麻烦. 假如这时一个人主张选择显著水平 $\\alpha=0.05$, 而另一个人主张选 $\\alpha=0.01$, 则第一个人的结论是拒绝 $H_{0}$, 而后一个人的结论是接受 $\\mathrm{H} 0$, 我们该如何处理这一问题呢? 下面从一个例子谈起.  \n例 7.3.5: 一支香烟中的尼古丁含量 $X$ 服从正态分布 $N(\\mu, 1)$, 质量标准规定 $\\mu$ 不能超过 $1.5 \\mathrm{mg}$.现从某厂生产的香烟中随机抽取 20 支测得其中平均每支香烟的尼古丁含量为 $\\bar{x}=1.97 \\mathrm{mg}$, 试问该厂生产的香烟尼古丁含量是否符合质量标准的规定. 这是一个单侧假设检验问题,  \n$$\n\\text { 原假设 } H_{0}: \\mu \\leqslant 1.5, \\quad \\text { 备择假设 } H_{1}: \\mu>1.5\n$$  \n由于总体的标准差已知,故采用 $\\mu$ 检验, 由数据,  \n$$\nu=\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}}=\\frac{1.97-1.5}{1 / \\sqrt{20}}=2.10\n$$  \n对一些的显著性水平, 表 7.3.1 列出了相应的拒绝域和检验结论. 我们看到, 不同的 $\\alpha$ 有不同的结  \n表 7.3.1: 例 7.3.5 的拒绝域  \n| 显著性水平 | 拒绝域 | $\\mu=2.10$ 对应的结论 |\n| :---: | :---: | :---: |\n| $\\alpha=0.05$ | $\\mu \\geqslant 1.645$ | 拒绝 $H_{0}$ |",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.4 检验的 $p$ 值"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\text { 原假设 } H_{0}: \\mu \\leqslant 1.5, \\quad \\text { 备择假设 } H_{1}: \\mu>1.5\n$$  \n由于总体的标准差已知,故采用 $\\mu$ 检验, 由数据,  \n$$\nu=\\frac{\\bar{x}-\\mu_{0}}{\\sigma / \\sqrt{n}}=\\frac{1.97-1.5}{1 / \\sqrt{20}}=2.10\n$$  \n对一些的显著性水平, 表 7.3.1 列出了相应的拒绝域和检验结论. 我们看到, 不同的 $\\alpha$ 有不同的结  \n表 7.3.1: 例 7.3.5 的拒绝域  \n| 显著性水平 | 拒绝域 | $\\mu=2.10$ 对应的结论 |\n| :---: | :---: | :---: |\n| $\\alpha=0.05$ | $\\mu \\geqslant 1.645$ | 拒绝 $H_{0}$ |\n| $\\alpha=0.025$ | $\\mu \\geqslant 1.96$ | 拒绝 $H_{0}$ |\n| $\\alpha=0.01$ | $\\mu \\geqslant 2.33$ | 接受 $H_{0}$ |\n| $\\alpha=0.005$ | $\\mu \\geqslant 2.58$ | 接受 $H_{0}$ |  \n论.  \n现在换一个角度来看, 在 $\\mu=1.5$ 时, $\\mu$ 的分布是 $N(0,1)$. 此时可算得, $P(u \\geqslant 2.10)=0.0179$,若以 0.0179 为基准来看上述检验问题,可得  \n- 当 $\\alpha<0.0179$ 时, $u_{1-a}>2.10$. 于是 2.10 就不在 $\\left\\{u>u_{1-a}\\right\\}$ 中, 此时应接受原假设;\n- 当 $\\alpha \\geqslant 0.0179$ 时, $u_{1-a} \\leqslant 2.10$. 于是 2.10 就落在 $\\left\\{u \\geqslant u_{1-a}\\right\\}$ 中, 此时应拒绝 $H_{0}$.\n由此可以看出, 0.0179 是能用观测值 2.10 做出 “拒绝 $H_{0}$ ” 的最小的显著性水平, 这就是 $p$ 值,直观图形见图 7.3.1.  \n!",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.4 检验的 $p$ 值"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\alpha=0.005$ | $\\mu \\geqslant 2.58$ | 接受 $H_{0}$ |  \n论.  \n现在换一个角度来看, 在 $\\mu=1.5$ 时, $\\mu$ 的分布是 $N(0,1)$. 此时可算得, $P(u \\geqslant 2.10)=0.0179$,若以 0.0179 为基准来看上述检验问题,可得  \n- 当 $\\alpha<0.0179$ 时, $u_{1-a}>2.10$. 于是 2.10 就不在 $\\left\\{u>u_{1-a}\\right\\}$ 中, 此时应接受原假设;\n- 当 $\\alpha \\geqslant 0.0179$ 时, $u_{1-a} \\leqslant 2.10$. 于是 2.10 就落在 $\\left\\{u \\geqslant u_{1-a}\\right\\}$ 中, 此时应拒绝 $H_{0}$.\n由此可以看出, 0.0179 是能用观测值 2.10 做出 “拒绝 $H_{0}$ ” 的最小的显著性水平, 这就是 $p$ 值,直观图形见图 7.3.1.  \n!  \n图 7.3.1: 观测值 $\\mu=2.10$ 对应的 $p$ 值  \n定义 7.3.1. 在一个假设检验问题中, 利用观测值能够做出拒绝原假设的最小显著性水平称为检验的 $p$ 值.  \n引进检验的 $p$ 值的概念有明显的好处. 第一, 它比较客观, 避免了事先确定显著水平; 其次, 由检验的 $p$ 值与人们心目中的显著性水平 $\\alpha$ 进行比较可以很容易做出检验的结论;  \n- 如果 $\\alpha \\geqslant p$,则在显著性水平 $\\alpha$ 下拒绝 $H_{0}$;\n- 如果 $\\alpha<p$,则在显著性水平 $\\alpha$ 下应保留 $H_{0}$.  \n$p$ 值在应用中很有用, 如今的统计软件中对检验问题一般都会给出检验的 $p$ 值.  \n例 7.3.6: 设 $x_{1}, \\cdots, x_{n}$ 是来自 $b(1, \\theta)$ 的样本, 要检验如下假设:  \n$$\nH_{0}: \\theta \\leqslant \\theta_{0} \\quad \\text { vs } \\quad H_{1} ; \\theta>\\theta_{0}\n$$",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.4 检验的 $p$ 值"
        },
        "type": "Document"
    },
    {
        "page_content": "定义 7.3.1. 在一个假设检验问题中, 利用观测值能够做出拒绝原假设的最小显著性水平称为检验的 $p$ 值.  \n引进检验的 $p$ 值的概念有明显的好处. 第一, 它比较客观, 避免了事先确定显著水平; 其次, 由检验的 $p$ 值与人们心目中的显著性水平 $\\alpha$ 进行比较可以很容易做出检验的结论;  \n- 如果 $\\alpha \\geqslant p$,则在显著性水平 $\\alpha$ 下拒绝 $H_{0}$;\n- 如果 $\\alpha<p$,则在显著性水平 $\\alpha$ 下应保留 $H_{0}$.  \n$p$ 值在应用中很有用, 如今的统计软件中对检验问题一般都会给出检验的 $p$ 值.  \n例 7.3.6: 设 $x_{1}, \\cdots, x_{n}$ 是来自 $b(1, \\theta)$ 的样本, 要检验如下假设:  \n$$\nH_{0}: \\theta \\leqslant \\theta_{0} \\quad \\text { vs } \\quad H_{1} ; \\theta>\\theta_{0}\n$$  \n若取检验的显著性水平为 $\\alpha$, 则我们可给出检验的拒绝域的形式为: $W=\\left|\\sum x_{i} \\geqslant c\\right|$ 这里我们很难对一般的 $n$ 和 $\\alpha$ 定出 $c$ 的表达式, 我们只能说 $c$ 是满足 $P_{\\theta_{0}}\\left|\\sum x_{i} \\geqslant c\\right| \\leqslant \\alpha$ 的最小正整数. 这样的叙说总觉得不是很自然, 事实上, 我们并不需要定出 $c$, 在得到观测值 $\\sum x_{i}=t_{0}$ 后, 我们只需要计算如下的概率即可  \n$$\np=P_{\\theta_{0}}\\left|\\sum x_{i} \\geqslant c\\right|\n$$  \n这就是检验的 $p$ 值. 譬如, $n=40, \\theta_{0}=0.1, t_{0}=8$, 则  \n$$\np=1-0.9^{40}-\\left(\\begin{array}{c}\n40 \\\\\n1\n\\end{array}\\right) 0.1 \\times 0.9^{39}-\\cdots-\\left(\\begin{array}{c}",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.4 检验的 $p$ 值"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\np=P_{\\theta_{0}}\\left|\\sum x_{i} \\geqslant c\\right|\n$$  \n这就是检验的 $p$ 值. 譬如, $n=40, \\theta_{0}=0.1, t_{0}=8$, 则  \n$$\np=1-0.9^{40}-\\left(\\begin{array}{c}\n40 \\\\\n1\n\\end{array}\\right) 0.1 \\times 0.9^{39}-\\cdots-\\left(\\begin{array}{c}\n40 \\\\\n7\n\\end{array}\\right) 0.1^{7} \\times 0.9^{33}=0.0419\n$$  \n于是, 若取 $\\alpha=0.05$, 由于 $p<\\alpha$, 则应拒绝原假设.  \n对双边假设检验, 同样可以计算检验的 $p$ 值, 下面以一个例子加以说明.  \n例 7.3.7: 某工厂两位化验员甲、乙分别独立地用相同方法对某种聚合物的含氯量进行测定. 甲测 9 次, 样本方差为 0.7292 ; 乙测 11 次, 样本方差为 0.2114 . 假定测量数据服从正态分布, 试对两总体方差作一致性检验.  \n解: 这是 7.2.3 节中关于二个正态总体的方差相等的检验, 待检验的假设是  \n$$\nH_{0}: \\sigma_{\\text {甲 }}^{2}=\\sigma_{\\text {乙 }}^{2}, \\quad \\text { vs } \\quad H_{1}: \\sigma_{F}^{2} \\neq \\sigma_{Z}^{2}\n$$  \n!  \n$$\nW=\\left\\{F \\geqslant F_{1-\\alpha / 2}(8,10) \\text { 或 } F \\leqslant F_{a / 2}(8,10)\\right\\}\n$$  \n如今我们不是把拒绝域具体化, 而是由观测值算得 $F=0.7292 / 0.2114=3.4494$, 再去计算该检验的 $p$ 值.  \n在这种双侧检验情况下, 如何由观测值 $F=3.4494$ 算得 $p$ 值呢?\n首先,我们用 $F$ 分布算得  \n$$\nP(F \\geqslant 3.4494)=0.0354 .\n$$",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.4 检验的 $p$ 值"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 这是 7.2.3 节中关于二个正态总体的方差相等的检验, 待检验的假设是  \n$$\nH_{0}: \\sigma_{\\text {甲 }}^{2}=\\sigma_{\\text {乙 }}^{2}, \\quad \\text { vs } \\quad H_{1}: \\sigma_{F}^{2} \\neq \\sigma_{Z}^{2}\n$$  \n!  \n$$\nW=\\left\\{F \\geqslant F_{1-\\alpha / 2}(8,10) \\text { 或 } F \\leqslant F_{a / 2}(8,10)\\right\\}\n$$  \n如今我们不是把拒绝域具体化, 而是由观测值算得 $F=0.7292 / 0.2114=3.4494$, 再去计算该检验的 $p$ 值.  \n在这种双侧检验情况下, 如何由观测值 $F=3.4494$ 算得 $p$ 值呢?\n首先,我们用 $F$ 分布算得  \n$$\nP(F \\geqslant 3.4494)=0.0354 .\n$$  \n其次考虑到双侧检验的拒绝域 $\\mathrm{W}$ 分散在两端, 且两端尾部概率相等 (见图 7.3.2), 据此可定出 $p$值为  \n$$\np=2 P(F \\geqslant 3.4494)=0.0708\n$$  \n!  \n图 7.3.2: 观测值 $F=3.4494$ 对应的 $p$ 值由两端尾部概率之和确定  \n此 $p$ 值不算很小, 若心目中的 $\\alpha=0.05$, 则接受两方差相等的假设.",
        "metadata": {
            "Header 2": "7.3 其他分布参数的假设检验",
            "Header 3": "7.3.4 检验的 $p$ 值"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 从一批服从指数分布的产品中抽取 10 个进行寿命试验, 观测值如下 (单位:h ):  \n$$\n\\begin{array}{llllllllll}\n1643 & 1629 & 426 & 132 & 1522 & 432 & 1759 & 1074 & 528 & 283\n\\end{array}\n$$  \n根据这批数据能否认为其平均寿命不低于 $1100 \\mathrm{~h}$ ? (取 $(\\alpha=0.05)$  \n2. 某厂一种元件平均使用寿命为 $1200 \\mathrm{~h}$, 偏低, 现厂里进行技术革新, 革新后任选 8 个元件进行寿命试验, 测得寿命数据如下:  \n$$\n\\begin{array}{llllllll}\n2686 & 2001 & 2082 & 792 & 1660 & 4105 & 1416 & 2089\n\\end{array}\n$$  \n假定元件寿命服从指数分布, 取 $(\\alpha=0.05)$, 问革新后元件的平均寿命是否有明显提高?  \n3. 有人称某地成年人中大学毕业生比例不低于 $30 \\%$, 为检验之, 随机调查该地 15 名成年人, 发现有 3 名大学毕业生, 取 $\\alpha=0.05$, 问该人看法是否成立? 并给出检验的 $p$ 值.\n4. 某大学随机调查 120 名男同学, 发现有 50 人非常喜欢看武侠小说, 而随机调查的 85 名女同学中有 23 人喜欢, 用大样本检验方法在 $\\alpha=0.05$ 下确认: 男女同学在喜爱武侠小说方面有无显著差异? 并给出检验的 $p$ 值.\n5. 假定电话总机在单位时间内接到的呼叫次数服从泊松分布, 现观测了 40 个单位时间, 接到的呼叫次数如下:  \n$$\n\\begin{array}{llllllllllllllllllll}\n0 & 2 & 3 & 2 & 3 & 2 & 1 & 0 & 2 & 2 & 1 & 2 & 2 & 1 & 3 & 1 & 1 & 4 & 1 & 1 \\\\\n5 & 1 & 2 & 2 & 3 & 3 & 1 & 3 & 1 & 3 & 4 & 0 & 6 & 1 & 1 & 1 & 4 & 0 & 1 & 3\n\\end{array}\n$$",
        "metadata": {
            "Header 2": "如习题 7.3"
        },
        "type": "Document"
    },
    {
        "page_content": "4. 某大学随机调查 120 名男同学, 发现有 50 人非常喜欢看武侠小说, 而随机调查的 85 名女同学中有 23 人喜欢, 用大样本检验方法在 $\\alpha=0.05$ 下确认: 男女同学在喜爱武侠小说方面有无显著差异? 并给出检验的 $p$ 值.\n5. 假定电话总机在单位时间内接到的呼叫次数服从泊松分布, 现观测了 40 个单位时间, 接到的呼叫次数如下:  \n$$\n\\begin{array}{llllllllllllllllllll}\n0 & 2 & 3 & 2 & 3 & 2 & 1 & 0 & 2 & 2 & 1 & 2 & 2 & 1 & 3 & 1 & 1 & 4 & 1 & 1 \\\\\n5 & 1 & 2 & 2 & 3 & 3 & 1 & 3 & 1 & 3 & 4 & 0 & 6 & 1 & 1 & 1 & 4 & 0 & 1 & 3\n\\end{array}\n$$  \n在显著性水平 0.05 下能否认为单位时间内平均呼叫次数不低于 2.5 次? 并给出检验的 $p$ 值.  \n6. 通常每平方米某种布上的疵点数服从泊松分布, 现观测该种布 $100 \\mathrm{~m}^{2}$, 发现有 126 个疵点, 在显著性水平为 0.05 下能否认为该种布每平方分米土平均疵点数不超过 1 个? 并给出检验的 $p$ 值.",
        "metadata": {
            "Header 2": "如习题 7.3"
        },
        "type": "Document"
    },
    {
        "page_content": "在前面我们讨论的检验问题都是在总体分布形式已知的前提下对分布的参数建立假设并进行检验, 它们都属于参数假设检验问题. 下面我们对总体分布的形式建立假设并进行检验. 这一类检验问题统称为分布的拟合检验, 它们是一类非参数检验问题.",
        "metadata": {
            "Header 2": "7.4 分布拟合检验"
        },
        "type": "Document"
    },
    {
        "page_content": "设总体 $X$ 可以分成 $k$ 类,记为 $A_{1}, \\cdots, A_{k}$, 现对该总体做了 $n$ 次观测, $k$ 个类出现的频数分别为 $n_{1}, \\cdots, n_{k}$, 且 $\\sum_{i=1}^{k} n_{i}=n$. 如今要检验的假设为  \n$$\n\\begin{equation*}\nH_{0}: P\\left(A_{i}\\right)=p_{i}, \\quad i=1,2, \\cdots, k \\tag{7.4.1}\n\\end{equation*}\n$$  \n其中诸 $p_{1} \\geqslant 0$, 且且 $\\sum_{i=1}^{k} p_{i}=1$. 其备择假设是 (7.4.1) 中的诸等式不全成立, 在实际中, 此种备择假设可以省略不写. 下面我们分两种情况讨论 (7.4.1) 的检验问题.  \n一、诸 $p_{i}$ 均已知  \n如果 $H_{0}$ 成立, 则对每一类 $A_{i}$, 其频率 $n_{i} / n$ 与概率 $p_{i}$ 应较接近. 或者说, 观测频数 $n_{i}$ 与理论频数 $n p_{i}$ 应相差不大. 据此, 英国统计学家 K.Pearson 提出如下检验统计量  \n$$\n\\begin{equation*}\n\\chi^{2}=\\sum_{i=1}^{k} \\frac{\\left(n_{i}-n p_{i}\\right)^{2}}{n p_{i}} \\tag{7.4.2}\n\\end{equation*}\n$$  \n并证明在 $H_{0}$ 成立时对充分大的 $n$, (7.4.2) 给出的检验统计量 $\\chi^{2}$ 近似服从自由度为 $k-1$ 的 $\\chi^{2}$ 分布. 由于统计量 $\\chi^{2}$ 度量的是观测频数 $n_{i}$ 与理论频数 $n p$; 的偏离程度, $\\chi^{2}$ 值大, 表示偏离程度大, 偏离程度越大越倾向于拒绝原假设 $H_{0}$. 因此, 对给定的显著性水平 $\\alpha(0<\\alpha<1)$, 该检验的拒绝域应为  \n$$\n\\begin{equation*}\nW=\\left\\{\\chi^{2} \\geqslant \\chi_{1-\\alpha}^{2}(k-1)\\right\\} \\tag{7.4.3}",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n\\chi^{2}=\\sum_{i=1}^{k} \\frac{\\left(n_{i}-n p_{i}\\right)^{2}}{n p_{i}} \\tag{7.4.2}\n\\end{equation*}\n$$  \n并证明在 $H_{0}$ 成立时对充分大的 $n$, (7.4.2) 给出的检验统计量 $\\chi^{2}$ 近似服从自由度为 $k-1$ 的 $\\chi^{2}$ 分布. 由于统计量 $\\chi^{2}$ 度量的是观测频数 $n_{i}$ 与理论频数 $n p$; 的偏离程度, $\\chi^{2}$ 值大, 表示偏离程度大, 偏离程度越大越倾向于拒绝原假设 $H_{0}$. 因此, 对给定的显著性水平 $\\alpha(0<\\alpha<1)$, 该检验的拒绝域应为  \n$$\n\\begin{equation*}\nW=\\left\\{\\chi^{2} \\geqslant \\chi_{1-\\alpha}^{2}(k-1)\\right\\} \\tag{7.4.3}\n\\end{equation*}\n$$  \n例 7.4.1: 为募集社会福利基金, 某地方政府发行福利彩票, 中彩者用摇大转盘的方法确定最后中奖金额. 大转盘均分为 20 份, 其中金额为 5 万、 10 万、 20 万、 30 万、 50 万、 100 万的分别占 2 份、 4 份、 6 份、 4 份、 2 份、 2 份, 假定大转盘是均匀的, 则每一点朝下是等可能的, 于是摇出各个奖项的概率如下:  \n| 额度 | 5 万 | 10 万 | 20 万 | 30 万 | 50 万 | 100 <br> 万 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 概率 | 0.1 | 0.2 | 0.3 | 0.2 | 0.1 | 0.1 |  \n现 20 人参加摇奖, 摇得 5 万、 10 万、 20 万、 30 万、 50 万和 100 万的人数分别为 $2 、 6 、 6 、 3 、 3 、 0$,由于没有一个人摇到 100 万, 于是有人怀疑大转盘是不均匀的, 那么该怀疑是否成立呢? 这就需要对转盘的均匀性做检验.",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n例 7.4.1: 为募集社会福利基金, 某地方政府发行福利彩票, 中彩者用摇大转盘的方法确定最后中奖金额. 大转盘均分为 20 份, 其中金额为 5 万、 10 万、 20 万、 30 万、 50 万、 100 万的分别占 2 份、 4 份、 6 份、 4 份、 2 份、 2 份, 假定大转盘是均匀的, 则每一点朝下是等可能的, 于是摇出各个奖项的概率如下:  \n| 额度 | 5 万 | 10 万 | 20 万 | 30 万 | 50 万 | 100 <br> 万 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 概率 | 0.1 | 0.2 | 0.3 | 0.2 | 0.1 | 0.1 |  \n现 20 人参加摇奖, 摇得 5 万、 10 万、 20 万、 30 万、 50 万和 100 万的人数分别为 $2 、 6 、 6 、 3 、 3 、 0$,由于没有一个人摇到 100 万, 于是有人怀疑大转盘是不均匀的, 那么该怀疑是否成立呢? 这就需要对转盘的均匀性做检验.  \n解: 这是一个典型的分布拟合优度检验, 总体共有 6 类, 其发生概率分别为 $0.1 、 0.2 、 0.3 、 0.2 、 0.1$ 和 0.1 . 这里 $k=6$, 检验拒绝域为 $\\left\\{x^{2} \\geqslant x_{1-a}^{2}(5)\\right\\}$, 若取 $\\alpha=0.05$, 则查附表 3 知 $\\chi_{0.95}^{2}(5)=11.07$. 由本例数据, 依 (7.4.2) 可以算出  \n$$\nx^{2}=\\frac{(2-2)^{2}}{2}+\\frac{(6-4)^{2}}{4}+\\frac{(6-6)^{2}}{6}+\\frac{(3-4)^{2}}{4}+\\frac{(3-2)^{2}}{2}+\\frac{(0-2)^{2}}{2}=3.75\n$$  \n由于 $x^{2}=3.75$ 未落人拒绝域, 故接受原假设, 没有理由认为转盘不均匀. 在分布拟合检验中使用\n$p$ 值也是方便的. 本例中,以 $T$ 记服从 $x^{5}$ 的随机变量,则使用统计软件可以算出  \n$$\np=P(T \\geqslant 3.75)=0.5859\n$$",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nx^{2}=\\frac{(2-2)^{2}}{2}+\\frac{(6-4)^{2}}{4}+\\frac{(6-6)^{2}}{6}+\\frac{(3-4)^{2}}{4}+\\frac{(3-2)^{2}}{2}+\\frac{(0-2)^{2}}{2}=3.75\n$$  \n由于 $x^{2}=3.75$ 未落人拒绝域, 故接受原假设, 没有理由认为转盘不均匀. 在分布拟合检验中使用\n$p$ 值也是方便的. 本例中,以 $T$ 记服从 $x^{5}$ 的随机变量,则使用统计软件可以算出  \n$$\np=P(T \\geqslant 3.75)=0.5859\n$$  \n这个 $p$ 值就反映了数据与假设的分布拟合程度的高低, $p$ 值越大, 拟合越好.  \n二。诸 $p_{i}$ 不完全已知  \n此种情况下最常见的情形是诸 $p_{I}, i=1, \\cdots, k$ 可由 $r(r<k)$ 个未知参数 $\\theta_{1}, \\cdots, \\theta_{r}$ 确定,即  \n$$\np_{i}=p_{i}\\left(\\theta_{1}, \\cdot, \\theta_{r}\\right), i=1, \\cdots, k .\n$$  \n为对假设 (7.4.1) 做检验, 首先由样本给出 $\\theta_{1}, \\cdots, \\theta_{r}$ 的最大似然估计 $\\hat{\\theta}_{1}, \\cdots, \\hat{\\theta}_{r}$, 然后给出诸 $p_{i}, i=1, \\cdots, k$ 的最大似然估计 $\\hat{p}_{i}=p_{i}\\left(\\hat{\\theta}_{1}, \\cdots, \\hat{\\theta}_{r}\\right)$. Fisher 证明了如下统计量  \n$$\n\\begin{equation*}\n\\chi^{2}=\\sum_{i=1}^{k} \\frac{\\left(n_{i}-n \\hat{p}_{i}\\right)^{2}}{n \\hat{p}_{i}} \\tag{7.4.4}\n\\end{equation*}\n$$  \n在 $H_{0}$ 成立时近似服从自由度为 $k-r-1$ 的 $\\chi^{2}$ 分布,于是检验拒绝域为  \n$$",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n为对假设 (7.4.1) 做检验, 首先由样本给出 $\\theta_{1}, \\cdots, \\theta_{r}$ 的最大似然估计 $\\hat{\\theta}_{1}, \\cdots, \\hat{\\theta}_{r}$, 然后给出诸 $p_{i}, i=1, \\cdots, k$ 的最大似然估计 $\\hat{p}_{i}=p_{i}\\left(\\hat{\\theta}_{1}, \\cdots, \\hat{\\theta}_{r}\\right)$. Fisher 证明了如下统计量  \n$$\n\\begin{equation*}\n\\chi^{2}=\\sum_{i=1}^{k} \\frac{\\left(n_{i}-n \\hat{p}_{i}\\right)^{2}}{n \\hat{p}_{i}} \\tag{7.4.4}\n\\end{equation*}\n$$  \n在 $H_{0}$ 成立时近似服从自由度为 $k-r-1$ 的 $\\chi^{2}$ 分布,于是检验拒绝域为  \n$$\n\\left\\{\\chi^{2} \\geqslant \\chi_{1-\\alpha}^{2}(k-r-1)\\right\\} .\n$$  \n例 7.4.2: 卢琴福在 2608 个等时间间隔内观测一枚放射性物质放射的粒子数 $X$, 表 7.4 .1 是观测结果的汇总, 其中 $n_{i}$ 表示 2608 次观测中放射粒子数为 $i$ 的次数. 试利用该组数据检验该放射物质在  \n表 7.4.1: 例 7.4.2 中的观测结果  \n| $i$ | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $n_{i}$ | 57 | 203 | 383 | 525 | 532 | 408 | 273 | 139 | 45 | 27 | 10 | 6 |  \n单位时间内放射出的粒子数是否服从泊松分布.",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\left\\{\\chi^{2} \\geqslant \\chi_{1-\\alpha}^{2}(k-r-1)\\right\\} .\n$$  \n例 7.4.2: 卢琴福在 2608 个等时间间隔内观测一枚放射性物质放射的粒子数 $X$, 表 7.4 .1 是观测结果的汇总, 其中 $n_{i}$ 表示 2608 次观测中放射粒子数为 $i$ 的次数. 试利用该组数据检验该放射物质在  \n表 7.4.1: 例 7.4.2 中的观测结果  \n| $i$ | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $n_{i}$ | 57 | 203 | 383 | 525 | 532 | 408 | 273 | 139 | 45 | 27 | 10 | 6 |  \n单位时间内放射出的粒子数是否服从泊松分布.  \n解: 本例中, 要检验总体是否服从泊松分布. 大家知道服从泊松分布的随机变量可取所有非负整数值. 虽然如此, 它取大数值的概率都非常小, 可以忽略不计. 另一方面, 对该随机变量进行观测时,也只能观测到有限个不同的值. 譬如, 本例中只观测到 $0,1, \\cdots, 11$ 共 12 个不同取值, 这相当于把总体分成 12 类. 在原假设下, 每类出现的概率为  \n$$\np_{i}=\\frac{\\lambda^{i}}{i !} \\mathrm{e}^{-\\lambda}, \\quad i=0,1, \\cdots, 10, \\quad p_{11}=\\sum_{i=11}^{\\infty} \\frac{\\lambda^{i}}{i !} \\mathrm{e}^{-\\lambda},\n$$  \n这里有一个未知参数 $\\lambda$,采用最大似然估计,  \n$$\n\\hat{\\lambda}=\\frac{1}{2608}(1 \\times 203+2 \\times 383+\\cdots+11 \\times 6)=3.870\n$$",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "单位时间内放射出的粒子数是否服从泊松分布.  \n解: 本例中, 要检验总体是否服从泊松分布. 大家知道服从泊松分布的随机变量可取所有非负整数值. 虽然如此, 它取大数值的概率都非常小, 可以忽略不计. 另一方面, 对该随机变量进行观测时,也只能观测到有限个不同的值. 譬如, 本例中只观测到 $0,1, \\cdots, 11$ 共 12 个不同取值, 这相当于把总体分成 12 类. 在原假设下, 每类出现的概率为  \n$$\np_{i}=\\frac{\\lambda^{i}}{i !} \\mathrm{e}^{-\\lambda}, \\quad i=0,1, \\cdots, 10, \\quad p_{11}=\\sum_{i=11}^{\\infty} \\frac{\\lambda^{i}}{i !} \\mathrm{e}^{-\\lambda},\n$$  \n这里有一个未知参数 $\\lambda$,采用最大似然估计,  \n$$\n\\hat{\\lambda}=\\frac{1}{2608}(1 \\times 203+2 \\times 383+\\cdots+11 \\times 6)=3.870\n$$  \n将 $\\hat{\\lambda}$ 代人可以估计出诸 $\\hat{p}_{i}$. 于是可计算出 (7.4.4) 式的 $\\chi^{2}$, 这个计算过程见表 7.4.2. 若取 $\\alpha=0.05$,则 $\\chi_{1-\\alpha}^{2}(k-r-1)=\\chi_{0.95}^{2}(10)=18.307$, 本例中 $\\chi^{2}=12.8967>18.307$, 故接受原假设. 使用统计软件可以计算出此处检验的 $p$ 值是 0.2295 .  \n| 性别 | 视觉 |  |\n| :---: | :---: | :---: |\n|  | 正常 | 色盲 |\n| 男 | 535 | 65 |\n| 女 | 382 | 18 |",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n这里有一个未知参数 $\\lambda$,采用最大似然估计,  \n$$\n\\hat{\\lambda}=\\frac{1}{2608}(1 \\times 203+2 \\times 383+\\cdots+11 \\times 6)=3.870\n$$  \n将 $\\hat{\\lambda}$ 代人可以估计出诸 $\\hat{p}_{i}$. 于是可计算出 (7.4.4) 式的 $\\chi^{2}$, 这个计算过程见表 7.4.2. 若取 $\\alpha=0.05$,则 $\\chi_{1-\\alpha}^{2}(k-r-1)=\\chi_{0.95}^{2}(10)=18.307$, 本例中 $\\chi^{2}=12.8967>18.307$, 故接受原假设. 使用统计软件可以计算出此处检验的 $p$ 值是 0.2295 .  \n| 性别 | 视觉 |  |\n| :---: | :---: | :---: |\n|  | 正常 | 色盲 |\n| 男 | 535 | 65 |\n| 女 | 382 | 18 |  \n一般, 若总体中的个体可按两个属性 $A$ 与 $B$ 分类, $A$ 有 $r$ 个类 $A_{1}, \\cdots, A_{r}, B$ 有 $c$ 个类 $B_{1}, \\cdots, B_{C}$, 从总体中抽取大小为 $n$ 的样本, 设其中有 $n_{i j}$ 个个体既属于类 $A_{i}$ 又属于类 $B_{j}, n_{i j}$ 称为频数,将 $r \\times c$ 个 $n_{i j}$ 排列为一个 $r$ 行 $c$ 列的二维列联表,简称 $t \\times c$ 表 (表 7.4.3).\n表 7.4.2: 例 7.4.2 的计算表  \n| $i$ | $n_{i}$ | $\\hat{p}_{i}$ | $h \\hat{p}_{i}$ | $\\left(n_{i}-n \\hat{p}_{i}\\right)^{2} / n \\hat{p}_{i}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 57 | 0.0209 | 54.5 | 0.1147 |\n| 1 | 203 | 0.0807 | 210.5 | 0.2672 |",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "表 7.4.2: 例 7.4.2 的计算表  \n| $i$ | $n_{i}$ | $\\hat{p}_{i}$ | $h \\hat{p}_{i}$ | $\\left(n_{i}-n \\hat{p}_{i}\\right)^{2} / n \\hat{p}_{i}$ |\n| :---: | :---: | :---: | :---: | :---: |\n| 0 | 57 | 0.0209 | 54.5 | 0.1147 |\n| 1 | 203 | 0.0807 | 210.5 | 0.2672 |\n| 2 | 383 | 0.1562 | 407.4 | 1.4614 |\n| 3 | 525 | 0.2015 | 525.5 | 0.0005 |\n| 4 | 532 | 0.1950 | 508.6 | 1.0766 |\n| 5 | 408 | 0.1509 | 393.5 | 0.5343 |\n| 6 | 273 | 0.0973 | 253.8 | 1.4525 |\n| 7 | 139 | 0.0538 | 140.3 | 0.0120 |\n| 8 | 45 | 0.0260 | 67.8 | 7.6673 |\n| 9 | 27 | 0.0112 | 29.2 | 0.1658 |\n| 10 | 10 | 0.0043 | 11.2 | 0.1258 |\n| 11 | 6 | 0.0022 | 5.7 | 0.0158 |\n| 合计 | 2608 | 1.0000 | 2068 | $\\chi^{2}=12.8967$ |  \n表 7.4.3: $r \\times c$ 列联表  \n| $A \\backslash B$ | 1 | $\\cdots$ | $j$ | $\\cdots$ | $c$ | 和 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | $n_{11}$ | $\\cdots$ | $n_{1 j}$ | $\\cdots$ | $n_{1 c}$ | $n_{1}$ |\n| $\\vdots$ | $\\vdots$ |  | $\\vdots$ |  | $\\vdots$ | $\\vdots$ |",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "| 8 | 45 | 0.0260 | 67.8 | 7.6673 |\n| 9 | 27 | 0.0112 | 29.2 | 0.1658 |\n| 10 | 10 | 0.0043 | 11.2 | 0.1258 |\n| 11 | 6 | 0.0022 | 5.7 | 0.0158 |\n| 合计 | 2608 | 1.0000 | 2068 | $\\chi^{2}=12.8967$ |  \n表 7.4.3: $r \\times c$ 列联表  \n| $A \\backslash B$ | 1 | $\\cdots$ | $j$ | $\\cdots$ | $c$ | 和 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | $n_{11}$ | $\\cdots$ | $n_{1 j}$ | $\\cdots$ | $n_{1 c}$ | $n_{1}$ |\n| $\\vdots$ | $\\vdots$ |  | $\\vdots$ |  | $\\vdots$ | $\\vdots$ |\n| $i$ | $n_{i 1}$ | $\\cdots$ | $n_{i j}$ | $\\cdots$ | $n_{i c}$ | $n_{i}$ |\n| $\\vdots$ | $\\vdots$ |  | $\\vdots$ |  | $\\vdots$ | $\\vdots$ |\n| $r$ | $n_{r 1}$ | $\\cdots$ | $n_{r j}$ | $\\cdots$ | $n_{r c}$ | $n_{r}$ |\n| 和 | $n_{\\cdot 1}$ | $\\cdots$ | $n_{\\cdot j}$ | $\\cdots$ | $n_{\\cdot c}$ | $n$ |",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.1 总体分布只取有限个值的情况"
        },
        "type": "Document"
    },
    {
        "page_content": "列联表是将观测数据按两个或更多属性 (定性变量) 分类时所列出的频数表. 例如, 对随机抽取的 1000 人按性别 (男或女) 及色觉 (正常或色育) 两个属性分类, 得到如下二维列联表, 又称 $2 \\times 2$ 表或四格表.  \n若所考虑的属性多于两个,也可按类似的方式作出列联表, 称为多维列联表. 本节只限于讨论二维列联表, 列联表分析在应用统计, 特别在医学、生物学及社会科学中, 有着广泛的应用.  \n列联表分析的基本问题是, 考察各属性之间有无关联, 即判别二属性是否独立. 如在前例中,问题是: 一个人是否色育与其性别是否有关? 在 $r \\times c$ 表中, 若以 $p_{i \\cdot,} p_{\\cdot j}$ 和 $p_{i j}$ 分别表示总体中的个体仅属于 $A_{i}$, 仅属于 $B_{j}$ 和同时属于 $A_{i}$ 与 $B_{j}$ 的概率, 可得一个二维离散分布表 (表 7.4.4), 则 “ $A 、 B$ 两属性独立”的假设可以表述为  \n$$\nH_{0}: p_{i j}=p_{i \\cdot p} p_{\\cdot j}, \\quad i=1, \\cdots, r, j=1, \\cdots, c .\n$$  \n表 7.4.4: 二维离散分布表  \n| $A \\backslash B$ | 1 | $\\cdots$ | $j$ | $\\cdots$ | $c$ | 行和 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | $p_{11}$ | $\\cdots$ | $p_{1 j}$ | $\\cdots$ | $p_{1 c}$ | $p_{1 \\cdot}$ |\n| $\\vdots$ | $\\vdots$ |  | $\\vdots$ |  | $\\vdots$ | $\\vdots$ |\n| $i$ | $p_{i 1}$ | $\\cdots$ | $p_{i j}$ | $\\cdots$ | $p_{i c}$ | $p_{i \\cdot}$ |\n| $\\vdots$ | $\\vdots$ |  | $\\vdots$ |  | $\\vdots$ | $\\vdots$ |",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.2 列联表的独立性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n表 7.4.4: 二维离散分布表  \n| $A \\backslash B$ | 1 | $\\cdots$ | $j$ | $\\cdots$ | $c$ | 行和 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | $p_{11}$ | $\\cdots$ | $p_{1 j}$ | $\\cdots$ | $p_{1 c}$ | $p_{1 \\cdot}$ |\n| $\\vdots$ | $\\vdots$ |  | $\\vdots$ |  | $\\vdots$ | $\\vdots$ |\n| $i$ | $p_{i 1}$ | $\\cdots$ | $p_{i j}$ | $\\cdots$ | $p_{i c}$ | $p_{i \\cdot}$ |\n| $\\vdots$ | $\\vdots$ |  | $\\vdots$ |  | $\\vdots$ | $\\vdots$ |\n| $r$ | $p_{r 1}$ | $\\cdots$ | $p_{r j}$ | $\\cdots$ | $p_{r c}$ | $p_{r} \\cdot$ |\n| 和 | $p_{\\cdot 1}$ | $\\cdots$ | $p_{\\cdot j}$ | $\\cdots$ | $p_{\\cdot c}$ | 1 |  \n这就变为上一小节中诸 $p_{i j}$ 的不完全已知时的分布拟合检验. 这里诸 $p_{i j}$ 共有 $r c$ 个参数, 在\n原假设 $H_{0}$ 成立时, 这 $r c$ 个参数 $p_{i j}$ 由 $r+c$ 个参数 $p_{1}, \\cdots, p_{r}$ 和 $p_{\\cdot 1}, \\cdots, p_{\\cdot c}$ 决定. 在这后 $r+c$个参数中存在两个约束提哦啊见: $\\sum_{i=1}^{r} p_{i}=1, \\sum_{j=1}^{c} p_{\\cdot j}=1$, 所以, 此时 $p_{i j}$ 实际上由 $r+c-2$个独立参数所确定. 据此, 检验统计量为  \n$$",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.2 列联表的独立性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| $r$ | $p_{r 1}$ | $\\cdots$ | $p_{r j}$ | $\\cdots$ | $p_{r c}$ | $p_{r} \\cdot$ |\n| 和 | $p_{\\cdot 1}$ | $\\cdots$ | $p_{\\cdot j}$ | $\\cdots$ | $p_{\\cdot c}$ | 1 |  \n这就变为上一小节中诸 $p_{i j}$ 的不完全已知时的分布拟合检验. 这里诸 $p_{i j}$ 共有 $r c$ 个参数, 在\n原假设 $H_{0}$ 成立时, 这 $r c$ 个参数 $p_{i j}$ 由 $r+c$ 个参数 $p_{1}, \\cdots, p_{r}$ 和 $p_{\\cdot 1}, \\cdots, p_{\\cdot c}$ 决定. 在这后 $r+c$个参数中存在两个约束提哦啊见: $\\sum_{i=1}^{r} p_{i}=1, \\sum_{j=1}^{c} p_{\\cdot j}=1$, 所以, 此时 $p_{i j}$ 实际上由 $r+c-2$个独立参数所确定. 据此, 检验统计量为  \n$$\n\\chi^{2}=\\sum_{i=1}^{r} \\sum_{j=1}^{c} \\frac{\\left(n_{i j}-n \\hat{p}_{i j}\\right)^{2}}{n \\hat{p}_{i j}}\n$$  \n在原假设 $H-0$ 成立时上式近似服从自由度为 $r c-(r+c-2)-1=(r-1)(c-1)$ 的 $\\chi^{2}$ 分布. 其中诸 $\\hat{p}_{i j}$ 是在 $H_{0}$ 成立下得到的 $p_{i j}$ 的最大似然估计,其表达式为  \n$$\n\\hat{p}_{i j}=\\hat{p}_{i \\cdot \\hat{p}_{\\cdot j}}=\\frac{n_{i} \\cdot}{n} \\cdot \\frac{n_{\\cdot j}}{n},\n$$  \n对给定的显著性水平 $\\alpha(0<\\alpha<1)$, 检验的拒绝域为 $W=\\left\\{\\chi^{2} \\geqslant \\chi_{1-\\alpha}^{2}((r-1)(c-1))\\right\\}$.",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.2 列联表的独立性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\chi^{2}=\\sum_{i=1}^{r} \\sum_{j=1}^{c} \\frac{\\left(n_{i j}-n \\hat{p}_{i j}\\right)^{2}}{n \\hat{p}_{i j}}\n$$  \n在原假设 $H-0$ 成立时上式近似服从自由度为 $r c-(r+c-2)-1=(r-1)(c-1)$ 的 $\\chi^{2}$ 分布. 其中诸 $\\hat{p}_{i j}$ 是在 $H_{0}$ 成立下得到的 $p_{i j}$ 的最大似然估计,其表达式为  \n$$\n\\hat{p}_{i j}=\\hat{p}_{i \\cdot \\hat{p}_{\\cdot j}}=\\frac{n_{i} \\cdot}{n} \\cdot \\frac{n_{\\cdot j}}{n},\n$$  \n对给定的显著性水平 $\\alpha(0<\\alpha<1)$, 检验的拒绝域为 $W=\\left\\{\\chi^{2} \\geqslant \\chi_{1-\\alpha}^{2}((r-1)(c-1))\\right\\}$.  \n例 7.4.3: 为研究儿童智力发展与营养的关系, 某研究机构调查了 1436 名儿童, 得到如表 7.4.5 的数据,试在显著性水平 0.05 下判断智力发展与营养有无关系.  \n表 7.4.5: 儿意智力与营养的调查数据  \n|  | 智商 |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  | $<80$ | $80 \\sim 89$ | $90 \\sim 99$ | $\\geqslant 100$ | 合计 |\n| 营养良好 | 367 | 342 | 266 | 329 | 1304 |\n| 营养不良 | 56 | 40 | 20 | 16 | 132 |\n| 合计 | 423 | 382 | 826 | 345 | 1436 |",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.2 列联表的独立性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n对给定的显著性水平 $\\alpha(0<\\alpha<1)$, 检验的拒绝域为 $W=\\left\\{\\chi^{2} \\geqslant \\chi_{1-\\alpha}^{2}((r-1)(c-1))\\right\\}$.  \n例 7.4.3: 为研究儿童智力发展与营养的关系, 某研究机构调查了 1436 名儿童, 得到如表 7.4.5 的数据,试在显著性水平 0.05 下判断智力发展与营养有无关系.  \n表 7.4.5: 儿意智力与营养的调查数据  \n|  | 智商 |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  | $<80$ | $80 \\sim 89$ | $90 \\sim 99$ | $\\geqslant 100$ | 合计 |\n| 营养良好 | 367 | 342 | 266 | 329 | 1304 |\n| 营养不良 | 56 | 40 | 20 | 16 | 132 |\n| 合计 | 423 | 382 | 826 | 345 | 1436 |  \n解: 用 $A$ 表示营养状况, 它有两个水平: $A_{1}$ 表示营养良好, $A_{2}$ 表示营养不良; $B$ 表示儿童智商, 它有四个水平, $B_{1}, B_{2}, B_{3}, B_{4}$ 分别表示表中四种情况. 沿用前面的记号, 首先建立假设 $H_{0}$ : 营养状况与智商无关联, 即 $A$ 与 $B$ 是独立的. 统计表示如下:  \n$$\nH_{0}: p_{i j}=p_{i \\cdot p \\cdot j}, \\quad i=1,2, j=1,2,3,4 .\n$$  \n在原假设 $H_{0}$ 成立下, 我们可以计算诸参数的最大似然估计值,  \n$$\n\\begin{array}{ll}\n\\hat{p}_{1}=1304 / 1436=0.9801, & \\hat{p}_{2 \\cdot}=132 / 1436=0.0919, \\\\\n\\hat{p}_{\\cdot 1}=423 / 1436=0.2946, & \\hat{p}_{\\cdot 2}=382 / 1436=0.2660, \\\\",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.2 列联表的独立性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "解: 用 $A$ 表示营养状况, 它有两个水平: $A_{1}$ 表示营养良好, $A_{2}$ 表示营养不良; $B$ 表示儿童智商, 它有四个水平, $B_{1}, B_{2}, B_{3}, B_{4}$ 分别表示表中四种情况. 沿用前面的记号, 首先建立假设 $H_{0}$ : 营养状况与智商无关联, 即 $A$ 与 $B$ 是独立的. 统计表示如下:  \n$$\nH_{0}: p_{i j}=p_{i \\cdot p \\cdot j}, \\quad i=1,2, j=1,2,3,4 .\n$$  \n在原假设 $H_{0}$ 成立下, 我们可以计算诸参数的最大似然估计值,  \n$$\n\\begin{array}{ll}\n\\hat{p}_{1}=1304 / 1436=0.9801, & \\hat{p}_{2 \\cdot}=132 / 1436=0.0919, \\\\\n\\hat{p}_{\\cdot 1}=423 / 1436=0.2946, & \\hat{p}_{\\cdot 2}=382 / 1436=0.2660, \\\\\n\\hat{p}_{\\cdot 3}=286 / 1436=0.1992, & \\hat{p}_{\\cdot 4}=345 / 1436=0.2403,\n\\end{array}\n$$  \n进而可给出诸 $n \\hat{p}_{i j}=n \\hat{p}_{i \\cdot \\hat{p} \\cdot j}$, 如  \n$$\nn \\hat{p}_{11}=1436 \\times 0.9801 \\times 0.2496=384.1677\n$$  \n其他结果见表 7.4.6 由表 7.4.5 和表 7.4.6 可以计算检验统计量的值  \n表 7.4.6: 诸 $n \\hat{p}_{i j}$ 的计算结果  \n|  | $<80$ | $80 \\sim 89$ | $90 \\sim 99$ | $\\geqslant 100$ | $\\hat{p}_{i}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 营养良好 | 384.1677 | 346.8724 | 259.7631 | 313.3588 | 0.9801 |",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.2 列联表的独立性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\hat{p}_{\\cdot 3}=286 / 1436=0.1992, & \\hat{p}_{\\cdot 4}=345 / 1436=0.2403,\n\\end{array}\n$$  \n进而可给出诸 $n \\hat{p}_{i j}=n \\hat{p}_{i \\cdot \\hat{p} \\cdot j}$, 如  \n$$\nn \\hat{p}_{11}=1436 \\times 0.9801 \\times 0.2496=384.1677\n$$  \n其他结果见表 7.4.6 由表 7.4.5 和表 7.4.6 可以计算检验统计量的值  \n表 7.4.6: 诸 $n \\hat{p}_{i j}$ 的计算结果  \n|  | $<80$ | $80 \\sim 89$ | $90 \\sim 99$ | $\\geqslant 100$ | $\\hat{p}_{i}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 营养良好 | 384.1677 | 346.8724 | 259.7631 | 313.3588 | 0.9801 |\n| 营养不良 | 38.8779 | 35.1036 | 26.2881 | 31.7120 | 0.0919 |\n| $p \\cdot j$ | 0.2946 | 0.2660 | 0.1992 | 0.2403 |  |  \n$$\n\\begin{aligned}\n\\chi^{2} & =\\frac{(367-384.1677)^{2}}{384.1677}+\\frac{(342-346.8724)^{2}}{346.8724}+\\cdots+\\frac{(16-31.7120)^{2}}{31.7120} \\\\\n& =19.2785\n\\end{aligned}\n$$  \n此处 $r=2, c=4,(r-1)(c-1)=3$, 若取 $\\alpha=0.05$, 查表有 $\\chi_{0.95}^{2}=7.815$, 由于 $19.2785>7.815$,故拒绝原假设,认为营养状况对智商有影响. 本例中检验的 $p$ 值为 0.0002 .",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.2 列联表的独立性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "正态分布是最常用的分布, 用来判断总体分布是否为正态分布的检验方法称为正态性检验,它在实际问题中大量使用. 接下来我们先叙述简单而又直观的正态性检验——正态概率纸, 然后介绍一个国家标准 GB/T4882-2001 中推荐的、并已被广泛应用的正态性检验方法——夏皮洛-威尔克检验.  \n一、正泰概率纸  \n正态概率纸是一种特殊的坐标纸, 其横坐标是等间隔的, 纵坐标是按标准正态分布函数值给出的,见图 7.4.1.  \n!  \n图 7.4.1: 正态概率纸  \n正态概率纸可用来作正态性检验, 方法如下: 利用样本数据在概率纸上描点, 用目测方法看这些点是否在一条直线附近, 若是的话, 可以认为该数据来自的总体为正态分布, 若明显不在一条直线附近,则认为该数据来自非正态总体. 具体操作步骤见下面的例子.  \n例 7.4.4: 随机选取 10 个零件, 测得其直径与标准尺寸的偏差如下: (单位: 丝)  \n$$\n\\begin{array}{llllllllll}\n9.4 & 8.8 & 9.6 & 10.2 & 10.1 & 7.2 & 11.1 & 8.2 & 8.6 & 9.6 \\text {. }\n\\end{array}\n$$  \n在正态概率纸上作图步骤如下:  \n1. 首先将数据按从小到大的次序排列: $x_{(1)} \\leqslant x_{(2)} \\leqslant \\cdots \\leqslant x_{(n)}$, 具体数据为  \n$$\n\\begin{array}{lllllllll}\n7.2 & 8.2 & 8.6 & 9.4 & 9.6 & 9.8 & 10.1 & 10.2 & 11.1 .\n\\end{array}\n$$  \n2. 对每一个 $i$, 计算修正频率 $(i=0.375) /(n+0.25), i=1,2, \\cdots, n$, 结果见表 7.4.7.\n3. 将点 $\\left(x_{(i)},(i=0.375) /(n+0.25)\\right), i=1,2, \\cdots, n$ 逐一画在正态概率纸上 (图 7.4.2),\n4. 观察上述 $n$ 个点的分布,\n表 7.4.7: $x_{(i)}$ 取值及其修正概率",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.3 正态性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array}\n$$  \n在正态概率纸上作图步骤如下:  \n1. 首先将数据按从小到大的次序排列: $x_{(1)} \\leqslant x_{(2)} \\leqslant \\cdots \\leqslant x_{(n)}$, 具体数据为  \n$$\n\\begin{array}{lllllllll}\n7.2 & 8.2 & 8.6 & 9.4 & 9.6 & 9.8 & 10.1 & 10.2 & 11.1 .\n\\end{array}\n$$  \n2. 对每一个 $i$, 计算修正频率 $(i=0.375) /(n+0.25), i=1,2, \\cdots, n$, 结果见表 7.4.7.\n3. 将点 $\\left(x_{(i)},(i=0.375) /(n+0.25)\\right), i=1,2, \\cdots, n$ 逐一画在正态概率纸上 (图 7.4.2),\n4. 观察上述 $n$ 个点的分布,\n表 7.4.7: $x_{(i)}$ 取值及其修正概率  \n| $i$ | $x_{(i)}$ | $\\frac{i-0.375}{n+0.25}$ | $i$ | $x_{(i)}$ | $\\frac{i-0.375}{n+0.25}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 7.2 | 0.061 | 6 | 9.6 | 0.549 |\n| 2 | 8.2 | 0.159 | 7 | 9.8 | 0.646 |\n| 3 | 8.6 | 0.256 | 8 | 10.1 | 0.743 |\n| 4 | 8.8 | 0.354 | 9 | 10.2 | 0.841 |\n| 5 | 9.4 | 0.451 | 10 | 11.1 | 0.939 |  \n!  \n图 7.4.2: 例 7.4.4 的正态概率纸  \n- 若诸点在一条直线附近, 则认为该批数据来自正态总体;\n- 若诸点明显不在一条直线附近, 则认为该批数据的总体不是正态分布. 本例中, 从图 7.4.2 上可以看到, 10 个点基本在一条直线附近,故可认为直径与标准尺寸的偏差服从正态分布.",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.3 正态性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| $i$ | $x_{(i)}$ | $\\frac{i-0.375}{n+0.25}$ | $i$ | $x_{(i)}$ | $\\frac{i-0.375}{n+0.25}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 7.2 | 0.061 | 6 | 9.6 | 0.549 |\n| 2 | 8.2 | 0.159 | 7 | 9.8 | 0.646 |\n| 3 | 8.6 | 0.256 | 8 | 10.1 | 0.743 |\n| 4 | 8.8 | 0.354 | 9 | 10.2 | 0.841 |\n| 5 | 9.4 | 0.451 | 10 | 11.1 | 0.939 |  \n!  \n图 7.4.2: 例 7.4.4 的正态概率纸  \n- 若诸点在一条直线附近, 则认为该批数据来自正态总体;\n- 若诸点明显不在一条直线附近, 则认为该批数据的总体不是正态分布. 本例中, 从图 7.4.2 上可以看到, 10 个点基本在一条直线附近,故可认为直径与标准尺寸的偏差服从正态分布.  \n这里对 “修正频率” 作一点说明. 对应第 $i$ 个观测值 $x_{(i)}$ 的累计分布函数值 $F\\left(x_{(i)}\\right)=P(X \\leqslant$ $\\left.x_{(i)}\\right)$ 是一个概率, 可用频率作出估计, 即  \n$$\n\\hat{F}\\left(x_{(i)}\\right)=\\frac{\\text { 样本中小于等于 } x_{(i)} \\text { 的个数 }}{\\text { 样本量 }}=\\frac{i}{n} \\text {. }\n$$  \n这个频率有合理的一面, 但也有很大缺陷, 即当 $i=n$ 时该频率为 1 , 这意味着 $\\mathrm{x}$ 的取值最大为 $x_{(n)}$, 不可能再超过 $x_{(n)}$, 这往往与实际不符, 对此需要修正, 常见的有如下三个修正频率  \n$$",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.3 正态性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "- 若诸点明显不在一条直线附近, 则认为该批数据的总体不是正态分布. 本例中, 从图 7.4.2 上可以看到, 10 个点基本在一条直线附近,故可认为直径与标准尺寸的偏差服从正态分布.  \n这里对 “修正频率” 作一点说明. 对应第 $i$ 个观测值 $x_{(i)}$ 的累计分布函数值 $F\\left(x_{(i)}\\right)=P(X \\leqslant$ $\\left.x_{(i)}\\right)$ 是一个概率, 可用频率作出估计, 即  \n$$\n\\hat{F}\\left(x_{(i)}\\right)=\\frac{\\text { 样本中小于等于 } x_{(i)} \\text { 的个数 }}{\\text { 样本量 }}=\\frac{i}{n} \\text {. }\n$$  \n这个频率有合理的一面, 但也有很大缺陷, 即当 $i=n$ 时该频率为 1 , 这意味着 $\\mathrm{x}$ 的取值最大为 $x_{(n)}$, 不可能再超过 $x_{(n)}$, 这往往与实际不符, 对此需要修正, 常见的有如下三个修正频率  \n$$\n\\hat{F}\\left(x_{(i)}\\right)=\\frac{i}{n+1}, \\hat{F}\\left(x_{(i)}\\right)=\\frac{i-1 / 2}{n}, \\hat{F}\\left(x_{(i)}\\right)=\\frac{i-3 / 8}{n+1 / 4},\n$$  \n国际标准 GB/T4882-2001 推荐使用后者,但并不反对使用前两个. 本节中使用后者.  \n如果从正态概率纸上确认总体是非正态分布时, 可对原始数据进行变换后再在正态概率纸上描点, 若变换后的点在正态概率纸上近似在一条直线附近, 则可以认为变换后的数据来自正态分布, 这样的变换称为正态性变换. 常用的正态性变换有如下三个: 对数变换 $y=\\ln x$ 、倒数变换 $y=1 / x$ 和根号变换 $y=\\sqrt{x}$.  \n例 7.4.5: 随机抽取某种电子元件 10 个,测得其寿命数据如下：  \n$$\n\\begin{array}{lllllllll}\n110.47 & 99.16 & 97.04 & 2269.82 & 539.35 & 179.49 & 782.93 & 561.10 & 286.80 .",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.3 正态性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n国际标准 GB/T4882-2001 推荐使用后者,但并不反对使用前两个. 本节中使用后者.  \n如果从正态概率纸上确认总体是非正态分布时, 可对原始数据进行变换后再在正态概率纸上描点, 若变换后的点在正态概率纸上近似在一条直线附近, 则可以认为变换后的数据来自正态分布, 这样的变换称为正态性变换. 常用的正态性变换有如下三个: 对数变换 $y=\\ln x$ 、倒数变换 $y=1 / x$ 和根号变换 $y=\\sqrt{x}$.  \n例 7.4.5: 随机抽取某种电子元件 10 个,测得其寿命数据如下：  \n$$\n\\begin{array}{lllllllll}\n110.47 & 99.16 & 97.04 & 2269.82 & 539.35 & 179.49 & 782.93 & 561.10 & 286.80 .\n\\end{array}\n$$  \n图 7.4.3 给出这 10 个点在正态概率纸上的图形, 这 10 个点明显不在一条直线附近, 所以可认为该电子元件的寿命的分布不是正态分布. 对该 10 个寿命数据作对数变换, 结果见表 7.4.8.  \n利用表 7.4.8 中最后两列上的数据在正态概率纸上描点, 结果见图 7.4.4, 从图上可以看到 10 个点近似在一条直线附近, 说明对数变换后的数据可以看成来自正态分布. 这也意味着, 可认为原始数据服从对数正态分布.  \n!  \n图 7.4.3: 例 7.4.5 的正态概率纸  \n表 7.4.8: 对数变换后的数据  \n| $i$ | $x_{(i)}$ | $\\ln x_{(i)}$ | $\\frac{i-0.375}{n+0.25}$ | $i$ | $x_{(i)}$ | $\\ln x_{(i)}$ | $\\frac{i-0.375}{n+0.25}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 32.64 | 3.4849 | 0.061 | 6 | 286.80 | 5.6588 | 0.549 |\n| 2 | 97.04 | 4.5752 | 0.159 | 7 | 539.35 | 6.2904 | 0.646 |",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.3 正态性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "利用表 7.4.8 中最后两列上的数据在正态概率纸上描点, 结果见图 7.4.4, 从图上可以看到 10 个点近似在一条直线附近, 说明对数变换后的数据可以看成来自正态分布. 这也意味着, 可认为原始数据服从对数正态分布.  \n!  \n图 7.4.3: 例 7.4.5 的正态概率纸  \n表 7.4.8: 对数变换后的数据  \n| $i$ | $x_{(i)}$ | $\\ln x_{(i)}$ | $\\frac{i-0.375}{n+0.25}$ | $i$ | $x_{(i)}$ | $\\ln x_{(i)}$ | $\\frac{i-0.375}{n+0.25}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 32.64 | 3.4849 | 0.061 | 6 | 286.80 | 5.6588 | 0.549 |\n| 2 | 97.04 | 4.5752 | 0.159 | 7 | 539.35 | 6.2904 | 0.646 |\n| 3 | 99.16 | 4.5967 | 0.256 | 8 | 561.10 | 6.3299 | 0.743 |\n| 4 | 110.47 | 4.7048 | 0.354 | 9 | 782.93 | 0.841 |  |\n| 5 | 179.49 | 5.1901 | 0.451 | 10 | 2269.82 | 7.7275 | 0.939 |  \n!  \n图 7.4.4: 变换后数据的正态概率纸",
        "metadata": {
            "Header 2": "7.4 分布拟合检验",
            "Header 3": "7.4.3 正态性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "夏皮洛-威尔克检验也简称 $W$ 检验. 这个检验当 $8 \\leqslant n \\leqslant 50$ 时可以使用过小样本 $(n<8)$ 对偏离正态分布的检验不太有效.  \n$W$ 检验是建立在次序统计量的基础上. 将 $n$ 个独立观测值按非降次序排列, 记为 $x_{(1)}, \\cdots, x_{(n)}$,检验统计量为  \n$$\n\\begin{equation*}\nW=\\frac{\\left[\\sum_{i=1}^{n}\\left(a_{i}-\\bar{a}\\right)\\left(x_{(i)}-\\bar{x}\\right)\\right]}{\\sum_{i=1}^{n}\\left(a_{i}-\\bar{a}\\right)^{2} \\sum_{i=1}^{n}\\left(x_{(i)}-\\bar{x}\\right)^{2}} \\tag{7.4.5}\n\\end{equation*}\n$$  \n其中系数 $a_{1}, \\cdots, a_{n}$ 在样本容量为 $n$ 时有特定的值, 可查附表 6 . 另外, 系数 $a_{1}, \\cdots, a_{n}$ 还具有如下几条性质:  \n$$\n\\begin{gathered}\na_{i}=-a_{n+1-i}, \\quad i=1,2, \\cdots,[n / 2] \\\\\n\\sum_{i=1}^{n} a_{i}=0, \\quad \\sum_{i=1}^{n} a_{i}^{2}=1\n\\end{gathered}\n$$  \n据此可将 (7.4.5) 简化为  \n$$\n\\begin{equation*}\nW=\\frac{\\left[\\sum_{i=1}^{[n / 2]}\\left(x_{(n+1-i)}-x_{(i)}\\right)\\right]^{2}}{\\sum_{i=1}^{n}\\left(x_{(i)}-\\bar{x}\\right)^{2}} . \\tag{7.4.6}\n\\end{equation*}\n$$  \n可以证明, 在原假设成立, 即总体分布为正态分布时, $W$ 的值应该接近 1 , 因此, 在显著性水平 $\\alpha$下,如果统计量 $W$ 的值小于其 $\\alpha$ 分位数,则拒绝原假设,即拒绝域为  \n$$",
        "metadata": {
            "Header 2": "二、夏皮洛一威尔克(Shapiro-Wilk)检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{gathered}\na_{i}=-a_{n+1-i}, \\quad i=1,2, \\cdots,[n / 2] \\\\\n\\sum_{i=1}^{n} a_{i}=0, \\quad \\sum_{i=1}^{n} a_{i}^{2}=1\n\\end{gathered}\n$$  \n据此可将 (7.4.5) 简化为  \n$$\n\\begin{equation*}\nW=\\frac{\\left[\\sum_{i=1}^{[n / 2]}\\left(x_{(n+1-i)}-x_{(i)}\\right)\\right]^{2}}{\\sum_{i=1}^{n}\\left(x_{(i)}-\\bar{x}\\right)^{2}} . \\tag{7.4.6}\n\\end{equation*}\n$$  \n可以证明, 在原假设成立, 即总体分布为正态分布时, $W$ 的值应该接近 1 , 因此, 在显著性水平 $\\alpha$下,如果统计量 $W$ 的值小于其 $\\alpha$ 分位数,则拒绝原假设,即拒绝域为  \n$$\n\\left\\{W \\leqslant W_{\\alpha}\\right\\}\n$$  \n其中 $\\alpha$ 分位数可查附表 7.  \n例 7.4.6: 某气象站收集了 44 个独立的年降雨量数据, 资料如下 (已排序):  \n| 520 | 556 | 561 | 616 | 635 | 669 | 686 | 692 | 704 | 707 | 711 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 713 | 714 | 719 | 727 | 735 | 740 | 744 | 745 | 750 | 776 | 777 |\n| 786 | 786 | 791 | 794 | 821 | 822 | 826 | 834 | 837 | 851 | 862 |\n| 873 | 879 | 889 | 900 | 904 | 922 | 926 | 952 | 963 | 1056 | 1074. |  \n我们要根据这批数据作正态性检验.  \n为此,利用 (7.4.6) 计算 $W$ 值. 首先由这批数据可算得  \n$$",
        "metadata": {
            "Header 2": "二、夏皮洛一威尔克(Shapiro-Wilk)检验"
        },
        "type": "Document"
    },
    {
        "page_content": "其中 $\\alpha$ 分位数可查附表 7.  \n例 7.4.6: 某气象站收集了 44 个独立的年降雨量数据, 资料如下 (已排序):  \n| 520 | 556 | 561 | 616 | 635 | 669 | 686 | 692 | 704 | 707 | 711 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 713 | 714 | 719 | 727 | 735 | 740 | 744 | 745 | 750 | 776 | 777 |\n| 786 | 786 | 791 | 794 | 821 | 822 | 826 | 834 | 837 | 851 | 862 |\n| 873 | 879 | 889 | 900 | 904 | 922 | 926 | 952 | 963 | 1056 | 1074. |  \n我们要根据这批数据作正态性检验.  \n为此,利用 (7.4.6) 计算 $W$ 值. 首先由这批数据可算得  \n$$\n\\bar{x}=785.114, \\quad \\sum_{i=1}^{44}\\left(x_{(i)}-\\bar{x}\\right)^{2}=630872.43,\n$$  \n我们将计算 $\\mathrm{W}$ 的过程列于表 7.4.9 中. 为便于计算, 值 $x_{(k)}-x_{(n+1-k)}$ 和 $d_{k}=x_{(n+1-k)}-x_{(k)}$ 安排在同一行. 从表 7.4.9 可以计算出 $W$ 的值:  \n表 7.4.9: 某一气象站收集的年降雨量  \n| $k$ | $x_{(k)}$ | $x_{(n+1-k)}$ | $d_{k}$ | $a_{k}$ | $k$ | $x_{(k)}$ | $x_{(n+1-k)}$ | $d_{k}$ | $a_{k}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 520 | 1074 | 554 | 0.3872 | 12 | 713 | 862 | 149 | 0.0943 |",
        "metadata": {
            "Header 2": "二、夏皮洛一威尔克(Shapiro-Wilk)检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\bar{x}=785.114, \\quad \\sum_{i=1}^{44}\\left(x_{(i)}-\\bar{x}\\right)^{2}=630872.43,\n$$  \n我们将计算 $\\mathrm{W}$ 的过程列于表 7.4.9 中. 为便于计算, 值 $x_{(k)}-x_{(n+1-k)}$ 和 $d_{k}=x_{(n+1-k)}-x_{(k)}$ 安排在同一行. 从表 7.4.9 可以计算出 $W$ 的值:  \n表 7.4.9: 某一气象站收集的年降雨量  \n| $k$ | $x_{(k)}$ | $x_{(n+1-k)}$ | $d_{k}$ | $a_{k}$ | $k$ | $x_{(k)}$ | $x_{(n+1-k)}$ | $d_{k}$ | $a_{k}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 520 | 1074 | 554 | 0.3872 | 12 | 713 | 862 | 149 | 0.0943 |\n| 2 | 556 | 1056 | 500 | 0.2667 | 13 | 714 | 951 | 137 | 0.0842 |\n| 3 | 561 | 963 | 402 | 0.2323 | 14 | 719 | 837 | 118 | 0.0745 |\n| 4 | 616 | 926 | 291 | 0.1868 | 16 | 735 | 826 | 91 | 0.0560 |\n| 6 | 669 | 922 | 253 | 0.1695 | 17 | 740 | 822 | 82 | 0.0471 |\n| 7 | 686 | 904 | 218 | 0.1542 | 18 | 744 | 821 | 77 | 0.0383 |\n| 8 | 692 | 900 | 208 | 0.1405 | 19 | 745 | 794 | 49 | 0.0296 |\n| 9 | 704 | 889 | 185 | 0.1278 | 20 | 750 | 791 | 41 | 0.0211 |",
        "metadata": {
            "Header 2": "二、夏皮洛一威尔克(Shapiro-Wilk)检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| 2 | 556 | 1056 | 500 | 0.2667 | 13 | 714 | 951 | 137 | 0.0842 |\n| 3 | 561 | 963 | 402 | 0.2323 | 14 | 719 | 837 | 118 | 0.0745 |\n| 4 | 616 | 926 | 291 | 0.1868 | 16 | 735 | 826 | 91 | 0.0560 |\n| 6 | 669 | 922 | 253 | 0.1695 | 17 | 740 | 822 | 82 | 0.0471 |\n| 7 | 686 | 904 | 218 | 0.1542 | 18 | 744 | 821 | 77 | 0.0383 |\n| 8 | 692 | 900 | 208 | 0.1405 | 19 | 745 | 794 | 49 | 0.0296 |\n| 9 | 704 | 889 | 185 | 0.1278 | 20 | 750 | 791 | 41 | 0.0211 |\n| 10 | 711 | 879 | 172 | 0.1160 | 21 | 776 | 786 | 10 | 0.0126 |\n| 11 | 711 | 873 | 162 | 0.1049 | 22 | 777 | 786 | 9 | 0.0042 |  \n$$\nW=\\frac{(0.3874 \\times 554+0.2667 \\times 500+\\cdots+0.0042 \\times 9)^{2}}{630872.43}=0.982 .\n$$  \n若取 $\\alpha=0.05$, 查附表 7 , 在 $n=44$ 时给出 $W_{0.05}=0.944$, 由于计算得到的 $W$ 值大于该值, 所以在显著性水平 $\\alpha=0.05$ 上不拒绝零假设, 即可以认为该批数据服从正态分布.",
        "metadata": {
            "Header 2": "二、夏皮洛一威尔克(Shapiro-Wilk)检验"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 有人对 $\\pi=3.1415926 \\cdots$ 的小数点后 800 位数字中数字 $0,1,2, \\cdots, 9$ 出现的次数进行了统计,结果如下  \n| 数字 | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 次数 | 74 | 92 | 83 | 79 | 80 | 73 | 77 | 75 | 76 | 91 |  \n试在显著性水平为 0.05 下检验每个数字出现概率相同的假设.  \n2. 郑一颗骰子 60 次, 结果如下:  \n试在显著性水平为 0.05 下检验这颗骰子是否均匀.  \n| 点数 | 1 | 2 | 3 | 4 | 5 | 6 |\n| :--- | :---: | :---: | :---: | :---: | :---: | :---: |\n| 次数 | 7 | 8 | 12 | 11 | 9 | 13 |  \n3. 检查了一本书的 100 页, 记录各页中的印刷错误的个数, 其结果如下: 问能否认为一页的印刷  \n| 错误个数 | 0 | 1 | 2 | 3 | 4 | 5 | $\\geqslant 6$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 页数 | 35 | 40 | 19 | 3 | 2 | 1 | 0 |  \n错误个数服从泊松分布? ( 取 $\\alpha=0.05$ )  \n4. 某建筑工地每天发生事故数现场记录如下: 试在显著性水平 $\\alpha=0.05$ 下检验这批数据是否服  \n| 一天发生的事故数 | 0 | 1 | 2 | 3 | 4 | 5 | $\\geqslant 6$ | 合计 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 天数 | 102 | 59 | 30 | 8 | 0 | 1 | 0 | 200 |  \n从泊松分布.",
        "metadata": {
            "Header 2": "丑习题 7.4"
        },
        "type": "Document"
    },
    {
        "page_content": "3. 检查了一本书的 100 页, 记录各页中的印刷错误的个数, 其结果如下: 问能否认为一页的印刷  \n| 错误个数 | 0 | 1 | 2 | 3 | 4 | 5 | $\\geqslant 6$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 页数 | 35 | 40 | 19 | 3 | 2 | 1 | 0 |  \n错误个数服从泊松分布? ( 取 $\\alpha=0.05$ )  \n4. 某建筑工地每天发生事故数现场记录如下: 试在显著性水平 $\\alpha=0.05$ 下检验这批数据是否服  \n| 一天发生的事故数 | 0 | 1 | 2 | 3 | 4 | 5 | $\\geqslant 6$ | 合计 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 天数 | 102 | 59 | 30 | 8 | 0 | 1 | 0 | 200 |  \n从泊松分布.  \n5. 在一批灯泡中抽取 300 只作寿命试验, 其结果如下:  \n$$\n\\begin{array}{c|cccc}\n\\text { 寿命 }(\\mathrm{h}) & <100 & 100 \\sim 200 & 200 \\sim 300 & \\geqslant 300 \\\\\n\\hline \\text { 灯泡数 } & 121 & 78 & 43 & 58\n\\end{array}\n$$  \n在显著性水平为 0.05 下能否认为灯泡寿命服从指数分布 $\\operatorname{Exp}(0.005)$ ?  \n6. 对 1000 位高中生做性别与色盲的调查,获得如下 2 位列联表  \n| 性别 | 视觉 |  |\n| :---: | :---: | :---: |\n|  | 正常 | 色盲 |\n| 男 | 535 | 65 |\n| 女 | 382 | 18 |  \n试在显著性水平 $\\alpha=0.05$ 下考察色育与性别之间是否独立.  \n7. 为研究慢性气管炎与吸烟量的关系, 调查了 813 人, 各类人数统计数字如下: 是否可以认为吸  \n| 健康情况 | 吸烟量 |  |  | 合计 |",
        "metadata": {
            "Header 2": "丑习题 7.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{array}{c|cccc}\n\\text { 寿命 }(\\mathrm{h}) & <100 & 100 \\sim 200 & 200 \\sim 300 & \\geqslant 300 \\\\\n\\hline \\text { 灯泡数 } & 121 & 78 & 43 & 58\n\\end{array}\n$$  \n在显著性水平为 0.05 下能否认为灯泡寿命服从指数分布 $\\operatorname{Exp}(0.005)$ ?  \n6. 对 1000 位高中生做性别与色盲的调查,获得如下 2 位列联表  \n| 性别 | 视觉 |  |\n| :---: | :---: | :---: |\n|  | 正常 | 色盲 |\n| 男 | 535 | 65 |\n| 女 | 382 | 18 |  \n试在显著性水平 $\\alpha=0.05$ 下考察色育与性别之间是否独立.  \n7. 为研究慢性气管炎与吸烟量的关系, 调查了 813 人, 各类人数统计数字如下: 是否可以认为吸  \n| 健康情况 | 吸烟量 |  |  | 合计 |\n| :--- | :--- | :--- | :--- | :--- |\n|  | 0 | $1 \\sim 5$ | $>5$ |  |\n| 患病 | 126 | 245 | 49 | 420 |\n| 健康 | 152 | 209 | 32 | 393 |\n| 合计 | 278 | 454 | 81 | 813 |  \n烟量对慢性气管炎没有影响? ( 取 $\\alpha=0.05$ )  \n8. 下表是 1976 年至 1977 年间在美国佛罗里达州 29 个地区发生判死刑的情况:  \n| 被害人肤色 | 判死刑 | 不判死刑 |\n| :---: | :---: | :---: |\n| 白人 | 30 | 184 |\n| 黑人 | 6 | 106 |  \n是否可以认为被害人肤色不同不会影响对被告的死刑判决?  \n9. 某调查机构连续三年对某城市的居民进行热点调查：对下列四个问题，（1）收人、(2) 物价、(3) 住房、(4) 交通, 要求被调查者选择其中之一作为最关心的问题. 调查结果如下:是否可以认为各年该城市居民对社会热点问题的看法保持不变?",
        "metadata": {
            "Header 2": "丑习题 7.4"
        },
        "type": "Document"
    },
    {
        "page_content": "| :--- | :--- | :--- | :--- | :--- |\n|  | 0 | $1 \\sim 5$ | $>5$ |  |\n| 患病 | 126 | 245 | 49 | 420 |\n| 健康 | 152 | 209 | 32 | 393 |\n| 合计 | 278 | 454 | 81 | 813 |  \n烟量对慢性气管炎没有影响? ( 取 $\\alpha=0.05$ )  \n8. 下表是 1976 年至 1977 年间在美国佛罗里达州 29 个地区发生判死刑的情况:  \n| 被害人肤色 | 判死刑 | 不判死刑 |\n| :---: | :---: | :---: |\n| 白人 | 30 | 184 |\n| 黑人 | 6 | 106 |  \n是否可以认为被害人肤色不同不会影响对被告的死刑判决?  \n9. 某调查机构连续三年对某城市的居民进行热点调查：对下列四个问题，（1）收人、(2) 物价、(3) 住房、(4) 交通, 要求被调查者选择其中之一作为最关心的问题. 调查结果如下:是否可以认为各年该城市居民对社会热点问题的看法保持不变?\n10. 某砖厂为考察其生产的砖的抗断强度是否服从正态分布, 现从一批砖中随机抽取 30 件, 测得其抗压强度如下：  \n$$\n\\begin{array}{lllllllllllllll}\n77 & 70 & 80 & 81 & 73 & 87 & 87 & 79 & 81 & 81 & 78 & 84 & 76 & 93 & 79\n\\end{array}\n$$  \n$$\n\\begin{array}{lllllllllllllll}\n80 & 86 & 80 & 79 & 75 & 81 & 71 & 84 & 89 & 75 & 85 & 87 & 70 & 71 & 83\n\\end{array}\n$$  \n试对这批数据用正态概率纸做正态性检验, 然后再进行 $W$ 检验.  \n11. 下列数据是某工厂的冷却水中的含氯量 $(\\mathrm{ppm})$,  \n| 0.9920 | 1.0138 | 1.0163 | 1.0142 | 1.0258 | 1.0134 | 1.0238 | 0.9760 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |",
        "metadata": {
            "Header 2": "丑习题 7.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{array}{lllllllllllllll}\n77 & 70 & 80 & 81 & 73 & 87 & 87 & 79 & 81 & 81 & 78 & 84 & 76 & 93 & 79\n\\end{array}\n$$  \n$$\n\\begin{array}{lllllllllllllll}\n80 & 86 & 80 & 79 & 75 & 81 & 71 & 84 & 89 & 75 & 85 & 87 & 70 & 71 & 83\n\\end{array}\n$$  \n试对这批数据用正态概率纸做正态性检验, 然后再进行 $W$ 检验.  \n11. 下列数据是某工厂的冷却水中的含氯量 $(\\mathrm{ppm})$,  \n| 0.9920 | 1.0138 | 1.0163 | 1.0142 | 1.0258 | 1.0134 | 1.0238 | 0.9760 |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| 0.9996 | 0.9969 | 0.9679 | 1.0051 | 0.9789 | 1.0283 | 0.9839 | 1.0106 |\n| 1.0044 | 0.9816 | 0.9566 | 0.9988 | 0.9798 | 1.0123 | 1.0102 | 1.0338 |\n| 1.0118 | 0.9871 | 1.0076 | 0.9798 | 0.9996 | 0.9900 | 1.0000 | 0.9936 |\n| 1.0219 | 0.9625 | 1.0086 | 1.0179 | 1.0146 | 1.0116 | 1.0008 | 1.0135 |\n| 1.0114 | 0.9949 | 0.9925 | 0.9941 | 0.9705 | 0.9953 | 1.0024 | 1.0063 |  \n试在显著性水平 0.01 下对这批数据做正态性检验.",
        "metadata": {
            "Header 2": "丑习题 7.4"
        },
        "type": "Document"
    },
    {
        "page_content": "前面几章我们讨论的都是一个总体或者两个总体的统计分析问题, 在实际工作中我们还会经常碰到多个总体均值的比较问题, 处理这类问题通常采用所谓的方差分析方法. 本节将叙述这个方法, 先看一个例子.  \n例 8.1.1: 在饲料养鸡增肥的研究中, 某研究所提出三种饲料配方: $A_{1}$ 是以鱼粉为主的饲料, $A_{2}$ 是以槐树粉为主的饲料, $A_{3}$ 是以苜落粉为主的饲料. 为比较三种饲料的效果, 特选 24 只相似的维鸡随机均分为三组, 每组各喂一种饲料, 60 天后观察它们的重量. 试验结果如下表所示:  \n| 表 8.1.1: 鸡饲料试验数据 |  |  |  |  |  |  |  |  |\n| :---: | ---: | ---: | ---: | :---: | :---: | :---: | :---: | :---: |\n| 饲料 $A$ | 鸡重 $/ \\mathrm{g}$ |  |  |  |  |  |  |  |\n| $A_{1}$ | 1073 | 1009 | 1060 | 1001 | 1002 | 1012 | 1009 | 1028 |\n| $A_{2}$ | 1107 | 1092 | 990 | 1109 | 1090 | 1074 | 1122 | 1001 |\n| $A_{3}$ | 1093 | 1029 | 1080 | 1021 | 1022 | 1032 | 1029 | 1048 |  \n本例 8.1.1 中, 我们要比较的是三种饲料对鸡的增肥作用是否相同. 为此, 把饲料称为因子, 记为 $A$, 三种不同的配方称为因子 $A$ 的三个水平, 记为 $A_{1}, A_{2}, A_{3}$, 使用配方 $A_{i}$ 下第 $j$ 只鸡 60 天后的重量用 $y_{i j}$ 表示, $i=1,2,3, j=1,2,3, \\ldots, 10$. 我们的目的是比较三种不同饲料配方下鸡的平均重量是否相等, 为此, 需要做一些基本假定, 把所研究的问题归结为一个统计问题, 然后用方差分析的方法进行解决.",
        "metadata": {
            "Header 2": "8.1 方差分析",
            "Header 3": "8.1.1 问题的提出"
        },
        "type": "Document"
    },
    {
        "page_content": "| $A_{1}$ | 1073 | 1009 | 1060 | 1001 | 1002 | 1012 | 1009 | 1028 |\n| $A_{2}$ | 1107 | 1092 | 990 | 1109 | 1090 | 1074 | 1122 | 1001 |\n| $A_{3}$ | 1093 | 1029 | 1080 | 1021 | 1022 | 1032 | 1029 | 1048 |  \n本例 8.1.1 中, 我们要比较的是三种饲料对鸡的增肥作用是否相同. 为此, 把饲料称为因子, 记为 $A$, 三种不同的配方称为因子 $A$ 的三个水平, 记为 $A_{1}, A_{2}, A_{3}$, 使用配方 $A_{i}$ 下第 $j$ 只鸡 60 天后的重量用 $y_{i j}$ 表示, $i=1,2,3, j=1,2,3, \\ldots, 10$. 我们的目的是比较三种不同饲料配方下鸡的平均重量是否相等, 为此, 需要做一些基本假定, 把所研究的问题归结为一个统计问题, 然后用方差分析的方法进行解决.  \n在例 8.1.1 中, 我们只考察了一个因子, 称其为单因子试验. 通常, 在单因子试验中, 记因子为 $A$, 设其有 $r$ 个水平, 记为 $A_{1}, A_{2}, \\ldots, A_{r}$, 在每一水平下考察的指标可以看成一个总体, 现有 $r$ 个水平, 故有 $r$ 个总体, 假定:  \n1. 每一总体均为正态分布, 记为 $N\\left(\\mu_{i}, \\sigma_{i}^{2}\\right), i=1, \\cdots, r$;\n2. 各总体的方差相同, 记为 $\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\cdots=\\sigma_{r}^{2}=\\sigma^{2}$;\n3. 从每一总体中抽取的样本是相互独立的, 即所有的试验结果 $y_{i j}$ 都相互独立.  \n这三个假定都可以用统计方法进行验证. 譬如, 利用正态性检验 (7.4.3 节) 验证 1 成立; 利用后面 $\\S 8.3$ 的方差齐次性检验验证 2 成立; 而试验结果 $y_{i j}$ 的独立性可由随机化实现, 这里的随机化是指所有试验按随机次序进行.",
        "metadata": {
            "Header 2": "8.1 方差分析",
            "Header 3": "8.1.1 问题的提出"
        },
        "type": "Document"
    },
    {
        "page_content": "在例 8.1.1 中, 我们只考察了一个因子, 称其为单因子试验. 通常, 在单因子试验中, 记因子为 $A$, 设其有 $r$ 个水平, 记为 $A_{1}, A_{2}, \\ldots, A_{r}$, 在每一水平下考察的指标可以看成一个总体, 现有 $r$ 个水平, 故有 $r$ 个总体, 假定:  \n1. 每一总体均为正态分布, 记为 $N\\left(\\mu_{i}, \\sigma_{i}^{2}\\right), i=1, \\cdots, r$;\n2. 各总体的方差相同, 记为 $\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\cdots=\\sigma_{r}^{2}=\\sigma^{2}$;\n3. 从每一总体中抽取的样本是相互独立的, 即所有的试验结果 $y_{i j}$ 都相互独立.  \n这三个假定都可以用统计方法进行验证. 譬如, 利用正态性检验 (7.4.3 节) 验证 1 成立; 利用后面 $\\S 8.3$ 的方差齐次性检验验证 2 成立; 而试验结果 $y_{i j}$ 的独立性可由随机化实现, 这里的随机化是指所有试验按随机次序进行.  \n我们要做的工作是比较各水平下的均值是否相同, 即要对如下的一个假设进行检验,  \n$$\n\\begin{equation*}\nH_{0}: \\mu_{1}=\\mu_{2}=\\cdots=\\mu_{r} \\tag{8.1.1}\n\\end{equation*}\n$$  \n其备择假设为  \n$$\nH_{1}: \\mu_{1}, \\mu_{2}, \\cdots, \\mu_{r} \\text { 不全相等, }\n$$  \n在不会引起误解的情况下, $H_{1}$ 通常可省略不写.  \n如果 $H_{0}$ 成立, 因子 $A$ 的 $r$ 个水平均值相同, 称因子 $A$ 的 $r$ 个水平间没有显著差异, 简称因子 $A$ 不显著; 反之, 当 $H_{0}$ 不成立时, 因子 $A$ 的 $r$ 个水平均值不全相同, 这时称因子 $A$ 的不同水平间有显著差异, 简称因子 $A$ 显著.  \n为对假设 (8.1.1) 进行检验, 需要从每一水平下的总体抽取样本, 设从第 $i$ 个水平下的总体获",
        "metadata": {
            "Header 2": "8.1 方差分析",
            "Header 3": "8.1.1 问题的提出"
        },
        "type": "Document"
    },
    {
        "page_content": "我们要做的工作是比较各水平下的均值是否相同, 即要对如下的一个假设进行检验,  \n$$\n\\begin{equation*}\nH_{0}: \\mu_{1}=\\mu_{2}=\\cdots=\\mu_{r} \\tag{8.1.1}\n\\end{equation*}\n$$  \n其备择假设为  \n$$\nH_{1}: \\mu_{1}, \\mu_{2}, \\cdots, \\mu_{r} \\text { 不全相等, }\n$$  \n在不会引起误解的情况下, $H_{1}$ 通常可省略不写.  \n如果 $H_{0}$ 成立, 因子 $A$ 的 $r$ 个水平均值相同, 称因子 $A$ 的 $r$ 个水平间没有显著差异, 简称因子 $A$ 不显著; 反之, 当 $H_{0}$ 不成立时, 因子 $A$ 的 $r$ 个水平均值不全相同, 这时称因子 $A$ 的不同水平间有显著差异, 简称因子 $A$ 显著.  \n为对假设 (8.1.1) 进行检验, 需要从每一水平下的总体抽取样本, 设从第 $i$ 个水平下的总体获\n得 $m$ 个试验结果 (简单起见, 这里先假设个水平下试验的重复数相同, 后面会看到, 重复数不同时的处理方式与此基本一致, 略有差异), 记 $y_{i j}$ 表示第 $i$ 个总体的第 $j$ 次重复试验结果. 共得到如下 $r \\times m$ 个试验结果:  \n$$\ny_{i j}, i=1,2, \\cdots, r, j=1,2, \\cdots, m\n$$  \n其中 $r$ 为水平数, $m$ 为重复数, $i$ 为水平编号, $j$ 为重复编号.  \n在水平 $A_{i}$ 下的试验结果 $y_{i j}$ 与该水平下的指标均值 $\\mu_{i}$ 一般总是有差距的, 记 $\\varepsilon_{i j}=y_{i j}-\\mu_{i}$, $\\varepsilon_{i j}$ 称为随机误差. 于是有  \n$$\n\\begin{equation*}\ny_{i j}=\\mu_{i}+\\varepsilon_{i j} \\tag{8.1.2}\n\\end{equation*}\n$$  \n(8.1.2) 式称为试验结果 $y_{i j}$ 的数据结构式. 把三个假定用子数据结构式就可以写出单因子方差分析的统计模型:  \n$$",
        "metadata": {
            "Header 2": "8.1 方差分析",
            "Header 3": "8.1.1 问题的提出"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\ny_{i j}, i=1,2, \\cdots, r, j=1,2, \\cdots, m\n$$  \n其中 $r$ 为水平数, $m$ 为重复数, $i$ 为水平编号, $j$ 为重复编号.  \n在水平 $A_{i}$ 下的试验结果 $y_{i j}$ 与该水平下的指标均值 $\\mu_{i}$ 一般总是有差距的, 记 $\\varepsilon_{i j}=y_{i j}-\\mu_{i}$, $\\varepsilon_{i j}$ 称为随机误差. 于是有  \n$$\n\\begin{equation*}\ny_{i j}=\\mu_{i}+\\varepsilon_{i j} \\tag{8.1.2}\n\\end{equation*}\n$$  \n(8.1.2) 式称为试验结果 $y_{i j}$ 的数据结构式. 把三个假定用子数据结构式就可以写出单因子方差分析的统计模型:  \n$$\n\\left\\{\\begin{array}{l}\ny_{i j}=\\mu_{i}+\\varepsilon_{i j}, i=1,2, \\cdots, r, j=1,2, \\cdots, m ;  \\tag{8.1.3}\\\\\n\\text { 诸 } \\varepsilon_{i j} \\text { 相互独立, 且都服从 } N\\left(0, \\sigma^{2}\\right) .\n\\end{array}\\right.\n$$  \n为了能更好地描述数据, 常在方差分析中引人总均值与效应的概念. 称诸 $\\mu_{i}$ 的平均 (所有试验结果的均值的平均)  \n$$\n\\begin{equation*}\n\\mu=\\frac{1}{r}\\left(\\mu_{1}+\\cdots+\\mu_{r}\\right)=\\frac{1}{r} \\sum_{i=1}^{r} \\mu_{i} \\tag{8.1.4}\n\\end{equation*}\n$$  \n为总均值. 称第 $i$ 水平下的均值 $\\mu_{i}$ 与总均值 $\\mu$ 的差  \n$$\n\\begin{equation*}\na_{i}=\\mu_{i}-\\mu, \\quad i=1,2, \\cdots, r \\tag{8.1.5}\n\\end{equation*}\n$$  \n为因子 $A$ 的第 $i$ 水平的主效应, 简称为 $A_{i}$ 的效应.",
        "metadata": {
            "Header 2": "8.1 方差分析",
            "Header 3": "8.1.1 问题的提出"
        },
        "type": "Document"
    },
    {
        "page_content": "\\text { 诸 } \\varepsilon_{i j} \\text { 相互独立, 且都服从 } N\\left(0, \\sigma^{2}\\right) .\n\\end{array}\\right.\n$$  \n为了能更好地描述数据, 常在方差分析中引人总均值与效应的概念. 称诸 $\\mu_{i}$ 的平均 (所有试验结果的均值的平均)  \n$$\n\\begin{equation*}\n\\mu=\\frac{1}{r}\\left(\\mu_{1}+\\cdots+\\mu_{r}\\right)=\\frac{1}{r} \\sum_{i=1}^{r} \\mu_{i} \\tag{8.1.4}\n\\end{equation*}\n$$  \n为总均值. 称第 $i$ 水平下的均值 $\\mu_{i}$ 与总均值 $\\mu$ 的差  \n$$\n\\begin{equation*}\na_{i}=\\mu_{i}-\\mu, \\quad i=1,2, \\cdots, r \\tag{8.1.5}\n\\end{equation*}\n$$  \n为因子 $A$ 的第 $i$ 水平的主效应, 简称为 $A_{i}$ 的效应.  \n容易看出  \n$$\n\\begin{gather*}\n\\sum_{i=1}^{r} a_{i}=0,  \\tag{8.1.6}\\\\\n\\mu_{i}=\\mu+a_{i} \\tag{8.1.7}\n\\end{gather*}\n$$  \n这表明第 $i$ 个总体均值是由总均值与该水平的效应叠加而成的, 从而模型 (8.1.3) 可以改写为  \n$$\n\\left\\{\\begin{array}{l}\ny_{i j}=\\mu+a_{i}+\\varepsilon_{i j}, \\quad i=1,2, \\cdots, r, j=1,2, \\cdots, m ;  \\tag{8.1.8}\\\\\n\\sum_{i=1}^{r} a_{i}=0 ; \\\\\n\\varepsilon_{i j} \\text { 相互独立, 且都服从 } N\\left(0, \\sigma^{2}\\right) .\n\\end{array}\\right.\n$$  \n假设 (8.1.1) 可改写为  \n$$\n\\begin{equation*}\nH_{0}: a_{1}=a_{2}=\\cdots=a_{r} \\tag{8.1.9}",
        "metadata": {
            "Header 2": "8.1 方差分析",
            "Header 3": "8.1.1 问题的提出"
        },
        "type": "Document"
    },
    {
        "page_content": "容易看出  \n$$\n\\begin{gather*}\n\\sum_{i=1}^{r} a_{i}=0,  \\tag{8.1.6}\\\\\n\\mu_{i}=\\mu+a_{i} \\tag{8.1.7}\n\\end{gather*}\n$$  \n这表明第 $i$ 个总体均值是由总均值与该水平的效应叠加而成的, 从而模型 (8.1.3) 可以改写为  \n$$\n\\left\\{\\begin{array}{l}\ny_{i j}=\\mu+a_{i}+\\varepsilon_{i j}, \\quad i=1,2, \\cdots, r, j=1,2, \\cdots, m ;  \\tag{8.1.8}\\\\\n\\sum_{i=1}^{r} a_{i}=0 ; \\\\\n\\varepsilon_{i j} \\text { 相互独立, 且都服从 } N\\left(0, \\sigma^{2}\\right) .\n\\end{array}\\right.\n$$  \n假设 (8.1.1) 可改写为  \n$$\n\\begin{equation*}\nH_{0}: a_{1}=a_{2}=\\cdots=a_{r} \\tag{8.1.9}\n\\end{equation*}\n$$  \n其备择假设为  \n$$\nH_{1}: a_{1}, a_{2}, \\cdots, a_{r} \\text { 不全为 } 0 \\text {. }\n$$",
        "metadata": {
            "Header 2": "8.1 方差分析",
            "Header 3": "8.1.1 问题的提出"
        },
        "type": "Document"
    },
    {
        "page_content": "通常在单因子方差分析中可将试验数据列成如下表格形式.  \n8.1.2 中的最后二列的和与平均的含义如下:  \n$$\n\\begin{aligned}\nT_{i} & =\\sum_{j=1}^{m} y_{i j}, \\bar{y}_{i}=\\frac{T_{i}}{m} \\quad i=1,2, \\cdots, r \\\\\nT_{i} & =\\sum_{i=1}^{r} T_{i}, \\bar{y}=\\frac{T}{r \\cdot m}=\\frac{T}{n}\n\\end{aligned}\n$$  \n| 表 8.1.2: 单因子方差分析试验数据 |  |  |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 因子水平 |  | 试验数据 |  | 和 | 平均 |  |\n| $A_{1}$ | $y_{11}$ | $y_{12}$ | $\\cdots$ | $y_{1 m}$ | $T_{1}$ | $\\bar{y}_{1}$ |\n| $A_{2}$ | $y_{21}$ | $y_{22}$ | $\\cdots$ | $y_{2 m}$ | $T_{2}$ | $\\bar{y}_{2}$ |\n| $\\vdots$ | $\\vdots$ | $\\vdots$ |  | $\\vdots$ | $\\vdots$ | $\\vdots$ |\n| $A_{r}$ | $y_{r 1}$ | $y_{r 2}$ | $\\cdots$ | $y_{r m}$ | $T_{r}$ | $\\bar{y}_{r}$ |\n|  |  |  |  |  |  |  |  \n$$\nn=r \\cdot m=\\text { 总试验次数. }\n$$",
        "metadata": {
            "Header 2": "二。试验数据"
        },
        "type": "Document"
    },
    {
        "page_content": "数据间是有差异的. 数据 $y_{i j}$ 与总平均 $\\bar{y}$ 间的偏差可用 $y_{i j}-\\bar{y}$ 表示, 它可分解为两个偏差之和  \n$$\n\\begin{equation*}\ny_{i j}-\\bar{y}=\\left(y_{i j}-\\bar{y}_{i}\\right)+\\left(\\bar{y}_{i}-\\bar{y}\\right) \\tag{8.1.10}\n\\end{equation*}\n$$  \n记  \n$$\n\\bar{\\varepsilon}_{i .}=\\frac{1}{m} \\sum_{j=1}^{m} \\varepsilon_{i j}, \\quad \\bar{\\varepsilon}=\\frac{1}{r} \\sum_{i=1}^{r} \\bar{\\varepsilon}_{i}=\\frac{1}{n} \\sum_{i=1}^{r} \\sum_{j=1}^{m} \\varepsilon_{i j}\n$$  \n由于  \n$$\n\\begin{equation*}\ny_{i j}-\\bar{y}_{i .}=\\left(\\mu_{i}+\\varepsilon_{i j}\\right)-\\left(\\mu_{i}+\\bar{\\varepsilon}_{i}\\right)=\\varepsilon_{i j}-\\bar{\\varepsilon}_{i} \\tag{8.1.11}\n\\end{equation*}\n$$  \n所以 $y_{i j}-\\bar{y}_{i}$. 仅反映组内数据与组内平均的随机误差, 称为组内偏差; 而  \n$$\n\\begin{equation*}\n\\bar{y}_{i .}-\\bar{y}=\\left(\\mu_{i}+\\bar{\\varepsilon}_{i .}\\right)-\\left(\\mu+\\bar{\\varepsilon}_{i}\\right)=a_{i}+\\bar{\\varepsilon}_{i .}-\\bar{\\varepsilon}, \\tag{8.1.12}\n\\end{equation*}\n$$  \n$\\bar{y}_{i}-\\bar{y}$ 除了反映随机误差外, 还反映了第 $i$ 个水平的效应, 称为组间偏差,",
        "metadata": {
            "Header 2": "二、组内偏差与组间偏差"
        },
        "type": "Document"
    },
    {
        "page_content": "在统计学中, 把 $k$ 个数据 $y_{1}, \\cdots, y_{k}$ 分别对其均值 $\\bar{y}=\\left(y_{1}+\\cdots+y_{k}\\right) / k$ 的偏差平方和  \n$$\nQ=\\left(y_{1}-\\bar{y}\\right)^{2}+\\cdots+\\left(y_{k}-\\bar{y}\\right)^{2}=\\sum_{i=1}^{k}\\left(y_{i}-\\bar{y}\\right)^{2}\n$$  \n称为 $k$ 个数据的偏差平方和, 有时简称平方和. 偏差平方和常用来度量若干个数据集中或分散的程度, 它是用来度量若干个数据间差异 (即波动) 的大小的一个重要的统计量.  \n在构成偏差平方和 $Q$ 的 $k$ 个偏差 $y_{1}-\\bar{y}, \\cdots, y_{k}-\\bar{y}$ 间有一个恒等式  \n$$\n\\sum_{i=1}^{k}\\left(y_{i}-\\bar{y}\\right)=0\n$$  \n这说明在 $Q$ 中独立的偏差只有 $k-1$ 个. 在统计学中把平方和中独立偏差个数称为该平方和的自由度, 常记为 $f$, 如 $Q$ 的自由度为 $f_{Q}=k-1$. 自由度是偏差平方和的一个重要参数.  \n四、总平方和分解公式  \n各 $y_{i j}$ 间总的差异大小可用总偏差平方和 $S_{T}$ 表示,  \n$$\n\\begin{equation*}\nS_{T}=\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}\\right)^{2}, \\quad f_{T}=n-1 \\tag{8.1.13}\n\\end{equation*}\n$$  \n仅由随机误差引起的数据间的差异可以用组内偏差平方和表示, 也称为误差偏差平方和, 记\n为 $S_{e}$  \n$$\n\\begin{equation*}\nS_{e}=\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}_{i .}\\right)^{2}, \\quad f_{e}=r(m-1)=n-r \\tag{8.1.14}\n\\end{equation*}\n$$  \n由于组间差异除了随机误差外, 还反映了效应间的差异, 故由效应不同引起的数据差异可用组间",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度"
        },
        "type": "Document"
    },
    {
        "page_content": "四、总平方和分解公式  \n各 $y_{i j}$ 间总的差异大小可用总偏差平方和 $S_{T}$ 表示,  \n$$\n\\begin{equation*}\nS_{T}=\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}\\right)^{2}, \\quad f_{T}=n-1 \\tag{8.1.13}\n\\end{equation*}\n$$  \n仅由随机误差引起的数据间的差异可以用组内偏差平方和表示, 也称为误差偏差平方和, 记\n为 $S_{e}$  \n$$\n\\begin{equation*}\nS_{e}=\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}_{i .}\\right)^{2}, \\quad f_{e}=r(m-1)=n-r \\tag{8.1.14}\n\\end{equation*}\n$$  \n由于组间差异除了随机误差外, 还反映了效应间的差异, 故由效应不同引起的数据差异可用组间  \n偏差平方和表示, 也称为因子 $A$ 的偏差平方和, 记为 $S_{A}$ ；  \n$$\n\\begin{equation*}\nS_{A}=m \\sum_{i=1}^{r}\\left(\\bar{y}_{i}-\\bar{y}\\right)^{2}, \\quad f_{A}=r-1 \\tag{8.1.15}\n\\end{equation*}\n$$  \n定理 8.1.1. 在上述符号下, 总平方和 $S_{T}$ 可以分解为因子平方和 $S_{A}$ 与误差平方和 $S_{e}$. 之和, 其自由度也有相应分解公式, 具体为:  \n$$\n\\begin{equation*}\nS_{T}=S_{A}+S_{e}, \\quad f_{T}=f_{A}+f_{e} \\tag{8.1.16}\n\\end{equation*}\n$$  \n(8.1.16) 式通常称为总平方和分解式.  \n证明: 注意到  \n$$",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n由于组间差异除了随机误差外, 还反映了效应间的差异, 故由效应不同引起的数据差异可用组间  \n偏差平方和表示, 也称为因子 $A$ 的偏差平方和, 记为 $S_{A}$ ；  \n$$\n\\begin{equation*}\nS_{A}=m \\sum_{i=1}^{r}\\left(\\bar{y}_{i}-\\bar{y}\\right)^{2}, \\quad f_{A}=r-1 \\tag{8.1.15}\n\\end{equation*}\n$$  \n定理 8.1.1. 在上述符号下, 总平方和 $S_{T}$ 可以分解为因子平方和 $S_{A}$ 与误差平方和 $S_{e}$. 之和, 其自由度也有相应分解公式, 具体为:  \n$$\n\\begin{equation*}\nS_{T}=S_{A}+S_{e}, \\quad f_{T}=f_{A}+f_{e} \\tag{8.1.16}\n\\end{equation*}\n$$  \n(8.1.16) 式通常称为总平方和分解式.  \n证明: 注意到  \n$$\n\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}_{i}\\right)\\left(\\bar{y}_{i}-\\bar{y}\\right)=\\sum_{i=1}^{r}\\left[\\left(\\bar{y}_{i .}-\\bar{y}\\right) \\sum_{i=1}^{m}\\left(y_{i j}-\\bar{y}_{i}\\right)\\right]=0\n$$  \n故有  \n$$\n\\begin{aligned}\nS_{T} & =\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}\\right)^{2}=\\sum_{i=1}^{r} \\sum_{i=1}^{m}\\left[\\left(y_{i j}-\\bar{y}_{i}\\right)+\\left(\\bar{y}_{i}-\\bar{y}\\right)\\right]^{2} \\\\",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n(8.1.16) 式通常称为总平方和分解式.  \n证明: 注意到  \n$$\n\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}_{i}\\right)\\left(\\bar{y}_{i}-\\bar{y}\\right)=\\sum_{i=1}^{r}\\left[\\left(\\bar{y}_{i .}-\\bar{y}\\right) \\sum_{i=1}^{m}\\left(y_{i j}-\\bar{y}_{i}\\right)\\right]=0\n$$  \n故有  \n$$\n\\begin{aligned}\nS_{T} & =\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}\\right)^{2}=\\sum_{i=1}^{r} \\sum_{i=1}^{m}\\left[\\left(y_{i j}-\\bar{y}_{i}\\right)+\\left(\\bar{y}_{i}-\\bar{y}\\right)\\right]^{2} \\\\\n& =S_{e}+S_{A}+2 \\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}_{i}\\right)+\\left(\\bar{y}_{i}-\\bar{y}\\right)=S_{e}+S_{A},\n\\end{aligned}\n$$  \n诸自由度间的等式是显然的.",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度"
        },
        "type": "Document"
    },
    {
        "page_content": "偏差平方和 $Q$ 的大小与数据个数 (或自由度) 有关, 一般说来, 数据越多, 其偏差平方和越大.为了便于在偏差平方和间进行比较, 统计上引人了均方和的概念, 它定义为  \n$$\nM S=Q / f_{Q},\n$$  \n其意为平均每个自由度上有多少平方和, 它比较好地度量了一组数据的离散程度.  \n如今要对因子平方和 SA 与误差平方和 S2 之间进行比较, 用其均方和  \n$$\nM S_{A}=S_{A} / f_{A}, \\quad M S_{e}=S_{e} / f_{e}\n$$  \n进行比较更为合理, 因为均方和排除了自由度不同所产生的干扰. 故用  \n$$\n\\begin{equation*}\nF=\\frac{M S_{A}}{M S_{e}}=\\frac{S_{A} / f_{A}}{S_{e} / f_{e}} \\tag{8.1.17}\n\\end{equation*}\n$$  \n作为检验 $H_{0}$ 的统计量, 为给出检验拒绝域, 我们需要如下定理:  \n定理 8.1.2. 在单因子方差分析模型 (8.1.8) 及前述符号下, 有  \n1. $S_{\\varepsilon} / \\sigma^{2} \\sim \\chi^{2}(n-r)$, 从而 $E\\left(S_{e}\\right)=(n-r) \\sigma^{2}$\n2. $E\\left(S_{A}\\right)=(r-1) \\sigma^{2}+m \\sum_{i=1}^{r} a_{i}^{2}$, 进一步, 若 $H_{0}$ 成立, 则有 $S_{A} / \\sigma^{2} \\sim \\chi^{2}(r-1)$;\n3. $S_{A}$ 与 $S_{e}$ 独立.",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.3 检验方法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\nF=\\frac{M S_{A}}{M S_{e}}=\\frac{S_{A} / f_{A}}{S_{e} / f_{e}} \\tag{8.1.17}\n\\end{equation*}\n$$  \n作为检验 $H_{0}$ 的统计量, 为给出检验拒绝域, 我们需要如下定理:  \n定理 8.1.2. 在单因子方差分析模型 (8.1.8) 及前述符号下, 有  \n1. $S_{\\varepsilon} / \\sigma^{2} \\sim \\chi^{2}(n-r)$, 从而 $E\\left(S_{e}\\right)=(n-r) \\sigma^{2}$\n2. $E\\left(S_{A}\\right)=(r-1) \\sigma^{2}+m \\sum_{i=1}^{r} a_{i}^{2}$, 进一步, 若 $H_{0}$ 成立, 则有 $S_{A} / \\sigma^{2} \\sim \\chi^{2}(r-1)$;\n3. $S_{A}$ 与 $S_{e}$ 独立.  \n证明: 由于 (8.1.11) 和 (8.1.14), $S_{e}=\\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(\\varepsilon_{i j}-\\overline{\\varepsilon_{i}}\\right)^{2}$, 在单因子方差分析模型 (8.1.8) 下, 我们知道,诸 $\\varepsilon_{i j}, i=1,2, \\cdots, r, j=1,2, \\cdots, m$ 独立同分布于 $N\\left(0, \\sigma^{2}\\right)$, 由定理 5.4 .1 知, $\\frac{1}{\\sigma^{2}} \\sum_{j=1}^{m}\\left(\\varepsilon_{i j}-\\bar{\\varepsilon}_{i} .\\right)^{2}, i=$ $1,2, \\cdots, r$, 相互独立, 其共同分布为 $\\chi^{2}(m-1)$, 由卡方分布的可加性, 有 $\\frac{S_{e}}{\\sigma^{2}} \\sim \\chi^{2}(n-r)$, 这给出 $E\\left(S_{e} / \\sigma^{2}\\right)=$ $n-r=f_{e}$, 1 得证.",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.3 检验方法"
        },
        "type": "Document"
    },
    {
        "page_content": "类似地, 由 (8.1.12) 和 (8.1.15), 有  \n$$\nS_{A}=m \\sum_{i=1}^{r}\\left(a_{i}+\\varepsilon_{i} \\cdot-\\bar{\\varepsilon}\\right)^{2}\n$$  \n由定理 5.4.1 知, 对每个 $i$, 平方和 $\\sum_{j=1}^{m}\\left(\\varepsilon_{i j}-\\bar{\\varepsilon}_{i} .\\right)^{2}$ 与均值 $\\bar{\\varepsilon}_{i}$ 独立, 从而 $\\bar{\\varepsilon}_{1 .}, \\bar{\\varepsilon}_{2 .}, \\cdots, \\bar{\\varepsilon}_{r}$. 与 $S_{e}$ 独立, 而 $S_{A}$ 只是, $\\bar{\\varepsilon}_{1}, \\bar{\\varepsilon}_{2}, \\cdots, \\bar{\\varepsilon}_{r}$. 的函数, 由此 3 得证.  \n在模型 8.1.8下, $S_{A}$ 的期望是  \n$$\nE\\left(S_{A}\\right)=m \\sum_{i=1}^{r} a^{2}+E\\left[m \\sum_{i=1}^{r}\\left(\\bar{\\varepsilon}_{i}-\\bar{\\varepsilon}\\right)^{2}\\right]\n$$  \n由于诸误差均值 $\\bar{\\varepsilon}_{1 .}, \\bar{\\varepsilon}_{2 .}, \\cdots, \\bar{\\varepsilon}_{r}$. 独立同分布于 $N\\left(0, \\sigma^{2} / m\\right)$, 从而由诸误差均值组成的偏差平方和除以 $\\sigma^{2} / m$服从卡方分布, 即  \n$$\n\\frac{1}{\\sigma^{2}} \\sum_{i=1}^{r} m\\left(\\bar{\\varepsilon}_{i},-\\bar{\\varepsilon}\\right)^{2}-\\chi^{2}(r-1) .\n$$",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.3 检验方法"
        },
        "type": "Document"
    },
    {
        "page_content": "在模型 8.1.8下, $S_{A}$ 的期望是  \n$$\nE\\left(S_{A}\\right)=m \\sum_{i=1}^{r} a^{2}+E\\left[m \\sum_{i=1}^{r}\\left(\\bar{\\varepsilon}_{i}-\\bar{\\varepsilon}\\right)^{2}\\right]\n$$  \n由于诸误差均值 $\\bar{\\varepsilon}_{1 .}, \\bar{\\varepsilon}_{2 .}, \\cdots, \\bar{\\varepsilon}_{r}$. 独立同分布于 $N\\left(0, \\sigma^{2} / m\\right)$, 从而由诸误差均值组成的偏差平方和除以 $\\sigma^{2} / m$服从卡方分布, 即  \n$$\n\\frac{1}{\\sigma^{2}} \\sum_{i=1}^{r} m\\left(\\bar{\\varepsilon}_{i},-\\bar{\\varepsilon}\\right)^{2}-\\chi^{2}(r-1) .\n$$  \n于是, $E\\left[\\sum_{i=1}^{r} m\\left(\\bar{\\varepsilon}_{i}-\\bar{\\varepsilon}\\right)\\right]$ 在 $H_{0}$ 成立下, $S_{A} / \\sigma^{2} \\sim \\chi^{2}(r-1)$, 这就完成了 2 的证明.  \n由定理 '8.1.2 知, 若 $H_{0}$ 成立, 则 (8.1.17) 定义的检验统计量 $F$ 服从自由度为 $f_{A}$ 和 $f_{e}$ 的 $F$ 分布, 因此, 由假设检验的一般理论, 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left|F \\geqslant F_{1-\\alpha}\\left(f_{A}, f_{e}\\right)\\right| . \\tag{8.1.18}\n\\end{equation*}\n$$  \n通常将上述计算过程列成一张表格, 称为方差分析表, 见表 8.1.3  \n表 8.1.3: 单因子方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.3 检验方法"
        },
        "type": "Document"
    },
    {
        "page_content": "由定理 '8.1.2 知, 若 $H_{0}$ 成立, 则 (8.1.17) 定义的检验统计量 $F$ 服从自由度为 $f_{A}$ 和 $f_{e}$ 的 $F$ 分布, 因此, 由假设检验的一般理论, 拒绝域为  \n$$\n\\begin{equation*}\nW=\\left|F \\geqslant F_{1-\\alpha}\\left(f_{A}, f_{e}\\right)\\right| . \\tag{8.1.18}\n\\end{equation*}\n$$  \n通常将上述计算过程列成一张表格, 称为方差分析表, 见表 8.1.3  \n表 8.1.3: 单因子方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :---: | :---: | :---: | :---: | :---: |\n| 因子 | $S_{A}$ | $f_{A}=r-1$ | $M S_{A}=S_{A} / f_{A}$ | $F=M S_{A} / M S_{e}$ |\n| 误差 | $S_{e}$ | $f_{e}=n-r$ | $M S_{e}=S_{e} / f_{e}$ |  |\n| 总和 | $S_{T}$ | $f_{T}=n-1$ |  |  |  \n对给定的 $\\alpha$, 可作如下判断:  \n- 如果 $F>F_{1-\\alpha}\\left(f_{A}, f_{e}\\right)$, 则认为因子 $A$ 显著;\n- 若 $F \\leqslant F_{1-\\alpha}\\left(f_{A}, f_{e}\\right)$, 则说明因子 $A$ 不显著.  \n该检验的 $p$ 值也可利用统计软件求出, 若以 $Y$ 记服从 $F\\left(f_{A}, f_{e}\\right)$ 的随机变量, 则检验的 $p$ 值为 $p=P(Y \\geqslant F)$.  \n经过简单推导, 可以给出常用的各偏差平方和的计算公式如下:  \n$$\n\\begin{align*}\nS_{T} & =\\sum_{i=1}^{r} \\sum_{j=1}^{m} y_{i j}^{2}-\\frac{T^{2}}{n} \\\\",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.3 检验方法"
        },
        "type": "Document"
    },
    {
        "page_content": "| 误差 | $S_{e}$ | $f_{e}=n-r$ | $M S_{e}=S_{e} / f_{e}$ |  |\n| 总和 | $S_{T}$ | $f_{T}=n-1$ |  |  |  \n对给定的 $\\alpha$, 可作如下判断:  \n- 如果 $F>F_{1-\\alpha}\\left(f_{A}, f_{e}\\right)$, 则认为因子 $A$ 显著;\n- 若 $F \\leqslant F_{1-\\alpha}\\left(f_{A}, f_{e}\\right)$, 则说明因子 $A$ 不显著.  \n该检验的 $p$ 值也可利用统计软件求出, 若以 $Y$ 记服从 $F\\left(f_{A}, f_{e}\\right)$ 的随机变量, 则检验的 $p$ 值为 $p=P(Y \\geqslant F)$.  \n经过简单推导, 可以给出常用的各偏差平方和的计算公式如下:  \n$$\n\\begin{align*}\nS_{T} & =\\sum_{i=1}^{r} \\sum_{j=1}^{m} y_{i j}^{2}-\\frac{T^{2}}{n} \\\\\nS_{A} & =\\frac{1}{m} \\sum_{i=1}^{r} T_{i}^{2}-\\frac{T^{2}}{n}  \\tag{8.1.19}\\\\\nS_{e} & =S_{T}-S_{A}\n\\end{align*}\n$$  \n一般可将计算过程列表进行, 见下例.  \n例 8.1.2: 采用例 8.1.1 的数据, 由偏差平方和的公式可以看出, 对数据作一个线性变换是不影响方差分析的结果的, 本例中, 我们将原始数据同时减去 1000 , 并用列表的办法给出计算过程:  \n利用 (8.1.19), 可算得各偏差平方和为:  \n$$\nS_{T}=91363-\\frac{1133^{2}}{24}=37876.04\n$$  \n$$\nf_{T}=24-1=23 \\text {, }\n$$  \n表 8.1.4: 例 8.1.2 的计算表  \n| 水平 | 数据 (原始数据 -1000$)$ |  |  |  |  | $T_{i}$ | $T_{i}^{2}$ | $\\sum_{j=1}^{m} y_{i j}^{2}$ |  |  |  |",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.3 检验方法"
        },
        "type": "Document"
    },
    {
        "page_content": "S_{A} & =\\frac{1}{m} \\sum_{i=1}^{r} T_{i}^{2}-\\frac{T^{2}}{n}  \\tag{8.1.19}\\\\\nS_{e} & =S_{T}-S_{A}\n\\end{align*}\n$$  \n一般可将计算过程列表进行, 见下例.  \n例 8.1.2: 采用例 8.1.1 的数据, 由偏差平方和的公式可以看出, 对数据作一个线性变换是不影响方差分析的结果的, 本例中, 我们将原始数据同时减去 1000 , 并用列表的办法给出计算过程:  \n利用 (8.1.19), 可算得各偏差平方和为:  \n$$\nS_{T}=91363-\\frac{1133^{2}}{24}=37876.04\n$$  \n$$\nf_{T}=24-1=23 \\text {, }\n$$  \n表 8.1.4: 例 8.1.2 的计算表  \n| 水平 | 数据 (原始数据 -1000$)$ |  |  |  |  | $T_{i}$ | $T_{i}^{2}$ | $\\sum_{j=1}^{m} y_{i j}^{2}$ |  |  |  |\n| :--- | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |\n| $A_{1}$ | 73 | 9 | 60 | 1 | 2 | 12 | 9 | 28 | 194 | 37636 | 10024 |\n| $A_{2}$ | 107 | 92 | -10 | 109 | 90 | 74 | 122 | 1 | 585 | 342225 | 60355 |\n| $A_{3}$ | 93 | 29 | 80 | 21 | 22 | 32 | 29 | 48 | 354 | 125316 | 20984 |  \n$$\n\\begin{aligned}\n& S_{A}=\\frac{505177}{8}-\\frac{1133^{2}}{24}=9660.08 \\text {, } \\\\\n& f_{A}=3-1=2 \\text {, } \\\\\n& S_{e}=S_{T}-S_{A}=37876.04-9660.08=28215.96 \\text {, } \\\\\n& f_{e}=3(8-1)=21 \\text {. }",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.3 检验方法"
        },
        "type": "Document"
    },
    {
        "page_content": "| $A_{1}$ | 73 | 9 | 60 | 1 | 2 | 12 | 9 | 28 | 194 | 37636 | 10024 |\n| $A_{2}$ | 107 | 92 | -10 | 109 | 90 | 74 | 122 | 1 | 585 | 342225 | 60355 |\n| $A_{3}$ | 93 | 29 | 80 | 21 | 22 | 32 | 29 | 48 | 354 | 125316 | 20984 |  \n$$\n\\begin{aligned}\n& S_{A}=\\frac{505177}{8}-\\frac{1133^{2}}{24}=9660.08 \\text {, } \\\\\n& f_{A}=3-1=2 \\text {, } \\\\\n& S_{e}=S_{T}-S_{A}=37876.04-9660.08=28215.96 \\text {, } \\\\\n& f_{e}=3(8-1)=21 \\text {. }\n\\end{aligned}\n$$  \n把上述诸平方和及其自由度填人方差分析表, 并继续计算得到各均方和以及 $F$ 比, 见表 8.1.5.  \n表 8.1.5: 8.1.2 的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :--- | :---: | :---: | :---: | :---: |\n| 因子 $A$ | 9660.08 | 2 | 4830.04 | 3.59 |\n| 误差 $e$ | 28215.96 | 21 | 1343.62 |  |\n| 总和 $T$ | 37876.04 | 23 |  |  |  \n若取 $a=0.05$, 则 $F_{0.95}(2,21)=3.47$, 由于 $F=3.59>3.47$, 故认为因子 $A$ (饲料) 是显著的,即三种饲料对鸡的增肥作用有明显的差别.",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.3 检验方法"
        },
        "type": "Document"
    },
    {
        "page_content": "在检验结果为显著时, 我们可进一步求出总均值 $\\mu$ 、各主效应 $a_{i}$ 和误差方差 $\\sigma^{2}$ 的估计.",
        "metadata": {
            "Header 2": "三、偏差平方和及其自由度",
            "Header 3": "8.1.4 参数估计"
        },
        "type": "Document"
    },
    {
        "page_content": "由模型 (8.1.8) 知诸 $y_{i j}$ 相互独立, 且 $y_{i j} \\sim N\\left(\\mu+a_{i}, \\sigma^{2}\\right)$, 因此, 可使用最大似然方法求出一般平均 $\\mu$ 、各主效应 $a_{i}$; 和误差方差 $\\sigma^{2}$ 的估计.  \n首先, 写出似然函数  \n$$\nL\\left(\\mu, a_{1}, \\cdots, a_{r}, \\sigma^{2}\\right) \\prod_{i=1}^{r} \\prod_{j=1}^{m}\\left\\{\\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} \\exp \\left\\{-\\frac{\\left(y_{i j}-\\mu-a_{i}\\right)^{2}}{2 \\sigma^{2}}\\right\\}\\right\\}\n$$  \n其对数似然函数为  \n$$\nl\\left(\\mu, a_{1}, \\cdots, a_{r}, \\sigma^{2}\\right)=-\\frac{n}{2} \\ln \\left(2 \\pi \\sigma^{2}\\right)-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n} \\sum_{i=1}^{m}\\left(y_{i j}-\\mu-a_{i}\\right)^{2}\n$$  \n求偏导, 得似然方程为  \n$$\n\\left\\{\\begin{array}{l}\n\\frac{\\partial l}{\\partial \\mu}=\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\mu-a_{i}\\right)=0 \\\\\n\\frac{\\partial l}{\\partial a_{i}}=\\frac{1}{2 \\sigma^{2}} \\sum_{j=1}^{m}\\left(y_{i j}-\\mu-a_{i}\\right)=0, \\quad i=1, \\cdots, r \\\\",
        "metadata": {
            "Header 2": "一。点估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其对数似然函数为  \n$$\nl\\left(\\mu, a_{1}, \\cdots, a_{r}, \\sigma^{2}\\right)=-\\frac{n}{2} \\ln \\left(2 \\pi \\sigma^{2}\\right)-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n} \\sum_{i=1}^{m}\\left(y_{i j}-\\mu-a_{i}\\right)^{2}\n$$  \n求偏导, 得似然方程为  \n$$\n\\left\\{\\begin{array}{l}\n\\frac{\\partial l}{\\partial \\mu}=\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\mu-a_{i}\\right)=0 \\\\\n\\frac{\\partial l}{\\partial a_{i}}=\\frac{1}{2 \\sigma^{2}} \\sum_{j=1}^{m}\\left(y_{i j}-\\mu-a_{i}\\right)=0, \\quad i=1, \\cdots, r \\\\\n\\frac{\\partial l}{\\partial \\sigma^{2}}=-\\frac{n}{2 \\sigma^{2}}+\\frac{1}{2 \\sum^{4}} \\sum_{i=1}^{m} \\sum_{j=1}^{m}\\left(y_{i j}-\\mu-a_{i}\\right)^{2}=0\n\\end{array}\\right.\n$$  \n考虑到约束条件 (8.1.8), 可求出前述各参数的最大似然估计为  \n$$\n\\begin{align*}\n\\hat{\\mu} & =\\bar{y} \\\\\n\\hat{a}_{i} & =\\bar{y}_{i},-\\bar{y}, i=1, \\cdots, r \\\\\n\\hat{\\sigma}_{M}^{2} & =\\frac{1}{n} \\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}\\right)^{2}=\\frac{S_{e}}{n} \\tag{8.1.20}\n\\end{align*}\n$$  \n由最大似然估计的不变性, 各水平均值 $\\mu_{i}$ 的最大似然估计为  \n$$",
        "metadata": {
            "Header 2": "一。点估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\frac{\\partial l}{\\partial \\sigma^{2}}=-\\frac{n}{2 \\sigma^{2}}+\\frac{1}{2 \\sum^{4}} \\sum_{i=1}^{m} \\sum_{j=1}^{m}\\left(y_{i j}-\\mu-a_{i}\\right)^{2}=0\n\\end{array}\\right.\n$$  \n考虑到约束条件 (8.1.8), 可求出前述各参数的最大似然估计为  \n$$\n\\begin{align*}\n\\hat{\\mu} & =\\bar{y} \\\\\n\\hat{a}_{i} & =\\bar{y}_{i},-\\bar{y}, i=1, \\cdots, r \\\\\n\\hat{\\sigma}_{M}^{2} & =\\frac{1}{n} \\sum_{i=1}^{r} \\sum_{j=1}^{m}\\left(y_{i j}-\\bar{y}\\right)^{2}=\\frac{S_{e}}{n} \\tag{8.1.20}\n\\end{align*}\n$$  \n由最大似然估计的不变性, 各水平均值 $\\mu_{i}$ 的最大似然估计为  \n$$\n\\begin{equation*}\n\\hat{\\mu}_{i}=\\bar{y}_{i} \\tag{8.1.21}\n\\end{equation*}\n$$  \n由于 $\\hat{\\sigma}_{M}^{2}$ 不是 $\\sigma^{2}$ 的无偏估计, 实用中通常采用如下误差方差的无偏估计  \n$$\n\\begin{equation*}\n\\hat{\\sigma}_{M}^{2}=M S_{e} \\tag{8.1.22}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "一。点估计"
        },
        "type": "Document"
    },
    {
        "page_content": "以下讨论各水平均值 $\\mu_{i}$ 的置信区间. 由定理 8.1.2 知 $\\bar{y}_{i} . \\sim N\\left(\\mu_{i}, \\sigma^{2} / m\\right)$, 且两者独立, 故 $S_{e} / \\sigma^{2} \\sim \\chi^{2}\\left(f_{e}\\right)$, 且两者独立, 故  \n$$\n\\frac{\\sqrt{m}\\left(\\bar{y}_{i \\cdot}-\\mu_{i}\\right)}{\\sqrt{\\mathrm{S}_{0} / f_{0}}} \\sim t\\left(f_{e}\\right)\n$$  \n由此给出 $A_{i}$ 的水平均值 $\\mu_{i}$ 的 $1-\\alpha$ 的置信区间为  \n$$\n\\begin{equation*}\n\\left[\\bar{y}_{i \\cdot}-\\hat{\\sigma} \\cdot t_{1-\\alpha / 2}\\left(f_{e}\\right) / \\sqrt{m}, \\bar{y}_{i}+\\hat{\\sigma} \\cdot t_{1-\\alpha / 2}\\left(f_{e}\\right) / \\sqrt{m}\\right] \\tag{8.1.23}\n\\end{equation*}\n$$  \n其中 $\\tilde{\\sigma}^{2}$ 由 (8.1.22) 给出.  \n例 8.1.3: 我们在 8.1.2 中已经指出饲料因子是显著的, 此处我们给出诸水平均值的估计. 因子 $A$ 的三个水平均值的估计分别为  \n$$\n\\begin{aligned}\n& \\hat{\\mu}_{1}=1000+\\frac{194}{8}=1024.25 \\\\\n& \\hat{\\mu}_{2}=1000+\\frac{585}{8}=1073.13 \\\\\n& \\hat{\\mu}_{3}=1000+\\frac{354}{8}=1044.25\n\\end{aligned}\n$$  \n从点估计来看, 水平 $A_{2}$ (以槐树粉为主的饲料) 是最优的. 误差方差的无偏估计为  \n$$\n\\hat{\\sigma}^{2}=M S_{e}=1343.62\n$$",
        "metadata": {
            "Header 2": "二、置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n其中 $\\tilde{\\sigma}^{2}$ 由 (8.1.22) 给出.  \n例 8.1.3: 我们在 8.1.2 中已经指出饲料因子是显著的, 此处我们给出诸水平均值的估计. 因子 $A$ 的三个水平均值的估计分别为  \n$$\n\\begin{aligned}\n& \\hat{\\mu}_{1}=1000+\\frac{194}{8}=1024.25 \\\\\n& \\hat{\\mu}_{2}=1000+\\frac{585}{8}=1073.13 \\\\\n& \\hat{\\mu}_{3}=1000+\\frac{354}{8}=1044.25\n\\end{aligned}\n$$  \n从点估计来看, 水平 $A_{2}$ (以槐树粉为主的饲料) 是最优的. 误差方差的无偏估计为  \n$$\n\\hat{\\sigma}^{2}=M S_{e}=1343.62\n$$  \n进一步, 利用 8.1.23 可以给出诸水平均值的置信区间. 此处, $\\sigma^{2}=\\sqrt{1343.62}=36.66$, 若取 $a=$ 0.05 , 则 $t_{1-\\alpha / 2}\\left(f_{e}\\right)=t_{0.975}(21)=2.0796, \\hat{\\sigma} t_{0.975}(21) / \\sqrt{8}=26.95$, 于是三个水平均值的 0.95 置信区间分别为  \n$$\n\\begin{aligned}\n& \\mu_{1}: 1024.25 \\mp 26.95=[997.30,1051.21], \\\\\n& \\mu_{2}: 1073.13 \\mp 26.95=[1046.18,1100.08] \\\\\n& \\mu_{3}: 1044.25 \\mp 26.95=[1017.30,1071.21]\n\\end{aligned}\n$$  \n至此, 我们可以看到: 在单因子试验的数据分析中可得到如下三个结果:  \n- 因子 $A$ 是否显著:\n- 试验的误差方差 $\\sigma^{2}$ 的估计;\n- 诸水平均值 $\\mu_{i}$ 的点估计与区间估计.  \n在因子 $A$ 显著时, 通常只需对较优的水平均值作参数估计, 在因子 $A$ 不显著场合, 参数估计无需进行.",
        "metadata": {
            "Header 2": "二、置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "有时, 每个水平下重复试验次数不全相等, 在这最一般情况下进行方差分析与重复数相等情况下的方差分析极为相似, 只在几处略有差别. 下面我们指出差异之处. $\\cdot$  \n- 数据设从第 $i$ 个水平下的总体获得 $m_{i}$ 个试验结果, 记为 $y_{i 1}, y_{i 2}, \\cdots, y_{i m_{i}}, i=1,2, \\cdots, r$, 故总试验次数为 $n=m_{1}+m_{2}+\\cdots+m_{r}$, 从而, 其统计模型为:  \n$$\n\\left\\{\\begin{array}{l}\ny_{i j}=\\mu_{i}+\\varepsilon_{i v}, \\quad i=1,2, \\cdots, r, \\quad j=1,2, \\cdots, m_{i},  \\tag{8.1.24}\\\\\n\\text { 各 } \\varepsilon_{i j} \\text { 相互独立, 且都服从 } N\\left(0, \\sigma^{2}\\right) .\n\\end{array}\\right.\n$$  \n- 总均值诸 $\\mu_{i}$ 的加权平均 (所有试验结果的均值的平均)  \n$$\n\\begin{equation*}\n\\mu=\\frac{1}{n}\\left(m_{1} \\mu_{1}+\\cdots+m_{n} \\mu_{r}\\right)=\\frac{1}{n} \\sum_{i=1}^{r} m_{i j} \\mu_{z} \\tag{8.1.25}\n\\end{equation*}\n$$  \n称为总均值. 第 $i$ 个水平均值 $\\mu i$ 与总均值 $\\mu$ 的差  \n$$\n\\begin{equation*}\na_{i}=\\mu_{i}-\\mu, \\quad i=1,2, \\cdots, r \\tag{8.1.26}\n\\end{equation*}\n$$  \n称为因子 $A$ 的第 $i$ 个水平的效应.  \n一效应约束条件由 (8.1.25) 和 (8.1.26), 容易看出关于效应的约束条件为  \n$$\n\\sum_{i=1}^{r} m_{i} a_{i}=0\n$$  \n且 $\\mu_{i}=\\mu+a_{i}$, 这表明第 $i$ 个总体的均值是由总均值与该水平的效应叠加而成的. 类似于 (8.1.8), 有  \n$$",
        "metadata": {
            "Header 2": "8.1 .5 重复数不等情形"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\n\\mu=\\frac{1}{n}\\left(m_{1} \\mu_{1}+\\cdots+m_{n} \\mu_{r}\\right)=\\frac{1}{n} \\sum_{i=1}^{r} m_{i j} \\mu_{z} \\tag{8.1.25}\n\\end{equation*}\n$$  \n称为总均值. 第 $i$ 个水平均值 $\\mu i$ 与总均值 $\\mu$ 的差  \n$$\n\\begin{equation*}\na_{i}=\\mu_{i}-\\mu, \\quad i=1,2, \\cdots, r \\tag{8.1.26}\n\\end{equation*}\n$$  \n称为因子 $A$ 的第 $i$ 个水平的效应.  \n一效应约束条件由 (8.1.25) 和 (8.1.26), 容易看出关于效应的约束条件为  \n$$\n\\sum_{i=1}^{r} m_{i} a_{i}=0\n$$  \n且 $\\mu_{i}=\\mu+a_{i}$, 这表明第 $i$ 个总体的均值是由总均值与该水平的效应叠加而成的. 类似于 (8.1.8), 有  \n$$\n\\left\\{\\begin{array}{l}\ny_{i j}=\\mu+a_{i}+\\varepsilon_{i j}, \\quad i=1,2, \\cdots, r, j=1,2, \\cdots, m_{i}  \\tag{8.1.27}\\\\\n\\sum_{i=1}^{r} m_{i} a_{i}=0 \\\\\n\\varepsilon_{i j} \\text { 相互独立, 服从 } N\\left(0, \\sigma^{2}\\right) .\n\\end{array}\\right.\n$$  \n- 各平方和的计算要考虑的问题仍是检验 (8.1.9) 给出的假设. 整个分析思路与方法基本一样,重要的区别是计算公式稍有不同, 特别要注意 $S_{A}$ 的计算公式. 类似地记  \n$$\n\\begin{gathered}\nT_{i}=\\sum_{j=1}^{m_{1}} y_{i j}, \\quad \\bar{y}_{i},=\\frac{T_{i}}{m_{i}} \\\\",
        "metadata": {
            "Header 2": "8.1 .5 重复数不等情形"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\left\\{\\begin{array}{l}\ny_{i j}=\\mu+a_{i}+\\varepsilon_{i j}, \\quad i=1,2, \\cdots, r, j=1,2, \\cdots, m_{i}  \\tag{8.1.27}\\\\\n\\sum_{i=1}^{r} m_{i} a_{i}=0 \\\\\n\\varepsilon_{i j} \\text { 相互独立, 服从 } N\\left(0, \\sigma^{2}\\right) .\n\\end{array}\\right.\n$$  \n- 各平方和的计算要考虑的问题仍是检验 (8.1.9) 给出的假设. 整个分析思路与方法基本一样,重要的区别是计算公式稍有不同, 特别要注意 $S_{A}$ 的计算公式. 类似地记  \n$$\n\\begin{gathered}\nT_{i}=\\sum_{j=1}^{m_{1}} y_{i j}, \\quad \\bar{y}_{i},=\\frac{T_{i}}{m_{i}} \\\\\nT=\\sum_{i=1}^{r} \\sum_{j=1}^{m_{i}} y_{i j}=\\sum_{i=1}^{r} T_{i}, \\quad \\bar{y}=\\frac{T}{n}\n\\end{gathered}\n$$  \n则  \n$$\n\\begin{align*}\n& S_{T}=\\sum_{i=1}^{r} \\sum_{j=1}^{m_{i}}\\left(y_{i j}-\\bar{y}\\right)^{2}=\\sum_{i=1}^{r} \\sum_{j=1}^{\\infty_{i}} y_{i j}^{2}-\\frac{T^{2}}{n}, \\quad f_{T}=n-1 \\\\\n& S_{A}=\\sum_{i=1}^{r} m_{i}\\left(\\bar{y}_{i} \\cdot-\\bar{y}\\right)^{2}=\\sum_{i=1}^{r} \\frac{T_{i}^{2}}{m_{i}}-\\frac{T^{2}}{n}, \\quad f_{A}=r-1  \\tag{8.1.28}\\\\\n& S_{e}=\\sum_{i=1}^{r} \\sum_{i=1}^{m_{3}}\\left(y_{i j}-\\bar{y}_{i}\\right)^{2}=S_{T}-S_{A}, \\quad f_{e}=n-r",
        "metadata": {
            "Header 2": "8.1 .5 重复数不等情形"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{gathered}\n$$  \n则  \n$$\n\\begin{align*}\n& S_{T}=\\sum_{i=1}^{r} \\sum_{j=1}^{m_{i}}\\left(y_{i j}-\\bar{y}\\right)^{2}=\\sum_{i=1}^{r} \\sum_{j=1}^{\\infty_{i}} y_{i j}^{2}-\\frac{T^{2}}{n}, \\quad f_{T}=n-1 \\\\\n& S_{A}=\\sum_{i=1}^{r} m_{i}\\left(\\bar{y}_{i} \\cdot-\\bar{y}\\right)^{2}=\\sum_{i=1}^{r} \\frac{T_{i}^{2}}{m_{i}}-\\frac{T^{2}}{n}, \\quad f_{A}=r-1  \\tag{8.1.28}\\\\\n& S_{e}=\\sum_{i=1}^{r} \\sum_{i=1}^{m_{3}}\\left(y_{i j}-\\bar{y}_{i}\\right)^{2}=S_{T}-S_{A}, \\quad f_{e}=n-r\n\\end{align*}\n$$  \n| 包装类型 | 销售量数据 |  |  | $m_{i}$ | $\\bar{T}$ | $T_{i}^{2} / m_{i}$ | $\\sum_{j=1}^{m_{i}} y_{i j}^{2}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| A1 | 12 | 18 |  | 2 | 30 | 450 | 468 |\n| A2 | 14 | 12 | 13 | 3 | 39 | 507 | 509 |\n| A3 | 19 | 17 | 21 | 3 | 57 | 1083 | 1091 |\n| A4 | 24 | 30 |  | 2 | 54 | 1458 | 1476 |\n| sum |  |  |  | 10 | 180 | 3498 | 3544 |  \n方差分析表以及参数估计是一样的.",
        "metadata": {
            "Header 2": "8.1 .5 重复数不等情形"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{align*}\n$$  \n| 包装类型 | 销售量数据 |  |  | $m_{i}$ | $\\bar{T}$ | $T_{i}^{2} / m_{i}$ | $\\sum_{j=1}^{m_{i}} y_{i j}^{2}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| A1 | 12 | 18 |  | 2 | 30 | 450 | 468 |\n| A2 | 14 | 12 | 13 | 3 | 39 | 507 | 509 |\n| A3 | 19 | 17 | 21 | 3 | 57 | 1083 | 1091 |\n| A4 | 24 | 30 |  | 2 | 54 | 1458 | 1476 |\n| sum |  |  |  | 10 | 180 | 3498 | 3544 |  \n方差分析表以及参数估计是一样的.  \n例 8.1.4: 某食品公司对一种食品设计了四种新包装. 为考察哪种包装最受顾客欢迎, 选了 10 个地段繁华程度相似、规模相近的商店做试验, 其中两种包装各指定两个商店销售, 另两个包装各指定三个商店销售. 在试验期内各店货架排放的位置、空间都相同, 营业员的促销方法也基本相同, 经过一段时间, 记录其销售量数据, 列于表 8.1.6 左半边, 其相应的计算结果列于右侧.  \n表 8.1.6: 销售量数据及计算表  \n由此可求得各类偏差平方和如下 $\\left(\\frac{T^{2}}{n}=\\frac{180^{2}}{10}=3240\\right)$.  \n$$\nS_{T}=91363-\\frac{1133^{2}}{24}=37876.04, \\quad f_{T}=24-1=23\n$$  \n$$\n\\begin{aligned}\n& S_{A}=\\frac{505177}{8}-\\frac{1133^{2}}{24}=9660.08, \\quad f_{A}=3-1=2 \\text {, } \\\\\n& S_{e}=S_{T}-S_{A}=37876.04-9660.08=28215.96, \\quad f_{e}=3(8-1)=21\n\\end{aligned}\n$$  \n方差分析表如表 8.1.7 所示.",
        "metadata": {
            "Header 2": "8.1 .5 重复数不等情形"
        },
        "type": "Document"
    },
    {
        "page_content": "表 8.1.6: 销售量数据及计算表  \n由此可求得各类偏差平方和如下 $\\left(\\frac{T^{2}}{n}=\\frac{180^{2}}{10}=3240\\right)$.  \n$$\nS_{T}=91363-\\frac{1133^{2}}{24}=37876.04, \\quad f_{T}=24-1=23\n$$  \n$$\n\\begin{aligned}\n& S_{A}=\\frac{505177}{8}-\\frac{1133^{2}}{24}=9660.08, \\quad f_{A}=3-1=2 \\text {, } \\\\\n& S_{e}=S_{T}-S_{A}=37876.04-9660.08=28215.96, \\quad f_{e}=3(8-1)=21\n\\end{aligned}\n$$  \n方差分析表如表 8.1.7 所示.  \n表 8.1.7: 8.1.4 的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :--- | :---: | :---: | :---: | :---: |\n| 因子 $A$ | 258 | 3 | 86 | 11.22 |\n| 误差 $e$ | 46 | 6 | 7.67 |  |\n| 总和 $T$ | 304 | 9 |  |  |  \n若取 $\\alpha=0.01$, 查表得 $F_{0.01}(3,6)=9.78$, 由于 $F=11.22>9.78$, 故我们可认为各水平间有显著差异.  \n由于因子显著, 我们还可以给出诸水平均值的估计. 因子 $A$ 的四个水平均值的估计分别为  \n$$\n\\begin{array}{ll}\n\\hat{\\mu}_{1}=30 / 2=15, & \\hat{\\mu}_{2}=39 / 3=13 \\\\\n\\hat{\\mu}_{3}=57 / 3=19, & \\bar{\\mu}_{4}=54 / 2=27\n\\end{array}\n$$  \n由此可见,第四种包装方式效果最好. 误差方差的无偏估计为  \n$$\n\\dot{\\sigma}^{2}=M S_{e}=7.67\n$$",
        "metadata": {
            "Header 2": "8.1 .5 重复数不等情形"
        },
        "type": "Document"
    },
    {
        "page_content": "| :--- | :---: | :---: | :---: | :---: |\n| 因子 $A$ | 258 | 3 | 86 | 11.22 |\n| 误差 $e$ | 46 | 6 | 7.67 |  |\n| 总和 $T$ | 304 | 9 |  |  |  \n若取 $\\alpha=0.01$, 查表得 $F_{0.01}(3,6)=9.78$, 由于 $F=11.22>9.78$, 故我们可认为各水平间有显著差异.  \n由于因子显著, 我们还可以给出诸水平均值的估计. 因子 $A$ 的四个水平均值的估计分别为  \n$$\n\\begin{array}{ll}\n\\hat{\\mu}_{1}=30 / 2=15, & \\hat{\\mu}_{2}=39 / 3=13 \\\\\n\\hat{\\mu}_{3}=57 / 3=19, & \\bar{\\mu}_{4}=54 / 2=27\n\\end{array}\n$$  \n由此可见,第四种包装方式效果最好. 误差方差的无偏估计为  \n$$\n\\dot{\\sigma}^{2}=M S_{e}=7.67\n$$  \n进一步, 利用 (8.1.23) 也可以给出诸水平均值的置信区间, 只是在这里要用不同的 $m_{i}$ 代替那里相同的 $m$. 此处, $\\hat{\\sigma}=\\sqrt{7.67}=2.7695$, 若取 $\\alpha=0.05$, 则 $t_{1-a / 2}\\left(f_{8}\\right)=t_{0.975}(6)=2.4469, \\hat{\\sigma} t_{0.975}(6)=$ 6.7767, 于是效果较好的第三和第四个水平均值的 0.95 置信区间分别为  \n$$\n\\begin{aligned}\n& \\mu_{3}: 19 \\pm 6.7767 / \\sqrt{3}=[15.09,22.91] \\\\\n& \\mu_{4}: 27 \\pm 6.7767 / \\sqrt{2}=[22.21,31.79]\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "8.1 .5 重复数不等情形"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 在一个单因子试验中, 因子 $A$ 有三个水平, 每个水平下各重复 4 次, 具体数据如下:  \n\\$\\$  \n\\$\\$  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :---: | :---: | :---: | :---: | :---: |\n| 因子 $A$ | 4.2 |  |  |  |\n| 误差 $e$ | 2.5 |  |  |  |\n| 和 $T$ | 6.7 |  |  |  |  \n试计算误差平方和 $S_{e}$ 、因子 $A$ 的平方和 $S_{A}$ 、总平方和 $S_{T}$, 并指出它们各自的自由度.  \n2. 在一个单因子试验中, 因子 $A$ 有 4 个水平, 每个水平下重复次数分别为 $5,7,6,8$. 那么误差平方和、 $\\mathrm{A}$ 的平方和及总平方和的自由度各是多少?\n3. 在单因子试验中, 因子 $A$ 有 4 个水平, 每个水平下各重复 3 次试验, 现已求得每个水平下试验结果的样本标准差分别为 $1.5,2.0,1.6,1.2$, 则其误差平方和为多少? 误差的方差 02 的估计值是多少?\n4. 在单因子方差分析中, 因子 $A$ 有三个水平, 每个水平各做 4 次重复试验, 请完成下列方拳分析表, 并在显著性水平 $\\alpha=0.05$ 下对因子 $\\mathrm{A}$ 是否显著作出检验.  \n方差分析表  \n5. 用 4 种安眠药在兔子身上进行试验, 特选 24 只健康的兔子, 随机把它们均分为 4 组, 每组各服一种安曝药, 安眠时间如下所示.",
        "metadata": {
            "Header 2": "习题 8.1"
        },
        "type": "Document"
    },
    {
        "page_content": "| 安眠药 | 安眠时间 $/ \\mathrm{h}$ |  |  |  |  |  |\n| :--- | ---: | ---: | ---: | ---: | ---: | ---: |\n| $A_{1}$ | 6.2 | 6.1 | 6 | 6.3 | 6.1 | 5.9 |\n| $A_{2}$ | 6.3 | 6.5 | 6.7 | 6.6 | 7.1 | 6.4 |\n| $A_{3}$ | 6.8 | 7.1 | 6.6 | 6.8 | 6.9 | 6.6 |\n| $A_{4}$ | 5.4 | 6.4 | 6.2 | 6.3 | 6.0 | 5.9 |  \n在显著性水平 $\\alpha=0.05$ 下对其进行方差分析, 可以得到什么结果?  \n6. 为研究咖啡因对人体功能的影响, 特选 30 名体质大致相同的链康的男大学生进行手指吒击训练, 此外咖啡因选三个水平:  \n$$\nA_{1}=0 \\mathrm{mg}, \\quad A_{2}=100 \\mathrm{mg}, \\quad A_{3}=200 \\mathrm{mg} .\n$$  \n每个水平下冲泡 10 杯水, 外观无差别, 并加以编号, 然后让 30 位大学生每人从中任选一杯服下, $2 \\mathrm{~h}$ 后, 请每人做手指吒击, 统计员记录其每分钟吒击次数, 试验结果统计如下表:  \n| 咖啡因剂量 | 吒击次数 |  |  |  |  |  |  |  |  |  |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| $A_{1}: 0 \\mathrm{mg}$ | 242 | 245 | 244 | 248 | 247 | 248 | 242 | 244 | 246 | 242 |\n| $A_{2}: 100 \\mathrm{mg}$ | 248 | 246 | 245 | 247 | 248 | 250 | 247 | 246 | 243 | 244 |\n| $A_{3}: 200 \\mathrm{mg}$ | 246 | 248 | 250 | 252 | 248 | 250 | 246 | 248 | 245 | 250 |",
        "metadata": {
            "Header 2": "安眠药试验数据"
        },
        "type": "Document"
    },
    {
        "page_content": "每个水平下冲泡 10 杯水, 外观无差别, 并加以编号, 然后让 30 位大学生每人从中任选一杯服下, $2 \\mathrm{~h}$ 后, 请每人做手指吒击, 统计员记录其每分钟吒击次数, 试验结果统计如下表:  \n| 咖啡因剂量 | 吒击次数 |  |  |  |  |  |  |  |  |  |\n| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n| $A_{1}: 0 \\mathrm{mg}$ | 242 | 245 | 244 | 248 | 247 | 248 | 242 | 244 | 246 | 242 |\n| $A_{2}: 100 \\mathrm{mg}$ | 248 | 246 | 245 | 247 | 248 | 250 | 247 | 246 | 243 | 244 |\n| $A_{3}: 200 \\mathrm{mg}$ | 246 | 248 | 250 | 252 | 248 | 250 | 246 | 248 | 245 | 250 |  \n请对上述数据进行方差分析, 从中可得到什么结论?  \n7. 某粮食加工厂试验三种储藏方法对粮食含水率有无显着影响. 现取一批粮食分成若干份, 分别用三种不同的方法储藏, 过一段时间后测得的含水率如下表:  \n| 储藏方法 | 含水率数据 |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $A_{1}$ | 7.3 | 8.3 | 7.6 | 8.4 | 8.3 |\n| $A_{2}$ | 5.4 | 7.4 | 7.1 | 6.8 | 5.3 |\n| $A_{3}$ | 7.9 | 9.5 | 10 | 9.8 | 8.4 |  \n（1）假定各种方法储戴的粮食的含水率服从正态分布, 且方差相等, 试在 $\\mathrm{a}=0.05$ 水平下检验这三种方法对含水率有无显着影响;  \n(2) 对每种方法的平均含水率给出置信水平为 0.95 的置信区间.",
        "metadata": {
            "Header 2": "安眠药试验数据"
        },
        "type": "Document"
    },
    {
        "page_content": "请对上述数据进行方差分析, 从中可得到什么结论?  \n7. 某粮食加工厂试验三种储藏方法对粮食含水率有无显着影响. 现取一批粮食分成若干份, 分别用三种不同的方法储藏, 过一段时间后测得的含水率如下表:  \n| 储藏方法 | 含水率数据 |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $A_{1}$ | 7.3 | 8.3 | 7.6 | 8.4 | 8.3 |\n| $A_{2}$ | 5.4 | 7.4 | 7.1 | 6.8 | 5.3 |\n| $A_{3}$ | 7.9 | 9.5 | 10 | 9.8 | 8.4 |  \n（1）假定各种方法储戴的粮食的含水率服从正态分布, 且方差相等, 试在 $\\mathrm{a}=0.05$ 水平下检验这三种方法对含水率有无显着影响;  \n(2) 对每种方法的平均含水率给出置信水平为 0.95 的置信区间.  \n8. 在人户推销上有五种方法, 某大公司想比较这五种方法有无显着的效果差异, 设计了一项实验:从应聘的且无推销经验的人员中随机挑选一部分人, 将他们随机地分为五个组, 每一组用一种推销方法进行培训, 培训相同时间后观宗他们在一个月内的推销额, 数据如下：  \n| 组别 | 推销额/千元 |  |  |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 第一组 | 20 | 16.8 | 17.9 | 21.2 | 23.9 | 26.8 | 22.4 |\n| 第二组 | 24.9 | 21.3 | 22.6 | 30.2 | 29.9 | 22.5 | 20.7 |\n| 第三组 | 16 | 20.1 | 17.3 | 20.9 | 22 | 26.8 | 20.8 |\n| 第四组 | 17.5 | 18.2 | 20.2 | 17.7 | 19.1 | 18.4 | 16.5 |\n| 第五组 | 25.2 | 26.2 | 26.9 | 29.3 | 30.4 | 29.7 | 28.2 |",
        "metadata": {
            "Header 2": "安眠药试验数据"
        },
        "type": "Document"
    },
    {
        "page_content": "| 组别 | 推销额/千元 |  |  |  |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 第一组 | 20 | 16.8 | 17.9 | 21.2 | 23.9 | 26.8 | 22.4 |\n| 第二组 | 24.9 | 21.3 | 22.6 | 30.2 | 29.9 | 22.5 | 20.7 |\n| 第三组 | 16 | 20.1 | 17.3 | 20.9 | 22 | 26.8 | 20.8 |\n| 第四组 | 17.5 | 18.2 | 20.2 | 17.7 | 19.1 | 18.4 | 16.5 |\n| 第五组 | 25.2 | 26.2 | 26.9 | 29.3 | 30.4 | 29.7 | 28.2 |  \n(1) 假定数据满足进行方差分析的假定, 对数据进行分析, 在 $\\alpha=0.05$ 下, 这五种方法在平均月推销额上有无显着差异?  \n(2) 哪种推销方法的效果最好? 试对该种方法一个月的平均推销额求置信水平为 0.95 的置信区间.",
        "metadata": {
            "Header 2": "安眠药试验数据"
        },
        "type": "Document"
    },
    {
        "page_content": "如果方差分析的结果因子 $A$ 显著, 则等于说有充分理由认为因子 $A$ 各水平的效应不全相同,但这并不是说它们中一定没有相同的. 就指定的一对水平 $A_{i}$ 与 $A_{j}$, 我们可通过求 $\\mu_{i}-\\mu_{j}$ 的区间估计来进行比较, 方法如下:由 (8.1.27) 可以推出  \n$$\n\\bar{y}_{i \\cdot}-\\bar{y}_{j .} \\sim N\\left(\\mu_{i}-\\mu_{j},\\left(\\frac{1}{m_{i}}+\\frac{1}{m_{j}}\\right) \\sigma^{2}\\right)\n$$  \n而定理 8.1.2 指出 $S_{e} / \\sigma^{2} \\sim \\chi^{2}\\left(f_{e}\\right)$, 且两者独立, 故  \n$$\n\\frac{\\left(\\bar{y}_{i} \\cdot-\\bar{y}_{j}\\right)-\\left(\\mu_{i}-\\mu_{j}\\right)}{\\sqrt{\\left(\\frac{1}{m_{i}}+\\frac{1}{m_{i}}\\right) \\frac{S_{e}}{f_{e}}}}\n$$  \n由此给出 $\\mu_{i}-\\mu_{j}$ 的置信水平为 $1-\\alpha$ 的置信区间为  \n$$\n\\begin{equation*}\n\\left[\\bar{y}_{i \\cdot}-\\bar{y}_{j \\cdot}-\\sqrt{\\left(\\frac{1}{m_{i}}+\\frac{1}{m_{j}}\\right)} \\hat{\\sigma} \\cdot t_{1-\\frac{\\alpha}{2}}\\left(f_{e}\\right), \\bar{y}_{i},-\\bar{y}_{j}+\\sqrt{\\left(\\frac{1}{m_{i}}+\\frac{1}{m_{j}}\\right)} \\hat{\\sigma} \\cdot t_{1-\\frac{\\alpha}{2}}\\left(f_{e}\\right)\\right] \\tag{8.2.1}\n\\end{equation*}\n$$  \n其中 $\\hat{\\sigma}^{2}$ 是 $\\sigma^{2}$ 的无偏估计.",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.1 效应差的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n由此给出 $\\mu_{i}-\\mu_{j}$ 的置信水平为 $1-\\alpha$ 的置信区间为  \n$$\n\\begin{equation*}\n\\left[\\bar{y}_{i \\cdot}-\\bar{y}_{j \\cdot}-\\sqrt{\\left(\\frac{1}{m_{i}}+\\frac{1}{m_{j}}\\right)} \\hat{\\sigma} \\cdot t_{1-\\frac{\\alpha}{2}}\\left(f_{e}\\right), \\bar{y}_{i},-\\bar{y}_{j}+\\sqrt{\\left(\\frac{1}{m_{i}}+\\frac{1}{m_{j}}\\right)} \\hat{\\sigma} \\cdot t_{1-\\frac{\\alpha}{2}}\\left(f_{e}\\right)\\right] \\tag{8.2.1}\n\\end{equation*}\n$$  \n其中 $\\hat{\\sigma}^{2}$ 是 $\\sigma^{2}$ 的无偏估计.  \n例 8.2.1: 在例 8.1.2 中, 我们已知饲料因子是显著的, 此处 $m_{1}=m_{2}=m_{3}=8, f_{e}=21, \\hat{\\sigma}=$ $\\sqrt{1343.62}=36.66$, 若取 $\\alpha=0.05$, 则 $t_{1-\\alpha / 2}\\left(f_{e}\\right)=t_{0.975}(21)=2.0796, \\sqrt{1 / 8+1 / 8} \\hat{\\sigma} t_{0.975}(21)=$ 38.11, 于是可算出各个置信区闻为  \n$$\n\\begin{aligned}\n& \\mu_{1}-\\mu_{2}:-48.88 \\pm 38.11=[-86.99,-10.77] \\\\\n& \\mu_{1}-\\mu_{3}:-20 \\pm 38.11=[-58.11,18.11] \\\\\n& \\mu_{2}-\\mu_{3}: 28.88 \\pm 38.11=[-9.23,66.99]\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.1 效应差的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其中 $\\hat{\\sigma}^{2}$ 是 $\\sigma^{2}$ 的无偏估计.  \n例 8.2.1: 在例 8.1.2 中, 我们已知饲料因子是显著的, 此处 $m_{1}=m_{2}=m_{3}=8, f_{e}=21, \\hat{\\sigma}=$ $\\sqrt{1343.62}=36.66$, 若取 $\\alpha=0.05$, 则 $t_{1-\\alpha / 2}\\left(f_{e}\\right)=t_{0.975}(21)=2.0796, \\sqrt{1 / 8+1 / 8} \\hat{\\sigma} t_{0.975}(21)=$ 38.11, 于是可算出各个置信区闻为  \n$$\n\\begin{aligned}\n& \\mu_{1}-\\mu_{2}:-48.88 \\pm 38.11=[-86.99,-10.77] \\\\\n& \\mu_{1}-\\mu_{3}:-20 \\pm 38.11=[-58.11,18.11] \\\\\n& \\mu_{2}-\\mu_{3}: 28.88 \\pm 38.11=[-9.23,66.99]\n\\end{aligned}\n$$  \n可见第一个区间在 0 的左边, 所以我们可以概率 $95 \\%$ 断言认为 $\\mu_{1}$ 小于 $\\mu_{2}$, 其他两个区间包含 0 点, 虽然从点估计角度看水平均值估计有差别, 但这种差异在 0.05 水平上是不显著的.  \n我们看到,(8.2.1) 给出的置信区间与第六章中的两样本的 $t$ 区间基本一致, 区别在于这里 $\\sigma^{2}$的估计使用了全部样本而不仅仅是 $A_{i}, A_{j}$ 两个水平下的观测值.",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.1 效应差的置信区间"
        },
        "type": "Document"
    },
    {
        "page_content": "这里遇到一个新的问题, 对每一组 $(i, j),(8.1$. 2 给出的区间的置信水平都是 $1-\\alpha$, 但对多个这样的区间, 要求其同时成立, 其联合置信水平就不再是 $1-\\alpha$ 了. 譬如, 设 $E_{1}, \\cdots, E_{k}$ 是 $k$ 个随机事件, 且有 $P\\left(E_{i}\\right)=1-\\alpha, i=1, \\cdots, k$, 则其同时发生的概率  \n$$\n\\begin{equation*}\nP\\left(\\bigcap_{i=1}^{k} E_{i}\\right)=1-P\\left(\\bigcup_{i=1}^{k} \\bar{E}_{i}\\right) \\geqslant 1-\\sum_{i=1}^{k} P\\left(\\bar{E}_{i}\\right)=1-k \\alpha \\tag{8.2.2}\n\\end{equation*}\n$$  \n这说明它们同时发生的概率可能比 $1-\\alpha$ 小很多. 为了使它们同时发生的概率不低于 $1-\\alpha$, 一个办法是把每个事件发生的概率提高到 $1-a / k$. 比如, 如果我们同时考虑所有的 $k=r(r-1) / 2$组对比 $\\mu_{i}-\\mu_{j}$ 的置信区间, 则在 (8.2.1) 中将 $t_{1-\\alpha / 2}\\left(f_{e}\\right)$ 替换为 $t_{1-\\alpha /(2 k)}\\left(f_{e}\\right)$ 即可. 这将导致每个置信区间过长, 联合置信区间的精度很差, 一般人们不采用这种方法, 而是采用我们下面介绍的多重比较来解决上述问题.  \n在方差分析中, 如果经过 $\\mathrm{F}$ 检验拒绝原假设, 表明因子 $A$ 是显著的, 即 $r$ 个水平对应的水平均值不全相等, 此时, 我们还需要进一步确认哪些水平均值间是确有差异的, 哪些水平均值间无显著差异.  \n在 $r(r>2)$ 个水平均值中同时比较任意两个水平均值间有无明显差异的问题称为多意比较,\n多重比较即要以显著性水平 $a$ 同时检验如下 $r(r-1) / 2$ 个假设  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.2 多重比较问题"
        },
        "type": "Document"
    },
    {
        "page_content": "在方差分析中, 如果经过 $\\mathrm{F}$ 检验拒绝原假设, 表明因子 $A$ 是显著的, 即 $r$ 个水平对应的水平均值不全相等, 此时, 我们还需要进一步确认哪些水平均值间是确有差异的, 哪些水平均值间无显著差异.  \n在 $r(r>2)$ 个水平均值中同时比较任意两个水平均值间有无明显差异的问题称为多意比较,\n多重比较即要以显著性水平 $a$ 同时检验如下 $r(r-1) / 2$ 个假设  \n$$\n\\begin{equation*}\nH_{0}^{i j}: \\mu_{i}=\\mu_{j}, \\quad 1 \\leqslant i<j \\leqslant r . \\tag{8.2.3}\n\\end{equation*}\n$$  \n直观地看, 当 $H_{0}^{i j}$ 成立时, $\\mid \\bar{y}_{i} .-\\bar{y}_{j}$. $\\mid$ 不应过大, 因此, 关子假设 (8.2.3) 的拒绝域应有如下形式  \n$$\nW=\\bigcup_{1 \\leqslant i<j \\leqslant r}\\left\\{\\left|\\bar{y}_{i}-\\bar{y}_{j .}\\right| \\geqslant \\varepsilon_{i j}\\right\\}\n$$  \n诸临界值应 (8.2.3) 成立时由 $P(W)=a$ 确定. 下面分重复数相等和不等分别介绍临界值的确定.",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.2 多重比较问题"
        },
        "type": "Document"
    },
    {
        "page_content": "在重复数相等时, 由对称性自然可以要求诸 $\\varepsilon_{i j}$ 相等, 记为 $c$. 记 $\\hat{\\sigma^{2}}=S_{e} / f_{e}$, 则由给定条件不难有  \n$$\nt_{i}=\\frac{\\bar{y}_{i \\cdot}-\\mu_{i}}{\\hat{\\sigma} / \\sqrt{m}} \\sim t\\left(f_{e}\\right)\n$$  \n于是当 (8.2.3) 成立时, $\\mu_{1}=\\cdots=\\mu_{r}=\\mu$, 故有  \n$$\n\\begin{aligned}\nP(W) & =P\\left(\\bigcup_{1 \\leqslant i<j \\leqslant r}\\left\\{\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right| \\geqslant c\\right\\}\\right) \\\\\n& =1-P\\left(\\bigcap_{1 \\leqslant i<j \\leqslant r}\\left\\{\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right|<c\\right\\}\\right) \\\\\n& =1-P\\left(\\max _{1 \\leqslant i<j \\leqslant r}\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right|<c\\right) \\\\\n& =P\\left(\\max _{1 \\leqslant i \\leqslant j \\leqslant r}\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right| \\geqslant c\\right) \\\\\n& =P\\left(\\max _{1 \\leqslant i<j \\leqslant r \\mid}\\left|\\frac{\\left(\\bar{y}_{i}-\\mu\\right)-\\left(\\bar{y}_{j \\cdot}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}}\\right| \\geqslant \\frac{c}{\\hat{\\sigma} / \\sqrt{m}}\\right) \\\\",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.3 重复数相等场合的 $T$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "& =1-P\\left(\\max _{1 \\leqslant i<j \\leqslant r}\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right|<c\\right) \\\\\n& =P\\left(\\max _{1 \\leqslant i \\leqslant j \\leqslant r}\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right| \\geqslant c\\right) \\\\\n& =P\\left(\\max _{1 \\leqslant i<j \\leqslant r \\mid}\\left|\\frac{\\left(\\bar{y}_{i}-\\mu\\right)-\\left(\\bar{y}_{j \\cdot}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}}\\right| \\geqslant \\frac{c}{\\hat{\\sigma} / \\sqrt{m}}\\right) \\\\\n& =P\\left(\\max _{i} \\frac{\\left(\\bar{y}_{i \\cdot}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}}-\\min _{j} \\frac{\\left(\\bar{y}_{j \\cdot}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}} \\geqslant \\frac{c}{\\hat{\\sigma} / \\sqrt{m}}\\right)\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.3 重复数相等场合的 $T$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "& =P\\left(\\max _{1 \\leqslant i<j \\leqslant r \\mid}\\left|\\frac{\\left(\\bar{y}_{i}-\\mu\\right)-\\left(\\bar{y}_{j \\cdot}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}}\\right| \\geqslant \\frac{c}{\\hat{\\sigma} / \\sqrt{m}}\\right) \\\\\n& =P\\left(\\max _{i} \\frac{\\left(\\bar{y}_{i \\cdot}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}}-\\min _{j} \\frac{\\left(\\bar{y}_{j \\cdot}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}} \\geqslant \\frac{c}{\\hat{\\sigma} / \\sqrt{m}}\\right)\n\\end{aligned}\n$$  \n这里 $q\\left(r, f_{e}\\right)=\\max _{i} \\frac{\\left(\\bar{y}_{i}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}}-\\min _{j} \\frac{\\left(\\bar{y}_{j}-\\mu\\right)}{\\hat{\\sigma} / \\sqrt{m}}$ 一般称为 $t$ 化极差统计量, 这是因为它的结构类似子 $t$统计量 $q\\left(r, f_{e}\\right)$ 的分布与参数 $\\mu, \\sigma^{2}$ 无关, 也与 $m$ 无关, 该分布可由随机模拟方法得到, 方法如下 (不妨设 $\\mu=0, \\sigma^{2}=1, m=1$ ): 对给定的 $r$ 和 $f_{e}$,  \n(1) 从标准正态分布 $N(0,1)$ 产生 $r$ 个随机数 $x_{1}, \\cdots, x_{r}$, 将该 $r$ 个随机数按从小到大排序得到 $x_{(1)}$ 和 $x_{(r))}$;  \n(2) 从自由度为 $f_{e}$ 的 $\\chi^{2}$ 分布 $\\chi^{2}\\left(f_{e}\\right)$ 产生一个随机数 $y$;",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.3 重复数相等场合的 $T$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "(1) 从标准正态分布 $N(0,1)$ 产生 $r$ 个随机数 $x_{1}, \\cdots, x_{r}$, 将该 $r$ 个随机数按从小到大排序得到 $x_{(1)}$ 和 $x_{(r))}$;  \n(2) 从自由度为 $f_{e}$ 的 $\\chi^{2}$ 分布 $\\chi^{2}\\left(f_{e}\\right)$ 产生一个随机数 $y$;  \n(3) 计算 $\\left.g=\\left(x_{(r)}-x_{(1)}\\right)\\right) / y$;  \n(4) 重复 (1) 到 (3) $N$ (例如 $10^{4}$ 或 $\\left.10^{5}\\right)$ 次, 即得 $g(r, f)$ 的 $N$ 个观测值, 由此可获得 $q(r, f)$ 的各种分位数.  \n于是, 由  \n$$\n\\begin{equation*}\nP(W)=P\\left(q\\left(r, f_{e}\\right)\\right) \\geqslant \\sqrt{m} c / \\hat{\\sigma}=\\alpha, \\tag{8.2.4}\n\\end{equation*}\n$$  \n可以得出  \n$$\n\\begin{equation*}\nc=q_{1-\\alpha}\\left(r, f_{e}\\right) \\hat{\\sigma} / \\sqrt{m} \\tag{8.2.5}\n\\end{equation*}\n$$  \n其中 $q_{1-\\alpha}\\left(r, f_{e}\\right)$ 表示 $g(r, f)$ 的 $1-\\alpha$ 分位数, 其值在附表 8 中给出.  \n至此, 可将重复数相同时多重比较的步骤总结如下: 对给定的显著性水平 $\\alpha$, 查多重比较的分\n位数 $q_{1-\\alpha}(r, f)$ 表, 计算 $c=q_{1-\\alpha}\\left(r, f_{e}\\right) \\hat{\\sigma} / \\sqrt{m}$, 比较诸 $\\left|\\bar{y}_{i}-\\bar{y}_{j}\\right|$ 与 $c$ 的大小, 若  \n$$\n\\mid \\bar{y}_{i} .-\\bar{y}_{j} . \\geqslant c\n$$",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.3 重复数相等场合的 $T$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n可以得出  \n$$\n\\begin{equation*}\nc=q_{1-\\alpha}\\left(r, f_{e}\\right) \\hat{\\sigma} / \\sqrt{m} \\tag{8.2.5}\n\\end{equation*}\n$$  \n其中 $q_{1-\\alpha}\\left(r, f_{e}\\right)$ 表示 $g(r, f)$ 的 $1-\\alpha$ 分位数, 其值在附表 8 中给出.  \n至此, 可将重复数相同时多重比较的步骤总结如下: 对给定的显著性水平 $\\alpha$, 查多重比较的分\n位数 $q_{1-\\alpha}(r, f)$ 表, 计算 $c=q_{1-\\alpha}\\left(r, f_{e}\\right) \\hat{\\sigma} / \\sqrt{m}$, 比较诸 $\\left|\\bar{y}_{i}-\\bar{y}_{j}\\right|$ 与 $c$ 的大小, 若  \n$$\n\\mid \\bar{y}_{i} .-\\bar{y}_{j} . \\geqslant c\n$$  \n则认为水平 $A_{i}$ 与水平 $A_{j}$ 间有显著差异, 反之, 则认为水平 $A_{i}$ 与水平 $A_{j}$ 间无明显差别. 这一方法最早由 Turkey 提出, 因此称为 $T$ 法.  \n例 8.2.2: 我们已在例 8.1.2 中指出饲料因于是显著的, 下面进行多重比较, 若取 $\\alpha=0.05$, 则查表知 $q_{1-0.05}(3,21)=3.57$, 而 $\\hat{\\sigma}=36.6554$. 所以 $c=3.57 \\times 36.6554 / \\sqrt{8}=46.27$.  \n$\\left|\\bar{y}_{1 .}-\\bar{y}_{2 .}\\right|=|1024.25-1073.13|=48.88>46.27$, 认为 $\\mu_{1}$ 与 $\\mu_{2}$ 有显著差别;  \n$\\left|\\bar{y}_{1 .}-\\bar{y}_{3 .}\\right|=|1024.25-1044.25|=20<46.27$, 认为 $\\mu_{1}$ 与 $\\mu_{3}$ 无显著差别 $;$",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.3 重复数相等场合的 $T$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n则认为水平 $A_{i}$ 与水平 $A_{j}$ 间有显著差异, 反之, 则认为水平 $A_{i}$ 与水平 $A_{j}$ 间无明显差别. 这一方法最早由 Turkey 提出, 因此称为 $T$ 法.  \n例 8.2.2: 我们已在例 8.1.2 中指出饲料因于是显著的, 下面进行多重比较, 若取 $\\alpha=0.05$, 则查表知 $q_{1-0.05}(3,21)=3.57$, 而 $\\hat{\\sigma}=36.6554$. 所以 $c=3.57 \\times 36.6554 / \\sqrt{8}=46.27$.  \n$\\left|\\bar{y}_{1 .}-\\bar{y}_{2 .}\\right|=|1024.25-1073.13|=48.88>46.27$, 认为 $\\mu_{1}$ 与 $\\mu_{2}$ 有显著差别;  \n$\\left|\\bar{y}_{1 .}-\\bar{y}_{3 .}\\right|=|1024.25-1044.25|=20<46.27$, 认为 $\\mu_{1}$ 与 $\\mu_{3}$ 无显著差别 $;$  \n$\\left|\\bar{y}_{2 .}-\\bar{y}_{3 .}\\right|=|1073.13-1044.25|=46.88>46.27$, 认为 $\\mu_{2}$ 与 $\\mu_{2}$ 有显著差别.  \n由此可见, $\\mu_{1}$ 与 $\\mu_{3}$ 之间无显著差别, 而它们与 $\\mu_{2}$ 之间都有显著差异, 即以鱼粉为主的饲料与以苜着粉为主的饲料在鸡的增重方面差别不明显, 但以槐树粉为主的饲料则明显更有效.",
        "metadata": {
            "Header 2": "8.2 多重比较",
            "Header 3": "8.2.3 重复数相等场合的 $T$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "在重复数不等时, 沿用上面的记号, 我们有  \n$$\n\\frac{\\left(\\bar{y}_{i .}-\\bar{y}_{j .}\\right)-\\left(\\mu_{i}-\\mu_{j}\\right)}{\\sqrt{\\frac{1}{m_{i}}+\\frac{1}{m_{j}}} \\hat{\\sigma}} \\sim t\\left(f_{e}\\right)\n$$  \n在假设 (8.2.3) 成立时, $\\mu_{1}=\\cdots=\\mu_{r}=\\mu$,于是有  \n$$\nt_{i j}=\\frac{\\left(\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right)}{\\sqrt{\\frac{1}{m_{i}}+\\frac{1}{m_{j}}} \\hat{\\sigma}} \\sim t\\left(f_{e}\\right) \\quad \\text { 或 } F_{i j}=\\frac{\\left(\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right)^{2}}{\\left(\\frac{1}{m_{i}}+\\frac{1}{m_{j}}\\right) \\hat{\\sigma}} \\sim F\\left(1, f_{e}\\right),\n$$  \n从而可以要求 $c_{i j}=c \\sqrt{\\frac{1}{m_{i}}+\\frac{1}{m_{j}}}$, 类似于重复数相等时的推导, 有  \n$$\n\\begin{aligned}\nP(W) & =P\\left[\\bigcap_{1 \\leqslant i<j \\leqslant r}\\left(\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right| \\geqslant c \\sqrt{\\frac{1}{m_{i}}+\\frac{1}{m_{j}}}\\right)\\right] \\\\",
        "metadata": {
            "Header 2": "8.2 .4 意复数不等场合的 $S$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n从而可以要求 $c_{i j}=c \\sqrt{\\frac{1}{m_{i}}+\\frac{1}{m_{j}}}$, 类似于重复数相等时的推导, 有  \n$$\n\\begin{aligned}\nP(W) & =P\\left[\\bigcap_{1 \\leqslant i<j \\leqslant r}\\left(\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right| \\geqslant c \\sqrt{\\frac{1}{m_{i}}+\\frac{1}{m_{j}}}\\right)\\right] \\\\\n& =P\\left[\\max _{1 \\leqslant i<j \\leqslant r} \\frac{\\left|\\bar{y}_{i \\cdot}-\\bar{y}_{j \\cdot}\\right|}{\\sqrt{\\frac{1}{m_{i}}+\\frac{1}{m_{j}}} \\hat{\\sigma}} \\geqslant \\frac{c}{\\hat{\\sigma}}\\right] \\\\\n& =P\\left[\\max _{1 \\leqslant i<j \\leqslant r} \\frac{\\left(\\bar{y}_{i \\cdot}-\\bar{y}_{j .}\\right)^{2}}{\\frac{1}{m_{i}}+\\frac{1}{m_{j}} \\hat{\\sigma}} \\geqslant \\frac{c}{\\hat{\\sigma}^{2}}\\right] \\\\\n& =P\\left(\\max _{1 \\leqslant i<j \\leqslant r} F_{i j} \\geqslant(c / \\hat{\\sigma})^{2}\\right) .\n\\end{aligned}\n$$  \n可以证明, $\\frac{\\max _{1 \\leqslant i<j \\leqslant r} F_{i j}}{r-1} \\sim F\\left(r-1, f_{e}\\right)$, 从而由 $P(W)=\\alpha$ 可推出 $(c / \\hat{\\sigma})^{2}=(r-1) F_{1-\\alpha}\\left(r-1, f_{e}\\right)$,亦即  \n$$",
        "metadata": {
            "Header 2": "8.2 .4 意复数不等场合的 $S$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "& =P\\left(\\max _{1 \\leqslant i<j \\leqslant r} F_{i j} \\geqslant(c / \\hat{\\sigma})^{2}\\right) .\n\\end{aligned}\n$$  \n可以证明, $\\frac{\\max _{1 \\leqslant i<j \\leqslant r} F_{i j}}{r-1} \\sim F\\left(r-1, f_{e}\\right)$, 从而由 $P(W)=\\alpha$ 可推出 $(c / \\hat{\\sigma})^{2}=(r-1) F_{1-\\alpha}\\left(r-1, f_{e}\\right)$,亦即  \n$$\nc_{i j}=\\sqrt{(r-1) F_{1-\\alpha}\\left(r-1, f_{e}\\right)\\left(\\frac{1}{m_{i}}+\\frac{1}{m_{j}} \\hat{\\sigma}^{2}\\right)}\n$$  \n例 8.2.3: 在例 8.1.4 中, 我们已指出包装方式对食品销量有显著影响, 此处 $r=4, f_{e}=6, \\hat{\\sigma}^{2}=$ 7.67, 若取 $\\alpha=0.05$, 则 $F_{0.95}(3,6)=4.76$. 注意到 $m_{1}=m_{4}=2, m_{2}=m_{3}=3$, 故  \n$$\n\\begin{aligned}\n& c_{12}=c_{13}=c_{24}=c_{34}=\\sqrt{3 \\times 4.76 \\times(1 / 2+1 / 3) \\times 7.67}=9.6 \\\\\n& c_{14}=\\sqrt{3 \\times 4.76 \\times(1 / 2+1 / 2) \\times 7.67}=10.5 \\\\\n& c_{23}=\\sqrt{3 \\times 4.76 \\times(1 / 3+1 / 3) \\times 7.67}=8.5\n\\end{aligned}\n$$  \n由于  \n$$\n\\begin{aligned}\n& \\left|\\bar{y}_{1 .}-\\bar{y}_{2 .}\\right|=2<c_{12}, \\\\\n& \\left|\\bar{y}_{1 .}-\\bar{y}_{3 .}\\right|=4<c_{13},",
        "metadata": {
            "Header 2": "8.2 .4 意复数不等场合的 $S$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n& c_{12}=c_{13}=c_{24}=c_{34}=\\sqrt{3 \\times 4.76 \\times(1 / 2+1 / 3) \\times 7.67}=9.6 \\\\\n& c_{14}=\\sqrt{3 \\times 4.76 \\times(1 / 2+1 / 2) \\times 7.67}=10.5 \\\\\n& c_{23}=\\sqrt{3 \\times 4.76 \\times(1 / 3+1 / 3) \\times 7.67}=8.5\n\\end{aligned}\n$$  \n由于  \n$$\n\\begin{aligned}\n& \\left|\\bar{y}_{1 .}-\\bar{y}_{2 .}\\right|=2<c_{12}, \\\\\n& \\left|\\bar{y}_{1 .}-\\bar{y}_{3 .}\\right|=4<c_{13},\n\\end{aligned}\n$$  \n$$\n\\begin{aligned}\n& \\left|\\bar{y}_{1 .}-\\bar{y}_{4}\\right|=12>c_{14}, \\\\\n& \\left|\\bar{y}_{2 .}-\\bar{y}_{3 .}\\right|=6<c_{23}, \\\\\n& \\left|\\bar{y}_{2 .}-\\bar{y}_{4 .}\\right|=14>c_{24}, \\\\\n& \\left|\\bar{y}_{3 .}-\\bar{y}_{4 .}\\right|=8<c_{34},\n\\end{aligned}\n$$  \n这说明 $A_{1}, A_{2}, A_{3}$ 间无显著差异, $A_{1}, A_{2}$ 与 $A_{4}$ 有显著差异, 但 $A_{4}$ 与 $A_{3}$ 的差异却尚未达到显著水平. 综合上述, 包装 $A_{4}$ 销售量最佳.",
        "metadata": {
            "Header 2": "8.2 .4 意复数不等场合的 $S$ 法"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 采用习题 8.1 中第 7 题的数据, 对三种储藏方法的平均含水率在 $\\alpha=0.05$ 下作多重比较.\n2. 采用习题 8.1 中第 8 题的数据, 对五种推销方法在 $\\alpha=0.05$ 下作多重比较.\n3. 有七种人造纤维, 每种抽 4 根测其强度, 得每种纤维的乎均强度及标准差如下:  \n| $\\mathrm{i}$ | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $\\mathrm{y}$ | 6.3 | 6.2 | 6.7 | 6.8 | 6.5 | 7 | 7.1 |\n| $\\mathrm{~s}$ | 0.81 | 0.92 | 1.22 | 0.74 | 0.88 | 0.58 | 1.05 |  \n假定各种纤维的强度凝从等方差的正态分布.  \n(1) 试问七种纤维强度间有无显着差异 (取 $\\alpha=0.05$ );  \n(2) 若各种纤维的强度间无显著差异, 则给出乎均强度的置信水平为 0.95 的置信区间; 若各种纤维的强度间有显著差异, 请进一步在 $\\alpha=0.05$ 下进行多重比较, 并指出哪种纤维的平均强度最大, 同时给出该种纤维平均强度的置信水平为 0.95 的置信区间.  \n4. 一位经济学家对生产电子计算机设备的企业收集了在一年内生产力提高指数 (用 0 到 100 内的数表示) 并按过去三年间在科研和开发上的乎均花费分为三类:  \n$$\nA_{1} \\text { : 花费少, } A_{2} \\text { : 花费中等, } A_{3} \\text { : 花费多. }\n$$  \n生产力提高的指数如下表所示:",
        "metadata": {
            "Header 2": "妇题 8.2"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\mathrm{~s}$ | 0.81 | 0.92 | 1.22 | 0.74 | 0.88 | 0.58 | 1.05 |  \n假定各种纤维的强度凝从等方差的正态分布.  \n(1) 试问七种纤维强度间有无显着差异 (取 $\\alpha=0.05$ );  \n(2) 若各种纤维的强度间无显著差异, 则给出乎均强度的置信水平为 0.95 的置信区间; 若各种纤维的强度间有显著差异, 请进一步在 $\\alpha=0.05$ 下进行多重比较, 并指出哪种纤维的平均强度最大, 同时给出该种纤维平均强度的置信水平为 0.95 的置信区间.  \n4. 一位经济学家对生产电子计算机设备的企业收集了在一年内生产力提高指数 (用 0 到 100 内的数表示) 并按过去三年间在科研和开发上的乎均花费分为三类:  \n$$\nA_{1} \\text { : 花费少, } A_{2} \\text { : 花费中等, } A_{3} \\text { : 花费多. }\n$$  \n生产力提高的指数如下表所示:  \n| 水平 | 生产力提高指数 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |",
        "metadata": {
            "Header 2": "妇题 8.2"
        },
        "type": "Document"
    },
    {
        "page_content": "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "妇题 8.2"
        },
        "type": "Document"
    },
    {
        "page_content": "| $A_{1}$ | 7.6 | 8.2 | 6.8 | 5.8 | 6.9 | 6.6 | 6.3 | 7.7 | 6 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $A_{2}$ | 6.7 | 8.1 | 9.4 | 8.6 | 7.8 | 7.7 | 8.9 | 7.9 | 8.3 | 8.7 | 7.1 | 8.4 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |",
        "metadata": {
            "Header 2": "妇题 8.2"
        },
        "type": "Document"
    },
    {
        "page_content": "| $A_{2}$ | 6.7 | 8.1 | 9.4 | 8.6 | 7.8 | 7.7 | 8.9 | 7.9 | 8.3 | 8.7 | 7.1 | 8.4 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $A_{3}$ | 8.5 | 9.7 | 10.1 | 7.8 | 9.6 | 9.5 |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  \n请列出方差分析表, 并进行多重比较.",
        "metadata": {
            "Header 2": "妇题 8.2"
        },
        "type": "Document"
    },
    {
        "page_content": "在单因子试验中 $r$ 个水平的指标可以用 $r$ 个正态分布 $N\\left(\\mu_{i}, \\sum_{i}^{2}\\right), i=1,2, \\cdots, r$ 表示. 在进行方差分析时要求 $r$ 个方差相等, 这称为方整齐性. 而方差齐性不一定自然具有. 理论研究表明,当正态性假定不满足时对 $F$ 检验影响较小, 即 $F$ 检验对正态性的偏离具有一定的稳健性, 而 $\\mathrm{F}$ 检验对方差齐性的偏离较为敏感. 所以 $r$ 个方差的齐性检验就显得十分必要.  \n所谓方差齐性检验是对如下一对假设作出检验:  \n$$\n\\begin{equation*}\nH_{0}: \\sum_{1}^{2}=\\sum_{2}^{2}=\\cdots=\\sum_{r}^{2} \\operatorname{vs} H_{1}: \\text { 诸 } \\sum_{i}^{2} \\text { 不全相等. } \\tag{8.3.1}\n\\end{equation*}\n$$  \n很多统计学家提出了一些很好的检验方法, 这里介绍几个最常用的检验, 它们是:  \n- Hartley 检验, 仅适用于样本量相等的场合;\n- Bartlett 检验, 可用于样本量相等或不等的场合, 但是每个样本量不得低于 5;\n- 修正的 Bartlett 检验, 在样本量较小或较大、相等或不等场合均可使用.  \n下面分别来叙述它们.",
        "metadata": {
            "Header 2": "8.3 方差齐次检验"
        },
        "type": "Document"
    },
    {
        "page_content": "当各水平下试验重复次数相等时, 即  \n$$\nm_{1}=m_{2}=\\cdots=m_{r}=m\n$$  \nHartley 提出检验方差相等的检验统计量：  \n$$\n\\begin{equation*}\nH=\\frac{\\max \\left\\{s_{1}^{2}, s_{2}^{2}, \\cdots, s_{r}^{2}\\right\\}}{\\min \\left\\{s_{1}^{2}, s_{2}^{2}, \\cdots, s_{r}^{2}\\right\\}} \\tag{8.3.2}\n\\end{equation*}\n$$  \n它是 $r$ 个样本方差的最大值与最小值之比. 这个统计量的分布尚无明显的表达式, 但在诸方差相等条件下, 可通过随机模拟方法获得 $\\mathrm{H}$ 分布的分位数, 该分布依赖于水平数 $r$ 和样本方差的自由度 $f=m-1$, 因此该分布可记为 $H(r, f)$, 其分位数表列于附表 10 上.  \n直观上看, 当 $H_{0}$ 成立, 即诸方差相等 $\\sum_{1}^{2}=\\sum_{2}^{2}=\\cdots=\\sum_{r}^{2}$ 时, $H$ 的值应接近于 1 , 当 $H$ 的值较大时, 诸方差间的差异就大, $H$ 愈大, 诸方差间的差异就愈大, 这时应拒绝 (8.3.1) 中的 $H_{0}$. 由此可知, 对给定的显著性水平 $\\alpha$, 检验 $H_{0}$ 的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left|H>H_{1-\\alpha}(r, f)\\right| \\tag{8.3.3}\n\\end{equation*}\n$$  \n其中 $H_{1-\\alpha}(r, f)$ 为 $H$ 分布的 $1-\\alpha$ 分位数.",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.1 Hartley 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "直观上看, 当 $H_{0}$ 成立, 即诸方差相等 $\\sum_{1}^{2}=\\sum_{2}^{2}=\\cdots=\\sum_{r}^{2}$ 时, $H$ 的值应接近于 1 , 当 $H$ 的值较大时, 诸方差间的差异就大, $H$ 愈大, 诸方差间的差异就愈大, 这时应拒绝 (8.3.1) 中的 $H_{0}$. 由此可知, 对给定的显著性水平 $\\alpha$, 检验 $H_{0}$ 的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left|H>H_{1-\\alpha}(r, f)\\right| \\tag{8.3.3}\n\\end{equation*}\n$$  \n其中 $H_{1-\\alpha}(r, f)$ 为 $H$ 分布的 $1-\\alpha$ 分位数.  \n例 8.3.1: 有四种不同牌号的铁锈防护剂 (简称防锈剂), 现要比较其防锈能力. 为此, 制作 40 个大小形状相同的铁块 (试验样品), 然后把它们随机分为四组, 每组 10 件样品. 在每一组样品上涂上同一牌号的防锈剂, 最后把 40 个样品放在一个广场上让其经受日晒、风吹和雨打.一段时间后再行观察其防锈能力. 由于防锈能力无测量仪器, 只能请专家评分. 五位受聘专家对评分标准进行讨论,取得共识. 样品上无锈迹的评 100 分, 全锈了评 0 分. 他们在不知牌号的情况下进行独立评分. 最  \n| 因子 $A$ (防锈剂 $)$ |  | $A_{1}$ | $A_{2}$ | $\\bar{A}$ | $A_{4}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $y_{i j}$ | 1 | 43.9 | 89.8 | 68.4 | 36.2 |\n|  | 2 | 39 | 87.1 | 69.3 | 45.2 |\n|  | 3 | 46.7 | 92.7 | 68.5 | 40.7 |\n|  | 4 | 43.8 | 90.6 | 66.4 | 40.5 |\n|  | 5 | 44.2 | 87.7 | 70 | 39.3 |\n|  | 6 | 47.7 | 92.4 | 68.1 | 40.3 |\n|  | 7 | 43.6 | 86.1 | 70.6 | 43.2 |",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.1 Hartley 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| 因子 $A$ (防锈剂 $)$ |  | $A_{1}$ | $A_{2}$ | $\\bar{A}$ | $A_{4}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| $y_{i j}$ | 1 | 43.9 | 89.8 | 68.4 | 36.2 |\n|  | 2 | 39 | 87.1 | 69.3 | 45.2 |\n|  | 3 | 46.7 | 92.7 | 68.5 | 40.7 |\n|  | 4 | 43.8 | 90.6 | 66.4 | 40.5 |\n|  | 5 | 44.2 | 87.7 | 70 | 39.3 |\n|  | 6 | 47.7 | 92.4 | 68.1 | 40.3 |\n|  | 7 | 43.6 | 86.1 | 70.6 | 43.2 |\n|  | 8 | 38.9 | 88.1 | 65.2 | 38.7 |\n|  | 9 | 43.6 | 90.8 | 63.8 | 40.9 |\n|  | 10 | 40 | 89.1 | 69.2 | 39.7 |\n| {和 $T_{i}$ <br> 均值 $\\bar{y}_{i}$ <br> 内平方和 $Q_{i}$} |  | 431.4 | 894.4 | 679.5 | 404.7 |\n|  |  | 43.14 | 89.44 | 67.95 | 40.47 |\n|  |  | 81.00 | 44.28 | 42.33 | 53.42 |  \n后把一个样品的 5 个专家所给分数的平均值作为该样品的防锈能力. 数据列于表 8.3.1 上. 这是一  \n表 8.3.1: 防锈能力数据及有关计算  \n个重复次数相等的单因子试验. 我们考虑用方差分析方法对之进行比较分析, 为此, 首先要进行方差齐性检验本例中, 四个样本方差可由表 8.3.1 中诸 $Q_{i}$ 求出, 即  \n$$\ns_{1}^{2}=\\frac{81.00}{9}=9.00, s_{2}^{2}=\\frac{44.28}{9}=4.92, s_{3}^{2}=\\frac{42.33}{9}=4.70, s_{4}^{2}=\\frac{53.42}{9}=4.94\n$$  \n由此可得统计量 $H$ 的值  \n$$",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.1 Hartley 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| {和 $T_{i}$ <br> 均值 $\\bar{y}_{i}$ <br> 内平方和 $Q_{i}$} |  | 431.4 | 894.4 | 679.5 | 404.7 |\n|  |  | 43.14 | 89.44 | 67.95 | 40.47 |\n|  |  | 81.00 | 44.28 | 42.33 | 53.42 |  \n后把一个样品的 5 个专家所给分数的平均值作为该样品的防锈能力. 数据列于表 8.3.1 上. 这是一  \n表 8.3.1: 防锈能力数据及有关计算  \n个重复次数相等的单因子试验. 我们考虑用方差分析方法对之进行比较分析, 为此, 首先要进行方差齐性检验本例中, 四个样本方差可由表 8.3.1 中诸 $Q_{i}$ 求出, 即  \n$$\ns_{1}^{2}=\\frac{81.00}{9}=9.00, s_{2}^{2}=\\frac{44.28}{9}=4.92, s_{3}^{2}=\\frac{42.33}{9}=4.70, s_{4}^{2}=\\frac{53.42}{9}=4.94\n$$  \n由此可得统计量 $H$ 的值  \n$$\nH=\\frac{9.00}{4.70}=1.9149\n$$  \n在 $\\alpha=0.05$ 时, 由附表 10 查得 $H_{0.95}(4,9)=6.31$, 由于 $H<6.31$, 所以应该接收原假设 $H_{0}$, 即认为四个总体方差间无显著差异.  \n进一步, 在正态性检验通过 (用正态概率纸) 的情况下, 我们可用方差分析方法对四种不同牌\n号的防锈剂比较其防锈能力. 由表 8.3.1 的数据可以算出 $T=T_{1}+\\cdots+T_{a}=2410$, 从而求得三个偏差平方和分别为  \n$$\n\\begin{aligned}\n& S_{T}=43.9^{2}+39.2^{2}+\\cdots+40.9^{2}+39.7^{2}-\\frac{2410^{2}}{40}=16174.50, f_{T}=39 \\\\\n& S_{A}=\\frac{1}{10}\\left(431.4^{2}+894.4^{2}+679.5^{2}+404.7^{2}-\\frac{2410^{2}}{40}=15953.47, f_{A}=3\\right. \\\\",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.1 Hartley 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nH=\\frac{9.00}{4.70}=1.9149\n$$  \n在 $\\alpha=0.05$ 时, 由附表 10 查得 $H_{0.95}(4,9)=6.31$, 由于 $H<6.31$, 所以应该接收原假设 $H_{0}$, 即认为四个总体方差间无显著差异.  \n进一步, 在正态性检验通过 (用正态概率纸) 的情况下, 我们可用方差分析方法对四种不同牌\n号的防锈剂比较其防锈能力. 由表 8.3.1 的数据可以算出 $T=T_{1}+\\cdots+T_{a}=2410$, 从而求得三个偏差平方和分别为  \n$$\n\\begin{aligned}\n& S_{T}=43.9^{2}+39.2^{2}+\\cdots+40.9^{2}+39.7^{2}-\\frac{2410^{2}}{40}=16174.50, f_{T}=39 \\\\\n& S_{A}=\\frac{1}{10}\\left(431.4^{2}+894.4^{2}+679.5^{2}+404.7^{2}-\\frac{2410^{2}}{40}=15953.47, f_{A}=3\\right. \\\\\n& S_{e}=S_{T}-S_{A}=221.03, f_{e}=36\n\\end{aligned}\n$$  \n把上述各项移到方差分析表上, 可继续计算各均方和与 $F$ 比, 具体见表 8.3.2.  \n表 8.3.2: 防锈能力的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :--- | ---: | ---: | ---: | :---: |\n| 因子 $A$ | 15953.47 | 3 | 5317.82 | 866.09 |\n| 误差 $e$ | 221.03 | 36 | 6.14 |  |\n| 和 $T$ | 16174.5 | 39 |  |  |  \n若给定显著性水平 $\\alpha=0.05$, 查表可得 $F_{0.95}(3,36)=2.87$, 由于 $F>2.87$, 故因子 $A$ 显著, 即四种防锈剂的防锈能力有显著差异.  \n各种防锈剂的防锈能力均值分别为  \n$$",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.1 Hartley 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "& S_{e}=S_{T}-S_{A}=221.03, f_{e}=36\n\\end{aligned}\n$$  \n把上述各项移到方差分析表上, 可继续计算各均方和与 $F$ 比, 具体见表 8.3.2.  \n表 8.3.2: 防锈能力的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :--- | ---: | ---: | ---: | :---: |\n| 因子 $A$ | 15953.47 | 3 | 5317.82 | 866.09 |\n| 误差 $e$ | 221.03 | 36 | 6.14 |  |\n| 和 $T$ | 16174.5 | 39 |  |  |  \n若给定显著性水平 $\\alpha=0.05$, 查表可得 $F_{0.95}(3,36)=2.87$, 由于 $F>2.87$, 故因子 $A$ 显著, 即四种防锈剂的防锈能力有显著差异.  \n各种防锈剂的防锈能力均值分别为  \n$$\n\\hat{\\mu}_{1}=43.14, \\hat{\\mu}_{2}=89.44, \\hat{\\mu}_{3}=67.95, \\hat{\\mu}_{4}=40.47 \\text {, }\n$$  \n第二种牌号的防锈剂的防锈能力最强.  \n此外, 试验误差的方差 $\\sigma^{2}$ 的估计为 $\\hat{\\sigma^{2}}=6.14, \\sum$ 的估计为 $\\hat{\\sigma}=\\sqrt{6.14}=2.48$.  \n由于第二种牌号的防锈剂的防锈能力最强, 我们还可求出其均值 $\\mu_{2}$ 的 $95 \\%$ 的置信区间, 现在 $t_{1-\\alpha / 2}(n-r)=t_{0.975}(36)=2.0281, \\hat{\\sigma}=2.48, m=10, \\hat{\\mu}_{2}=\\bar{y}_{2}=89.44$, 则  \n$$\n\\hat{y}_{2} \\pm t_{1-\\alpha / 2}(n-r) \\hat{\\sigma} / \\sqrt{m}=89.44 \\pm 1.73\n$$  \n即 $A_{2}$ 的 $95 \\%$ 的置信区间为 $[87.71,91.17]$.",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.1 Hartley 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "在单因子方差分析中有 $r$ 个样本, 设第 $i$ 个样本方差为:  \n$$\ns_{i}^{2}=\\frac{1}{m_{i}-1} \\sum_{j=1}^{m_{i}}\\left(y_{i j}-\\hat{y}_{l}\\right)^{2}=\\frac{Q_{i}}{f_{i}}, \\quad i=1,2, \\cdots, r\n$$  \n其中 $m_{i}$ 为第 $i$ 个样本的容量 (即试验重复次数), $Q_{i}=\\sum_{j=1}^{m_{i}}\\left(y_{i j}-\\bar{y}_{i}\\right)^{2}$ 与 $f_{i}=m_{i}-1$ 为该样本的偏差平方和及自由度. 由于误差均方和  \n$$\nM S_{e}=\\frac{1}{f_{e}} \\sum_{i=1}^{r} Q_{i}=\\sum_{i=1}^{r} \\frac{f_{i}}{f_{e}^{2}} s_{i}^{2}\n$$  \n它是 $r$ 个样本方差 $s_{1}^{2}, s_{2}^{2}, \\cdots, s_{r}^{2}$ 的 (加权) 算术平均数. 而相应的 $r$ 个样本方差的几何平均数记为 $G M S_{e}$, 它是:  \n$$\nG M S_{e}=\\left[\\left(s_{1}^{2}\\right)^{f_{1}}\\left(s_{2}^{2}\\right)^{f_{2}} \\cdots\\left(s_{r}^{2}\\right)^{f_{r}}\\right]^{1 / f_{e}}\n$$  \n其中 $f_{e}=f_{1}+f_{2}+\\cdots+f_{r}=\\sum_{i=1}^{r}\\left(m_{i}-1\\right)=n-r$.  \n由于几何平均数总不会超过算术平均数, 故有  \n$$\n\\begin{equation*}\nG M S_{e} \\leqslant M S_{e} \\tag{8.3.4}\n\\end{equation*}\n$$  \n其中等号成立当且仅当诸 $s_{i}^{2}$ 系彼此相等, 若诸 $s_{i}^{2}$ 间的差异愈大, 则此两个平均值相差也愈大. 由此可见, 当诸总体方差相等时, 其样本方差间不应相差较大, 从而比值 $M S_{e} / G M S_{e}$ 接近于 1. 反之,",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.2 Bartlett 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nG M S_{e}=\\left[\\left(s_{1}^{2}\\right)^{f_{1}}\\left(s_{2}^{2}\\right)^{f_{2}} \\cdots\\left(s_{r}^{2}\\right)^{f_{r}}\\right]^{1 / f_{e}}\n$$  \n其中 $f_{e}=f_{1}+f_{2}+\\cdots+f_{r}=\\sum_{i=1}^{r}\\left(m_{i}-1\\right)=n-r$.  \n由于几何平均数总不会超过算术平均数, 故有  \n$$\n\\begin{equation*}\nG M S_{e} \\leqslant M S_{e} \\tag{8.3.4}\n\\end{equation*}\n$$  \n其中等号成立当且仅当诸 $s_{i}^{2}$ 系彼此相等, 若诸 $s_{i}^{2}$ 间的差异愈大, 则此两个平均值相差也愈大. 由此可见, 当诸总体方差相等时, 其样本方差间不应相差较大, 从而比值 $M S_{e} / G M S_{e}$ 接近于 1. 反之,\n在比值 $M S_{e} / G M S_{e}$ 较大时, 就意味着诸样本方差差异较大, 从而反映诸总体方差差异也较大. 这个结论对此比值的对数也成立. 从而检验 (8.3.1) 表示的一对假设的拒绝域应是  \n$$\n\\begin{equation*}\nW=\\left\\{\\ln \\left(M S_{e} / G M S_{e}\\right)>d\\right\\} \\tag{8.3.5}\n\\end{equation*}\n$$  \nBartlett 证明了: 在大样本场合, $\\ln \\left(M S_{e} / G M S_{e}\\right)$ 的某个函数近似服从自由度为 $r-1$ 的 $\\chi^{2}$ 分布,具体是:  \n$$\n\\begin{equation*}\nB=\\frac{f_{e}}{C}\\left(\\ln M S_{e}-\\ln G M S_{e}\\right) \\sim \\chi^{2}(r-1) \\tag{8.3.6}\n\\end{equation*}\n$$  \n其中  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.2 Bartlett 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "在比值 $M S_{e} / G M S_{e}$ 较大时, 就意味着诸样本方差差异较大, 从而反映诸总体方差差异也较大. 这个结论对此比值的对数也成立. 从而检验 (8.3.1) 表示的一对假设的拒绝域应是  \n$$\n\\begin{equation*}\nW=\\left\\{\\ln \\left(M S_{e} / G M S_{e}\\right)>d\\right\\} \\tag{8.3.5}\n\\end{equation*}\n$$  \nBartlett 证明了: 在大样本场合, $\\ln \\left(M S_{e} / G M S_{e}\\right)$ 的某个函数近似服从自由度为 $r-1$ 的 $\\chi^{2}$ 分布,具体是:  \n$$\n\\begin{equation*}\nB=\\frac{f_{e}}{C}\\left(\\ln M S_{e}-\\ln G M S_{e}\\right) \\sim \\chi^{2}(r-1) \\tag{8.3.6}\n\\end{equation*}\n$$  \n其中  \n$$\n\\begin{equation*}\nC=1+\\frac{1}{3(r-1)}\\left[\\sum_{i=1}^{r} \\frac{1}{f_{i}}-\\frac{1}{f_{e}}\\right] \\tag{8.3.7}\n\\end{equation*}\n$$  \n等号成立当且仅当诸且 $C$ 通常会大于 1. 根据上述结论, 可取  \n$$\n\\begin{equation*}\nB=\\frac{1}{C}\\left[f_{e} \\ln M S_{e}-\\sum_{i=1}^{r} f_{i} \\ln s_{i}^{2}\\right] \\tag{8.3.8}\n\\end{equation*}\n$$  \n作为检验统计量, 对给定的显著性水平 $\\alpha$, 检验的拒绝域为  \n$$\n\\begin{equation*}\n\\boldsymbol{W}=\\left\\{B>\\chi_{1-\\alpha}^{2}(r-1)\\right\\} \\tag{8.3.9}\n\\end{equation*}\n$$  \n考虑到这里 $\\chi^{2}$ 分布是近似分布, 在诸样本量 $m_{i}$ 均不小于 5 时使用上述检验是适当的.",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.2 Bartlett 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "C=1+\\frac{1}{3(r-1)}\\left[\\sum_{i=1}^{r} \\frac{1}{f_{i}}-\\frac{1}{f_{e}}\\right] \\tag{8.3.7}\n\\end{equation*}\n$$  \n等号成立当且仅当诸且 $C$ 通常会大于 1. 根据上述结论, 可取  \n$$\n\\begin{equation*}\nB=\\frac{1}{C}\\left[f_{e} \\ln M S_{e}-\\sum_{i=1}^{r} f_{i} \\ln s_{i}^{2}\\right] \\tag{8.3.8}\n\\end{equation*}\n$$  \n作为检验统计量, 对给定的显著性水平 $\\alpha$, 检验的拒绝域为  \n$$\n\\begin{equation*}\n\\boldsymbol{W}=\\left\\{B>\\chi_{1-\\alpha}^{2}(r-1)\\right\\} \\tag{8.3.9}\n\\end{equation*}\n$$  \n考虑到这里 $\\chi^{2}$ 分布是近似分布, 在诸样本量 $m_{i}$ 均不小于 5 时使用上述检验是适当的.  \n例 8.3.2: 茶是世界上最为广泛的一种饮料, 但很少人知其营养价值. 任一种茶叶都含有叶酸, 它是一种维他命 $\\mathrm{B}$. 如今已有测定茶叶中叶酸含量的方法. 为研究各产地的绿茶的叶酸含量是否有显著差异, 特选四个产地绿茶, 其中 $A_{1}$ 制作了 7 个样品, $A_{2}$ 制作了 5 个样品, $A_{3}$ 与 $A_{4}$ 各制作了 6 个样品, 共有 24 个样品, 按随机次序测试其叶酸含量 (单位: $\\mathrm{mg}$ ), 测试结果如表 8.3.3 所示.  \n表 8.3.3: 绿茶的叶酸含量数据  \n| 水平 | 数据 |  |  |  |  |  |  | 重复数 | 和 | 均值 | 组内平方和 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.2 Bartlett 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n考虑到这里 $\\chi^{2}$ 分布是近似分布, 在诸样本量 $m_{i}$ 均不小于 5 时使用上述检验是适当的.  \n例 8.3.2: 茶是世界上最为广泛的一种饮料, 但很少人知其营养价值. 任一种茶叶都含有叶酸, 它是一种维他命 $\\mathrm{B}$. 如今已有测定茶叶中叶酸含量的方法. 为研究各产地的绿茶的叶酸含量是否有显著差异, 特选四个产地绿茶, 其中 $A_{1}$ 制作了 7 个样品, $A_{2}$ 制作了 5 个样品, $A_{3}$ 与 $A_{4}$ 各制作了 6 个样品, 共有 24 个样品, 按随机次序测试其叶酸含量 (单位: $\\mathrm{mg}$ ), 测试结果如表 8.3.3 所示.  \n表 8.3.3: 绿茶的叶酸含量数据  \n| 水平 | 数据 |  |  |  |  |  |  | 重复数 | 和 | 均值 | 组内平方和 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $A_{1}$ | 7.9 | 6.2 | 6.6 | 8.6 | 8.9 | 10.1 | 9.6 | $m_{1}=7$ | $T_{1}=57.9$ | 8.27 | $Q_{1}=12.83$ |\n| $A_{2}$ | 5.7 | 7.5 | 9.8 | 6.1 | 8.4 |  |  | $m_{2}=5$ | $T_{2}=37.5$ | 7.50 | $Q_{2}=11.30$ |\n| $A_{3}$ | 6.4 | 7.1 | 7.9 | 4.5 | 5.0 | 4.0 |  | $m_{3}=6$ | $T_{3}=34.9$ | 5.82 | $Q 3=12.03$ |\n| $A_{4}$ | 6.8 | 7.5 | 5 | 5.3 | 6.1 | 7.4 |  | $m_{4}$ | $T_{4}=38.1$ | 6.35 | $Q_{4}=5.61$ |\n| $n=24$ |  |  |  |  |  |  |  | $T=168.4$ |  | $S_{e}=41.77$ |  |  \n平方和计算如下  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.2 Bartlett 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| $A_{1}$ | 7.9 | 6.2 | 6.6 | 8.6 | 8.9 | 10.1 | 9.6 | $m_{1}=7$ | $T_{1}=57.9$ | 8.27 | $Q_{1}=12.83$ |\n| $A_{2}$ | 5.7 | 7.5 | 9.8 | 6.1 | 8.4 |  |  | $m_{2}=5$ | $T_{2}=37.5$ | 7.50 | $Q_{2}=11.30$ |\n| $A_{3}$ | 6.4 | 7.1 | 7.9 | 4.5 | 5.0 | 4.0 |  | $m_{3}=6$ | $T_{3}=34.9$ | 5.82 | $Q 3=12.03$ |\n| $A_{4}$ | 6.8 | 7.5 | 5 | 5.3 | 6.1 | 7.4 |  | $m_{4}$ | $T_{4}=38.1$ | 6.35 | $Q_{4}=5.61$ |\n| $n=24$ |  |  |  |  |  |  |  | $T=168.4$ |  | $S_{e}=41.77$ |  |  \n平方和计算如下  \n$$\n\\begin{aligned}\nS_{A} & =\\frac{57.9^{2}}{7}+\\frac{37.5^{2}}{5}+\\frac{34.9^{2}}{6}+\\frac{38.1^{2}}{6}-\\frac{168 \\cdot 4^{2}}{24}=23.50, f_{\\mathrm{A}}=3 \\\\\nS_{T} & =\\left(7.9^{2}+6.2^{2}+\\cdots+6.1^{2}+7.4^{2}\\right)-\\frac{168.4^{2}}{24}=65.27, f_{T}=23 \\\\\nS_{e} & =65.27-23.50=41.77, f_{c}=20\n\\end{aligned}\n$$  \n方差分析表见表 8.3.4  \n表 8.3.4: 绿茶叶酸含量的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $\\mathrm{F}$ 比 |\n| :---: | :---: | :---: | :---: | :---: |\n| 因子 $\\mathrm{A}$ | 23.5 | 3 | 7.83 | 3.75 |",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.2 Bartlett 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "平方和计算如下  \n$$\n\\begin{aligned}\nS_{A} & =\\frac{57.9^{2}}{7}+\\frac{37.5^{2}}{5}+\\frac{34.9^{2}}{6}+\\frac{38.1^{2}}{6}-\\frac{168 \\cdot 4^{2}}{24}=23.50, f_{\\mathrm{A}}=3 \\\\\nS_{T} & =\\left(7.9^{2}+6.2^{2}+\\cdots+6.1^{2}+7.4^{2}\\right)-\\frac{168.4^{2}}{24}=65.27, f_{T}=23 \\\\\nS_{e} & =65.27-23.50=41.77, f_{c}=20\n\\end{aligned}\n$$  \n方差分析表见表 8.3.4  \n表 8.3.4: 绿茶叶酸含量的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $\\mathrm{F}$ 比 |\n| :---: | :---: | :---: | :---: | :---: |\n| 因子 $\\mathrm{A}$ | 23.5 | 3 | 7.83 | 3.75 |\n| 误差 $\\mathrm{e}$ | 41.77 | 20 | 2.09 |  |\n| 和 $\\mathrm{T}$ | 65.27 | 23 |  |  |  \n若取显著性水平 $\\alpha=0.05$, 查表可得 $F_{0.95}(3,20)=3.10$, 由于 $F>3.10$, 故应拒绝原假设 $H_{0}$,即认为四种绿茶的叶酸平均含量有显著差异.  \n为说明上述方差分析合理, 需要对其作方差齐性检验. 从表 8.3.3 中数据可查得  \n$$\n\\begin{array}{llll}\nQ_{1}=12.83, & Q_{2}=11.30, & Q_{3}=12.03, & Q_{4}=5.61 \\\\\nf_{1}=6, & f_{2}=4, & f_{3}=5, & f_{4}=5\n\\end{array}\n$$  \n从而用公式 $s=Q ; / f$; 可求得  \n$$\ns_{1}^{2}=2.14, s_{2}^{2}=2.83, s_{3}^{2}=2.41, s_{4}^{2}=1.12\n$$",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.2 Bartlett 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "| 误差 $\\mathrm{e}$ | 41.77 | 20 | 2.09 |  |\n| 和 $\\mathrm{T}$ | 65.27 | 23 |  |  |  \n若取显著性水平 $\\alpha=0.05$, 查表可得 $F_{0.95}(3,20)=3.10$, 由于 $F>3.10$, 故应拒绝原假设 $H_{0}$,即认为四种绿茶的叶酸平均含量有显著差异.  \n为说明上述方差分析合理, 需要对其作方差齐性检验. 从表 8.3.3 中数据可查得  \n$$\n\\begin{array}{llll}\nQ_{1}=12.83, & Q_{2}=11.30, & Q_{3}=12.03, & Q_{4}=5.61 \\\\\nf_{1}=6, & f_{2}=4, & f_{3}=5, & f_{4}=5\n\\end{array}\n$$  \n从而用公式 $s=Q ; / f$; 可求得  \n$$\ns_{1}^{2}=2.14, s_{2}^{2}=2.83, s_{3}^{2}=2.41, s_{4}^{2}=1.12\n$$  \n再从表 8.3.4 上查得 $M S_{e}=2.09$, 由 (8.3.7), 可求得  \n$$\nC=1+\\frac{1}{3(4-1)}\\left[\\left(\\frac{1}{6}+\\frac{1}{4}+\\frac{1}{5}+\\frac{1}{5}\\right)-\\frac{1}{20}\\right]=1.0856\n$$  \n再由 (8.3.8), 还可求得 Bartlett 检验统计量的值  \n$$\n\\begin{aligned}\nB= & \\frac{1}{1.0856}[20 \\times \\ln 2 \\cdot 09-(6 \\times \\ln 2.14+4 \\times \\ln 2.83+ \\\\\n& 5 \\times \\ln 2.41+5 \\times \\ln 1.12)]=0.970\n\\end{aligned}\n$$  \n对给定的显著性水平 $\\alpha=0.05$, 查表知 $\\chi_{0.95}^{2}(4-1)=7.815$. 由于 $B<7.815$, 故应接收原假设 $H_{0}$,即可认为诸水平下的方差间无显著差异.",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.2 Bartlett 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "针对样本量低于 5 时不能使用 Bartlett 检验的缺点, Box 提出修正的 Bartlett 检验统计量  \n$$\n\\begin{equation*}\nB^{\\prime}=\\frac{f_{2} B C}{f_{1}(A-B C)} \\tag{8.3.10}\n\\end{equation*}\n$$  \n其中 $B$ 与 $C$ 如 (8.3.8) 与 (8.3.7) 所示, 且  \n$$\nf_{1}=r-1, f_{2}=\\frac{r+1}{(C-1)^{2}}, A=\\frac{f_{2}}{2-C+2 / f_{2}}\n$$  \n在原假设 $H_{0}: \\sigma_{1}^{2}=\\sum_{2}^{2}=\\cdots=\\sigma_{r}^{2}$ 成立下, Box 还证明了统计量 $B^{\\prime}$ 的近似分布是 $F$ 分布 $F\\left(f_{1}, f_{2}\\right)$, 对给定的显著性水平 $\\alpha$, 该检验的拒绝域为  \n$$\n\\begin{equation*}\nW=\\left\\{B^{\\prime}>F_{1-a}\\left(f_{1}, f_{2}\\right)\\right\\} \\tag{8.3.11}\n\\end{equation*}\n$$  \n其中 $f_{2}$ 的值可能不是整数, 这时可通过对 $F$ 分布的分位数表施行内插法得到分位数.  \n例 8.3.3: 对例 8.3.2 中的绿茶叶酸含量的数据, 我们用修正的 Bartlett 检验再一次对方差齐性作出检验.  \n在例 8.3.2 中已求得 $C=1.0856, B=0.970$, 还可求得：  \n$$\n\\begin{aligned}\nf_{1} & =4-1=3, \\\\\nf_{2} & =\\frac{4+1}{(1.0856 C-1)^{2}}=682.4, \\\\\nA & =\\frac{682.4}{2-1.0856+2 / 682.4}=743.9, \\\\\nB^{\\prime} & =\\frac{682.4 \\times 0.970 \\times 1.0856}{3(743.9-0.970 \\times 1.0856)}=0.322 .\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.3 修正的 Bartlett"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n其中 $f_{2}$ 的值可能不是整数, 这时可通过对 $F$ 分布的分位数表施行内插法得到分位数.  \n例 8.3.3: 对例 8.3.2 中的绿茶叶酸含量的数据, 我们用修正的 Bartlett 检验再一次对方差齐性作出检验.  \n在例 8.3.2 中已求得 $C=1.0856, B=0.970$, 还可求得：  \n$$\n\\begin{aligned}\nf_{1} & =4-1=3, \\\\\nf_{2} & =\\frac{4+1}{(1.0856 C-1)^{2}}=682.4, \\\\\nA & =\\frac{682.4}{2-1.0856+2 / 682.4}=743.9, \\\\\nB^{\\prime} & =\\frac{682.4 \\times 0.970 \\times 1.0856}{3(743.9-0.970 \\times 1.0856)}=0.322 .\n\\end{aligned}\n$$  \n对给定的显著性水平 $\\alpha=0.05$, 在 $F$ 分布的分位数表上可查得  \n$$\n\\begin{equation*}\nF_{0.95}(3,682.4)=F_{0.95}(3,+\\infty)=2.60 \\tag{8.3.12}\n\\end{equation*}\n$$  \n由于 $B^{\\prime}<2.60$, 故接收原假设 $H_{0}$, 即认为四个水平下的方差间无显著差异.",
        "metadata": {
            "Header 2": "8.3 方差齐次检验",
            "Header 3": "8.3.3 修正的 Bartlett"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 采用例 8.1 .1 的数据, 在显著性水平 $\\alpha=0.05$ 下用 Hartley 检验考察三个总体方差是否彼此相\n等.\n2. 在安眠药试验 (见习题 8.1.5 ) 中已求得四个样本方差:  \n$$\n\\begin{equation*}\ns_{1}^{2}=0.02, s_{2}^{2}=0.08, s_{3}^{2}=0.036, s_{4}^{2}=0.01307 \\tag{8.3.13}\n\\end{equation*}\n$$  \n请用 Hartley 检验在显著性水平 $\\alpha=0.05$ 下考察四个总体方差是否彼此相等.  \n3. 在生产力提高的指数研究中 (见习题 8.2.4) 已求得三个样本方差, 它们是  \n$$\n\\begin{equation*}\ns_{1}^{2}=0.663, s_{2}^{2}=0.547, s_{3}^{2}=0.036, s_{4}^{2}=0.752 . \\tag{8.3.14}\n\\end{equation*}\n$$  \n请用 Bartlett 检验在显著性水平 $\\alpha=0.05$ 下考察三个总体方差是否彼此相等.  \n4. 在人户推销效果研究中 (见习题 8.1.8), 分别用 Hartley 检验和 Bartlett 检验在显著性水平 $\\alpha=0.05$ 下对五个总体作方差齐性检验.\n5. 在对粮食含水率的研究中 (见习题 8.1.7) 已求得 3 个水平下的组内平方和:  \n$$\n\\begin{equation*}\nQ_{1}=1.148, Q_{2}=2.237, Q_{3}=2.407 . \\tag{8.3.15}\n\\end{equation*}\n$$  \n请用修正的 Bartlett 检验在显著性水平 $\\alpha=0.05$ 下考察三个总体方差是否彼此相等  \n6. 针对糖果包装研究的数据 (见例 8.1.4), 请用修正的 Bartlett 检验在显著性水平 $\\alpha=0.05$ 下考察四个总体是否满足方差齐性假定.",
        "metadata": {
            "Header 2": "丑习题 8.3"
        },
        "type": "Document"
    },
    {
        "page_content": "早在十九世纪, 英国生物学家兼统计学家高尔顿在研究父与子身高的遗传问题时, 观察了 1078 对父与子, 用 $x$ 表示父亲身高, $y$ 表示成年儿子的身高, 发现将 $(x, y)$ 点在直角坐标系中, 这 1078 个点基本在一条直线附近, 并求出了该直线的方程 (单位: 英寸, 1 英寸 $=2.54 \\mathrm{~cm}$ ):  \n$$\n\\hat{y}=33.73+0.516 x \\text {. }\n$$  \n这表明:  \n- 父亲身高每增加 1 个单位, 其儿子的身高平均增加 0.516 个单位;\n- 高个子父辈有生高个子儿子的趋势, 但是一群高个子父辈的儿子们的平均高度要低于父辈的平均高度. 譬如 $x=80$, 那么 $\\hat{y}=75.01$, 低于父辈的平均高度;\n- 低个子父辈的儿子们虽为低个子, 但是其平均身高要比父辈高一些. 譬如 $x=60$, 那么 $\\hat{y}=64.69$, 高于父辈的平均高度.  \n这便是子代的平均高度有向中心回归的意思, 使得一段时间内人的身高相对稳定. 之后回归分析的思想渗透到了数理统计的其他分支中. 随着计算机的发展, 各种统计软件包的出现, 回归分析的应用就越来越广泛。",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.1 变量之间的两类关系"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\hat{y}=33.73+0.516 x \\text {. }\n$$  \n这表明:  \n- 父亲身高每增加 1 个单位, 其儿子的身高平均增加 0.516 个单位;\n- 高个子父辈有生高个子儿子的趋势, 但是一群高个子父辈的儿子们的平均高度要低于父辈的平均高度. 譬如 $x=80$, 那么 $\\hat{y}=75.01$, 低于父辈的平均高度;\n- 低个子父辈的儿子们虽为低个子, 但是其平均身高要比父辈高一些. 譬如 $x=60$, 那么 $\\hat{y}=64.69$, 高于父辈的平均高度.  \n这便是子代的平均高度有向中心回归的意思, 使得一段时间内人的身高相对稳定. 之后回归分析的思想渗透到了数理统计的其他分支中. 随着计算机的发展, 各种统计软件包的出现, 回归分析的应用就越来越广泛。  \n回归分析处理的是变量与变量间的关系. 变量间常见的关系有两类:一类称为确定性关系: 这些变量间的关系完全是已知的, 可以用函数 $y=f(x)$ 来表示, $x$ (可以是向量) 给定后, $y$ 的值就唯一确定了. 譬如正方形的面积 $S$ 与边长 $a$ 之间有关系: $S=a^{2}$, 电路中有欧姆定律 $V=I R$ 等.另一类称为相关关系: 变量间有关系, 但是不能用函数来表示, 譬如: 人的身高 $x$ 与体重 $y$, 两者间有相关关系, 一般来讲, 身高较高的人体重也较重, 但是同样身高的人的体重可以是不同的, 医学上就利用这两个变量间的相关关系, 给出了一些经验公式来确定一个人是否过于 “肥胖”或 “瘦小”; 人的脚掌的长度 $x$ 与身高 $y$, 两者间也有相关关系, 一般来讲, 脚掌较长的人身高也较高, 但是同样脚掌长度的人的身高可以是不同的, 医学上就利用这两个变量间的相关关系, 给出了一些经验公式来确定一个人是否过于 “肥胖”或 “瘦小”; 人的脚掌的长度 $x$ 与身高 $y$, 两者间也有相关关系, 一般来讲, 脚掌较长的人身高也较高, 但是同样脚掌长度的人的身高可以是不同的, 公安机\n关在破案时,常常根据案犯留下的脚印来推测罪犯的身高.",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.1 变量之间的两类关系"
        },
        "type": "Document"
    },
    {
        "page_content": "关在破案时,常常根据案犯留下的脚印来推测罪犯的身高.  \n变量间的相关关系不能用完全确切的函数形式表示, 但在平均意义下有一定的定量关系表达式, 寻找这种定量关系表达式就是回归分析的主要任务. 回归分析便是研究变量间相关关系的一门学科. 它通过对客观事物中变量的大量观察或试验获得的数据, 去寻找隐藏在数据背后的相关关系, 给出它们的表达形式一一回归函数的估计.",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.1 变量之间的两类关系"
        },
        "type": "Document"
    },
    {
        "page_content": "设 $y$ 与 $x$ 间有相关关系, 称 $x$ 为自变量 (预报变量), $y$ 为因变量 (响应变量), 在知道 $x$ 取值后, $y$ 的取值并不是确定的, 它是一个随机变量, 因此有一个分布, 这个分布是在知道 $x$ 的取值后 $Y$的条件密度函数 $p(y \\mid x)$, 我们关心的是 $y$ 的均值 $E(Y \\mid x)$, 它是 $x$ 的函数, 这个函数是确定性的:  \n$$\n\\begin{equation*}\nf(x)=E(Y \\mid x)=\\int_{-\\infty}^{+\\infty} y p(y \\mid x) \\mathrm{d} y \\tag{8.4.1}\n\\end{equation*}\n$$  \n这便是 $y$ 关于 $x$ 的理论回归函数——条件期望, 也就是我们要寻找的相关关系的表达式.  \n以上的叙述是在 $x$ 与 $y$ 均为随机变量场合进行的, 这是一类回归问题. 实际中还有第二类回归问题, 其自变量 $x$ 是可控变量 (一般变量), 只有 $y$ 是随机变量, 它们之间的相关关系可用下式表示  \n$$\ny=f(x)+\\varepsilon \\text {, }\n$$  \n其中 $\\varepsilon$ 是随机误差,一般假设 $\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$. 由于 $\\varepsilon$ 的随机性, 导致 $y$ 是随机变量. 本节主要研究第二类回归问题.  \n进行回归分析首先是回归函数形式的选择, 当只有一个自变量时, 通常可采用画散点图的方法进行选择, 具体见下例.  \n例 8.4.1: 由专业知识知道, 合金的强度 $y\\left(\\times 10^{7} \\mathrm{~Pa}\\right)$ 与合金中碳的含量 $x(\\%)$ 有关. 为了生产强度满足用户需要的合金, 在冶炼时如何控制碳的含量? 如果在冶炼过程中通过化验得知了碳的含量,能否预测这炉合金的强度?  \n为解决这类问题就需要研究两个变量间的关系, 首先是收集数据, 我们把收集到的数据记为 $\\left(x_{i}, y_{i}\\right), i=1,2, \\cdots, n$. 本例中, 我们收集到 12 组数据, 列于表 8.4.1 中.",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.2 一元线性回归模型"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其中 $\\varepsilon$ 是随机误差,一般假设 $\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$. 由于 $\\varepsilon$ 的随机性, 导致 $y$ 是随机变量. 本节主要研究第二类回归问题.  \n进行回归分析首先是回归函数形式的选择, 当只有一个自变量时, 通常可采用画散点图的方法进行选择, 具体见下例.  \n例 8.4.1: 由专业知识知道, 合金的强度 $y\\left(\\times 10^{7} \\mathrm{~Pa}\\right)$ 与合金中碳的含量 $x(\\%)$ 有关. 为了生产强度满足用户需要的合金, 在冶炼时如何控制碳的含量? 如果在冶炼过程中通过化验得知了碳的含量,能否预测这炉合金的强度?  \n为解决这类问题就需要研究两个变量间的关系, 首先是收集数据, 我们把收集到的数据记为 $\\left(x_{i}, y_{i}\\right), i=1,2, \\cdots, n$. 本例中, 我们收集到 12 组数据, 列于表 8.4.1 中.  \n表 8.4.1: 合金钢强度 $y$ 与碳含量 $x$ 的数据  \n| 序号 | $x / \\%$ | $y / 10^{7} \\mathrm{~Pa}$ | 序号 | $x / \\%$ | $y / 10^{7} \\mathrm{~Pa}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 0.10 | 42.0 | 7 | 0.16 | 49.0 |\n| 2 | 0.11 | 43.0 | 8 | 0.17 | 53.0 |\n| 3 | 0.12 | 45.0 | 9 | 0.18 | 50.0 |\n| 4 | 0.13 | 45.0 | 10 | 0.19 | 55.0 |\n| 5 | 0.14 | 45.0 | 11 | 0.2 | 55.0 |\n| 6 | 0.15 | 47.5 | 12 | 0.21 | 60.0 |  \n为找出两个变量间存在的回归函数的形式, 可以画一张图: 把每一对数 $\\left(x_{i}, y_{i}\\right)$ 看成直角坐标系中的一个点, 在图上画出 $n$ 个点, 称这张图为散点图, 见图 8.4.1.",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.2 一元线性回归模型"
        },
        "type": "Document"
    },
    {
        "page_content": "| 序号 | $x / \\%$ | $y / 10^{7} \\mathrm{~Pa}$ | 序号 | $x / \\%$ | $y / 10^{7} \\mathrm{~Pa}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 0.10 | 42.0 | 7 | 0.16 | 49.0 |\n| 2 | 0.11 | 43.0 | 8 | 0.17 | 53.0 |\n| 3 | 0.12 | 45.0 | 9 | 0.18 | 50.0 |\n| 4 | 0.13 | 45.0 | 10 | 0.19 | 55.0 |\n| 5 | 0.14 | 45.0 | 11 | 0.2 | 55.0 |\n| 6 | 0.15 | 47.5 | 12 | 0.21 | 60.0 |  \n为找出两个变量间存在的回归函数的形式, 可以画一张图: 把每一对数 $\\left(x_{i}, y_{i}\\right)$ 看成直角坐标系中的一个点, 在图上画出 $n$ 个点, 称这张图为散点图, 见图 8.4.1.  \n从散点图我们发现 12 个点基本在一条直线附近, 这说明两个变量之间有一个线性相关关系,若记 $y$ 轴方向上的误差为 $\\varepsilon$, 这个相关关系可以表示为  \n$$\n\\begin{equation*}\ny=\\beta_{0}+\\beta_{1} x+\\varepsilon . \\tag{8.4.2}\n\\end{equation*}\n$$  \n这便是 $y$ 关于 $x$ 的一元线性回归的数据结构式. 这里总假定 $x$ 为一般变量, 是非随机变量, 其值是可以精确测量或严格控制的, $\\beta_{0}, \\beta_{1}$ 为未知参数, $\\beta_{1}$ 是直线的斜率, 它表示 $x$ 每增加一个单位 $E(y)$ 的增加量. $\\varepsilon$ 是随机误差, 通常假定  \n$$\n\\begin{equation*}\nE(\\varepsilon)=0, \\operatorname{Var}(\\varepsilon)=\\sigma^{2} . \\tag{8.4.3}\n\\end{equation*}\n$$  \n!  \n图 8.4.1: 合金钢强度及碳含量的散点图",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.2 一元线性回归模型"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{equation*}\ny=\\beta_{0}+\\beta_{1} x+\\varepsilon . \\tag{8.4.2}\n\\end{equation*}\n$$  \n这便是 $y$ 关于 $x$ 的一元线性回归的数据结构式. 这里总假定 $x$ 为一般变量, 是非随机变量, 其值是可以精确测量或严格控制的, $\\beta_{0}, \\beta_{1}$ 为未知参数, $\\beta_{1}$ 是直线的斜率, 它表示 $x$ 每增加一个单位 $E(y)$ 的增加量. $\\varepsilon$ 是随机误差, 通常假定  \n$$\n\\begin{equation*}\nE(\\varepsilon)=0, \\operatorname{Var}(\\varepsilon)=\\sigma^{2} . \\tag{8.4.3}\n\\end{equation*}\n$$  \n!  \n图 8.4.1: 合金钢强度及碳含量的散点图  \n在对未知参数做区间估计或假设检验时, 还需要假定误差服从正态分布, 即  \n$$\n\\begin{equation*}\ny \\sim N\\left(\\beta_{0}+\\beta_{1} x, \\sigma^{2}\\right) \\tag{8.4.4}\n\\end{equation*}\n$$  \n显然, 假定 8.4.4 比 8.4.3 要强. 由 $\\beta_{0}, \\beta_{1}$ 均未知, 需要我们从收集到的数据 $\\left(x_{i}, y_{i}\\right), i=1,2, \\cdots, n$出发进行估计. 在收集数据时, 我们一般要求观察独立地进行, 即假定 $y_{1}, y_{2}, \\cdots, y_{n}$ 相互独立. 综合上述诸项假定,我们可以给出最简单、常用的一元线性回归的统计模型:  \n$$\n\\left\\{\\begin{array}{l}\ny_{i}=\\beta_{0}+\\beta_{1}+\\varepsilon_{i}, \\quad i=1,2, \\cdots, n ;  \\tag{8.4.5}\\\\\n\\text { 各 } \\varepsilon_{i} \\text { 独立同分布, 其分布为 } N\\left(0, \\sigma^{2}\\right)\n\\end{array}\\right.\n$$",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.2 一元线性回归模型"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n显然, 假定 8.4.4 比 8.4.3 要强. 由 $\\beta_{0}, \\beta_{1}$ 均未知, 需要我们从收集到的数据 $\\left(x_{i}, y_{i}\\right), i=1,2, \\cdots, n$出发进行估计. 在收集数据时, 我们一般要求观察独立地进行, 即假定 $y_{1}, y_{2}, \\cdots, y_{n}$ 相互独立. 综合上述诸项假定,我们可以给出最简单、常用的一元线性回归的统计模型:  \n$$\n\\left\\{\\begin{array}{l}\ny_{i}=\\beta_{0}+\\beta_{1}+\\varepsilon_{i}, \\quad i=1,2, \\cdots, n ;  \\tag{8.4.5}\\\\\n\\text { 各 } \\varepsilon_{i} \\text { 独立同分布, 其分布为 } N\\left(0, \\sigma^{2}\\right)\n\\end{array}\\right.\n$$  \n由数据 $\\left(x_{i}, y_{i}\\right), i=1,2, \\cdots, n$, 可以获得 $\\beta_{0}, \\beta_{1}$ 的估计 $\\hat{\\beta}_{0}, \\hat{\\beta}_{1}$ 称  \n$$\n\\begin{equation*}\n\\hat{y}=\\hat{\\beta}_{0}+\\hat{\\beta}_{x} \\tag{8.4.6}\n\\end{equation*}\n$$  \n为 $y$ 关于 $x$ 的经验回归函数, 简称为回归方程, 其图形称为回归直线. 给定 $x=x_{0}$ 后, 称 $\\hat{y}_{0}=$ $\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{0}$ 为回归值 (在不同场合也称其为拟合值、预测值 ).",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.2 一元线性回归模型"
        },
        "type": "Document"
    },
    {
        "page_content": "一般采用最小二乘方法估计模型 8.4 .5 中的 $\\beta_{0}, \\beta_{1}$. 令  \n$$\nQ\\left(\\beta_{0}, \\beta_{1}\\right)=\\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\beta_{1} x_{i}\\right)^{2}\n$$  \n$\\beta_{0}, \\beta_{1}$ 应该满足  \n$$\nQ\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right)=\\min _{\\beta_{0}, \\beta_{1}}=Q\\left(\\beta_{0}, \\beta_{1}\\right),\n$$  \n称这样得到的 $\\hat{\\beta}_{0}, \\hat{\\beta}_{1}$ 称为 $\\beta_{0}, \\beta_{1}$ 为的最小二乘估计, 记为 LSE.  \n由于 $Q \\geqslant 0$, 且对 $\\beta_{0}, \\beta_{1}$ 的导数存在, 因此最小二乘估计可以通过求偏导数并命其为 0 而得到:  \n$$\n\\left\\{\\begin{array}{l}\n\\frac{\\partial Q}{\\partial \\beta_{0}}=-2 \\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\beta_{1} x_{i}\\right)=0  \\tag{8.4.7}\\\\\n\\frac{\\partial Q}{\\partial \\beta_{1}}=-2 \\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\beta_{1} x_{i}\\right) x_{i}=0\n\\end{array}\\right.\n$$  \n这组方程称为正规方程组, 经过整理, 可得  \n$$\n\\left\\{\\begin{array}{l}\nn \\hat{\\beta}_{0}+n \\bar{x} \\hat{\\beta}_{1}=n \\bar{y}  \\tag{8.4.8}\\\\\nn \\bar{x} \\hat{\\beta}_{0}+\\sum x_{i}^{2} \\hat{\\beta}_{1}=\\sum x_{i} y_{i}\n\\end{array}\\right.\n$$",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\left\\{\\begin{array}{l}\n\\frac{\\partial Q}{\\partial \\beta_{0}}=-2 \\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\beta_{1} x_{i}\\right)=0  \\tag{8.4.7}\\\\\n\\frac{\\partial Q}{\\partial \\beta_{1}}=-2 \\sum_{i=1}^{n}\\left(y_{i}-\\beta_{0}-\\beta_{1} x_{i}\\right) x_{i}=0\n\\end{array}\\right.\n$$  \n这组方程称为正规方程组, 经过整理, 可得  \n$$\n\\left\\{\\begin{array}{l}\nn \\hat{\\beta}_{0}+n \\bar{x} \\hat{\\beta}_{1}=n \\bar{y}  \\tag{8.4.8}\\\\\nn \\bar{x} \\hat{\\beta}_{0}+\\sum x_{i}^{2} \\hat{\\beta}_{1}=\\sum x_{i} y_{i}\n\\end{array}\\right.\n$$  \n(今后凡是不作说明 $\\sum$ 都表示 “ $\\sum_{i=1}^{n}$ ). 记  \n$$\n\\begin{aligned}\n\\bar{x} & =\\frac{1}{n} \\sum x_{i}, \\bar{y}=\\frac{1}{n} \\sum y_{i}, \\\\\nl_{x y} & =\\sum\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)=\\sum x_{i} y_{i}-n \\bar{x} \\cdot \\bar{y}=\\sum x_{i} y_{i}-\\frac{1}{n} \\sum x_{i} \\sum y_{i}, \\\\\nl_{x x} & =\\sum\\left(x_{i}-\\bar{x}\\right)^{2}=\\sum x_{i}^{2}-n \\bar{x}^{2}=\\sum x_{i}^{2}-\\frac{1}{n}\\left(\\sigma x_{i}\\right)^{2}, \\\\",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array}\\right.\n$$  \n(今后凡是不作说明 $\\sum$ 都表示 “ $\\sum_{i=1}^{n}$ ). 记  \n$$\n\\begin{aligned}\n\\bar{x} & =\\frac{1}{n} \\sum x_{i}, \\bar{y}=\\frac{1}{n} \\sum y_{i}, \\\\\nl_{x y} & =\\sum\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)=\\sum x_{i} y_{i}-n \\bar{x} \\cdot \\bar{y}=\\sum x_{i} y_{i}-\\frac{1}{n} \\sum x_{i} \\sum y_{i}, \\\\\nl_{x x} & =\\sum\\left(x_{i}-\\bar{x}\\right)^{2}=\\sum x_{i}^{2}-n \\bar{x}^{2}=\\sum x_{i}^{2}-\\frac{1}{n}\\left(\\sigma x_{i}\\right)^{2}, \\\\\nl_{y y} & =\\sum\\left(y_{i}-\\bar{y}\\right)^{2}=\\sum y_{i}^{2}-n \\bar{y}^{2}=\\sum y_{i}^{2}-\\frac{1}{n}\\left(\\sigma y_{i}\\right)^{2} .\n\\end{aligned}\n$$  \n解 8.4.8 可得  \n$$\n\\left\\{\\begin{array}{l}\n\\hat{\\beta}_{1}=l_{x y} / l_{x x}  \\tag{8.4.9}\\\\\n\\hat{\\beta}_{0}=\\bar{y}-\\hat{\\beta}_{1} \\bar{x}\n\\end{array}\\right.\n$$  \n这就是参数的最小二乘估计, 其计算通常可列表进行, 见表 8.4.2.  \n例 8.4.2: 使用例 8.4.1 种合金钢强度和碳含量数据, 我们可求得回归方程, 见表 8.4.1.  \n表 8.4.2: 例 8.4.1 的计算表  \n| $\\sum x_{i}=1.90$ | $n=12$ | $\\sum y_{i}=590.5$ |\n| :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n解 8.4.8 可得  \n$$\n\\left\\{\\begin{array}{l}\n\\hat{\\beta}_{1}=l_{x y} / l_{x x}  \\tag{8.4.9}\\\\\n\\hat{\\beta}_{0}=\\bar{y}-\\hat{\\beta}_{1} \\bar{x}\n\\end{array}\\right.\n$$  \n这就是参数的最小二乘估计, 其计算通常可列表进行, 见表 8.4.2.  \n例 8.4.2: 使用例 8.4.1 种合金钢强度和碳含量数据, 我们可求得回归方程, 见表 8.4.1.  \n表 8.4.2: 例 8.4.1 的计算表  \n| $\\sum x_{i}=1.90$ | $n=12$ | $\\sum y_{i}=590.5$ |\n| :---: | :---: | :---: |\n| $\\bar{x}=0.1583$ |  | $\\bar{y}=49.2083$ |\n| $\\sum x_{i}^{2}=0.3194$ | $\\sum x_{i} y_{i}=95.9250$ | $\\sum y_{i}^{2}=29392.75$ |\n| $n \\bar{x}^{2}=0.3008$ | $n \\cdot \\bar{x} \\cdot \\bar{y}=93.4958$ | $n \\bar{y}^{2}=29057.52$ |\n| $l_{x x}=0.0186$ | $l_{x y}=2.4292$ | $l_{y y}=335.23$ |\n| $\\hat{\\beta}_{1}=l_{x y} / l_{x x}=130.60$ |  |  |\n| $\\hat{\\beta}_{0}=\\bar{y}-\\bar{x} \\hat{\\beta}_{1}=28.53$ |  |  |  \n( $l_{y y}$ 在后面将会用到) 由此给出回归方程为  \n$$\n\\hat{y}=28.53+130.60 x\n$$  \n关于最小二乘估计的一些性质罗列在如下定理之中:  \n定理 8.4.1. 在模型 8.4.5 下, 有",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\sum x_{i}^{2}=0.3194$ | $\\sum x_{i} y_{i}=95.9250$ | $\\sum y_{i}^{2}=29392.75$ |\n| $n \\bar{x}^{2}=0.3008$ | $n \\cdot \\bar{x} \\cdot \\bar{y}=93.4958$ | $n \\bar{y}^{2}=29057.52$ |\n| $l_{x x}=0.0186$ | $l_{x y}=2.4292$ | $l_{y y}=335.23$ |\n| $\\hat{\\beta}_{1}=l_{x y} / l_{x x}=130.60$ |  |  |\n| $\\hat{\\beta}_{0}=\\bar{y}-\\bar{x} \\hat{\\beta}_{1}=28.53$ |  |  |  \n( $l_{y y}$ 在后面将会用到) 由此给出回归方程为  \n$$\n\\hat{y}=28.53+130.60 x\n$$  \n关于最小二乘估计的一些性质罗列在如下定理之中:  \n定理 8.4.1. 在模型 8.4.5 下, 有  \n1. $\\hat{\\beta}_{0} \\sim N\\left(\\beta_{0},\\left(\\frac{1}{n}+\\frac{\\bar{x}^{2}}{l_{x x}}\\right) \\sigma^{2}\\right), \\quad \\hat{\\beta}_{1} \\sim N\\left(\\beta_{1}, \\frac{\\sigma^{2}}{l_{x x}}\\right)$;\n2. $\\operatorname{Cov}\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right)=-\\frac{\\bar{x}}{l_{x x}} \\sigma^{2}$;\n3. 对于给定的 $x_{0}, \\hat{y}_{0}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{0} \\sim N\\left(\\beta_{0}+\\beta_{1} x_{0},\\left(\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}\\right) \\sigma^{2}\\right)$.",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "1. $\\hat{\\beta}_{0} \\sim N\\left(\\beta_{0},\\left(\\frac{1}{n}+\\frac{\\bar{x}^{2}}{l_{x x}}\\right) \\sigma^{2}\\right), \\quad \\hat{\\beta}_{1} \\sim N\\left(\\beta_{1}, \\frac{\\sigma^{2}}{l_{x x}}\\right)$;\n2. $\\operatorname{Cov}\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right)=-\\frac{\\bar{x}}{l_{x x}} \\sigma^{2}$;\n3. 对于给定的 $x_{0}, \\hat{y}_{0}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{0} \\sim N\\left(\\beta_{0}+\\beta_{1} x_{0},\\left(\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}\\right) \\sigma^{2}\\right)$.  \n证明: 利用 $\\sum\\left(x_{i}-\\bar{x}\\right)=0$, 可把 $\\hat{\\beta}_{1}$ 和 $\\hat{\\beta}_{0}$ 改写为  \n$$\n\\begin{aligned}\n& \\hat{\\beta}_{1}=\\frac{l_{z x}}{l_{x x}}=\\sum \\frac{x_{i}-\\bar{x}}{l_{x x}} y_{i} \\\\\n& \\hat{\\beta}_{0}=\\bar{y}-\\hat{\\beta}_{1} \\bar{x}=\\sum\\left[\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right] y_{i} .\n\\end{aligned}\n$$  \n它们是独立正态变量 $y_{1}, y_{2}, \\cdots, y_{n}$ 的线性组合, 故都服从正态分布, 下面分别求其期望与方差  \n$$\n\\begin{aligned}",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "证明: 利用 $\\sum\\left(x_{i}-\\bar{x}\\right)=0$, 可把 $\\hat{\\beta}_{1}$ 和 $\\hat{\\beta}_{0}$ 改写为  \n$$\n\\begin{aligned}\n& \\hat{\\beta}_{1}=\\frac{l_{z x}}{l_{x x}}=\\sum \\frac{x_{i}-\\bar{x}}{l_{x x}} y_{i} \\\\\n& \\hat{\\beta}_{0}=\\bar{y}-\\hat{\\beta}_{1} \\bar{x}=\\sum\\left[\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right] y_{i} .\n\\end{aligned}\n$$  \n它们是独立正态变量 $y_{1}, y_{2}, \\cdots, y_{n}$ 的线性组合, 故都服从正态分布, 下面分别求其期望与方差  \n$$\n\\begin{aligned}\nE\\left(\\hat{\\beta}_{1}\\right) & =\\sum \\frac{x_{i}-\\bar{x}}{l_{x x}} E\\left(y_{i}\\right)=\\sum \\frac{x_{i}-\\bar{x}}{l_{x x}}\\left(\\beta_{0}+\\beta_{1} x_{i}\\right)=\\beta_{1}, \\\\\n\\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right) & =\\sum\\left(\\frac{x_{i}-\\bar{x}}{l_{x x}}\\right)^{2} \\operatorname{Var}\\left(y_{i}\\right)=\\sum \\frac{\\left(x_{i}-\\bar{x}\\right)^{2}}{l_{x x}^{2}} \\sigma^{2}=\\frac{\\sigma^{2}}{l_{x x}} \\\\\nE\\left(\\hat{\\beta}_{0}\\right) & =E(\\hat{y})-E\\left(\\hat{\\beta}_{1}\\right) \\bar{x}=\\beta_{0}+\\beta_{1} \\bar{x}-\\beta_{1} \\bar{x}=\\beta_{0} \\\\",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right) & =\\sum\\left(\\frac{x_{i}-\\bar{x}}{l_{x x}}\\right)^{2} \\operatorname{Var}\\left(y_{i}\\right)=\\sum \\frac{\\left(x_{i}-\\bar{x}\\right)^{2}}{l_{x x}^{2}} \\sigma^{2}=\\frac{\\sigma^{2}}{l_{x x}} \\\\\nE\\left(\\hat{\\beta}_{0}\\right) & =E(\\hat{y})-E\\left(\\hat{\\beta}_{1}\\right) \\bar{x}=\\beta_{0}+\\beta_{1} \\bar{x}-\\beta_{1} \\bar{x}=\\beta_{0} \\\\\n\\operatorname{Var}\\left(\\hat{\\beta}_{0}\\right) & =\\sum\\left[\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right]^{2} \\operatorname{Var}\\left(y_{i}\\right)=\\left(\\frac{1}{n}+\\frac{\\bar{x}^{2}}{l_{x x}}\\right) \\sigma^{2} .\n\\end{aligned}\n$$  \n这就证明了 1. 进一步, 考虑到诸 $y_{i}$ 之间的独立性, 可得  \n$$\n\\begin{aligned}\n\\operatorname{Cov}\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right) & =\\operatorname{Cov}\\left(\\sum\\left[\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right] y_{i}, \\sum \\frac{x_{i}-\\bar{x}}{l_{x x}} y_{i}\\right) \\\\",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n这就证明了 1. 进一步, 考虑到诸 $y_{i}$ 之间的独立性, 可得  \n$$\n\\begin{aligned}\n\\operatorname{Cov}\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right) & =\\operatorname{Cov}\\left(\\sum\\left[\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right] y_{i}, \\sum \\frac{x_{i}-\\bar{x}}{l_{x x}} y_{i}\\right) \\\\\n& =\\sum\\left[\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right] \\frac{x_{i}-\\bar{x}}{l_{x x}} \\sigma^{2}=-\\frac{\\bar{x}}{l_{x x}} \\sigma^{2} .\n\\end{aligned}\n$$  \n这就证明了 2. 为证明 3 , 注意到 $\\hat{y}_{0}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{0}$ 也是 $y_{1}, y_{2}, \\cdots, y_{n}$ 的线性组合, 它也服从正态分布, 只需求出其期望与方差即可.  \n证明完成。  \n$$\n\\begin{aligned}\nE\\left(\\hat{y}_{0}\\right) & =E\\left(\\hat{\\beta}_{0}\\right)+E\\left(\\hat{\\beta}_{1}\\right) x_{0}=\\beta_{0}+\\beta_{1} x_{0}=E\\left(y_{0}\\right) \\\\",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "& =\\sum\\left[\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right] \\frac{x_{i}-\\bar{x}}{l_{x x}} \\sigma^{2}=-\\frac{\\bar{x}}{l_{x x}} \\sigma^{2} .\n\\end{aligned}\n$$  \n这就证明了 2. 为证明 3 , 注意到 $\\hat{y}_{0}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{0}$ 也是 $y_{1}, y_{2}, \\cdots, y_{n}$ 的线性组合, 它也服从正态分布, 只需求出其期望与方差即可.  \n证明完成。  \n$$\n\\begin{aligned}\nE\\left(\\hat{y}_{0}\\right) & =E\\left(\\hat{\\beta}_{0}\\right)+E\\left(\\hat{\\beta}_{1}\\right) x_{0}=\\beta_{0}+\\beta_{1} x_{0}=E\\left(y_{0}\\right) \\\\\n\\operatorname{Var}\\left(\\hat{y}_{0}\\right) & =\\operatorname{Var}\\left(\\hat{\\beta}_{0}\\right)+\\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right) x_{0}^{2}+2 \\operatorname{Cov}\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right) \\\\\n& =\\left[\\left(\\frac{1}{n}+\\frac{\\bar{x}^{2}}{l_{x x}}\\right)+\\frac{x_{0}^{2}}{l_{x x}}-2 \\frac{x_{0} \\bar{x}}{l_{x x}}\\right] \\sigma^{2}=\\left[\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}\\right] \\sigma^{2}\n\\end{aligned}\n$$  \n定理 8.4.1 说明:",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "\\operatorname{Var}\\left(\\hat{y}_{0}\\right) & =\\operatorname{Var}\\left(\\hat{\\beta}_{0}\\right)+\\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right) x_{0}^{2}+2 \\operatorname{Cov}\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right) \\\\\n& =\\left[\\left(\\frac{1}{n}+\\frac{\\bar{x}^{2}}{l_{x x}}\\right)+\\frac{x_{0}^{2}}{l_{x x}}-2 \\frac{x_{0} \\bar{x}}{l_{x x}}\\right] \\sigma^{2}=\\left[\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}\\right] \\sigma^{2}\n\\end{aligned}\n$$  \n定理 8.4.1 说明:  \n- $\\hat{\\beta}_{0}, \\hat{\\beta}_{1}$ 分别是 $\\beta_{0}, \\beta_{1}$ 的无偏估计;\n- $\\hat{y}_{0}$ 是 $E\\left(y_{0}\\right)=\\beta_{0}+\\beta_{1} x_{1}$ 的无偏估计;\n- 除 $\\bar{x}=0$ 外, $\\hat{\\beta}_{0}$ 与 $\\hat{\\beta}_{1}$ 是相关的.\n- 要提高 $\\hat{\\beta}_{0}, \\hat{\\beta}_{1}$ 的估计精度 (即降低它们的方差) 就要求 $n$ 大, $l_{x x}$ 大 (即要求 $x_{1}, x_{2}, \\cdots, x_{n}$ 较分散).",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.3 回归系数的最小二乘估计"
        },
        "type": "Document"
    },
    {
        "page_content": "从回归系数的 LSE 可以看出, 对任意给出的 $n$ 对数据 $\\left(x_{i}, y_{i}\\right)$, 都可以求出 $\\hat{\\beta}_{0}, \\hat{\\beta}_{1}$, 从而给出回归方程 $\\hat{y}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{i}$, 但是这样给出的回归方程不一定有意义.  \n在使用回归方程作进一步的分析以前, 首先应对回归方程是否有意义进行判断. 什么叫回归方程有意义呢? 我们知道, 建立回归方程的目的是寻找 $y$ 的均值随 $x$ 变化的规律, 即找出回归方程 $E(y)=\\beta_{0}+\\beta_{1} x$. 如果 $\\beta_{1}=0$, 那么不管 $x$ 如何变化, $E(y)$ 不随 $x$ 的变化作线性变化, 那么这时求得的一元线性回归方程就没有意义, 称回归方程不显著. 如果 $\\beta \\neq 0$, 那么当 $x$ 变化时, $E(y)$ 随 $x$ 的变化作线性变化, 那么这时求得的回归方程就有意义, 称回归方程是显著的, 综上, 对回归方程是否有意义作判断就是要作如下的显著性检验:  \n$$\nH_{0}: \\beta_{1}=0 \\quad \\text { vs } \\quad H_{1}: \\beta_{1} \\neq 0\n$$  \n拒绝 $H_{0}$ 表示回归方程是显著的. 在一元线性回归中有三种等价的检验方法, 使用中只要任选其中之一即可.",
        "metadata": {
            "Header 2": "8.4 一元线性回归",
            "Header 3": "8.4.4 回归方程的显著性检验"
        },
        "type": "Document"
    },
    {
        "page_content": "采用方差分析的思想,我们从数据出发研究各 $y_{i}$ 不同的原因. 首先引人记号: 记 $\\hat{y}_{i}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x$为回归值, $y_{i}-\\hat{y}_{i}$ 为残差.  \n数据总的波动用总偏差平方和  \n$$\n\\begin{equation*}\nS_{T}=\\sigma\\left(y_{i}-\\bar{y}_{i}\\right)^{2}=l_{y y} \\tag{8.4.10}\n\\end{equation*}\n$$  \n表示. 引起各 $y_{i}$ 不同的原因主要有两个因素: 其一是 $H_{0}$ 可能不真, $E(y)$ 随 $x$ 的变化而变化, 从而在每一个 $x$ 的观测值处的回归值不同, 其波动用回归平方和  \n$$\n\\begin{equation*}\nS_{R}=\\sigma\\left(\\hat{y}_{i}-\\bar{y}_{i}\\right)^{2} \\tag{8.4.11}\n\\end{equation*}\n$$  \n表示; 其二是其他一切因素, 包括随机误差、 $x$ 对 $E(y)$ 的非线性影响等, 这样在得到回归值以后, $y$\n的观测值与回归值之间还有差距, 这可用残差平方和  \n$$\n\\begin{equation*}\nS_{e}=\\sigma\\left(y_{i}-\\hat{y}_{i}\\right)^{2} \\tag{8.4.12}\n\\end{equation*}\n$$  \n表示. 注意到 $\\hat{\\beta}_{0}, \\hat{\\beta}_{1}$ 满足正规方程组 8.4.8, 因此有  \n$$\n\\begin{aligned}\n\\sum\\left(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right)=0 & \\Rightarrow \\sum\\left(y_{i}-\\hat{y}_{i}\\right)=0 \\\\\n\\sum\\left(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right) x_{i}=0 & \\Rightarrow \\sum\\left(y_{i}-\\hat{y}_{i}\\right) x_{i}=0\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "的观测值与回归值之间还有差距, 这可用残差平方和  \n$$\n\\begin{equation*}\nS_{e}=\\sigma\\left(y_{i}-\\hat{y}_{i}\\right)^{2} \\tag{8.4.12}\n\\end{equation*}\n$$  \n表示. 注意到 $\\hat{\\beta}_{0}, \\hat{\\beta}_{1}$ 满足正规方程组 8.4.8, 因此有  \n$$\n\\begin{aligned}\n\\sum\\left(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right)=0 & \\Rightarrow \\sum\\left(y_{i}-\\hat{y}_{i}\\right)=0 \\\\\n\\sum\\left(y_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right) x_{i}=0 & \\Rightarrow \\sum\\left(y_{i}-\\hat{y}_{i}\\right) x_{i}=0\n\\end{aligned}\n$$  \n利用 $\\hat{y}_{i}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{i}, x_{i}=\\bar{y}+\\hat{\\beta}_{1}\\left(x_{i}-\\bar{x}\\right)$, 可得  \n从而  \n$$\n\\begin{aligned}\n\\sum\\left(y_{i}-\\hat{y}_{i}\\right)\\left(\\hat{y}_{i}-\\bar{y}\\right) & =\\sum\\left(y_{i}-\\hat{y}_{i}\\right)\\left[\\hat{\\beta}_{1}\\left(x_{i}-\\bar{x}\\right)\\right] \\\\\n& =\\hat{\\beta}_{1}\\left[\\sum\\left(y_{i}-\\hat{y}_{i}\\right) x_{i}-\\sum\\left(y_{i}-\\hat{y}_{i}\\right) \\bar{x}\\right]=0\n\\end{aligned}\n$$  \n$$",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n利用 $\\hat{y}_{i}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{i}, x_{i}=\\bar{y}+\\hat{\\beta}_{1}\\left(x_{i}-\\bar{x}\\right)$, 可得  \n从而  \n$$\n\\begin{aligned}\n\\sum\\left(y_{i}-\\hat{y}_{i}\\right)\\left(\\hat{y}_{i}-\\bar{y}\\right) & =\\sum\\left(y_{i}-\\hat{y}_{i}\\right)\\left[\\hat{\\beta}_{1}\\left(x_{i}-\\bar{x}\\right)\\right] \\\\\n& =\\hat{\\beta}_{1}\\left[\\sum\\left(y_{i}-\\hat{y}_{i}\\right) x_{i}-\\sum\\left(y_{i}-\\hat{y}_{i}\\right) \\bar{x}\\right]=0\n\\end{aligned}\n$$  \n$$\nS_{T}=\\sum\\left(y_{i}-\\bar{y}\\right)^{2}=\\sum\\left(y_{i}-\\hat{y}_{i}+\\hat{y}_{i}-\\bar{y}\\right)^{2}=\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}+\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2}\n$$  \n即  \n$$\n\\begin{equation*}\nS_{T}=S_{R}+S_{E} \\tag{8.4.13}\n\\end{equation*}\n$$  \n上式就是一元线性回归场合下的平方和分解式.  \n关于 $S_{R}$ 和 $S_{e}$ 所含有的成分可由如下定理说明.  \n定理 8.4.2. 设 $y_{i}=\\beta_{0}+\\beta_{1}+\\varepsilon_{i}$, 其中 $\\varepsilon_{1}, \\cdots, \\varepsilon_{n}$ 相互独立, 且  \n$$",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n$$\nS_{T}=\\sum\\left(y_{i}-\\bar{y}\\right)^{2}=\\sum\\left(y_{i}-\\hat{y}_{i}+\\hat{y}_{i}-\\bar{y}\\right)^{2}=\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}+\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2}\n$$  \n即  \n$$\n\\begin{equation*}\nS_{T}=S_{R}+S_{E} \\tag{8.4.13}\n\\end{equation*}\n$$  \n上式就是一元线性回归场合下的平方和分解式.  \n关于 $S_{R}$ 和 $S_{e}$ 所含有的成分可由如下定理说明.  \n定理 8.4.2. 设 $y_{i}=\\beta_{0}+\\beta_{1}+\\varepsilon_{i}$, 其中 $\\varepsilon_{1}, \\cdots, \\varepsilon_{n}$ 相互独立, 且  \n$$\nE\\left(\\varepsilon_{i}\\right)=0, \\operatorname{Var}\\left(y_{i}\\right)=\\sigma^{2}, i=1, \\cdots, n,\n$$  \n沿用上面的记号, 有  \n$$\n\\begin{gather*}\nE\\left(S_{R}\\right)=\\sigma^{2}+\\beta_{1}^{2} l_{x x}  \\tag{8.4.14}\\\\\nE\\left(S_{e}\\right)=(n-2) \\sigma^{2} \\tag{8.4.15}\n\\end{gather*}\n$$  \n这说明 $\\hat{\\sigma}^{2}=S_{e} /(n-2)$ 是 $\\sigma^{2}$ 的无偏估计.  \n证明: 首先我们可以写出 $S_{R}$ 的简化公式:  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "定理 8.4.2. 设 $y_{i}=\\beta_{0}+\\beta_{1}+\\varepsilon_{i}$, 其中 $\\varepsilon_{1}, \\cdots, \\varepsilon_{n}$ 相互独立, 且  \n$$\nE\\left(\\varepsilon_{i}\\right)=0, \\operatorname{Var}\\left(y_{i}\\right)=\\sigma^{2}, i=1, \\cdots, n,\n$$  \n沿用上面的记号, 有  \n$$\n\\begin{gather*}\nE\\left(S_{R}\\right)=\\sigma^{2}+\\beta_{1}^{2} l_{x x}  \\tag{8.4.14}\\\\\nE\\left(S_{e}\\right)=(n-2) \\sigma^{2} \\tag{8.4.15}\n\\end{gather*}\n$$  \n这说明 $\\hat{\\sigma}^{2}=S_{e} /(n-2)$ 是 $\\sigma^{2}$ 的无偏估计.  \n证明: 首先我们可以写出 $S_{R}$ 的简化公式:  \n$$\n\\begin{equation*}\nS_{R}=\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2}=\\sum\\left[\\bar{y}+\\hat{\\bar{\\beta}}_{1}\\left(x_{i}-\\bar{x}\\right)-\\bar{y}\\right]^{2}=\\hat{\\beta}_{1}^{2} l_{x x} \\tag{8.4.16}\n\\end{equation*}\n$$  \n从而  \n$$\n\\begin{aligned}\nE\\left(S_{R}\\right) & =E\\left(\\hat{\\beta}_{1}^{2}\\right) l_{x x}=\\left[\\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right)+\\left(E \\hat{\\beta}_{1}\\right)^{2}\\right] \\cdot l_{x x} \\\\\n& =\\left(\\frac{\\sigma^{2}}{l_{-x}}+\\beta_{1}^{2}\\right) l_{x x}=\\sigma^{2}+\\beta_{1}^{2} l_{x x}",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "S_{R}=\\sum\\left(\\hat{y}_{i}-\\bar{y}\\right)^{2}=\\sum\\left[\\bar{y}+\\hat{\\bar{\\beta}}_{1}\\left(x_{i}-\\bar{x}\\right)-\\bar{y}\\right]^{2}=\\hat{\\beta}_{1}^{2} l_{x x} \\tag{8.4.16}\n\\end{equation*}\n$$  \n从而  \n$$\n\\begin{aligned}\nE\\left(S_{R}\\right) & =E\\left(\\hat{\\beta}_{1}^{2}\\right) l_{x x}=\\left[\\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right)+\\left(E \\hat{\\beta}_{1}\\right)^{2}\\right] \\cdot l_{x x} \\\\\n& =\\left(\\frac{\\sigma^{2}}{l_{-x}}+\\beta_{1}^{2}\\right) l_{x x}=\\sigma^{2}+\\beta_{1}^{2} l_{x x}\n\\end{aligned}\n$$  \n又  \n故  \n$$\n\\begin{aligned}\nS_{e}= & \\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2} \\\\\n= & \\sum\\left(\\beta_{0}+\\beta_{1} x_{i}+\\varepsilon_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right)^{2} \\\\\n= & \\sum\\left[\\left(\\hat{\\beta}_{0}-\\beta_{0}\\right)^{2}+x_{k}^{2}\\left(\\hat{\\beta}_{1}-\\beta_{1}\\right)^{2}+\\varepsilon_{i}^{2}+2\\left(\\hat{\\beta}_{0}-\\beta_{0}\\right)\\left(\\hat{\\beta}_{1}-\\beta_{1}\\right) x_{i}-\\right. \\\\",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n又  \n故  \n$$\n\\begin{aligned}\nS_{e}= & \\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2} \\\\\n= & \\sum\\left(\\beta_{0}+\\beta_{1} x_{i}+\\varepsilon_{i}-\\hat{\\beta}_{0}-\\hat{\\beta}_{1} x_{i}\\right)^{2} \\\\\n= & \\sum\\left[\\left(\\hat{\\beta}_{0}-\\beta_{0}\\right)^{2}+x_{k}^{2}\\left(\\hat{\\beta}_{1}-\\beta_{1}\\right)^{2}+\\varepsilon_{i}^{2}+2\\left(\\hat{\\beta}_{0}-\\beta_{0}\\right)\\left(\\hat{\\beta}_{1}-\\beta_{1}\\right) x_{i}-\\right. \\\\\n& \\left.2\\left(\\hat{\\beta}_{0}-\\beta_{0}\\right) \\varepsilon_{1}-2\\left(\\hat{\\beta}_{1}-\\beta_{1}\\right) x_{i} \\varepsilon_{i}\\right]\n\\end{aligned}\n$$  \n$$\n\\begin{gathered}\nE\\left(S_{e}\\right)=n \\operatorname{Var}\\left(\\hat{\\beta}_{0}\\right)+\\sum x_{i}^{2} \\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right)+n \\operatorname{Var}(\\varepsilon)+2 n \\bar{x} \\operatorname{Cov}\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right)- \\\\\n2 \\sum E\\left(\\hat{\\beta}_{0} \\varepsilon_{i}\\right)-2 \\sum x_{i} E\\left(\\hat{\\beta}_{1} \\varepsilon_{i}\\right)\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{aligned}\n$$  \n$$\n\\begin{gathered}\nE\\left(S_{e}\\right)=n \\operatorname{Var}\\left(\\hat{\\beta}_{0}\\right)+\\sum x_{i}^{2} \\operatorname{Var}\\left(\\hat{\\beta}_{1}\\right)+n \\operatorname{Var}(\\varepsilon)+2 n \\bar{x} \\operatorname{Cov}\\left(\\hat{\\beta}_{0}, \\hat{\\beta}_{1}\\right)- \\\\\n2 \\sum E\\left(\\hat{\\beta}_{0} \\varepsilon_{i}\\right)-2 \\sum x_{i} E\\left(\\hat{\\beta}_{1} \\varepsilon_{i}\\right)\n\\end{gathered}\n$$  \n将 $\\hat{\\beta}_{0}, \\hat{\\beta}_{i}$ 写成 $y_{1}, y_{2}, \\cdots, y_{n}$ 的线性组合, 利用 $y_{i}$ 与 $\\varepsilon_{i}(i \\neq j)$ 的独立性, 有  \n$$\n\\begin{aligned}\n& E\\left(\\hat{\\beta}_{0} \\varepsilon_{i}\\right)=E\\left[\\varepsilon_{i} \\sum_{j}\\left(\\frac{1}{n}-\\frac{\\left(x_{j}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right) y_{j}\\right]=\\left(\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right) \\sigma^{2} \\\\\n& E\\left(\\hat{\\beta}_{1} \\varepsilon_{i}\\right)=E\\left[\\varepsilon_{i} \\sum_{j} \\frac{x_{j}-\\bar{x}}{l_{x x}} y_{j}\\right]=\\frac{x_{i}-\\bar{x}}{l_{x x}} \\sigma^{2}\n\\end{aligned}",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\begin{aligned}\n& E\\left(\\hat{\\beta}_{0} \\varepsilon_{i}\\right)=E\\left[\\varepsilon_{i} \\sum_{j}\\left(\\frac{1}{n}-\\frac{\\left(x_{j}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right) y_{j}\\right]=\\left(\\frac{1}{n}-\\frac{\\left(x_{i}-\\bar{x}\\right) \\bar{x}}{l_{x x}}\\right) \\sigma^{2} \\\\\n& E\\left(\\hat{\\beta}_{1} \\varepsilon_{i}\\right)=E\\left[\\varepsilon_{i} \\sum_{j} \\frac{x_{j}-\\bar{x}}{l_{x x}} y_{j}\\right]=\\frac{x_{i}-\\bar{x}}{l_{x x}} \\sigma^{2}\n\\end{aligned}\n$$  \n由此既有  \n$$\n\\sum E\\left(\\hat{\\beta}_{0} \\varepsilon_{i}\\right)=\\sigma^{2}, \\quad \\sum x_{i} E\\left(\\hat{\\beta}_{1} \\varepsilon_{i}\\right)=\\sigma^{2}\n$$  \n从而  \n$$\n\\begin{aligned}\nE\\left(S_{e}\\right) & =n\\left[\\frac{1}{n}+\\frac{\\bar{x}^{2}}{l_{x x}}\\right] \\sigma^{2}+\\sum \\frac{x_{i}^{2}}{l_{x x}} \\sigma^{2}+n \\sigma^{2}-\\frac{2 n \\bar{x}^{2}}{l_{x x}} \\sigma^{2}-2 \\sigma^{2}-2 \\sigma^{2} \\\\\n& =(1+n-4) \\sigma^{2}+\\frac{1}{l_{x x}} \\sum\\left(x_{i}-\\bar{x}\\right)^{2} \\sigma^{2}=(n-2) \\sigma^{2}\n\\end{aligned}\n$$  \n这就完成了证明.",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n从而  \n$$\n\\begin{aligned}\nE\\left(S_{e}\\right) & =n\\left[\\frac{1}{n}+\\frac{\\bar{x}^{2}}{l_{x x}}\\right] \\sigma^{2}+\\sum \\frac{x_{i}^{2}}{l_{x x}} \\sigma^{2}+n \\sigma^{2}-\\frac{2 n \\bar{x}^{2}}{l_{x x}} \\sigma^{2}-2 \\sigma^{2}-2 \\sigma^{2} \\\\\n& =(1+n-4) \\sigma^{2}+\\frac{1}{l_{x x}} \\sum\\left(x_{i}-\\bar{x}\\right)^{2} \\sigma^{2}=(n-2) \\sigma^{2}\n\\end{aligned}\n$$  \n这就完成了证明.  \n进一步, 有关 $S_{R}$ 和 $S_{e}$ 的分布, 有如下定理.  \n定理 8.4.3. 设 $y_{1} \\cdots, y_{n}$ 相互独立, 且 $y_{i} \\sim N\\left(\\beta_{0}+\\beta_{1} x_{i}\\right), i=1 \\cdots, n$, 则在上述记号下, 有  \n1. $S_{e} / \\sigma^{2} \\sim \\chi^{2}(n-2)$,\n2. 若 $H_{0}$ 成立, 则有 $S_{R} / \\sigma^{2} \\sim \\chi^{2}(1)$,\n3. $S_{R}$ 与 $S_{e} 、 \\bar{y}$ 独立(或 $\\hat{\\beta}_{1}$ 与 $S_{e} 、 \\bar{y}$ 独立).  \n证明: 取 $n \\times n$ 的正交矩阵 $A$, 具有如下形式:  \n$$\nA=\\left(\\begin{array}{cccc}\n& a_{12} & \\cdots & a_{1 n} \\\\\n\\vdots & \\vdots & & \\vdots \\\\\na_{n-2,1} & a_{n-2,2} & \\cdots & a_{n-2, n} \\\\",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "定理 8.4.3. 设 $y_{1} \\cdots, y_{n}$ 相互独立, 且 $y_{i} \\sim N\\left(\\beta_{0}+\\beta_{1} x_{i}\\right), i=1 \\cdots, n$, 则在上述记号下, 有  \n1. $S_{e} / \\sigma^{2} \\sim \\chi^{2}(n-2)$,\n2. 若 $H_{0}$ 成立, 则有 $S_{R} / \\sigma^{2} \\sim \\chi^{2}(1)$,\n3. $S_{R}$ 与 $S_{e} 、 \\bar{y}$ 独立(或 $\\hat{\\beta}_{1}$ 与 $S_{e} 、 \\bar{y}$ 独立).  \n证明: 取 $n \\times n$ 的正交矩阵 $A$, 具有如下形式:  \n$$\nA=\\left(\\begin{array}{cccc}\n& a_{12} & \\cdots & a_{1 n} \\\\\n\\vdots & \\vdots & & \\vdots \\\\\na_{n-2,1} & a_{n-2,2} & \\cdots & a_{n-2, n} \\\\\n\\left(x_{1}-\\bar{x}\\right) / \\sqrt{l_{x x}} & \\left(x_{2}-\\bar{x}\\right) / \\sqrt{l_{x x}} & \\cdots & \\left(x_{n}-\\bar{x}\\right) / \\sqrt{l_{x x}} \\\\\n1 / \\sqrt{n} & 1 / \\sqrt{n} & \\cdots & 1 / \\sqrt{n}\n\\end{array}\\right)\n$$  \n由正交性, 可得如下一些约束条件  \n$$\n\\begin{gathered}\n\\sum_{j} a_{i j}=0, \\sum_{j} a_{i j} x_{j}=0, \\quad \\sum_{j} a_{i j}^{2}=1, i=1,2, \\cdots, n-2 \\\\\n\\sum_{k} a_{i k} a_{j k}=0, \\quad 1 \\leqslant i<j \\leqslant n-2\n\\end{gathered}\n$$",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "a_{n-2,1} & a_{n-2,2} & \\cdots & a_{n-2, n} \\\\\n\\left(x_{1}-\\bar{x}\\right) / \\sqrt{l_{x x}} & \\left(x_{2}-\\bar{x}\\right) / \\sqrt{l_{x x}} & \\cdots & \\left(x_{n}-\\bar{x}\\right) / \\sqrt{l_{x x}} \\\\\n1 / \\sqrt{n} & 1 / \\sqrt{n} & \\cdots & 1 / \\sqrt{n}\n\\end{array}\\right)\n$$  \n由正交性, 可得如下一些约束条件  \n$$\n\\begin{gathered}\n\\sum_{j} a_{i j}=0, \\sum_{j} a_{i j} x_{j}=0, \\quad \\sum_{j} a_{i j}^{2}=1, i=1,2, \\cdots, n-2 \\\\\n\\sum_{k} a_{i k} a_{j k}=0, \\quad 1 \\leqslant i<j \\leqslant n-2\n\\end{gathered}\n$$  \n这里共有 $n(n-2)$ 个未知参数, 约束条件有 $3(n-2)+\\left(\\begin{array}{c}n-2 \\\\ 2\\end{array}\\right)=(n-2)(n+3) / 2$ 个, 只要 $n \\geqslant 3$, 未知参数个数就不少于约束条件数, 因此必定有解. 令  \n$$\nZ=\\left(\\begin{array}{c}\nz_{1} \\\\\nz_{2} \\\\\n\\vdots \\\\\nx_{n}\n\\end{array}\\right)=A Y=A\\left(\\begin{array}{c}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{n}\n\\end{array}\\right)=\\left(\\begin{array}{c}\n\\sum_{j} a_{1 j} y_{j} \\\\\n\\vdots \\\\\n\\sum_{j} a_{n-2, j} y_{j} \\\\\n\\sum_{j} \\frac{x_{j}-\\bar{x}}{\\sqrt{l_{x x}}} y_{j} \\\\\n\\sum_{j} \\frac{1}{\\sqrt{n}} y_{j}",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n这里共有 $n(n-2)$ 个未知参数, 约束条件有 $3(n-2)+\\left(\\begin{array}{c}n-2 \\\\ 2\\end{array}\\right)=(n-2)(n+3) / 2$ 个, 只要 $n \\geqslant 3$, 未知参数个数就不少于约束条件数, 因此必定有解. 令  \n$$\nZ=\\left(\\begin{array}{c}\nz_{1} \\\\\nz_{2} \\\\\n\\vdots \\\\\nx_{n}\n\\end{array}\\right)=A Y=A\\left(\\begin{array}{c}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{n}\n\\end{array}\\right)=\\left(\\begin{array}{c}\n\\sum_{j} a_{1 j} y_{j} \\\\\n\\vdots \\\\\n\\sum_{j} a_{n-2, j} y_{j} \\\\\n\\sum_{j} \\frac{x_{j}-\\bar{x}}{\\sqrt{l_{x x}}} y_{j} \\\\\n\\sum_{j} \\frac{1}{\\sqrt{n}} y_{j}\n\\end{array}\\right) \\text {, }\n$$  \n其中  \n$$\n\\begin{aligned}\nz_{n-1} & =\\frac{\\sum\\left(x_{t}-\\bar{x}\\right) y_{i}}{\\sqrt{l_{x x}}}=\\frac{\\sum\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)}{\\sqrt{l_{x x}}}=\\frac{l_{x y}}{\\sqrt{l_{x x}}}=\\sqrt{l_{x x}} \\hat{\\beta}_{1}, \\\\\nz_{n} & =\\frac{1}{\\sqrt{n}} \\sum y_{i}=\\sqrt{n} \\bar{y}\n\\end{aligned}\n$$  \n则 $Z$ 仍然服从正态分布, 且其期望与协差阵分别为  \n$$\nE Z=\\left(\\begin{array}{c}\n0 \\\\\n\\vdots \\\\\n\\beta_{1} \\sqrt{l_{x x}} \\\\\n\\sqrt{n}\\left(\\beta_{0}+\\beta_{1} \\bar{x}\\right)",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n其中  \n$$\n\\begin{aligned}\nz_{n-1} & =\\frac{\\sum\\left(x_{t}-\\bar{x}\\right) y_{i}}{\\sqrt{l_{x x}}}=\\frac{\\sum\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)}{\\sqrt{l_{x x}}}=\\frac{l_{x y}}{\\sqrt{l_{x x}}}=\\sqrt{l_{x x}} \\hat{\\beta}_{1}, \\\\\nz_{n} & =\\frac{1}{\\sqrt{n}} \\sum y_{i}=\\sqrt{n} \\bar{y}\n\\end{aligned}\n$$  \n则 $Z$ 仍然服从正态分布, 且其期望与协差阵分别为  \n$$\nE Z=\\left(\\begin{array}{c}\n0 \\\\\n\\vdots \\\\\n\\beta_{1} \\sqrt{l_{x x}} \\\\\n\\sqrt{n}\\left(\\beta_{0}+\\beta_{1} \\bar{x}\\right)\n\\end{array}\\right), \\quad \\operatorname{Var}(Z)=A \\operatorname{Var}(Y) A^{\\mathrm{T}}=\\sigma^{2} I_{n}\n$$  \n这表明 $z_{1}, z_{2}, \\cdots, z_{n}$ 相互独立, $z_{1}, z_{2}, \\cdots, z_{n-2}$ 的共同分布为 $N\\left(0, \\sigma^{2}\\right), z_{n-1} \\sim N\\left(\\beta_{1} \\sqrt{l_{x x}}, \\sigma^{2}\\right), z_{n} \\sim$ $N\\left(\\sqrt{n}\\left(\\beta_{0}+\\beta_{1} \\bar{x}\\right), \\sigma^{2}\\right)$.",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\nE Z=\\left(\\begin{array}{c}\n0 \\\\\n\\vdots \\\\\n\\beta_{1} \\sqrt{l_{x x}} \\\\\n\\sqrt{n}\\left(\\beta_{0}+\\beta_{1} \\bar{x}\\right)\n\\end{array}\\right), \\quad \\operatorname{Var}(Z)=A \\operatorname{Var}(Y) A^{\\mathrm{T}}=\\sigma^{2} I_{n}\n$$  \n这表明 $z_{1}, z_{2}, \\cdots, z_{n}$ 相互独立, $z_{1}, z_{2}, \\cdots, z_{n-2}$ 的共同分布为 $N\\left(0, \\sigma^{2}\\right), z_{n-1} \\sim N\\left(\\beta_{1} \\sqrt{l_{x x}}, \\sigma^{2}\\right), z_{n} \\sim$ $N\\left(\\sqrt{n}\\left(\\beta_{0}+\\beta_{1} \\bar{x}\\right), \\sigma^{2}\\right)$.  \n由于 $\\sum z_{i}^{2}=\\sum y_{i}^{2}=S_{T}+n \\bar{y}^{2}=S_{R}+S_{e}+n \\bar{y}^{2}$, 而 $z_{n}=\\sqrt{n} \\bar{y}, z_{n-1}=\\sqrt{l_{x x}} \\hat{\\beta}_{1}=\\sqrt{S_{R}}$, 于是 $z_{1}^{2}+z_{2}^{2}+\\cdots+z_{n-2}^{2}=S_{e}$, 所以 $S_{e}, S_{R}, \\bar{y}$ 三者相互独立, 并有  \n$$\n\\begin{gathered}\nS_{e} / \\sigma^{2}=\\sum_{i=1}^{n-2}\\left(z_{i} / \\sigma^{2}\\right) \\sim \\chi^{2}(n-2) \\\\\n\\text { 在 } \\beta_{1}=0 \\text { 时, } S_{R} / \\sigma^{2}=\\left(z_{n-1} / \\sum\\right)^{2} \\sim \\chi^{2}(1)\n\\end{gathered}\n$$  \n证明完成.",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "由于 $\\sum z_{i}^{2}=\\sum y_{i}^{2}=S_{T}+n \\bar{y}^{2}=S_{R}+S_{e}+n \\bar{y}^{2}$, 而 $z_{n}=\\sqrt{n} \\bar{y}, z_{n-1}=\\sqrt{l_{x x}} \\hat{\\beta}_{1}=\\sqrt{S_{R}}$, 于是 $z_{1}^{2}+z_{2}^{2}+\\cdots+z_{n-2}^{2}=S_{e}$, 所以 $S_{e}, S_{R}, \\bar{y}$ 三者相互独立, 并有  \n$$\n\\begin{gathered}\nS_{e} / \\sigma^{2}=\\sum_{i=1}^{n-2}\\left(z_{i} / \\sigma^{2}\\right) \\sim \\chi^{2}(n-2) \\\\\n\\text { 在 } \\beta_{1}=0 \\text { 时, } S_{R} / \\sigma^{2}=\\left(z_{n-1} / \\sum\\right)^{2} \\sim \\chi^{2}(1)\n\\end{gathered}\n$$  \n证明完成.  \n如同方差分析那样, 我们可以考虑采用 $F$ 作为检验统计量:  \n$$\nF=\\frac{S_{R}}{S_{e} /(n-2)}\n$$  \n在 $\\beta_{1}=0$ 时, $F \\sim F(1, n-2)$, 其中 $f_{R}=1, f_{e}=n-2$. 对于给定的显著性水平 $\\alpha$, 拒绝域为  \n$$\nF \\geqslant F_{1-\\alpha}(1, n-2) .\n$$  \n整个检验也可列成一张方差分析表.  \n例 8.4.3: 在合金钢强度的例 8.4.2 中, 我们已求出了回归方程, 这里我们考虑关于回归方程的显著性检验. 经计算有  \n$$\n\\begin{array}{ll}\nS_{T}=l_{y y}=335.23, & f_{T}=11 \\\\\nS_{R}=\\hat{\\beta}_{1}^{2} l_{x x}=130.60^{2} \\times 0.0186=317.26, & f_{R}=1 \\\\\nS_{e}=S_{T}-S_{R}=335.23-317.26=17.97, & f_{e}=10\n\\end{array}\n$$",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "如同方差分析那样, 我们可以考虑采用 $F$ 作为检验统计量:  \n$$\nF=\\frac{S_{R}}{S_{e} /(n-2)}\n$$  \n在 $\\beta_{1}=0$ 时, $F \\sim F(1, n-2)$, 其中 $f_{R}=1, f_{e}=n-2$. 对于给定的显著性水平 $\\alpha$, 拒绝域为  \n$$\nF \\geqslant F_{1-\\alpha}(1, n-2) .\n$$  \n整个检验也可列成一张方差分析表.  \n例 8.4.3: 在合金钢强度的例 8.4.2 中, 我们已求出了回归方程, 这里我们考虑关于回归方程的显著性检验. 经计算有  \n$$\n\\begin{array}{ll}\nS_{T}=l_{y y}=335.23, & f_{T}=11 \\\\\nS_{R}=\\hat{\\beta}_{1}^{2} l_{x x}=130.60^{2} \\times 0.0186=317.26, & f_{R}=1 \\\\\nS_{e}=S_{T}-S_{R}=335.23-317.26=17.97, & f_{e}=10\n\\end{array}\n$$  \n把各平方和移人方差分析表, 继续进行计算, 具体见表 8.4.3. 若取 $\\alpha=0.01$, 则 $F_{0.99}(1,10)=10.0$.  \n表 8.4.3: 合金钢强度与碳含量回归方程的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :---: | :---: | :---: | :---: | :---: |\n| 回归 | $S_{R}=317.26$ | $f_{R}=1$ | $M S_{R}=317.26$ | 176.26 |\n| 残差 | $S_{e}=17.97$ | $f_{e}=10$ | $M S_{e}=1.80$ |  |\n| 总计 | $S_{T}=335.23$ | $f_{T}=11$ |  |  |  \n由于 $176.55>10.0$, 因此, 在显著性水平 0.01 下回归方程是显著的.",
        "metadata": {
            "Header 2": "一. $F$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "对 $H_{0}: \\beta_{1}=0$ 的检验也可基于 $t$ 分布进行. 由于 $\\hat{\\beta}_{1} \\sim N\\left(\\beta_{1}, \\frac{\\sigma^{2}}{l_{x x}}\\right), \\frac{S_{e}}{\\sigma^{2}} \\sim \\chi^{2}(n-2)$, 且与 $\\hat{\\beta}_{1}$相互独立, 因此在 $H_{0}$ 为真时, 有  \n$$\n\\begin{equation*}\nt=\\frac{\\hat{\\beta}_{1}}{\\hat{\\sigma} / \\sqrt{l_{x x}}} \\sim t(n-2) \\tag{8.4.17}\n\\end{equation*}\n$$  \n其中 $\\hat{\\sigma}=\\sqrt{S_{e} /(n-2)}$, 由于 $\\sigma_{\\hat{\\beta}_{1}}=\\sigma / \\sqrt{l_{x x}}$, 因此称 $\\hat{\\sigma}_{\\hat{\\beta}_{1}}=\\hat{\\sigma} / \\sqrt{l_{x x}}$ 为 $\\hat{\\beta}_{1}$ 的标准误, 即 $\\hat{\\beta}_{1}$ 的标准差的估计. (8.4.17) 式表示的 $t$ 统计量可用来检验假设 $H_{0}$. 对给定的显著性水平 $\\alpha$, 拒绝域为  \n$$\nW=|| t\\left|>t_{1-\\alpha / 2}(n-2)\\right|\n$$  \n注意到 $t^{2}=F$, 因此, $t$ 检验与 $F$ 检验是等同的.\n以例 8.4.2 中数据为例, 可以计算得到  \n$$\nt=\\frac{130.6022}{\\sqrt{1.7970} / \\sqrt{0.0186}}=13.2872\n$$  \n若取 $\\alpha=0.01$, 则 $t_{0.995}(10)=3.1698$, 由于 $13.2872>3.1698$, 因此, 在显著性水平 0.01 下回归方程是显著的.",
        "metadata": {
            "Header 2": "二。 $t$ 检验"
        },
        "type": "Document"
    },
    {
        "page_content": "当一元线性回归方程是反映两个随机变量 $x$ 与 $y$ 间的线性相关关系时, 它的显著性检验还可通过对二维总体相关系数 $p$ 的检验进行. 它的一对假设是  \n$$\n\\begin{equation*}\nH_{0}: \\rho=0 \\quad \\text { vs } \\quad H_{1}: \\rho \\neq 0 \\tag{8.4.18}\n\\end{equation*}\n$$  \n所用的检验统计量为样本相关系数  \n$$\n\\begin{equation*}\nr=\\frac{\\sum\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)}{\\sqrt{\\sum\\left(x_{i}-\\bar{x}\\right)^{2} \\sum\\left(y_{i}-\\bar{y}\\right)^{2}}}=\\frac{l_{x y}}{\\sqrt{l_{x x} l_{y y}}} \\tag{8.4.19}\n\\end{equation*}\n$$  \n其中 $\\left(x_{i}, y_{i}\\right), i=1, \\cdots, n$ 是容量为 $n$ 的二维样本.  \n利用施瓦茨不等式可以证明: 样本相关系数也满足 $|r| \\leqslant 1$, 其中等号成立条件是存在两个实数 $a$ 与 $b$, 使得对 $i=1, \\cdots, n$ 有 $y_{i}=a+b x_{i}$. 由此可见, $n$ 个点 $\\left(x_{i}, y_{u}\\right), i=1, \\cdots, n$ 在散布图上的位置与样本相关系数 $r$ 有关, 譬如:  \n1. $r= \\pm 1, n$ 个点完全在一条上升或下降的直线上;\n2. $r>0$, 当 $x$ 增加时, $y$ 有线性增加趋势, 此时称正相关;\n3. $r<0$, 当 $x$ 增加时, $y$ 反而有线性减少趋势, 此时称负相关;\n4. $r=0, n$ 个点可能毫无规律, 也可能呈某种曲线趋势, 此时称不相关.  \n根据样本相关系数的上述性质, 检验 (8.4.18) 中原假设 $H_{0}: \\rho=0$ 的拒绝域为  \n$$\nW=\\{|r| \\geqslant c\\}\n$$",
        "metadata": {
            "Header 2": "三、相关系数检验"
        },
        "type": "Document"
    },
    {
        "page_content": "利用施瓦茨不等式可以证明: 样本相关系数也满足 $|r| \\leqslant 1$, 其中等号成立条件是存在两个实数 $a$ 与 $b$, 使得对 $i=1, \\cdots, n$ 有 $y_{i}=a+b x_{i}$. 由此可见, $n$ 个点 $\\left(x_{i}, y_{u}\\right), i=1, \\cdots, n$ 在散布图上的位置与样本相关系数 $r$ 有关, 譬如:  \n1. $r= \\pm 1, n$ 个点完全在一条上升或下降的直线上;\n2. $r>0$, 当 $x$ 增加时, $y$ 有线性增加趋势, 此时称正相关;\n3. $r<0$, 当 $x$ 增加时, $y$ 反而有线性减少趋势, 此时称负相关;\n4. $r=0, n$ 个点可能毫无规律, 也可能呈某种曲线趋势, 此时称不相关.  \n根据样本相关系数的上述性质, 检验 (8.4.18) 中原假设 $H_{0}: \\rho=0$ 的拒绝域为  \n$$\nW=\\{|r| \\geqslant c\\}\n$$  \n其中临界值 $c$ 可由 $H_{0}: \\rho=0$ 成立时样本相关系数的分布定出, 该分布与自由度 $n-2$ 有关.  \n对给定的显著性水平 $\\alpha$, 由 $P(W)=P(|r| \\geqslant c)=\\alpha$ 知, 临界值 $c$ 应是 $H_{0}: \\rho=0$ 成立下 $|r|$的分布的 $1-\\alpha$ 分位数, 故记为 $c=r_{1-\\alpha}(n-2)$. 我们还可以用 $F$ 分布来确定临界值 $c$, 下面加以叙述.  \n由样本相关系数的定义可以得到统计量 $r$ 与 $F$ 之间的关系  \n$$\nr^{2}=\\frac{l_{x y}^{2}}{l_{x x} l_{y y}}=\\frac{S_{R}}{S_{T}}=\\frac{S_{R}}{S_{R}+S_{e}}=\\frac{S_{R} / S_{e}}{S_{R} / S_{e}+1}\n$$  \n而  \n$$\nF=\\frac{M S_{R}}{M S_{e}}=\\frac{S_{R}}{S_{e} /(n-2)}=\\frac{(n-2) S_{R}}{S_{e}}\n$$  \n两者综合, 可得  \n$$\nr^{2}=\\frac{F}{F+(n-2)}\n$$",
        "metadata": {
            "Header 2": "三、相关系数检验"
        },
        "type": "Document"
    },
    {
        "page_content": "对给定的显著性水平 $\\alpha$, 由 $P(W)=P(|r| \\geqslant c)=\\alpha$ 知, 临界值 $c$ 应是 $H_{0}: \\rho=0$ 成立下 $|r|$的分布的 $1-\\alpha$ 分位数, 故记为 $c=r_{1-\\alpha}(n-2)$. 我们还可以用 $F$ 分布来确定临界值 $c$, 下面加以叙述.  \n由样本相关系数的定义可以得到统计量 $r$ 与 $F$ 之间的关系  \n$$\nr^{2}=\\frac{l_{x y}^{2}}{l_{x x} l_{y y}}=\\frac{S_{R}}{S_{T}}=\\frac{S_{R}}{S_{R}+S_{e}}=\\frac{S_{R} / S_{e}}{S_{R} / S_{e}+1}\n$$  \n而  \n$$\nF=\\frac{M S_{R}}{M S_{e}}=\\frac{S_{R}}{S_{e} /(n-2)}=\\frac{(n-2) S_{R}}{S_{e}}\n$$  \n两者综合, 可得  \n$$\nr^{2}=\\frac{F}{F+(n-2)}\n$$  \n这表明, $|r|$ 是 $F$ 的严格单调增函数, 故可以从 $F$ 分布的 $1-\\alpha$ 分位数 $F_{1-\\alpha}(1, n-2)$ 得到 $|r|$ 的 $1-\\alpha$ 分位数为  \n$$\nc=r_{1-\\alpha}(n-2)=\\sqrt{\\frac{F_{1-\\alpha}(1, n-2)}{F_{1-\\alpha}(1, n-2)+1}}\n$$  \n譬如, 对 $\\alpha=0.01, n=12$, 查表知 $F_{0.99}(1,10)=10.04$,于是  \n$$\nr_{0.99}(10)=\\sqrt{\\frac{10.04}{10.04+1}}=0.708\n$$  \n为实际使用方便, 人们已对 $r_{1-\\alpha}(n-2)$ 编制了专门的表, 见附表 9. 以例 8.4.2 中数据为例, 可以计\n算得到  \n$$\nr=\\frac{2.4292}{\\sqrt{0.0186 \\times 335.2292}}=0.9728\n$$",
        "metadata": {
            "Header 2": "三、相关系数检验"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n两者综合, 可得  \n$$\nr^{2}=\\frac{F}{F+(n-2)}\n$$  \n这表明, $|r|$ 是 $F$ 的严格单调增函数, 故可以从 $F$ 分布的 $1-\\alpha$ 分位数 $F_{1-\\alpha}(1, n-2)$ 得到 $|r|$ 的 $1-\\alpha$ 分位数为  \n$$\nc=r_{1-\\alpha}(n-2)=\\sqrt{\\frac{F_{1-\\alpha}(1, n-2)}{F_{1-\\alpha}(1, n-2)+1}}\n$$  \n譬如, 对 $\\alpha=0.01, n=12$, 查表知 $F_{0.99}(1,10)=10.04$,于是  \n$$\nr_{0.99}(10)=\\sqrt{\\frac{10.04}{10.04+1}}=0.708\n$$  \n为实际使用方便, 人们已对 $r_{1-\\alpha}(n-2)$ 编制了专门的表, 见附表 9. 以例 8.4.2 中数据为例, 可以计\n算得到  \n$$\nr=\\frac{2.4292}{\\sqrt{0.0186 \\times 335.2292}}=0.9728\n$$  \n若取 $\\alpha=0.01$, 查附表 9 知则 $r_{0.99}(10)=0.708$, 由于 $0.9728>0.708$, 因此, 在显著性水平 0.01 下回归方程是显著的.",
        "metadata": {
            "Header 2": "三、相关系数检验"
        },
        "type": "Document"
    },
    {
        "page_content": "当回归方程经过检验是显著的后, 可用来做估计和预测. 这是两个不同的问题:  \n- 当 $x=x_{0}$ 时, 寻求均值 $E\\left(y_{0}\\right)=\\beta_{0}+\\beta_{1} x_{0}$ 的点估计与区间估计 (注意这里 $E\\left(y_{0}\\right)$ 是常量),这是估计问题;\n- 当 $x=x_{0}$ 时, $y_{0}$ 的观察值在什么范围内? 由于 $y_{0}$ 是随机变量, 为此只能求一个区间, 使 $y_{0}$落在这一区间的概率为 $1-\\alpha$, 即要求 $\\delta$, 使 $P\\left(\\left|y_{0}-\\hat{y}_{0}\\right|<\\delta\\right)=1-\\alpha$, 称区间 $\\left[\\hat{y}_{0}-\\delta, \\hat{y}_{0}+\\delta\\right]$为 $y_{0}$ 的概率为 $1-\\alpha$ 的预测区间, 这是预测问题.",
        "metadata": {
            "Header 2": "三、相关系数检验",
            "Header 3": "8.4.5 估计与检测"
        },
        "type": "Document"
    },
    {
        "page_content": "在 $x=x_{0}$ 时, 其对应的因变量 $y_{0}$ 是一个随机变量, 有一个分布, 我们经常需要对该分布的均值给出估计. 我们知道, 该分布的均值 $E\\left(y_{0}\\right)=\\beta_{0}+\\beta_{1} x_{0}$, 因此, 一个直观的估计应为  \n$$\n\\hat{E}\\left(y_{0}\\right)=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{0}\n$$  \n简单起见, 我们习惯上将上述估计记为 $\\hat{y}_{0}$ (注意这里 $\\hat{y}_{0}$ 表示的是 $E\\left(y_{0}\\right)$ 的估计, 而不表示 $y_{0}$ 的估计, 因为 $y_{0}$ 是随机变量, 它是没有估计的). 由于 $\\hat{\\beta}_{0}, \\hat{\\beta}_{1}$ 分别是 $\\beta_{0}, \\beta_{1}$ 的无偏估计, 因此 $\\hat{y}_{0}$ 也是 $E\\left(y_{0}\\right)$ 的无偏估计.  \n为得到 $E\\left(y_{0}\\right)$ 的区间估计, 我们需要知道 $\\hat{y}_{0}$ 的分布. 由定理 8.4.1 可得  \n$$\n\\hat{y}_{0}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{0} \\sim N\\left(\\beta_{0}+\\beta_{1} x_{0},\\left[\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}\\right] \\sigma^{2}\\right)\n$$  \n又由定理 8.4.3 知, $S_{e} / \\sigma^{2} \\sim \\chi^{2}(n-2)$, 且与 $\\hat{y}_{0}=\\bar{y}+\\hat{\\beta}_{1}\\left(x_{0}-\\bar{x}\\right)$ 相互独立, 记  \n则  \n$$\n\\hat{\\sigma}^{2}=\\frac{S_{e}}{n-2}\n$$  \n$$",
        "metadata": {
            "Header 2": "一、 $E\\left(y_{0}\\right)$ 的估计"
        },
        "type": "Document"
    },
    {
        "page_content": "为得到 $E\\left(y_{0}\\right)$ 的区间估计, 我们需要知道 $\\hat{y}_{0}$ 的分布. 由定理 8.4.1 可得  \n$$\n\\hat{y}_{0}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x_{0} \\sim N\\left(\\beta_{0}+\\beta_{1} x_{0},\\left[\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}\\right] \\sigma^{2}\\right)\n$$  \n又由定理 8.4.3 知, $S_{e} / \\sigma^{2} \\sim \\chi^{2}(n-2)$, 且与 $\\hat{y}_{0}=\\bar{y}+\\hat{\\beta}_{1}\\left(x_{0}-\\bar{x}\\right)$ 相互独立, 记  \n则  \n$$\n\\hat{\\sigma}^{2}=\\frac{S_{e}}{n-2}\n$$  \n$$\n\\frac{\\left(\\hat{y}_{0}-E y_{0}\\right) / \\sqrt{\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}} \\sigma}{\\sqrt{\\frac{S_{e}}{\\sigma^{2}} /(n-2)}}=\\frac{\\hat{y}_{0}-E y_{0}}{\\hat{\\sigma} \\sqrt{\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}}}-t(n-2)\n$$  \n于是 $E\\left(y_{0}\\right)$ 的 $1-\\alpha$ 的置信区间是  \n$$\n\\begin{equation*}\n\\left[\\hat{y}_{0}-\\delta_{0}, \\hat{y}_{0}+\\delta_{0}\\right] \\tag{8.4.20}\n\\end{equation*}\n$$  \n其中  \n$$\n\\begin{equation*}",
        "metadata": {
            "Header 2": "一、 $E\\left(y_{0}\\right)$ 的估计"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n$$\n\\frac{\\left(\\hat{y}_{0}-E y_{0}\\right) / \\sqrt{\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}} \\sigma}{\\sqrt{\\frac{S_{e}}{\\sigma^{2}} /(n-2)}}=\\frac{\\hat{y}_{0}-E y_{0}}{\\hat{\\sigma} \\sqrt{\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}}}-t(n-2)\n$$  \n于是 $E\\left(y_{0}\\right)$ 的 $1-\\alpha$ 的置信区间是  \n$$\n\\begin{equation*}\n\\left[\\hat{y}_{0}-\\delta_{0}, \\hat{y}_{0}+\\delta_{0}\\right] \\tag{8.4.20}\n\\end{equation*}\n$$  \n其中  \n$$\n\\begin{equation*}\n\\delta_{0}=t_{1-\\alpha / 2}(n-2) \\hat{\\sigma} \\sqrt{\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}} \\tag{8.4.21}\n\\end{equation*}\n$$",
        "metadata": {
            "Header 2": "一、 $E\\left(y_{0}\\right)$ 的估计"
        },
        "type": "Document"
    },
    {
        "page_content": "(8.4.20) 给出了 $x=x_{0}$ 时对应的因变量的均值 $E\\left(y_{0}\\right)$ 的区间估计, 实用中往往更关心 $x=x_{0}$时对应的因变量 $y_{0}$ 的取值范围. 我们举一个不是非常贴切的例子说明这两者之间的差别: 设想你要去买一台某厂生产的某种型号的彩电, 则你很关心彩电的寿命一它能正常使用多长时间, 彩电的寿命是一个随机变量, 该厂生产的该型号的彩电寿命有一个分布, 其均值就是它的平均寿命, 当然, 这是一个重要的质量指标, 我们可以对它给出估计, 譬如, 平均寿命的 0.95 置信区间为 $(12,18)$  \n(单位: 千小时). 然而, 作为消费者, 我们更关心的可能是我所购买的这台彩电的寿命在一个什么范围内, 我所购买的这台彩电的寿命是一个随机变量, 我们能否对该随机变量的取值给出一个预测区间呢? 这就是我们这里要讨论的预测问题.  \n事实上, $y_{0}=E\\left(y_{0}\\right)+\\varepsilon$, 由于通常假定 $\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$, 因此, $y_{0}$ 的最可能取值仍然为 $y_{0}$, 于是,我们可以使用以列为中心的一个区间  \n$$\n\\begin{equation*}\n\\left(\\hat{y}_{0}-\\delta, \\hat{y}_{0}+\\delta\\right) \\tag{8.4.22}\n\\end{equation*}\n$$  \n作为 $y_{0}$ 的取值范围, 为确定 $\\delta$ 的值, 我们需要如下的结果:由于 $y_{0}$ 与 $\\hat{y}_{0}$ 独立, 故  \n$$\ny_{0}-\\hat{y}_{0} \\sim N\\left(0,\\left[1+\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}\\right] \\sigma^{2}\\right) \\text {. }\n$$  \n因此有  \n$$",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "事实上, $y_{0}=E\\left(y_{0}\\right)+\\varepsilon$, 由于通常假定 $\\varepsilon \\sim N\\left(0, \\sigma^{2}\\right)$, 因此, $y_{0}$ 的最可能取值仍然为 $y_{0}$, 于是,我们可以使用以列为中心的一个区间  \n$$\n\\begin{equation*}\n\\left(\\hat{y}_{0}-\\delta, \\hat{y}_{0}+\\delta\\right) \\tag{8.4.22}\n\\end{equation*}\n$$  \n作为 $y_{0}$ 的取值范围, 为确定 $\\delta$ 的值, 我们需要如下的结果:由于 $y_{0}$ 与 $\\hat{y}_{0}$ 独立, 故  \n$$\ny_{0}-\\hat{y}_{0} \\sim N\\left(0,\\left[1+\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}\\right] \\sigma^{2}\\right) \\text {. }\n$$  \n因此有  \n$$\n\\frac{y_{0}-\\hat{y}_{0}}{\\hat{\\sigma} \\sqrt{1+\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}}} \\sim t(n-2)\n$$  \n从而 (8.4.22) 表示的预测区间中 $\\delta$ 的表达式为:  \n$$\n\\begin{equation*}\n\\delta=\\delta\\left(x_{0}\\right)=t_{1-a / 2}(n-2) \\hat{\\sigma} \\sqrt{1+\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}} . \\tag{8.4.23}\n\\end{equation*}\n$$  \n上述预测区间与 $E\\left(y_{0}\\right)$ 的置信区间 (8.4.21) 的差别就在于根号里多个 1 , 计算时要注意到这个差别, 这个差别导致预测区间要比置信区间宽一些.",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n因此有  \n$$\n\\frac{y_{0}-\\hat{y}_{0}}{\\hat{\\sigma} \\sqrt{1+\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}}} \\sim t(n-2)\n$$  \n从而 (8.4.22) 表示的预测区间中 $\\delta$ 的表达式为:  \n$$\n\\begin{equation*}\n\\delta=\\delta\\left(x_{0}\\right)=t_{1-a / 2}(n-2) \\hat{\\sigma} \\sqrt{1+\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{x}\\right)^{2}}{l_{x x}}} . \\tag{8.4.23}\n\\end{equation*}\n$$  \n上述预测区间与 $E\\left(y_{0}\\right)$ 的置信区间 (8.4.21) 的差别就在于根号里多个 1 , 计算时要注意到这个差别, 这个差别导致预测区间要比置信区间宽一些.  \n由 (8.4.23) 式可以看出预测区间的长度 $2 \\delta$ 与样本量 $n, x$ 的偏差平方和 $l_{x x}, x_{0}$ 到 $\\bar{x}$ 的距离 $\\left|x_{0}-\\bar{x}\\right|$ 有关. $x_{0}$ 愈远离 $\\bar{x}$ 预测精度就愈差. 当 $x_{0} \\notin\\left[x_{(1)}, x_{(n)}\\right]$ 时, 预测精度可能变得很差, 在这种情况下的预测称作外推, 需要特别小心. 另外, 若 $x_{1}, x_{2}, \\cdots, x_{n}$ 较为集中时, 那么 $l_{x x}$ 就较小,也会导致预测精度的降低. 因此, 在收集数据时要使 $x_{1}, x_{2}, \\cdots, x_{n}$, 尽量分散, 这对提高精度有利.图 8.4.2a 给出在不同的 $x$ 值上预测区间的示意图: 在 $x=\\bar{x}$ 处预测区间最短, 远离乏的预测区间愈来愈长, 呈喇叫状.  \n!  \n(a) 精确预测区间  \n!  \n(b) 近似预测区间  \n图 8.4.2: 预测区间示意图",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "由 (8.4.23) 式可以看出预测区间的长度 $2 \\delta$ 与样本量 $n, x$ 的偏差平方和 $l_{x x}, x_{0}$ 到 $\\bar{x}$ 的距离 $\\left|x_{0}-\\bar{x}\\right|$ 有关. $x_{0}$ 愈远离 $\\bar{x}$ 预测精度就愈差. 当 $x_{0} \\notin\\left[x_{(1)}, x_{(n)}\\right]$ 时, 预测精度可能变得很差, 在这种情况下的预测称作外推, 需要特别小心. 另外, 若 $x_{1}, x_{2}, \\cdots, x_{n}$ 较为集中时, 那么 $l_{x x}$ 就较小,也会导致预测精度的降低. 因此, 在收集数据时要使 $x_{1}, x_{2}, \\cdots, x_{n}$, 尽量分散, 这对提高精度有利.图 8.4.2a 给出在不同的 $x$ 值上预测区间的示意图: 在 $x=\\bar{x}$ 处预测区间最短, 远离乏的预测区间愈来愈长, 呈喇叫状.  \n!  \n(a) 精确预测区间  \n!  \n(b) 近似预测区间  \n图 8.4.2: 预测区间示意图  \n当 $n$ 较大时 (如 $n>30$ ), $t$ 分布可以用正态分布近似, 进一步, 若 $x_{0}$ 与 $\\bar{x}$ 相差不大时, $\\delta$ 可以近似取为:  \n$$\n\\begin{equation*}\n\\delta \\approx \\hat{\\sigma} u_{1-\\alpha / 2} \\tag{8.4.24}\n\\end{equation*}\n$$  \n其中 $u_{1-\\alpha / 2}$ 是标准正态分布的 $1-\\alpha / 2$ 分位数, 见图 8.4.2b.  \n例 8.4.4: 在例 8.4.2 中, 如果 $x_{0}=0.16$, 则得预测值为  \n$$\ny_{0}=28.5364+130.6022 \\times 0.16=49.4328 \\text {. }\n$$  \n若取 $\\alpha=0.05$, 则 $t_{0.975}(10)=2.2281$, 又 $\\hat{\\sigma}=\\sqrt{17.9703 /(12-2)}=1.3405$, 应用 (8.4.21),  \n$$",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "图 8.4.2: 预测区间示意图  \n当 $n$ 较大时 (如 $n>30$ ), $t$ 分布可以用正态分布近似, 进一步, 若 $x_{0}$ 与 $\\bar{x}$ 相差不大时, $\\delta$ 可以近似取为:  \n$$\n\\begin{equation*}\n\\delta \\approx \\hat{\\sigma} u_{1-\\alpha / 2} \\tag{8.4.24}\n\\end{equation*}\n$$  \n其中 $u_{1-\\alpha / 2}$ 是标准正态分布的 $1-\\alpha / 2$ 分位数, 见图 8.4.2b.  \n例 8.4.4: 在例 8.4.2 中, 如果 $x_{0}=0.16$, 则得预测值为  \n$$\ny_{0}=28.5364+130.6022 \\times 0.16=49.4328 \\text {. }\n$$  \n若取 $\\alpha=0.05$, 则 $t_{0.975}(10)=2.2281$, 又 $\\hat{\\sigma}=\\sqrt{17.9703 /(12-2)}=1.3405$, 应用 (8.4.21),  \n$$\n\\delta_{0}=1.3405 \\times 2.2281 \\times \\sqrt{\\frac{1}{12}+\\frac{(0.16-0.19)^{2}}{0.0186}}=1.08\n$$  \n故 $x_{0}=0.16$ 对应因变量 $y_{0}$ 的均值 $E\\left(y_{0}\\right)$ 的 0.95 置信区间为  \n$$\n49.43 \\pm 1.08=(48.35,50.51)\n$$  \n应用 (8.4.23),  \n$$\n\\delta=1.3405 \\times 2.2281 \\times \\sqrt{1+\\frac{1}{12}+\\frac{(0.16-0.19)^{2}}{0.0186}}=3.18\n$$  \n从而 $y_{0}$ 的概率为 0.95 的预测区间为  \n$$\n49.43 \\pm 3.18=(46.25,52.61) .\n$$  \n我们可以清楚地看到, $E\\left(y_{0}\\right)$ 的 0.95 置信区间比 $y_{0}$ 的概率为 0.95 的预测区间窄很多, 这是因为随机变量的均值相对于随机变量本身而言要更容易估计出来.",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "\\delta_{0}=1.3405 \\times 2.2281 \\times \\sqrt{\\frac{1}{12}+\\frac{(0.16-0.19)^{2}}{0.0186}}=1.08\n$$  \n故 $x_{0}=0.16$ 对应因变量 $y_{0}$ 的均值 $E\\left(y_{0}\\right)$ 的 0.95 置信区间为  \n$$\n49.43 \\pm 1.08=(48.35,50.51)\n$$  \n应用 (8.4.23),  \n$$\n\\delta=1.3405 \\times 2.2281 \\times \\sqrt{1+\\frac{1}{12}+\\frac{(0.16-0.19)^{2}}{0.0186}}=3.18\n$$  \n从而 $y_{0}$ 的概率为 0.95 的预测区间为  \n$$\n49.43 \\pm 3.18=(46.25,52.61) .\n$$  \n我们可以清楚地看到, $E\\left(y_{0}\\right)$ 的 0.95 置信区间比 $y_{0}$ 的概率为 0.95 的预测区间窄很多, 这是因为随机变量的均值相对于随机变量本身而言要更容易估计出来.  \n如果求近似预测区间, 则可按 (8.4.24) 计算, 由于 $u_{0.975}=1.96$, 故有 $\\delta \\approx 1.96 \\times 1.34=2.63$,则所求区间为  \n$$\n(49.43-2.63,49.43+2.63)=(46.80,52.06) \\text {. }\n$$  \n此处近似预测区间与精确预测区间相差较大, 主要是因为 $n$ 较小的原因.  \n下而我们以一个完整的例子把本节内容重新梳理一遍.  \n例 8.4.5: 在动物学研究中, 有时需要找出某种动物的体积与重量的关系. 因为动物的重量相对而言容易测量, 而测量体积比较困难, 因此, 人们希望用动物的重量预测其体积. 下面是 18 只某种动物的体积与重量数据, 在这里, 动物重量被看作自变量, 用 $x$ 表示, 单位为 $\\mathrm{kg}$, 动物体积则作为因变量, 用 $y$ 表示, 单位为 $\\mathrm{dm}^{3}, 18$ 组数据列于表 8.4.4 中.  \n表 8.4.4: 18 只某种动物的重量 $x$ 与体积 $y$ 数据",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "如果求近似预测区间, 则可按 (8.4.24) 计算, 由于 $u_{0.975}=1.96$, 故有 $\\delta \\approx 1.96 \\times 1.34=2.63$,则所求区间为  \n$$\n(49.43-2.63,49.43+2.63)=(46.80,52.06) \\text {. }\n$$  \n此处近似预测区间与精确预测区间相差较大, 主要是因为 $n$ 较小的原因.  \n下而我们以一个完整的例子把本节内容重新梳理一遍.  \n例 8.4.5: 在动物学研究中, 有时需要找出某种动物的体积与重量的关系. 因为动物的重量相对而言容易测量, 而测量体积比较困难, 因此, 人们希望用动物的重量预测其体积. 下面是 18 只某种动物的体积与重量数据, 在这里, 动物重量被看作自变量, 用 $x$ 表示, 单位为 $\\mathrm{kg}$, 动物体积则作为因变量, 用 $y$ 表示, 单位为 $\\mathrm{dm}^{3}, 18$ 组数据列于表 8.4.4 中.  \n表 8.4.4: 18 只某种动物的重量 $x$ 与体积 $y$ 数据  \n| $x$ | $y$ | $x$ | $y$ | $x$ | $y$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 10.4 | 10.2 | 15.1 | 14.8 | 16.5 | 15.9 |\n| 10.5 | 10.4 | 15.1 | 15.1 | 16.7 | 16.6 |\n| 11.9 | 11.6 | 15.1 | 14.5 | 17.1 | 16.7 |\n| 12.1 | 11.9 | 15.7 | 15.7 | 17.1 | 16.7 |\n| 13.8 | 13.5 | 15.8 | 15.2 | 17.8 | 17.6 |\n| 15.0 | 14.5 | 16.0 | 15.8 | 18.4 | 18.3 |  \n为能用动物重量估计动物体积, 必须建立动物体积 $y$ 关于动物重量 $x$ 的回归方程. 首先, 我们用这 18 组数据画出散点图, 见图 8.4.3.  \n!  \n图 8.4.3: 动物体积与动物重量的散点图",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "表 8.4.4: 18 只某种动物的重量 $x$ 与体积 $y$ 数据  \n| $x$ | $y$ | $x$ | $y$ | $x$ | $y$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 10.4 | 10.2 | 15.1 | 14.8 | 16.5 | 15.9 |\n| 10.5 | 10.4 | 15.1 | 15.1 | 16.7 | 16.6 |\n| 11.9 | 11.6 | 15.1 | 14.5 | 17.1 | 16.7 |\n| 12.1 | 11.9 | 15.7 | 15.7 | 17.1 | 16.7 |\n| 13.8 | 13.5 | 15.8 | 15.2 | 17.8 | 17.6 |\n| 15.0 | 14.5 | 16.0 | 15.8 | 18.4 | 18.3 |  \n为能用动物重量估计动物体积, 必须建立动物体积 $y$ 关于动物重量 $x$ 的回归方程. 首先, 我们用这 18 组数据画出散点图, 见图 8.4.3.  \n!  \n图 8.4.3: 动物体积与动物重量的散点图\n从散点图我们发现 18 个点基本在一条直线附近, 这说明两个变量之间有一个线性相关关系,下面求该线性回归方程, 计算过程见表 8.4.5.  \n表 8.4.5: 例 8.4.5 的计算表  \n| $\\sum x_{i}=270.1$ | $n=18$ | $\\sum y_{i}=265.0$ |\n| :---: | :---: | :---: |\n| $\\bar{x}=15.0056$ |  | $\\bar{y}=14.7222$ |\n| $\\sum x_{i}^{2}=4149.39$ | $\\sum x_{i} y_{i}=4071.71$ | $\\sum y_{i}^{2}=3996.14$ |\n| $n \\bar{x}^{2}=4053.0006$ | $n \\cdot \\bar{x} \\cdot \\bar{y}=39976.422$ | $n \\bar{y}^{2}=3901.3889$ |\n| $l_{x y}=96.3894$ | $l_{x y}=95.238$ | $l_{y y}=94.7511$ |",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "!  \n图 8.4.3: 动物体积与动物重量的散点图\n从散点图我们发现 18 个点基本在一条直线附近, 这说明两个变量之间有一个线性相关关系,下面求该线性回归方程, 计算过程见表 8.4.5.  \n表 8.4.5: 例 8.4.5 的计算表  \n| $\\sum x_{i}=270.1$ | $n=18$ | $\\sum y_{i}=265.0$ |\n| :---: | :---: | :---: |\n| $\\bar{x}=15.0056$ |  | $\\bar{y}=14.7222$ |\n| $\\sum x_{i}^{2}=4149.39$ | $\\sum x_{i} y_{i}=4071.71$ | $\\sum y_{i}^{2}=3996.14$ |\n| $n \\bar{x}^{2}=4053.0006$ | $n \\cdot \\bar{x} \\cdot \\bar{y}=39976.422$ | $n \\bar{y}^{2}=3901.3889$ |\n| $l_{x y}=96.3894$ | $l_{x y}=95.238$ | $l_{y y}=94.7511$ |\n| $\\hat{\\beta}_{1}=l_{x y} / l_{x x}=0.9881$ |  |  |\n| $\\hat{\\beta}_{0}=\\bar{y}-x \\hat{\\beta}_{1}=-0.1048$ |  |  |  \n由此给出回归方程为  \n$$\n\\begin{equation*}\n\\hat{y}=-0.1048+0.9881 x . \\tag{8.4.25}\n\\end{equation*}\n$$  \n接下来我们考虑关于回归方程的显著性检验. 经计算有  \n$$\n\\begin{array}{ll}\nS_{T}=l_{y y}=94.751, & f_{T}=17 \\\\\nS_{R}=\\hat{\\beta}_{1}^{2} l_{x x}=0.9881^{2} \\times 96.3894=94.1090, & f_{R}=1 \\\\\nS_{e}=S_{T}-S_{R}=0.6421, & f_{e}=16\n\\end{array}\n$$  \n把诸平方和移人方差分析表上, 继续计算, 具体见表 8.4.6.  \n表 8.4.6: 合金钢强度与碳含量回归方程的方差分析表",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\hat{\\beta}_{1}=l_{x y} / l_{x x}=0.9881$ |  |  |\n| $\\hat{\\beta}_{0}=\\bar{y}-x \\hat{\\beta}_{1}=-0.1048$ |  |  |  \n由此给出回归方程为  \n$$\n\\begin{equation*}\n\\hat{y}=-0.1048+0.9881 x . \\tag{8.4.25}\n\\end{equation*}\n$$  \n接下来我们考虑关于回归方程的显著性检验. 经计算有  \n$$\n\\begin{array}{ll}\nS_{T}=l_{y y}=94.751, & f_{T}=17 \\\\\nS_{R}=\\hat{\\beta}_{1}^{2} l_{x x}=0.9881^{2} \\times 96.3894=94.1090, & f_{R}=1 \\\\\nS_{e}=S_{T}-S_{R}=0.6421, & f_{e}=16\n\\end{array}\n$$  \n把诸平方和移人方差分析表上, 继续计算, 具体见表 8.4.6.  \n表 8.4.6: 合金钢强度与碳含量回归方程的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :---: | :---: | :---: | :---: | :---: |\n| 回归 | $S_{R}=94.4090$ | $f_{R}=1$ | $M S_{R}=94.1090$ | 2346.9 |\n| 残差 | $S_{e}=0.6421$ | $f_{e}=16$ | $M S_{e}=0.0401$ |  |\n| 总计 | $S_{T}=94.7511$ | $f_{T}=17$ |  |  |  \n若取 $\\alpha=0.01$, 则 $F_{0.99}(1,10)=8.53$, 由于 $2346.9>8.53$, 因此, 在显著性水平 0.01 下回归方程是显著的.  \n如果测得某动物的重量为 $x_{0}=17.6 \\mathrm{~kg}$, 则由 (8.4.25), 该动物体积的估计值为  \n$$\n\\hat{y}_{0}=-0.1048+0.9881 \\times 17.6=17.2858\n$$",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "表 8.4.6: 合金钢强度与碳含量回归方程的方差分析表  \n| 来源 | 平方和 | 自由度 | 均方和 | $F$ 比 |\n| :---: | :---: | :---: | :---: | :---: |\n| 回归 | $S_{R}=94.4090$ | $f_{R}=1$ | $M S_{R}=94.1090$ | 2346.9 |\n| 残差 | $S_{e}=0.6421$ | $f_{e}=16$ | $M S_{e}=0.0401$ |  |\n| 总计 | $S_{T}=94.7511$ | $f_{T}=17$ |  |  |  \n若取 $\\alpha=0.01$, 则 $F_{0.99}(1,10)=8.53$, 由于 $2346.9>8.53$, 因此, 在显著性水平 0.01 下回归方程是显著的.  \n如果测得某动物的重量为 $x_{0}=17.6 \\mathrm{~kg}$, 则由 (8.4.25), 该动物体积的估计值为  \n$$\n\\hat{y}_{0}=-0.1048+0.9881 \\times 17.6=17.2858\n$$  \n若取 $\\alpha=0.05$, 则 $t_{0.975}(16)=2.1199$, 又 $\\hat{\\sigma}=\\sqrt{0.0401}=0.2002$, 应用 $(8.4 .21)$  \n$$\n\\delta=0.2002 \\times 2.1199 \\times \\sqrt{1+\\frac{1}{18}+\\frac{(17.6-15.0056)^{2}}{96.3894}}=0.4776\n$$  \n从而该动物体积的概率为 0.95 的预测区间为  \n$$\n(17.2858-0.4776,17.2858+0.4776)=(16.8082,17.7634)\n$$  \n用 (8.4.24)可以求近似预测区间, 由于 $u_{0.975}=1.96$, 故有 $\\delta \\approx 1.96 \\times 0.2002=0.3924$, 则所求区间为  \n$$\n(17.2858-0.3924,17.2858+0.3924)=(16.8934,17.6782) .\n$$  \n此处近似预测区间与精确预测区间差距已不大了, 当 $n$ 更大一些, 两者差距会更小一些.",
        "metadata": {
            "Header 2": "二、 $y_{0}$ 的预测区间"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 假设回归直线过原点, 即一元线性回妇模型为  \n$$\ny_{i}=\\beta x_{i}+\\varepsilon_{i}, \\quad i=1, \\cdots, n\n$$  \n$E\\left(\\varepsilon_{i}\\right)=0, \\operatorname{Var}\\left(\\varepsilon_{i}\\right)=\\sigma^{2}$, 诸观测值相互独立.  \n(1) 写出 $\\beta, \\sigma^{2}$ 的最小二乘估计;  \n(2) 对给定的 $x_{0}$, 其对应的因变量均值的估计为 $\\hat{y}_{0}$, 求 $\\operatorname{Var}\\left(\\hat{y}_{0}\\right)$.  \n2. 设回归模型为  \n$$\n\\left\\{\\begin{array}{l}\ny_{i}=\\beta_{0}+\\beta_{1} x_{i}+\\varepsilon_{i}, i=1,2, \\cdots, n, \\\\\n\\text { 各 } \\varepsilon \\text { 独立同分布, 其分布为 } N\\left(0, \\sigma^{2}\\right)\n\\end{array}\\right.\n$$  \n试求 $\\beta_{0}, \\beta_{1}, \\sigma^{2}$ 的最大似然估计, 它们与其最小二乘估计一致吗?  \n3. 在回归分析计算中, 常对数据进行变换:  \n$$\n\\tilde{y}_{\\mathrm{i}}=\\frac{y_{i}-c_{1}}{d_{1}}, \\tilde{x}_{i}=\\frac{x_{i}-c_{2}}{d_{2}}, i=1, \\cdots, n\n$$  \n其中 $c_{1}, c_{2}, d_{1}(>0), d_{2}(>0)$ 是适当选取的常数.  \n(1) 试建立由原始数据和变换后数据得到的最小二乘估计、总平方和、回归平方和以及残差平方和之间的关系；  \n(2) 证明:由原始数据和变换后数据得到的 $F$ 检验统计量的值保持不变.  \n4. 对给定的 $n$ 组数据 $\\left(x_{i}, y_{i}\\right), i=1, \\cdots, n$, 若我们关心的是 $y$ 如何依赖 $x$ 的取值而变动, 则可以建立如下回归方程  \n$$",
        "metadata": {
            "Header 2": "如 题 8.4"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{array}\\right.\n$$  \n试求 $\\beta_{0}, \\beta_{1}, \\sigma^{2}$ 的最大似然估计, 它们与其最小二乘估计一致吗?  \n3. 在回归分析计算中, 常对数据进行变换:  \n$$\n\\tilde{y}_{\\mathrm{i}}=\\frac{y_{i}-c_{1}}{d_{1}}, \\tilde{x}_{i}=\\frac{x_{i}-c_{2}}{d_{2}}, i=1, \\cdots, n\n$$  \n其中 $c_{1}, c_{2}, d_{1}(>0), d_{2}(>0)$ 是适当选取的常数.  \n(1) 试建立由原始数据和变换后数据得到的最小二乘估计、总平方和、回归平方和以及残差平方和之间的关系；  \n(2) 证明:由原始数据和变换后数据得到的 $F$ 检验统计量的值保持不变.  \n4. 对给定的 $n$ 组数据 $\\left(x_{i}, y_{i}\\right), i=1, \\cdots, n$, 若我们关心的是 $y$ 如何依赖 $x$ 的取值而变动, 则可以建立如下回归方程  \n$$\n\\hat{y}=a+b x .\n$$  \n反之, 若我们关心的是 $x$ 如何依赖 $y$ 的取值而变动, 则可以建立另一个回归方程  \n$$\n\\hat{x}=c+d y .\n$$  \n试问这两条直线在直角坐标系中是否重合? 为什么? 若不重合, 它们有无交点? 若有, 试给出交点的坐标.  \n5. 为考察某种维尼纶纤维的耐水性能, 安排了一组试验, 测得其甲醇浓度 $x$ 及相应的 “缩醇化度” $y$ 数据如下:  \n| $x$ | 18 | 20 | 22 | 24 | 26 | 28 | 30 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $y$ | 26.86 | 28.35 | 28.75 | 28.87 | 29.75 | 30.00 | 30.36 |  \n(1) 作散点图;  \n(2) 求样本相关系数;  \n(3) 建立一元线性回归方程;  \n(4) 对建立的回归方程作显著性检验 $(\\alpha=0.05)$.",
        "metadata": {
            "Header 2": "如 题 8.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\hat{y}=a+b x .\n$$  \n反之, 若我们关心的是 $x$ 如何依赖 $y$ 的取值而变动, 则可以建立另一个回归方程  \n$$\n\\hat{x}=c+d y .\n$$  \n试问这两条直线在直角坐标系中是否重合? 为什么? 若不重合, 它们有无交点? 若有, 试给出交点的坐标.  \n5. 为考察某种维尼纶纤维的耐水性能, 安排了一组试验, 测得其甲醇浓度 $x$ 及相应的 “缩醇化度” $y$ 数据如下:  \n| $x$ | 18 | 20 | 22 | 24 | 26 | 28 | 30 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $y$ | 26.86 | 28.35 | 28.75 | 28.87 | 29.75 | 30.00 | 30.36 |  \n(1) 作散点图;  \n(2) 求样本相关系数;  \n(3) 建立一元线性回归方程;  \n(4) 对建立的回归方程作显著性检验 $(\\alpha=0.05)$.  \n6. 测得一组弹簧形变 $x$ (单位: $\\mathrm{cm}$ ) 和相应的外力 $y$ (单位: $\\mathrm{N}$ ) 数据如下:  \n| $x$ | 1.0 | 1.2 | 1.4 | 1.6 | 1.8 | 2.0 | 2.2 | 2.4 | 2.8 | 3.0 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $y$ | 3.08 | 3.76 | 4.31 | 5.02 | 5.51 | 6.25 | 6.74 | 7.40 | 8.54 | 9.24 |  \n由胡克定律知 $y=k x$, 试估计 $k$, 并在 $x=2.6 \\mathrm{~cm}$ 试给出相应的外力 $y$ 的 0.95 预测区间.  \n7. 设由 $\\left(x_{i}, y_{i}\\right), i=1, \\cdots, n$ 可建立一元线性回归方程, 是由回归方程得到的拟合值, 证明: 样本相关系数 $r$ 满足如下关系  \n$$",
        "metadata": {
            "Header 2": "如 题 8.4"
        },
        "type": "Document"
    },
    {
        "page_content": "6. 测得一组弹簧形变 $x$ (单位: $\\mathrm{cm}$ ) 和相应的外力 $y$ (单位: $\\mathrm{N}$ ) 数据如下:  \n| $x$ | 1.0 | 1.2 | 1.4 | 1.6 | 1.8 | 2.0 | 2.2 | 2.4 | 2.8 | 3.0 |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| $y$ | 3.08 | 3.76 | 4.31 | 5.02 | 5.51 | 6.25 | 6.74 | 7.40 | 8.54 | 9.24 |  \n由胡克定律知 $y=k x$, 试估计 $k$, 并在 $x=2.6 \\mathrm{~cm}$ 试给出相应的外力 $y$ 的 0.95 预测区间.  \n7. 设由 $\\left(x_{i}, y_{i}\\right), i=1, \\cdots, n$ 可建立一元线性回归方程, 是由回归方程得到的拟合值, 证明: 样本相关系数 $r$ 满足如下关系  \n$$\nr^{2}=\\frac{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}}\n$$  \n上式也称为回归方程的决定系数.  \n8. 现收集了 16 组合金钢中的碳含量 $x$ 及强度 $y$ 的数据, 求得  \n$$\n\\bar{x}=0.125, \\quad y=45.7886, \\quad l_{x x}=0.3024, \\quad l_{x y}=25.5218, \\quad l_{y y}=2432.4566 .\n$$  \n(1) 建立 $y$ 关于 $x$ 的一元线性回归方程 $\\hat{y}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x$;  \n(2) 写出 $\\hat{\\beta}_{0}$ 和 $\\hat{\\beta}_{1}$ 的分布;  \n(3) 求 $\\hat{\\beta}_{0}$ 和 $\\hat{\\beta}_{1}$ 的相关系数;  \n（4）列出对回归方程做显著性检验的方差分析表 $(\\alpha=0.05)$;",
        "metadata": {
            "Header 2": "如 题 8.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$  \n上式也称为回归方程的决定系数.  \n8. 现收集了 16 组合金钢中的碳含量 $x$ 及强度 $y$ 的数据, 求得  \n$$\n\\bar{x}=0.125, \\quad y=45.7886, \\quad l_{x x}=0.3024, \\quad l_{x y}=25.5218, \\quad l_{y y}=2432.4566 .\n$$  \n(1) 建立 $y$ 关于 $x$ 的一元线性回归方程 $\\hat{y}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1} x$;  \n(2) 写出 $\\hat{\\beta}_{0}$ 和 $\\hat{\\beta}_{1}$ 的分布;  \n(3) 求 $\\hat{\\beta}_{0}$ 和 $\\hat{\\beta}_{1}$ 的相关系数;  \n（4）列出对回归方程做显著性检验的方差分析表 $(\\alpha=0.05)$;  \n(5) 给出 $\\beta_{1}$ 的 0.95 置信区间;  \n(6) 在 $x=0.15$ 时求对应的 $y$ 的 0.95 预测区间.  \n9. 设回归模型为 $\\left\\{\\begin{array}{l}y_{i}=\\beta_{0}+\\beta_{1} x_{1}+\\varepsilon_{i}, \\\\ \\varepsilon_{i} \\sim N\\left(0, \\sigma^{2}\\right),\\end{array}\\right.$ 现收集了 15 组数据, 经计算有  \n$$\n\\bar{x}=0.85 \\quad \\bar{y}=25.60, \\quad l_{x x}=19.56, \\quad l_{x y}=32.54, \\quad l_{x y}=46.74\n$$  \n后经核对, 发现有一组数据记录错误, 正确数据为 $(1.2,32.6)$, 记录为 $(1.5,32.3)$.  \n(1) 求 $\\beta_{0}, \\beta_{1}$ 的 LSE ;  \n(2) 对回归方程做显著性检验 $(\\alpha=0.05)$;  \n(3) 若 $x_{0}=1.1$, 给出对应响应变量的 0.95 预测区间.  \n10. 在生产中积累了 32 组某种铸件在不同腐蚀时间 $x$ 下腐蚀深度 $y$ 的数据, 求得回归方程为  \n$$",
        "metadata": {
            "Header 2": "如 题 8.4"
        },
        "type": "Document"
    },
    {
        "page_content": "$$\n\\bar{x}=0.85 \\quad \\bar{y}=25.60, \\quad l_{x x}=19.56, \\quad l_{x y}=32.54, \\quad l_{x y}=46.74\n$$  \n后经核对, 发现有一组数据记录错误, 正确数据为 $(1.2,32.6)$, 记录为 $(1.5,32.3)$.  \n(1) 求 $\\beta_{0}, \\beta_{1}$ 的 LSE ;  \n(2) 对回归方程做显著性检验 $(\\alpha=0.05)$;  \n(3) 若 $x_{0}=1.1$, 给出对应响应变量的 0.95 预测区间.  \n10. 在生产中积累了 32 组某种铸件在不同腐蚀时间 $x$ 下腐蚀深度 $y$ 的数据, 求得回归方程为  \n$$\n\\hat{y}=-0.4441+0.002263 x\n$$  \n, 且误差方差的无偏估计为 $\\hat{\\sigma}^{2}=0.001452$, 总偏差平方和为 0.1246 .  \n(1) 对回归方程做显著性检验 $(\\alpha=0.05)$, 列出方差分析表;  \n(2) 求样本相关系数;  \n(3) 若腐蚀时间 $x=870$, 试给出 $y$ 的 0.95 近似预测区间.  \n11. 我们知道营业税税收总额 $y$ 与社会商品零售总额 $x$ 有关, 为能从社会商品零售总额去预测税收总额, 需要了解两者之间的关系. 现收集了如下九组数据:(单位:亿元)  \n| 序号 | 社会商品零售额 | 营业税收总额 |\n| :---: | :---: | :---: |\n| 1 | 142.08 | 3.93 |\n| 2 | 177.30 | 5.96 |\n| 3 | 204.68 | 7.85 |\n| 4 | 242.68 | 9.82 |\n| 5 | 316.24 | 12.50 |\n| 6 | 341.99 | 15.55 |\n| 7 | 332.69 | 15.79 |\n| 8 | 389.29 | 16.39 |\n| 9 | 453.40 | 18.45 |  \n(1) 画散点图;  \n（2）建立一元线性回归方程, 并做显著性检验 (取 $\\alpha=0.05$ ), 列出方差分析表;",
        "metadata": {
            "Header 2": "如 题 8.4"
        },
        "type": "Document"
    },
    {
        "page_content": "(2) 求样本相关系数;  \n(3) 若腐蚀时间 $x=870$, 试给出 $y$ 的 0.95 近似预测区间.  \n11. 我们知道营业税税收总额 $y$ 与社会商品零售总额 $x$ 有关, 为能从社会商品零售总额去预测税收总额, 需要了解两者之间的关系. 现收集了如下九组数据:(单位:亿元)  \n| 序号 | 社会商品零售额 | 营业税收总额 |\n| :---: | :---: | :---: |\n| 1 | 142.08 | 3.93 |\n| 2 | 177.30 | 5.96 |\n| 3 | 204.68 | 7.85 |\n| 4 | 242.68 | 9.82 |\n| 5 | 316.24 | 12.50 |\n| 6 | 341.99 | 15.55 |\n| 7 | 332.69 | 15.79 |\n| 8 | 389.29 | 16.39 |\n| 9 | 453.40 | 18.45 |  \n(1) 画散点图;  \n（2）建立一元线性回归方程, 并做显著性检验 (取 $\\alpha=0.05$ ), 列出方差分析表;  \n(3) 若已知某年社会商品零售额为 300 亿元, 试给出营业税税收总额的概率为 0.95 的预测区间；  \n(4) 若已知回归直线过原点, 试求回归方程, 并在显著性水平 0.05 下做显著性检验.",
        "metadata": {
            "Header 2": "如 题 8.4"
        },
        "type": "Document"
    },
    {
        "page_content": "有时, 回归函数并非是自变量的线性函数, 但通过变换可以将之化为线性函数, 从而利用一元线性回归对其分析, 这样的问题是非线性回归问题. 下面以一个例子说明上述非线性回归的分析步骤.  \n例 8.5.1: 炼钢厂出钢水时用的钢包, 在使用过程中由于钢水及炉渣对耐火材料的侵蚀, 其容积不断增大. 现在钢包的容积用盛满钢水时的质量 $y \\mathrm{~kg}$ 表示, 相应的试验次数用 $x$ 表示. 数据见表 8.5.1,要找出 $y$ 与 $x$ 的定量关系表达式.  \n下面我们分三步进行.\n表 8.5.1: 钢包的置量 $y$ 与试验次数 $x$ 数据  \n| 序号 | $x$ | $y$ | 序号 | $x$ | $y$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 2 | 106.42 | 8 | 11 | 110.59 |\n| 2 | 3 | 108.20 | 9 | 14 | 110.60 |\n| 3 | 4 | 109.58 | 10 | 15 | 110.90 |\n| 4 | 5 | 109.50 | 11 | 16 | 110.76 |\n| 5 | 7 | 110.00 | 12 | 18 | 111.00 |\n| 6 | 8 | 109.93 | 13 | 19 | 111.20 |\n| 7 | 10 | 110.49 |  |  |  |",
        "metadata": {
            "Header 2": "8.5 一元非线性回归"
        },
        "type": "Document"
    },
    {
        "page_content": "为对数据进行分析, 首先描出数据的散点图, 判断两个变量之间可能的函数关系, 图 8.5 .1 是本例的散点图.  \n!  \n图 8.5.1: 钢包质量与试验次数散点图  \n观测这 13 个点构成的散点图, 我们可以看到它们并不接近一条直线, 用曲线拟合这些点应该是更恰当的. 这里就涉及如何选择曲线函数形式的问题, 首先, 如果可由专业知识确定回归函数形式, 则应尽可能利用专业知识. 当若不能由专业知识加以确定函数形式, 则可将散点图与一些常见的函数关系的图形进行比较, 选择几个可能的函数形式, 然后使用统计方法在这些函数形式之间进行比较, 最后确定合适的曲线回归方程. 为此, 必须了解常见的曲线函数的图形, 见图 8.5.2.  \n本例中, 散点图呈现一个明显的向上且上凸的趋势, 可能选择的函数关系有很多, 比如, 参照图 8.5.2, 我们可以给出如下四个曲线函数:  \n$$\n\\begin{array}{ll}\n1 & 1 / y=a+b / x \\\\\n2 & y=a+b \\ln x \\\\\n3 & y=a+b \\sqrt{x} \\\\\n4 & y-100=a \\cdot \\mathrm{e}^{-x / b}(b>0) \\tag{8.5.4}\n\\end{array}\n$$  \n在初步选出可能的函数关系 (即方程) 后, 我们必须解决两个问题:  \n- 如何估计所选方程中的参数? 这在 8.5.2 中讨论;\n- 如何评价所选不同方程的优劣? 这在 8.5.3 中介绍.  \n!  \n图 8.5.2: 部分常见的曲线函数的图形",
        "metadata": {
            "Header 2": "8.5 一元非线性回归",
            "Header 3": "8.5.1 确定可能的函数形式"
        },
        "type": "Document"
    },
    {
        "page_content": "对形如 (8.5.1) 式至 (8.5.4) 式的非线性函数, 参数估计最常用的方法是 “线性化” 方法, 即通过某种变换,将方程化为一元线性方程的形式.  \n以 (8.5.1) 式为例, 为了能采用一元线性回归分析方法, 我们作如下变换  \n$$\nu=1 / x, \\quad v=1 / y\n$$  \n则 $(8.5 .1)$ 的曲线函数就化为如下的直线  \n$$\nv=a+b u\n$$  \n这是理论回归函数. 对数据而言, 回归方程为  \n$$\nv_{i}=a+b u_{i}+\\varepsilon_{i},\n$$  \n于是可用一元线性回归的方法估计出 $a, b$. 图 8.5.3 给出变换后的数据的散点图.  \n从图 8.5.3 上看出可以认为所有的点近似在一条直线上下被动, 因此, 建立一元线性回归方程是可行的. 整个计算过程及估计列于表 8.5.2 和表 8.5.3 中.  \n!  \n图 8.5.3: 变换后数据的散点图  \n表 8.5.2: 钢包数据的变换值  \n| $x$ | $y$ | $u=1 / x$ | $v=1 / y$ | $v^{2}$ | $u v$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 2 | 106.42 | 0.500000 | 0.009397 | 0.250000 | 0.004698 |\n| 3 | 108.20 | 0.333333 | 0.009242 | 0.111111 | 0.003081 |\n| 4 | 109.58 | 0.250000 | 0.009126 | 0.062500 | 0.002281 |\n| 5 | 109.50 | 0.200000 | 0.009132 | 0.040000 | 0.001826 |\n| 7 | 110.00 | 0.142857 | 0.009091 | 0.020408 | 0.001299 |\n| 10 | 109.93 | 0.125000 | 0.009097 | 0.015625 | 0.001137 |\n| 11 | 110.49 | 0.100000 | 0.009051 | 0.010000 | 0.000905 |",
        "metadata": {
            "Header 2": "8.5 一元非线性回归",
            "Header 3": "8.5.2 参数估计"
        },
        "type": "Document"
    },
    {
        "page_content": "| :---: | :---: | :---: | :---: | :---: | :---: |\n| 2 | 106.42 | 0.500000 | 0.009397 | 0.250000 | 0.004698 |\n| 3 | 108.20 | 0.333333 | 0.009242 | 0.111111 | 0.003081 |\n| 4 | 109.58 | 0.250000 | 0.009126 | 0.062500 | 0.002281 |\n| 5 | 109.50 | 0.200000 | 0.009132 | 0.040000 | 0.001826 |\n| 7 | 110.00 | 0.142857 | 0.009091 | 0.020408 | 0.001299 |\n| 10 | 109.93 | 0.125000 | 0.009097 | 0.015625 | 0.001137 |\n| 11 | 110.49 | 0.100000 | 0.009051 | 0.010000 | 0.000905 |\n| 14 | 110.59 | 0.090909 | 0.009042 | 0.008264 | 0.000822 |\n| 15 | 110.60 | 0.071429 | 0.009042 | 0.005102 | 0.000646 |\n| 16 | 110.90 | 0.066667 | 0.009017 | 0.004444 | 0.000601 |\n| 18 | 110.76 | 0.062500 | 0.009029 | 0.003906 | 0.000564 |\n| 19 | 111.00 | 0.055556 | 0.009009 | 0.003086 | 0.000501 |\n|  | 合计 | 0.052632 | 0.008993 | 0.002770 | 0.000473 |\n|  | 均值 | 2.050882 | 0.118267 | 0.537218 | 0.018835 |  \n表 8.5.3: 参数估计计算表  \n| $\\sum u_{i}=2.05088194$ | $n=13$ | $\\sum v_{i}=0.11826672$ |\n| :---: | :---: | :---: |",
        "metadata": {
            "Header 2": "8.5 一元非线性回归",
            "Header 3": "8.5.2 参数估计"
        },
        "type": "Document"
    },
    {
        "page_content": "| 15 | 110.60 | 0.071429 | 0.009042 | 0.005102 | 0.000646 |\n| 16 | 110.90 | 0.066667 | 0.009017 | 0.004444 | 0.000601 |\n| 18 | 110.76 | 0.062500 | 0.009029 | 0.003906 | 0.000564 |\n| 19 | 111.00 | 0.055556 | 0.009009 | 0.003086 | 0.000501 |\n|  | 合计 | 0.052632 | 0.008993 | 0.002770 | 0.000473 |\n|  | 均值 | 2.050882 | 0.118267 | 0.537218 | 0.018835 |  \n表 8.5.3: 参数估计计算表  \n| $\\sum u_{i}=2.05088194$ | $n=13$ | $\\sum v_{i}=0.11826672$ |\n| :---: | :---: | :---: |\n| $\\bar{u}=0.15776015$ |  | $\\bar{v}=0.00909744$ |\n| $\\sum u_{i}^{2}=0.53721798$ | $n u_{i} v_{i}=0.01883495$ |  |\n| $n \\bar{u}=0.53721798$ | $n \\overline{u v}=0.01865778$ |  |\n| $l_{\\nu v}=0.21367054$ | $l_{u v}=0.00017717$ |  |\n|  | $\\hat{b}=l_{u v} / l_{u u}=0.00082917$ | $\\hat{a} \\bar{v}-\\bar{u} \\hat{b}=0.00896663$ |\n|  | $\\therefore \\hat{y}=\\frac{x}{0.00082917+0.00896663 . x}$ |  |  \n用类似的方法可以得出其他三个曲线回归方程, 它们分别是:  \n$$\n\\begin{aligned}\n& \\hat{y}=106.3147+3.9466 \\ln x \\\\\n& \\hat{y}=106.3013+1.1947 \\sqrt{x} \\\\",
        "metadata": {
            "Header 2": "8.5 一元非线性回归",
            "Header 3": "8.5.2 参数估计"
        },
        "type": "Document"
    },
    {
        "page_content": "| $\\sum u_{i}^{2}=0.53721798$ | $n u_{i} v_{i}=0.01883495$ |  |\n| $n \\bar{u}=0.53721798$ | $n \\overline{u v}=0.01865778$ |  |\n| $l_{\\nu v}=0.21367054$ | $l_{u v}=0.00017717$ |  |\n|  | $\\hat{b}=l_{u v} / l_{u u}=0.00082917$ | $\\hat{a} \\bar{v}-\\bar{u} \\hat{b}=0.00896663$ |\n|  | $\\therefore \\hat{y}=\\frac{x}{0.00082917+0.00896663 . x}$ |  |  \n用类似的方法可以得出其他三个曲线回归方程, 它们分别是:  \n$$\n\\begin{aligned}\n& \\hat{y}=106.3147+3.9466 \\ln x \\\\\n& \\hat{y}=106.3013+1.1947 \\sqrt{x} \\\\\n& \\hat{y}=100+11.7506 \\mathrm{e}^{-1.1256 / x}\n\\end{aligned}\n$$",
        "metadata": {
            "Header 2": "8.5 一元非线性回归",
            "Header 3": "8.5.2 参数估计"
        },
        "type": "Document"
    },
    {
        "page_content": "我们上面得到了四个曲线回归方程, 在这四个方程中, 哪一个更好一点呢? 通常可采用如下两个指标进行选择.  \n1. 决定系数 $R^{2}:$ 类似于一元线性回归方程中相关系数, 决定系数定义为:  \n$$\n\\begin{equation*}\nR^{2}=1-\\frac{\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{\\sum\\left(y_{i}-\\bar{y}\\right)^{2}} \\tag{8.5.5}\n\\end{equation*}\n$$  \n$R^{2}$ 越大, 说明残差越小, 回归曲线拟合越好, $R^{2}$ 从总体上给出一个拟合好坏程度的度量.  \n2. 剩余标准差 $s$ : 类似于一元线性回归中标准差的估计公式, 此剩余标准差可用残差平方和来获得, 即  \n$$\n\\begin{equation*}\ns=\\sqrt{\\frac{\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{n-2}} \\tag{8.5.6}\n\\end{equation*}\n$$  \n$s$ 为诸观测点 $y_{i}$ 与由曲线给出的拟合值 $\\hat{y}_{i}$ 间的平均偏离程度的度量, $s$ 越小, 方程越好.  \n在观测数据给定后, 不同的曲线选择不会影响 $\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}_{i}\\right)^{2}$ 的取值, 但会影响到残差平方和 $\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$ 的取值. 因此, 对选择的曲线而言, 决定系数和剩余标准差都取决于残差平方和 $\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$, 从而, 两种选择准则是一致的, 只是从两个不同侧面作出评价.  \n表 8.5.4 给出第一个曲线回归方程的残差平方和的计算过程, 由于 $n=13, \\sum_{i=1}^{13}\\left(y_{i}-\\bar{y}\\right)^{2}=$ 0.5743 , 故其决定系数及剩余标准差分别为:  \n$$",
        "metadata": {
            "Header 2": "8.5 一元非线性回归",
            "Header 3": "8.5.3 曲线回归方程的比较"
        },
        "type": "Document"
    },
    {
        "page_content": "\\end{equation*}\n$$  \n$s$ 为诸观测点 $y_{i}$ 与由曲线给出的拟合值 $\\hat{y}_{i}$ 间的平均偏离程度的度量, $s$ 越小, 方程越好.  \n在观测数据给定后, 不同的曲线选择不会影响 $\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}_{i}\\right)^{2}$ 的取值, 但会影响到残差平方和 $\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$ 的取值. 因此, 对选择的曲线而言, 决定系数和剩余标准差都取决于残差平方和 $\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$, 从而, 两种选择准则是一致的, 只是从两个不同侧面作出评价.  \n表 8.5.4 给出第一个曲线回归方程的残差平方和的计算过程, 由于 $n=13, \\sum_{i=1}^{13}\\left(y_{i}-\\bar{y}\\right)^{2}=$ 0.5743 , 故其决定系数及剩余标准差分别为:  \n$$\nR^{2}=1-\\frac{0.5743}{21.2105}=0.9729, \\quad s=\\sqrt{\\frac{0.5743}{13-2}}=0.2285\n$$  \n其他三个方程的决定系数及剩余标准差可同样计算, 我们将它们列在表 8.5.5 中.  \n从表 8.5.5 中可以看出, 第一个曲线方程的决定系数最大, 剩余标准差最小, 在这四个曲线回归方程中, 不论用哪个标准, 都是第一个方程拟合得最好. 因此, 近似得比较好的定量关系式就是  \n$$\n\\hat{y}=\\frac{x}{0.00082917+0.00896663 x}\n$$",
        "metadata": {
            "Header 2": "8.5 一元非线性回归",
            "Header 3": "8.5.3 曲线回归方程的比较"
        },
        "type": "Document"
    },
    {
        "page_content": "1. 设曲线函数形式为 $y=a+b \\ln x$, 试给出一个变换将之化为一元线性回归的形式.\n表 8.5.4: 第一个方程的残整平方和计算表  \n| $y_{i}$ | $\\hat{y}_{i}$ | $\\hat{e}_{i}=y_{i}-\\hat{y}_{i}$ | $\\hat{e}_{i}^{2}$ | $y_{i}$ | $\\hat{y}_{i}$ | $\\hat{e}_{i}$ | $\\hat{e}_{i}^{2}$ |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| 106.42 | 106.596 | -0.179 | 0.030976 | 110.59 | 110.595 | -0.00489 | 0.000024 |\n| 108.2 | 108.19 | 0.010252 | 0.000105 | 110.6 | 110.793 | -0.193 | 0.037249 |\n| 109.52 | 109.005 | 0.575373 | 0.331054 | 110.9 | 110.841 | 0.059 | 0.003481 |\n| 109.5 | 109.499 | 0.00526 | 0.000000 | 110.76 | 110.884 | -0.124 | 0.015376 |\n| 110 | 110.071 | -0.07054 | 0.004976 | 111 | 110.955 | 0.045 | 0.002025 |\n| 109.93 | 110.25 | -0.32023 | 0.102544 | 111.2 | 110.984 | 0.216 | 0.046656 |\n| 110.49 | 110.503 | -0.01277 | 0.000163 |  | 和 |  | 0.5743 |  \n表 8.5.5: 四种曲线回归的决定系数及剩余标准差  \n| 模型编号 | 1 | 2 | 3 | 4 |\n| :---: | :---: | :---: | :---: | :---: |\n| $R^{2}$ | 0.9729 | 0.8773 | 0.7551 | 0.9623 |",
        "metadata": {
            "Header 2": "如题 8.5"
        },
        "type": "Document"
    },
    {
        "page_content": "| 109.5 | 109.499 | 0.00526 | 0.000000 | 110.76 | 110.884 | -0.124 | 0.015376 |\n| 110 | 110.071 | -0.07054 | 0.004976 | 111 | 110.955 | 0.045 | 0.002025 |\n| 109.93 | 110.25 | -0.32023 | 0.102544 | 111.2 | 110.984 | 0.216 | 0.046656 |\n| 110.49 | 110.503 | -0.01277 | 0.000163 |  | 和 |  | 0.5743 |  \n表 8.5.5: 四种曲线回归的决定系数及剩余标准差  \n| 模型编号 | 1 | 2 | 3 | 4 |\n| :---: | :---: | :---: | :---: | :---: |\n| $R^{2}$ | 0.9729 | 0.8773 | 0.7551 | 0.9623 |\n| $s$ | 0.2285 | 0.4864 | 0.6437 | 0.2696 |  \n2. 设曲线函数形式为 $y=a+b \\sqrt{x}$, 试给出一个变换将之化为一元线性回归的形式.\n3. 设曲线函数形式为 $y-100=a \\mathrm{e}^{-x / b}(b>0)$, 试给出一个变换将之化为一元线性回归的形式.\n4. 设曲线函数形式为 $y=a+\\mathrm{e}^{b z}$, 问能否找到一个变换将之化为一元线性回归的形式, 若能, 试给出;若不能, 说明理由.\n5. 设曲线函数形式为 $y=\\frac{1}{a+b \\mathrm{e}^{-x}}$, 问能否找到一个变换将之化为一元线性回归的形式, 若能,试给出;若不能, 说明理由.\n6. 设曲线函数形式为 $y=a \\mathrm{e}^{b / x}$, 问能否找到一个变换将之化为一元线性回归的形式, 若能, 试给出;若不能, 说明理由.\n7. 为了检验 $X$ 射线的杀菌作用, 用 $200 \\mathrm{kV}$ 的 $X$ 射线照射杀菌, 每次照射 $6 \\mathrm{~min}$, 照射次数为 $x$,照射后所剩细菌数为 $y$,下表是一组试验结果",
        "metadata": {
            "Header 2": "如题 8.5"
        },
        "type": "Document"
    },
    {
        "page_content": "2. 设曲线函数形式为 $y=a+b \\sqrt{x}$, 试给出一个变换将之化为一元线性回归的形式.\n3. 设曲线函数形式为 $y-100=a \\mathrm{e}^{-x / b}(b>0)$, 试给出一个变换将之化为一元线性回归的形式.\n4. 设曲线函数形式为 $y=a+\\mathrm{e}^{b z}$, 问能否找到一个变换将之化为一元线性回归的形式, 若能, 试给出;若不能, 说明理由.\n5. 设曲线函数形式为 $y=\\frac{1}{a+b \\mathrm{e}^{-x}}$, 问能否找到一个变换将之化为一元线性回归的形式, 若能,试给出;若不能, 说明理由.\n6. 设曲线函数形式为 $y=a \\mathrm{e}^{b / x}$, 问能否找到一个变换将之化为一元线性回归的形式, 若能, 试给出;若不能, 说明理由.\n7. 为了检验 $X$ 射线的杀菌作用, 用 $200 \\mathrm{kV}$ 的 $X$ 射线照射杀菌, 每次照射 $6 \\mathrm{~min}$, 照射次数为 $x$,照射后所剩细菌数为 $y$,下表是一组试验结果  \n| $x$ | $y$ | $x$ | $y$ | $x$ | $y$ |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 1 | 783 | 8 | 154 | 15 | 28 |\n| 2 | 621 | 9 | 129 | 16 | 20 |\n| 3 | 433 | 10 | 103 | 17 | 16 |\n| 4 | 431 | 11 | 72 | 18 | 12 |\n| 5 | 287 | 12 | 50 | 19 | 9 |\n| 6 | 251 | 13 | 43 | 20 | 7 |\n| 7 | 175 | 14 | 31 |  |  |  \n根据经验知道 $y$ 关于 $x$ 的曲线回归方程形如  \n$$\ny=a \\mathrm{e}^{b x},\n$$  \n试给出具体的回归方程, 并求其对应的决定系数 $R^{2}$ 和剩余标准差 $s$.",
        "metadata": {
            "Header 2": "如题 8.5"
        },
        "type": "Document"
    }
]